# Description of parameters: 
# https://github.com/twitter-research/cwn/blob/main/exp/parser.py

# Model Configuration
model: higher-gat
nonlinearity: relu
num_layers: 4
readout: sum
readout_dims: (0, 1, 2)
max_ring_size: 18
task_type: regression
minimize: true
hidden_channels: 64
heads: 1

# Dataset Configuration
exp_name: cwn-zinc
dataset: ZINC
max_dim: 2
final_readout: sum
init_method: sum
fold: None
folds: None
tune: false
flow_points: 400
flow_classes: 3
train_orient: "default"
test_orient: "default"
fully_orient_invar: false
simple_features: false
dim: 0
use_down_adj: true
include_down_adj: true
use_coboundaries: true
use_edge_features: true


# Optimizer Configuration
lr: 0.001
graph_norm: bn
lr_scheduler: 'ReduceLROnPlateau' 
early_stop: true
lr_scheduler_patience: 20
lr_scheduler_decay_steps: 50
lr_scheduler_decay_rate: 0.5
lr_scheduler_min: 0.00001

# Training Configuration
epochs: 1000
batch_size: 128
in_drop_rate: 0.0
drop_rate: 0.0
drop_position: lin2
emb_dim: 128
preproc_jobs: 32
jump_mode: None
num_workers: 16
iso_eps: 0.01
sync_batchnorm: false
precision: "32-true"
accumulate_grad_batches: 1

# Evaluation Configuration
train_eval_period: 20
eval_metric: mae

# WandB Configuration
project_name: "fine"
wandb_api_key_path: "wandb_api_key.txt"
wandb_offline: false
log_every_n_steps: 5

# GPU Configuration
device: 8
trainer_accelerator: "gpu"
devices_count: 1
seed: 43
start_seed: 0
stop_seed: 9

# Miscellaneous Configuration
use_progress_bar: true
checkpoint_dir: "checkpoints/"
checkpoint_name_pattern: "ckpt"
nodes_count: 1
pin_memory: true
result_folder: os.path.join(ROOT_DIR, 'exp', 'results')
untrained: false
paraid: 0

