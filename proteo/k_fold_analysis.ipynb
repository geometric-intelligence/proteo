{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import os\n",
    "import pandas as pd\n",
    "import ast\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_mean_std_from_json(row):\n",
    "    \"\"\"\n",
    "    Given a row from the CSV, build the JSON filename, \n",
    "    load it, and return (mu, sigma).\n",
    "    \n",
    "    EXPECTED structure in the JSON file:\n",
    "      {\n",
    "        \"mean\": <float>,\n",
    "        \"std\": <float>\n",
    "      }\n",
    "    \n",
    "    Adjust the filename construction as needed for your environment.\n",
    "    \"\"\"\n",
    "    # 1) Extract needed fields from the row\n",
    "    #    (Example fields; adapt if your CSV columns differ.)\n",
    "    y_val = row[\"config/train_loop_config/y_val\"]\n",
    "    adj   = row[\"config/train_loop_config/adj_thresh\"]\n",
    "    num_nodes = row[\"config/train_loop_config/num_nodes\"]\n",
    "    \n",
    "    # Potentially parse mutation/sex if they're comma-separated\n",
    "    mutation_raw = row[\"config/train_loop_config/mutation\"]\n",
    "    mutation = ast.literal_eval(mutation_raw)\n",
    "    mutation_str = f\"mutation_{','.join(mutation)}\"\n",
    "    \n",
    "    sex_raw = row[\"config/train_loop_config/sex\"]\n",
    "    sex = ast.literal_eval(sex_raw)\n",
    "    sex_str = f'sex_{\",\".join(sex)}'\n",
    "    \n",
    "    modality = row[\"config/train_loop_config/modality\"]\n",
    "    \n",
    "    y_val_str = f\"y_val_{y_val}\"\n",
    "    adj_str   = f\"adj_thresh_{adj}\"\n",
    "    num_nodes_str = f\"num_nodes_{num_nodes}\"\n",
    "    \n",
    "    experiment_id = (\n",
    "        f\"ftd_{y_val_str}_{adj_str}_{num_nodes_str}_{mutation_str}_{modality}_{sex_str}\"\n",
    "    )\n",
    "    \n",
    "    split = row.get(\"config/train_loop_config/split\", \"train\")\n",
    "    random_state = row[\"config/train_loop_config/seed\"]\n",
    "    num_folds = 5\n",
    "    fold = row[\"config/train_loop_config/fold\"]\n",
    "    \n",
    "    # 2) Construct the JSON filename (example):\n",
    "    filename = (\n",
    "        f\"{experiment_id}_{split}_random_state_{random_state}_\"\n",
    "        f\"{num_folds}fold_{fold}.json\"\n",
    "    )\n",
    "    \n",
    "    # Optionally prepend a directory path if needed\n",
    "    # directory = \"mean_std_files\"\n",
    "    # full_path = os.path.join(directory, filename)\n",
    "    # Or just use filename if it's already a full path\n",
    "    full_path = os.path.join(\"/scratch/lcornelis/data/data_louisa/processed\", filename)\n",
    "    \n",
    "    # 3) Load JSON and extract mean, std\n",
    "    with open(full_path, \"r\") as f:\n",
    "        lines = f.read().splitlines()\n",
    "  \n",
    "    # parse them manually\n",
    "    mean_str = lines[0].split(\":\")[1].strip()\n",
    "    std_str  = lines[1].split(\":\")[1].strip()\n",
    "\n",
    "    mean_val = float(mean_str)\n",
    "    std_val  = float(std_str)\n",
    "\n",
    "    return mean_val, std_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   config/train_loop_config/seed  config/train_loop_config/batch_size  \\\n",
      "0                             42                                    8   \n",
      "1                             42                                    8   \n",
      "2                             42                                    8   \n",
      "3                             42                                    8   \n",
      "4                             42                                    8   \n",
      "\n",
      "  config/train_loop_config/lr_scheduler  config/train_loop_config/dropout  \\\n",
      "0                     CosineAnnealingLR                               0.1   \n",
      "1                     CosineAnnealingLR                               0.1   \n",
      "2                     CosineAnnealingLR                               0.1   \n",
      "3                     CosineAnnealingLR                               0.1   \n",
      "4                     CosineAnnealingLR                               0.1   \n",
      "\n",
      "  config/train_loop_config/act  config/train_loop_config/num_nodes  \\\n",
      "0                          elu                                7258   \n",
      "1                          elu                                7258   \n",
      "2                          elu                                7258   \n",
      "3                          elu                                7258   \n",
      "4                          elu                                7258   \n",
      "\n",
      "   config/train_loop_config/adj_thresh  config/train_loop_config/mutation  \\\n",
      "0                                  0.5  ['GRN', 'MAPT', 'C9orf72', 'CTL']   \n",
      "1                                  0.5  ['GRN', 'MAPT', 'C9orf72', 'CTL']   \n",
      "2                                  0.5  ['GRN', 'MAPT', 'C9orf72', 'CTL']   \n",
      "3                                  0.5  ['GRN', 'MAPT', 'C9orf72', 'CTL']   \n",
      "4                                  0.5  ['GRN', 'MAPT', 'C9orf72', 'CTL']   \n",
      "\n",
      "  config/train_loop_config/sex config/train_loop_config/modality  ...  \\\n",
      "0                   ['M', 'F']                               csf  ...   \n",
      "1                   ['M', 'F']                               csf  ...   \n",
      "2                   ['M', 'F']                               csf  ...   \n",
      "3                   ['M', 'F']                               csf  ...   \n",
      "4                   ['M', 'F']                               csf  ...   \n",
      "\n",
      "  config/train_loop_config/channel_list config/train_loop_config/norm  \\\n",
      "0                                   NaN                           NaN   \n",
      "1                                   NaN                           NaN   \n",
      "2                                   NaN                           NaN   \n",
      "3                                   NaN                           NaN   \n",
      "4                                   NaN                           NaN   \n",
      "\n",
      "   config/train_loop_config/plain_last val_loss_mean val_loss_std  \\\n",
      "0                                  NaN      1.081737     0.893468   \n",
      "1                                  NaN      1.084921     0.917395   \n",
      "2                                  NaN      1.170133     1.040005   \n",
      "3                                  NaN      1.086715     0.891217   \n",
      "4                                  NaN      1.080164     0.911391   \n",
      "\n",
      "  rmse_original_mean  rmse_original_std train_loss_mean train_loss_std  \\\n",
      "0          19.034074           7.132933        1.009296       0.051030   \n",
      "1          18.996901           7.384663        1.215357            NaN   \n",
      "2          19.571359           8.230301        1.029691       0.042224   \n",
      "3          19.096842           7.077793        0.997538       0.033120   \n",
      "4          18.961378           7.345857        0.980931       0.012844   \n",
      "\n",
      "   trial_id_concatenate_trial_ids  \n",
      "0         fa1a7_02980,fa1a7_04132  \n",
      "1         fa1a7_02981,fa1a7_04133  \n",
      "2         fa1a7_02978,fa1a7_04130  \n",
      "3         fa1a7_02979,fa1a7_04131  \n",
      "4         fa1a7_02982,fa1a7_04134  \n",
      "\n",
      "[5 rows x 29 columns]\n"
     ]
    }
   ],
   "source": [
    "def compute_rmse_original(row):\n",
    "    \"\"\"\n",
    "    Convert the normalized val_loss (z-space MSE) back to original-scale MSE\n",
    "    using the fold-specific sigma from JSON.\n",
    "    \"\"\"\n",
    "    val_loss_z = row[\"val_loss\"]  # MSE in normalized space\n",
    "    if pd.isna(val_loss_z):\n",
    "        return np.nan\n",
    "    mu, sigma = load_mean_std_from_json(row)\n",
    "    val_loss_orig = val_loss_z * (sigma ** 2)  # MSE_x = MSE_z * sigma^2\n",
    "    return np.sqrt(val_loss_orig)\n",
    "\n",
    "def concatenate_trial_ids(trial_ids):\n",
    "    \"\"\"\n",
    "    Helper function to join trial_id values for grouped rows.\n",
    "    \"\"\"\n",
    "    return \",\".join(trial_ids.astype(str))\n",
    "\n",
    "def main():\n",
    "    # 1) Read the CSV\n",
    "    df = pd.read_csv(\"ray_results_search_hyperparameters.csv\")\n",
    "    \n",
    "    # 2) Create a new column for val_loss in original scale\n",
    "    df[\"rmse_original\"] = df.apply(compute_rmse_original, axis=1)\n",
    "    \n",
    "    # 3) Identify columns to group by (all 'config/train_loop_config/' except fold)\n",
    "    fold_col = \"config/train_loop_config/fold\"\n",
    "    all_config_cols = [\n",
    "        c for c in df.columns\n",
    "        if c.startswith(\"config/train_loop_config/\") and c != fold_col\n",
    "    ]\n",
    "    \n",
    "    # 4) Group by everything except the fold column\n",
    "    grouped = df.groupby(all_config_cols, dropna=False)\n",
    "    \n",
    "    # 5) Compute mean & std across folds for relevant metrics\n",
    "    #    We have \"val_loss\" (normalized), \"val_loss_original\" (unscaled), \"train_loss\" etc.\n",
    "    metrics_of_interest = [\"val_loss\", \"rmse_original\", \"train_loss\"]\n",
    "    \n",
    "    agg_df = grouped.agg({\n",
    "        **{metric: [\"mean\", \"std\"] for metric in metrics_of_interest},\n",
    "        \"trial_id\": concatenate_trial_ids\n",
    "    })\n",
    "    \n",
    "    # 6) Flatten the multi-level columns\n",
    "    agg_df.reset_index(inplace=True)\n",
    "    agg_df.columns = [\"_\".join(col).rstrip(\"_\") for col in agg_df.columns.to_flat_index()]\n",
    "\n",
    "    # 7) Inspect & save results\n",
    "    print(agg_df.head())\n",
    "    agg_df.to_csv(\"kfold_mean_std_results_with_original.csv\", index=False)\n",
    "\n",
    "main()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proteo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
