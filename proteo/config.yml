# Description of parameters: 
# https://github.com/twitter-research/cwn/blob/main/exp/parser.py


adj_thresh: 0.08
task: 'grad'
task_type: regression # Placeholder
minimize: true #Placeholder

# Model Configuration
model: gat-v4

gat-v4:
  lambda_cox: 1.0
  lambda_reg: 0.0003
  lambda_nll: 1.0
  input_dim: 1
  lin_input_dim: 960
  which_layer: 'all'
  cnv_dim: 0
  omic_dim: 32
  act_type: 'none'
  lr: 0.002
  final_lr: 0.1
  weight_decay: 0.0005
  fc_dropout: 0.2  # was dropout
  alpha: 0.2
  patience: 0.005
  # Optimizer Configuration
  lr_scheduler: LambdaLR
  lr_scheduler_params: None
  num_nodes: 320
  layer_norm: true
  

higher-gat:
  nonlinearity: relu
  num_layers: 4
  readout: sum
  readout_dims: (0, 1, 2)
  max_ring_size: 18
  minimize: true
  hidden_channels: 64
  heads: 1
  # Optimizer Configuration
  lr: 0.001
  graph_norm: bn
  lr_scheduler: ReduceLROnPlateau
  lr_scheduler_params:
    mode: #TO DO
    lr_scheduler_patience: 20
    lr_scheduler_decay_steps: 50
    lr_scheduler_decay_rate: 0.5
    lr_scheduler_min: 0.00001
    verbose: true

gat:
  hidden_channels: 64
  heads: 1
  minimize: true #Placeholder
  # Optimizer Configuration
  lr: 0.001
  lr_scheduler: ReduceLROnPlateau
  lr_scheduler_params:
    mode: #TO DO
    lr_scheduler_patience: 20
    lr_scheduler_decay_steps: 50
    lr_scheduler_decay_rate: 0.5
    lr_scheduler_min: 0.00001
    verbose: true

early_stop: true




# Dataset Configuration
exp_name: cwn-zinc
dataset: ZINC
max_dim: 2
final_readout: sum
init_method: sum
fold: None
folds: None
tune: false
flow_points: 400
flow_classes: 3
train_orient: "default"
test_orient: "default"
fully_orient_invar: false
simple_features: false
dim: 0
use_down_adj: true
include_down_adj: true
use_coboundaries: true
use_edge_features: true



# Training Configuration
epochs: 1000
batch_size: 128
in_drop_rate: 0.0
drop_rate: 0.0
drop_position: lin2
emb_dim: 128
preproc_jobs: 32
jump_mode: None
num_workers: 16
iso_eps: 0.01
sync_batchnorm: false
precision: "32-true"
accumulate_grad_batches: 1

# Evaluation Configuration
train_eval_period: 20
eval_metric: mae

# WandB Configuration
project_name: "proteo"
wandb_api_key_path: "wandb_api_key.txt"
wandb_offline: false
log_every_n_steps: 5

# GPU Configuration
device: 8
trainer_accelerator: "gpu"
devices_count: 1
seed: 43
start_seed: 0
stop_seed: 9

# Miscellaneous Configuration
use_progress_bar: true
checkpoint_dir: "checkpoints/"
checkpoint_name_pattern: "ckpt"
nodes_count: 1
pin_memory: true
result_folder: os.path.join(ROOT_DIR, 'exp', 'results')
untrained: false
paraid: 0

