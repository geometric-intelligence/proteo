dataset_name: "ftd"
root_dir: "/home/nmiolane/code/proteo"

adj_thresh: 0.08
wgcna_power: 6 #replaced this with softThreshold
wgcna_minModuleSize: 10
wgcna_mergeCutHeight: 0.25
task: 'survival'  
task_type: regression # Placeholder

# Model Configuration
model: gat

gat-v4:
  heads: [4, 3, 4]
  hidden_channels: [8, 16, 12]
  fc_dim: [64, 48, 32, 32]
  which_layer: ['layer1', 'layer2', 'layer3']
  lr: 0.1 
  final_lr: 0.0001
  weight_decay: 0.0005
  fc_dropout: 0.05
  l1_lambda: 0.005
  optimizer: Adam
  lr_scheduler: LambdaLR
  num_nodes: 7289 #TO DO: This should not be hardcoded

gat:
  v2: true
  # For one off training
  heads: 1
  hidden_channels: 20
  num_layers: 4
  optimizer: Adam
  lr: 0.001
  l1_lambda: 0.0005
  weight_decay: 0.0005
  lr_scheduler: LambdaLR

# Training Configuration
batch_size: 12 #for one off training
epochs: 7
num_workers: 16
sync_batchnorm: false
precision: "32-true"
accumulate_grad_batches: 1

# WandB Configuration
project: "proteo"
wandb_api_key_path: "proteo/wandb_api_key.txt" # relative to root_dir
wandb_offline: false
# Controls the frequency of logging within training, 
# by specifying how many training steps should occur between each logging event.
log_every_n_steps: 5

# GPU Configuration
device: [5, 6, 7] #[0, 1, 2, 3, 4, 5, 6, 7] 
trainer_accelerator: "gpu"
seed: 43

# Miscellaneous Configuration
use_progress_bar: true
nodes_count: 1
pin_memory: true

# Hyperparameter search configuration
# Number of trials = len(model_grid_search) * num_samples
cpu_per_worker: 32
gpu_per_worker: 4
lr_min: 0.0001
lr_max: 0.1
model_grid_search: ['gat']   #['gat', 'gat-v4']
batch_size_choice: [1, 4]
num_layers_choice: [2, 3, 4] # only for gat, gat-v4 has a fixed number of layers
gat_hidden_channels: [64, 128, 256]
gat_heads: [1, 2, 4]
num_samples: 30
grace_period: 2
reduction_factor: 8
num_to_keep: 5  # number of checkpoints to keep. 
# higher values means checkpoints are overwritten less often, gaining speed