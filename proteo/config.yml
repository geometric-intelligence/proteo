dataset_name: "ftd"
root_dir: "/home/nmiolane/code/proteo"

adj_thresh: 0.08
wgcna_power: 6 #replaced this with softThreshold
wgcna_minModuleSize: 10
wgcna_mergeCutHeight: 0.25
task: 'survival'  
task_type: regression # Placeholder

# Model Configuration
model: gat-v4

gat-v4:
  heads: 2
  hidden_channels: 8
  num_layers: 3
  use_layer_norm: true
  which_layer: ['layer1', 'layer2', 'layer3']
  fc_dropout: 0.05
  fc_dim: 64
  num_fc_layers: 4
  num_nodes: 7289 #TO DO: This should not be hardcoded
  # Training gat-v4
  lr: 0.1 
  weight_decay: 0.0005
  l1_lambda: 0.005
  optimizer: Adam
  lr_scheduler: LambdaLR

gat:
  heads: 2
  hidden_channels: 32  # needs to be divisible by heads
  num_layers: 2
  dropout: 0.1
  act: tanh
  v2: true
  # Training gat
  lr: 0.001
  weight_decay: 0.0005
  l1_lambda: 0.0005
  optimizer: Adam
  lr_scheduler: LambdaLR


# Training Configuration
batch_size: 16 #for one off training
epochs: 20
num_workers: 16
sync_batchnorm: false
precision: "32-true"
accumulate_grad_batches: 1

# WandB Configuration
project: "proteo"
wandb_api_key_path: "proteo/wandb_api_key.txt" # relative to root_dir
wandb_offline: false
# Controls the frequency of logging within training, 
# by specifying how many training steps should occur between each logging event.
log_every_n_steps: 5

# GPU Configuration
device: [0, 1, 2, 3, 4, 5, 6, 7] 
trainer_accelerator: "gpu"
seed: 43

# Miscellaneous Configuration
use_progress_bar: true
nodes_count: 1
pin_memory: true

# Hyperparameter search configuration
# Number of trials = len(model_grid_search) * num_samples
cpu_per_worker: 32
gpu_per_worker: 4
lr_min: 0.0001
lr_max: 0.1
model_grid_search: ['gat']   #['gat', 'gat-v4']
batch_size_choice: [1, 4]
num_layers_choice: [2, 3, 4] # only for gat, gat-v4 has a fixed number of layers
gat_hidden_channels: [64, 128, 256]
gat_heads: [1, 2, 4]
num_samples: 30
grace_period: 2
reduction_factor: 8
num_to_keep: 5  # number of checkpoints to keep. 
# higher values means checkpoints are overwritten less often, gaining speed