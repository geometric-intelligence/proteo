# Description of parameters: 
# https://github.com/twitter-research/cwn/blob/main/exp/parser.py

dataset_name: "ftd"
adj_thresh: 0.08
wgcna_power: 6 #replaced this with softThreshold
wgcna_minModuleSize: 10
wgcna_mergeCutHeight: 0.25
task: 'survival'  
task_type: regression # Placeholder
mode: 'min'
minimize: true #Placeholder
#TODO: add root_dir to the config file, folders of data for ftd and mlagnn

# Model Configuration
model: gat

gat-v4:
  # Model Configuration
  #heads: [4, 3, 4]
  #hidden_channels: [8, 16, 12]
  fc_dim: [64, 48, 32, 32]
  which_layer: ['layer1', 'layer2', 'layer3']
  lr: 0.1 
  final_lr: 0.0001
  weight_decay: 0.0005
  fc_dropout: 0.05
  l1_lambda: 0.005
  # Optimizer Configuration
  optimizer: Adam
  lr_scheduler: LambdaLR
  lr_scheduler_params: 
    mode: min'
    factor: 0.2
    threshold: 0.01
    patience: 5
  num_nodes: 7289 #TO DO: This should not be hardcoded
  layer_norm: true


gat:
  #hidden_channels: 20
  num_layers: 4
  #heads: 1
  # Optimizer Configuration
  optimizer: Adam
  lr: 0.001
  l1_lambda: 0.0005
  weight_decay: 0.0005
  lr_scheduler: LambdaLR
  lr_scheduler_params:
    lr_scheduler_patience: 20
    lr_scheduler_decay_steps: 50
    lr_scheduler_decay_rate: 0.5
    lr_scheduler_min: 0.00001
    verbose: true

early_stop: true




# Training Configuration
epochs: 100
batch_size: 12
in_drop_rate: 0.0
drop_rate: 0.0
drop_position: lin2
emb_dim: 128
preproc_jobs: 32
jump_mode: None
num_workers: 16
iso_eps: 0.01
sync_batchnorm: false
precision: "32-true"
accumulate_grad_batches: 1

# Evaluation Configuration
train_eval_period: 20
eval_metric: mae

# WandB Configuration
project_name: "proteo"
wandb_api_key_path: "/home/lcornelis/code/proteo/proteo/wandb_api_key.txt"
wandb_offline: false
log_every_n_steps: 1

# GPU Configuration
device: [0, 1, 2, 3, 4, 5, 6, 7]
trainer_accelerator: "gpu"
seed: 43
start_seed: 0
stop_seed: 9

# Miscellaneous Configuration
use_progress_bar: true
checkpoint_dir: "checkpoints/"
checkpoint_name_pattern: "ckpt"
nodes_count: 1
pin_memory: true
result_folder: os.path.join(ROOT_DIR, 'exp', 'results')
untrained: false
paraid: 0

