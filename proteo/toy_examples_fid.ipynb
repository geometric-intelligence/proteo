{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "\n",
    "# Fetch the dataset from UCI repository\n",
    "def fetch_adult_data():\n",
    "    adult = fetch_ucirepo(id=2)\n",
    "    X = adult.data.features\n",
    "    y = adult.data.targets\n",
    "    y = y.squeeze()  # Remove the second axis\n",
    "    return X, y\n",
    "\n",
    "def clean_adult_data(X: pd.DataFrame, y: pd.Series) -> (pd.DataFrame, pd.Series):\n",
    "    # Renaming columns for easier access\n",
    "    X.rename(columns={'capital-gain': 'gain', 'capital-loss': 'loss', 'native-country': 'country',\n",
    "                      'hours-per-week': 'hours', 'marital-status': 'marital', 'sex': 'gender'}, inplace=True)\n",
    "    \n",
    "    # Replace missing values ('?') with NaN\n",
    "    X.replace('?', pd.NA, inplace=True)\n",
    "    \n",
    "    # Drop rows with missing values\n",
    "    X.dropna(inplace=True)\n",
    "    y = pd.Series(y)[X.index].reset_index(drop=True)  # Keep the same indices for `y`\n",
    "    \n",
    "    # Map target labels\n",
    "    y = y.map({'<=50K': 0, '>50K': 1, '<=50K.': 0, '>50K.': 1})\n",
    "\n",
    "    # Normalize numerical features\n",
    "    numerical_features = ['age', 'fnlwgt', 'education-num', 'gain', 'loss', 'hours']\n",
    "    scaler = MinMaxScaler()\n",
    "    X[numerical_features] = scaler.fit_transform(X[numerical_features])\n",
    "    \n",
    "    return X.reset_index(drop=True), y.reset_index(drop=True)\n",
    "\n",
    "def encode_features(X: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Apply one-hot encoding to categorical columns\n",
    "    X_encoded = pd.get_dummies(X).astype(float)\n",
    "    return X_encoded\n",
    "\n",
    "# Fetch and clean the data\n",
    "X, y = fetch_adult_data()\n",
    "X_cleaned, y_cleaned = clean_adult_data(X, y)\n",
    "\n",
    "# Encode the features\n",
    "X_encoded = encode_features(X_cleaned)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define PyTorch Logistic Regression model\n",
    "class LogisticRegressionModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(LogisticRegressionModel, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return torch.sigmoid(self.linear(x))\n",
    "\n",
    "# Training the logistic regression model\n",
    "def train_pytorch_logistic_regression(X_train, y_train, input_dim, lr=0.01, epochs=200):\n",
    "    model = LogisticRegressionModel(input_dim)\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "    \n",
    "    X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "     # Convert labels (y_train) to numeric type, then to PyTorch tensor\n",
    "    y_train_numeric = pd.to_numeric(y_train, errors='coerce').astype(float)\n",
    "    y_train_tensor = torch.tensor(y_train_numeric.values, dtype=torch.float32).view(-1, 1)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train_tensor)\n",
    "        loss = criterion(outputs, y_train_tensor)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        if (epoch + 1) % 10 == 0:\n",
    "            print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')\n",
    "    \n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [10/200], Loss: 0.6689\n",
      "Epoch [20/200], Loss: 0.6423\n",
      "Epoch [30/200], Loss: 0.6212\n",
      "Epoch [40/200], Loss: 0.6043\n",
      "Epoch [50/200], Loss: 0.5907\n",
      "Epoch [60/200], Loss: 0.5795\n",
      "Epoch [70/200], Loss: 0.5703\n",
      "Epoch [80/200], Loss: 0.5626\n",
      "Epoch [90/200], Loss: 0.5560\n",
      "Epoch [100/200], Loss: 0.5503\n",
      "Epoch [110/200], Loss: 0.5454\n",
      "Epoch [120/200], Loss: 0.5410\n",
      "Epoch [130/200], Loss: 0.5372\n",
      "Epoch [140/200], Loss: 0.5336\n",
      "Epoch [150/200], Loss: 0.5304\n",
      "Epoch [160/200], Loss: 0.5275\n",
      "Epoch [170/200], Loss: 0.5247\n",
      "Epoch [180/200], Loss: 0.5222\n",
      "Epoch [190/200], Loss: 0.5197\n",
      "Epoch [200/200], Loss: 0.5174\n",
      "Epoch [10/200], Loss: 0.6762\n",
      "Epoch [20/200], Loss: 0.6553\n",
      "Epoch [30/200], Loss: 0.6382\n",
      "Epoch [40/200], Loss: 0.6239\n",
      "Epoch [50/200], Loss: 0.6119\n",
      "Epoch [60/200], Loss: 0.6018\n",
      "Epoch [70/200], Loss: 0.5931\n",
      "Epoch [80/200], Loss: 0.5856\n",
      "Epoch [90/200], Loss: 0.5791\n",
      "Epoch [100/200], Loss: 0.5733\n",
      "Epoch [110/200], Loss: 0.5682\n",
      "Epoch [120/200], Loss: 0.5635\n",
      "Epoch [130/200], Loss: 0.5593\n",
      "Epoch [140/200], Loss: 0.5554\n",
      "Epoch [150/200], Loss: 0.5519\n",
      "Epoch [160/200], Loss: 0.5486\n",
      "Epoch [170/200], Loss: 0.5454\n",
      "Epoch [180/200], Loss: 0.5425\n",
      "Epoch [190/200], Loss: 0.5397\n",
      "Epoch [200/200], Loss: 0.5371\n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y_cleaned, test_size=0.3, random_state=42)\n",
    "\n",
    "# Model 1: Train on all attributes except age\n",
    "X_train_no_age = X_train.drop(columns=['age'])\n",
    "X_test_no_age = X_test.drop(columns=['age'])\n",
    "\n",
    "# Ensure all columns are numeric (floats)\n",
    "X_train_no_age = X_train_no_age.astype(float)\n",
    "X_test_no_age = X_test_no_age.astype(float)\n",
    "\n",
    "input_dim_no_age = X_train_no_age.shape[1]\n",
    "model_no_age = train_pytorch_logistic_regression(X_train_no_age, y_train, input_dim_no_age)\n",
    "\n",
    "# Model 2: Train on all attributes except age, sex, and race\n",
    "X_train_no_age_sex_race = X_train.drop(columns=['age', 'gender_Female', 'gender_Male'])\n",
    "\n",
    "X_test_no_age_sex_race = X_test.drop(columns=['age', 'gender_Female', 'gender_Male'])\n",
    "\n",
    "# Ensure all columns are numeric (floats)\n",
    "X_train_no_age_sex_race = X_train_no_age_sex_race.astype(float)\n",
    "X_test_no_age_sex_race = X_test_no_age_sex_race.astype(float)\n",
    "\n",
    "input_dim_no_age_sex_race = X_train_no_age_sex_race.shape[1]\n",
    "model_no_age_sex_race = train_pytorch_logistic_regression(X_train_no_age_sex_race, y_train, input_dim_no_age_sex_race)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import IntegratedGradients\n",
    "import torch\n",
    "\n",
    "# Function to apply Integrated Gradients\n",
    "def explain_with_ig(model, X_test):\n",
    "    ig = IntegratedGradients(model)\n",
    "    \n",
    "    # Convert the test set to PyTorch tensor\n",
    "    X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "    \n",
    "    # Compute attributions using Integrated Gradients\n",
    "    attributions, delta = ig.attribute(X_test_tensor, target=0, return_convergence_delta=True)\n",
    "    \n",
    "    return attributions, delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Attributions for Model 1 (Excluding Age): tensor([[ 0.0027, -0.0135,  0.0000,  ..., -0.0000, -0.0000,  0.0000],\n",
      "        [ 0.0009, -0.0040,  0.0000,  ..., -0.0659, -0.0000,  0.0000],\n",
      "        [ 0.0015, -0.0080,  0.0000,  ..., -0.0582, -0.0000,  0.0000],\n",
      "        ...,\n",
      "        [ 0.0018, -0.0092,  0.0000,  ..., -0.0669, -0.0000,  0.0000],\n",
      "        [ 0.0018, -0.0089,  0.0000,  ..., -0.0650, -0.0000,  0.0000],\n",
      "        [ 0.0012, -0.0091,  0.0000,  ..., -0.0665, -0.0000,  0.0000]],\n",
      "       dtype=torch.float64)\n",
      "Convergence delta for Model 1: tensor([-4.5800e-08, -3.8636e-08, -1.2884e-08,  ..., -5.6466e-09,\n",
      "        -3.0050e-09, -1.3951e-08], dtype=torch.float64)\n",
      "Attributions for Model 2 (Excluding Age, Sex, and Race): tensor([[ 0.0015, -0.0373, -0.0000,  ..., -0.0000, -0.0000,  0.0000],\n",
      "        [ 0.0005, -0.0112, -0.0000,  ..., -0.0302, -0.0000,  0.0000],\n",
      "        [ 0.0009, -0.0237, -0.0000,  ..., -0.0286, -0.0000,  0.0000],\n",
      "        ...,\n",
      "        [ 0.0010, -0.0258, -0.0000,  ..., -0.0310, -0.0000,  0.0000],\n",
      "        [ 0.0010, -0.0250, -0.0000,  ..., -0.0301, -0.0000,  0.0000],\n",
      "        [ 0.0007, -0.0250, -0.0000,  ..., -0.0301, -0.0000,  0.0000]],\n",
      "       dtype=torch.float64)\n",
      "Convergence delta for Model 2: tensor([-3.0710e-08,  1.3708e-08,  3.8680e-09,  ..., -1.0222e-08,\n",
      "        -8.5078e-09, -3.8255e-09], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "# Apply Integrated Gradients to Model 1 (excluding age)\n",
    "attributions_no_age, delta_no_age = explain_with_ig(model_no_age, X_test_no_age)\n",
    "\n",
    "# Print the attributions and convergence delta for Model 1\n",
    "print(\"Attributions for Model 1 (Excluding Age):\", attributions_no_age)\n",
    "print(\"Convergence delta for Model 1:\", delta_no_age)\n",
    "\n",
    "# Apply Integrated Gradients to Model 2 (excluding age, sex, and race)\n",
    "attributions_no_age_sex_race, delta_no_age_sex_race = explain_with_ig(model_no_age_sex_race, X_test_no_age_sex_race)\n",
    "\n",
    "# Print the attributions and convergence delta for Model 2\n",
    "print(\"Attributions for Model 2 (Excluding Age, Sex, and Race):\", attributions_no_age_sex_race)\n",
    "print(\"Convergence delta for Model 2:\", delta_no_age_sex_race)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "13567\n"
     ]
    }
   ],
   "source": [
    "print(len(attributions_no_age))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate fidelity+ (comprehensiveness)\n",
    "def fidelity_plus(model, X_test, original_preds, attributions, top_k=5):\n",
    "    X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "    \n",
    "    # Sort attributions by importance\n",
    "    top_attributions = torch.argsort(attributions, descending=True)\n",
    "    \n",
    "    # Remove top_k important features\n",
    "    for i in range(X_test_tensor.size(0)):\n",
    "        top_features = top_attributions[i, :top_k]\n",
    "        X_test_tensor[i, top_features] = 0\n",
    "    \n",
    "    # Re-run the model to get new predictions with removed features\n",
    "    with torch.no_grad():\n",
    "        new_predictions = (model(X_test_tensor) > 0.5).int()\n",
    "    \n",
    "    # Compare new predictions to original predictions (fidelity+)\n",
    "    fidelity_plus_score = 1 - (1 / X_test_tensor.size(0)) * torch.sum((new_predictions == original_preds).float())\n",
    "    \n",
    "    return fidelity_plus_score.item()\n",
    "\n",
    "# Function to calculate fidelity- (sufficiency)\n",
    "def fidelity_minus(model, X_test, original_preds, attributions, top_k=5):\n",
    "    X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "    \n",
    "    # Sort attributions by importance\n",
    "    top_attributions = torch.argsort(attributions, descending=True)\n",
    "    \n",
    "    # Keep only top_k important features and zero out the rest\n",
    "    for i in range(X_test_tensor.size(0)):\n",
    "        mask = torch.zeros(X_test_tensor.size(1), dtype=torch.float32)\n",
    "        top_features = top_attributions[i, :top_k]\n",
    "        mask[top_features] = 1\n",
    "        X_test_tensor[i] = X_test_tensor[i] * mask\n",
    "    \n",
    "    # Re-run the model to get new predictions with only important features\n",
    "    with torch.no_grad():\n",
    "        new_predictions = (model(X_test_tensor) > 0.5).int()\n",
    "    \n",
    "    # Compare new predictions to original predictions (fidelity-)\n",
    "    fidelity_minus_score = 1 - (1 / X_test_tensor.size(0)) * torch.sum((new_predictions == original_preds).float())\n",
    "    \n",
    "    return fidelity_minus_score.item()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity+ (Comprehensiveness) Score for Model 1 (Excluding Age): 0.00044232606887817383\n",
      "Fidelity- (Sufficiency) Score for Model 1 (Excluding Age): 5.960464477539063e-08\n",
      "Fidelity+ (Comprehensiveness) Score for Model 2 (Excluding Age, Sex, and Race): 5.960464477539063e-08\n",
      "Fidelity- (Sufficiency) Score for Model 2 (Excluding Age, Sex, and Race): 5.960464477539063e-08\n"
     ]
    }
   ],
   "source": [
    "# For model 1 (excluding age):\n",
    "original_preds_no_age = (model_no_age(torch.tensor(X_test_no_age.values, dtype=torch.float32)) > 0.5).int()\n",
    "\n",
    "# For model 2 (excluding age, sex, and race):\n",
    "original_preds_no_age_sex_race = (model_no_age_sex_race(torch.tensor(X_test_no_age_sex_race.values, dtype=torch.float32)) > 0.5).int()\n",
    "\n",
    "# Calculate fidelity+ and fidelity- for model_no_age (first model)\n",
    "fidelity_plus_score_no_age = fidelity_plus(model_no_age, X_test_no_age, original_preds_no_age, attributions_no_age, top_k=5000)\n",
    "fidelity_minus_score_no_age = fidelity_minus(model_no_age, X_test_no_age, original_preds_no_age, attributions_no_age, top_k=5000)\n",
    "\n",
    "# Calculate fidelity+ and fidelity- for model_no_age_sex_race (second model)\n",
    "fidelity_plus_score_no_age_sex_race = fidelity_plus(model_no_age_sex_race, X_test_no_age_sex_race, original_preds_no_age_sex_race, attributions_no_age_sex_race, top_k=5000)\n",
    "fidelity_minus_score_no_age_sex_race = fidelity_minus(model_no_age_sex_race, X_test_no_age_sex_race, original_preds_no_age_sex_race, attributions_no_age_sex_race, top_k=5000)\n",
    "\n",
    "# Print the results:\n",
    "print(f\"Fidelity+ (Comprehensiveness) Score for Model 1 (Excluding Age): {fidelity_plus_score_no_age}\")\n",
    "print(f\"Fidelity- (Sufficiency) Score for Model 1 (Excluding Age): {fidelity_minus_score_no_age}\")\n",
    "\n",
    "print(f\"Fidelity+ (Comprehensiveness) Score for Model 2 (Excluding Age, Sex, and Race): {fidelity_plus_score_no_age_sex_race}\")\n",
    "print(f\"Fidelity- (Sufficiency) Score for Model 2 (Excluding Age, Sex, and Race): {fidelity_minus_score_no_age_sex_race}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proteo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
