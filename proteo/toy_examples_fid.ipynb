{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Column names: Index(['age', 'workclass', 'fnlwgt', 'education', 'education-num', 'marital',\n",
      "       'occupation', 'relationship', 'race', 'sex', 'gain', 'loss', 'hours',\n",
      "       'country'],\n",
      "      dtype='object')\n",
      "Number of significant groups: 145\n",
      "Columns after encoding: Index(['age', 'fnlwgt', 'education-num', 'gain', 'loss', 'hours',\n",
      "       'workclass_Federal-gov', 'workclass_Local-gov', 'workclass_Private',\n",
      "       'workclass_Self-emp-inc', 'workclass_Self-emp-not-inc',\n",
      "       'workclass_State-gov', 'education_10th', 'education_11th',\n",
      "       'education_7th-8th', 'education_Assoc-acdm', 'education_Assoc-voc',\n",
      "       'education_Bachelors', 'education_Doctorate', 'education_HS-grad',\n",
      "       'education_Masters', 'education_Prof-school', 'education_Some-college',\n",
      "       'marital_Divorced', 'marital_Married-civ-spouse',\n",
      "       'marital_Never-married', 'occupation_Adm-clerical',\n",
      "       'occupation_Craft-repair', 'occupation_Exec-managerial',\n",
      "       'occupation_Farming-fishing', 'occupation_Handlers-cleaners',\n",
      "       'occupation_Machine-op-inspct', 'occupation_Other-service',\n",
      "       'occupation_Prof-specialty', 'occupation_Protective-serv',\n",
      "       'occupation_Sales', 'occupation_Tech-support',\n",
      "       'occupation_Transport-moving', 'relationship_Husband',\n",
      "       'relationship_Not-in-family', 'relationship_Own-child',\n",
      "       'relationship_Unmarried', 'relationship_Wife', 'race_Black',\n",
      "       'race_White', 'sex_Female', 'sex_Male', 'country_United-States'],\n",
      "      dtype='object')\n",
      "length of y_cleaned: 20358\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from ucimlrepo import fetch_ucirepo \n",
    "\n",
    "# Fetch the dataset from UCI repository\n",
    "def fetch_adult_data():\n",
    "    adult = fetch_ucirepo(id=2)\n",
    "    X = adult.data.features\n",
    "    y = adult.data.targets\n",
    "    y = y.squeeze()  # Remove the second axis\n",
    "    return X, y\n",
    "\n",
    "def clean_adult_data(X: pd.DataFrame, y: pd.Series) -> (pd.DataFrame, pd.Series):\n",
    "    # Renaming columns for easier access\n",
    "    X.rename(columns={'capital-gain': 'gain', 'capital-loss': 'loss', 'native-country': 'country',\n",
    "                      'hours-per-week': 'hours', 'marital-status': 'marital'}, inplace=True)\n",
    "    \n",
    "    print(\"Column names:\", X.columns)\n",
    "    \n",
    "    # Replace missing values ('?') with NaN\n",
    "    X.replace('?', pd.NA, inplace=True)\n",
    "    \n",
    "    # Drop rows with missing values\n",
    "    X.dropna(inplace=True)\n",
    "    y = y.loc[X.index]\n",
    "    \n",
    "    # Map target labels\n",
    "    y = y.map({'<=50K': 0, '>50K': 1, '<=50K.': 0, '>50K.': 1})\n",
    "\n",
    "    # Group by categorical columns\n",
    "    group_columns = ['workclass', 'education', 'marital', 'occupation', 'relationship', 'race', 'country']\n",
    "\n",
    "    # Finding significant groups, i.e., counting samples per group\n",
    "    adult_counting_groups = X.groupby(group_columns).size().to_frame('m').reset_index()\n",
    "    \n",
    "    \n",
    "    # Filter for groups with more than `group_threshold` elements\n",
    "    group_threshold = 50\n",
    "    significant_groups = adult_counting_groups[adult_counting_groups['m'] > group_threshold]\n",
    "    print(\"Number of significant groups:\", significant_groups.shape[0])\n",
    "    \n",
    "    # Get the significant groups as a list of tuples\n",
    "    adult_list_significant = significant_groups[group_columns].apply(tuple, axis=1).tolist()\n",
    "    \n",
    "    # Filtering for only rows that belong to the significant groups\n",
    "    X_filtered = X[X[group_columns].apply(tuple, axis=1).isin(adult_list_significant)]\n",
    "    y_filtered = y.reindex(X_filtered.index)\n",
    "\n",
    "    # Drop any rows where y might have missing values after reindexing\n",
    "    X_filtered = X_filtered[y_filtered.notna()]\n",
    "    y_filtered = y_filtered.dropna()\n",
    "\n",
    "    # Normalize numerical features\n",
    "    numerical_features = ['age', 'fnlwgt', 'education-num', 'gain', 'loss', 'hours']\n",
    "    scaler = MinMaxScaler()\n",
    "    X_filtered[numerical_features] = scaler.fit_transform(X_filtered[numerical_features])\n",
    "    \n",
    "    return X_filtered.reset_index(drop=True), y_filtered.reset_index(drop=True)\n",
    "\n",
    "def encode_features(X: pd.DataFrame) -> pd.DataFrame:\n",
    "    # Apply one-hot encoding to categorical columns\n",
    "    X_encoded = pd.get_dummies(X).astype(float)\n",
    "    return X_encoded\n",
    "\n",
    "# Fetch and clean the data\n",
    "X, y = fetch_adult_data()\n",
    "X_cleaned, y_cleaned = clean_adult_data(X, y)\n",
    "\n",
    "# Encode the features\n",
    "X_encoded = encode_features(X_cleaned)\n",
    "print(\"Columns after encoding:\", X_encoded.columns)\n",
    "print(\"length of y_cleaned:\", len(y_cleaned))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "\n",
    "# Define PyTorch Logistic Regression model\n",
    "class LogisticRegressionModel(nn.Module):\n",
    "    def __init__(self, input_dim):\n",
    "        super(LogisticRegressionModel, self).__init__()\n",
    "        self.linear = nn.Linear(input_dim, 1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return torch.sigmoid(self.linear(x))\n",
    "\n",
    "# Training the logistic regression model\n",
    "def train_pytorch_logistic_regression(X_train, y_train, input_dim, lr=0.01, epochs=200):\n",
    "    model = LogisticRegressionModel(input_dim)\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.SGD(model.parameters(), lr=lr)\n",
    "    \n",
    "    X_train_tensor = torch.tensor(X_train.values, dtype=torch.float32)\n",
    "     # Convert labels (y_train) to numeric type, then to PyTorch tensor\n",
    "    y_train_numeric = pd.to_numeric(y_train, errors='coerce').astype(float)\n",
    "    y_train_tensor = torch.tensor(y_train_numeric.values, dtype=torch.float32).view(-1, 1)\n",
    "    \n",
    "    for epoch in range(epochs):\n",
    "        model.train()\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X_train_tensor)\n",
    "        loss = criterion(outputs, y_train_tensor)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        #if (epoch + 1) % 10 == 0:\n",
    "            #print(f'Epoch [{epoch + 1}/{epochs}], Loss: {loss.item():.4f}')\n",
    "    \n",
    "    return model\n",
    "\n",
    "\n",
    "# Function to predict using the PyTorch model\n",
    "def predict_pytorch_logistic_regression(model, X):\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    X_tensor = torch.tensor(X.values, dtype=torch.float32)\n",
    "    with torch.no_grad():\n",
    "        probabilities = model(X_tensor).squeeze()  # Get predicted probabilities\n",
    "        predictions = (probabilities >= 0.5).float()  # Convert probabilities to binary predictions (0 or 1)\n",
    "    return predictions.numpy()  # Return predictions as NumPy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Accuracy h_p: 0.6816\n",
      "Test Accuracy h_p: 0.6902\n",
      "Training Accuracy h_0: 0.6801\n",
      "Test Accuracy h_0: 0.6886\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_encoded, y_cleaned, test_size=0.3, random_state=42)\n",
    "\n",
    "# Model 1: Train on all attributes - h_p model\n",
    "input_dim_no_age = X_train.shape[1]\n",
    "model_h_p = train_pytorch_logistic_regression(X_train, y_train, input_dim_no_age)\n",
    "\n",
    "# Predict on training and test data\n",
    "y_train_pred_h0 = predict_pytorch_logistic_regression(model_h_p, X_train)\n",
    "y_test_pred_h0 = predict_pytorch_logistic_regression(model_h_p, X_test)\n",
    "\n",
    "# Calculate accuracy\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred_h0)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred_h0)\n",
    "\n",
    "# Print accuracy results\n",
    "print(f\"Training Accuracy h_p: {train_accuracy:.4f}\")\n",
    "print(f\"Test Accuracy h_p: {test_accuracy:.4f}\")\n",
    "\n",
    "# Model 2: Train on all attributes except age, sex, and race\n",
    "X_train_no_sex = X_train.drop(columns=['sex_Female', 'sex_Male'])\n",
    "X_test_no_sex = X_test.drop(columns=['sex_Female', 'sex_Male'])\n",
    "\n",
    "# Ensure all columns are numeric (floats)\n",
    "X_train_no_sex = X_train_no_sex.astype(float)\n",
    "X_test_no_sex = X_test_no_sex.astype(float)\n",
    "\n",
    "input_dim_no_sex = X_train_no_sex.shape[1]\n",
    "model_no_sex = train_pytorch_logistic_regression(X_train_no_sex, y_train, input_dim_no_sex)\n",
    "\n",
    "# Predict on training and test data\n",
    "y_train_pred = predict_pytorch_logistic_regression(model_no_sex, X_train_no_sex)\n",
    "y_test_pred = predict_pytorch_logistic_regression(model_no_sex, X_test_no_sex)\n",
    "\n",
    "# Calculate accuracy\n",
    "train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "\n",
    "# Print accuracy results\n",
    "print(f\"Training Accuracy h_0: {train_accuracy:.4f}\")\n",
    "print(f\"Test Accuracy h_0: {test_accuracy:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in X_test: Index(['age', 'fnlwgt', 'education-num', 'gain', 'loss', 'hours',\n",
      "       'workclass_Federal-gov', 'workclass_Local-gov', 'workclass_Private',\n",
      "       'workclass_Self-emp-inc', 'workclass_Self-emp-not-inc',\n",
      "       'workclass_State-gov', 'education_10th', 'education_11th',\n",
      "       'education_7th-8th', 'education_Assoc-acdm', 'education_Assoc-voc',\n",
      "       'education_Bachelors', 'education_Doctorate', 'education_HS-grad',\n",
      "       'education_Masters', 'education_Prof-school', 'education_Some-college',\n",
      "       'marital_Divorced', 'marital_Married-civ-spouse',\n",
      "       'marital_Never-married', 'occupation_Adm-clerical',\n",
      "       'occupation_Craft-repair', 'occupation_Exec-managerial',\n",
      "       'occupation_Farming-fishing', 'occupation_Handlers-cleaners',\n",
      "       'occupation_Machine-op-inspct', 'occupation_Other-service',\n",
      "       'occupation_Prof-specialty', 'occupation_Protective-serv',\n",
      "       'occupation_Sales', 'occupation_Tech-support',\n",
      "       'occupation_Transport-moving', 'relationship_Husband',\n",
      "       'relationship_Not-in-family', 'relationship_Own-child',\n",
      "       'relationship_Unmarried', 'relationship_Wife', 'race_Black',\n",
      "       'race_White', 'sex_Female', 'sex_Male', 'country_United-States'],\n",
      "      dtype='object')\n",
      "X_test shape: (6108, 48)\n",
      "X_train shape: (14250, 48)\n",
      "Accuracy for sex_Female h_p: 0.9059\n",
      "Accuracy for sex_Male h_p: 0.6272\n",
      "Accuracy for sex_Female h_0: 0.9059\n",
      "Accuracy for sex_Male h_0: 0.6251\n",
      "Difference in accuracy female: 0.0000\n",
      "Difference in accuracy male: 0.0021\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "print(\"Columns in X_test:\", X_test.columns)\n",
    "print(\"X_test shape:\", X_test.shape)\n",
    "print(\"X_train shape:\", X_train.shape)\n",
    "\n",
    "# Function to calculate accuracy using sklearn's accuracy_score\n",
    "def calculate_accuracy(model, X, y_true):\n",
    "    \"\"\"Calculates accuracy for a given model, input data X, and true labels y_true.\"\"\"\n",
    "    model.eval()  # Set the model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        # Convert data to torch tensors\n",
    "        X_tensor = torch.tensor(X.values, dtype=torch.float32)\n",
    "        \n",
    "        # Get predictions from the model (probabilities between 0 and 1)\n",
    "        y_pred = model(X_tensor).squeeze()\n",
    "\n",
    "        # Convert probabilities to binary predictions (0 or 1)\n",
    "        y_pred_rounded = (y_pred >= 0.5).float()\n",
    "\n",
    "        # Calculate accuracy using sklearn's accuracy_score\n",
    "        accuracy = accuracy_score(y_true, y_pred_rounded)\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "# Function to filter data based on sex and calculate accuracy per group\n",
    "def get_sex_filtered_accuracy(model, X, y, sex_filter):\n",
    "    \"\"\"Calculates accuracy for sex_Female and sex_Male groups.\"\"\"\n",
    "    # Filter the data using the sex filter (from the original X_test with sex columns)\n",
    "    X_filtered = X[sex_filter]\n",
    "    y_filtered = y[sex_filter]\n",
    "    \n",
    "    # Calculate accuracy for the filtered data\n",
    "    accuracy = calculate_accuracy(model, X_filtered, y_filtered)\n",
    "    \n",
    "    return accuracy\n",
    "\n",
    "# Filter for sex_Female and sex_Male using the original test set (X_test)\n",
    "female_filter = X_test['sex_Female'] == 1\n",
    "male_filter = X_test['sex_Male'] == 1\n",
    "\n",
    "# Calculate accuracy for sex_Female and sex_Male in model_h_p (with sex attributes)\n",
    "accuracy_female_h_p = get_sex_filtered_accuracy(model_h_p, X_test, y_test, female_filter)\n",
    "accuracy_male_h_p = get_sex_filtered_accuracy(model_h_p, X_test, y_test, male_filter)\n",
    "\n",
    "print(f\"Accuracy for sex_Female h_p: {accuracy_female_h_p:.4f}\")\n",
    "print(f\"Accuracy for sex_Male h_p: {accuracy_male_h_p:.4f}\")\n",
    "\n",
    "# Now calculate accuracy for sex_Female and sex_Male in model_no_sex (without sex attributes)\n",
    "# Use X_test_no_sex for the data, but use the same sex filter based on X_test\n",
    "accuracy_female_h_0 = get_sex_filtered_accuracy(model_no_sex, X_test_no_sex, y_test, female_filter)\n",
    "accuracy_male_h_0 = get_sex_filtered_accuracy(model_no_sex, X_test_no_sex, y_test, male_filter)\n",
    "\n",
    "print(f\"Accuracy for sex_Female h_0: {accuracy_female_h_0:.4f}\")\n",
    "print(f\"Accuracy for sex_Male h_0: {accuracy_male_h_0:.4f}\")\n",
    "\n",
    "# Calculate the difference in accuracy (h_p model minus no_sex model)\n",
    "diff_female_accuracy = accuracy_female_h_p - accuracy_female_h_0\n",
    "diff_male_accuracy = accuracy_male_h_p - accuracy_male_h_0\n",
    "\n",
    "print(f\"Difference in accuracy female: {diff_female_accuracy:.4f}\")\n",
    "print(f\"Difference in accuracy male: {diff_male_accuracy:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "from captum.attr import IntegratedGradients\n",
    "import torch\n",
    "\n",
    "# Function to apply Integrated Gradients\n",
    "def explain_with_ig(model, X_test):\n",
    "    ig = IntegratedGradients(model)\n",
    "    \n",
    "    # Convert the test set to PyTorch tensor\n",
    "    X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "    \n",
    "    # Compute attributions using Integrated Gradients\n",
    "    attributions, delta = ig.attribute(X_test_tensor, return_convergence_delta=True)\n",
    "    # Print the shape of attributions\n",
    "    print(\"Shape of attributions:\", attributions.shape)\n",
    "    \n",
    "    return attributions, delta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply Integrated Gradients to Model 1 (excluding age)\n",
    "attributions_h_p, delta_h_p = explain_with_ig(model_h_p, X_test)\n",
    "\n",
    "# Print the attributions and convergence delta for Model 1\n",
    "print(\"Attributions for Model 1 (h_p):\", attributions_h_p)\n",
    "print(\"Convergence delta for Model 1:\", delta_h_p)\n",
    "\n",
    "# Apply Integrated Gradients to Model 2 (excluding sex)\n",
    "attributions_no_sex, delta_no_sex = explain_with_ig(model_no_sex, X_test_no_sex)\n",
    "\n",
    "# Print the attributions and convergence delta for Model 2\n",
    "print(\"Attributions for Model 2 (Excluding Age, Sex, and Race):\", attributions_no_sex)\n",
    "print(\"Convergence delta for Model 2:\", delta_no_sex)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'attributions_h_p' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[55], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(\u001b[43mattributions_h_p\u001b[49m))\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28mprint\u001b[39m(attributions_h_p\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;28mlen\u001b[39m(attributions_no_sex))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'attributions_h_p' is not defined"
     ]
    }
   ],
   "source": [
    "print(len(attributions_h_p))\n",
    "print(attributions_h_p.shape)\n",
    "print(len(attributions_no_sex))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to calculate fidelity+ (comprehensiveness)\n",
    "def fidelity_plus(model, X_test, original_preds, attributions, top_k=5):\n",
    "    X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "    \n",
    "    # Sort attributions by importance\n",
    "    top_attributions = torch.argsort(attributions, descending=True)\n",
    "    \n",
    "    # Remove top_k important features\n",
    "    for i in range(X_test_tensor.size(0)):\n",
    "        top_features = top_attributions[i, :top_k]\n",
    "        X_test_tensor[i, top_features] = 0\n",
    "    \n",
    "    # Re-run the model to get new predictions with removed features\n",
    "    with torch.no_grad():\n",
    "        new_predictions = (model(X_test_tensor) > 0.5).int()\n",
    "    \n",
    "    # Compare new predictions to original predictions (fidelity+)\n",
    "    fidelity_plus_score = 1 - (1 / X_test_tensor.size(0)) * torch.sum((new_predictions == original_preds).float())\n",
    "    \n",
    "    return fidelity_plus_score.item()\n",
    "\n",
    "# Function to calculate fidelity- (sufficiency)\n",
    "def fidelity_minus(model, X_test, original_preds, attributions, top_k=5):\n",
    "    X_test_tensor = torch.tensor(X_test.values, dtype=torch.float32)\n",
    "    \n",
    "    # Sort attributions by importance\n",
    "    top_attributions = torch.argsort(attributions, descending=True)\n",
    "    \n",
    "    # Keep only top_k important features and zero out the rest\n",
    "    for i in range(X_test_tensor.size(0)):\n",
    "        mask = torch.zeros(X_test_tensor.size(1), dtype=torch.float32)\n",
    "        top_features = top_attributions[i, :top_k]\n",
    "        mask[top_features] = 1\n",
    "        X_test_tensor[i] = X_test_tensor[i] * mask\n",
    "    \n",
    "    # Re-run the model to get new predictions with only important features\n",
    "    with torch.no_grad():\n",
    "        new_predictions = (model(X_test_tensor) > 0.5).int()\n",
    "    \n",
    "    # Compare new predictions to original predictions (fidelity-)\n",
    "    fidelity_minus_score = 1 - (1 / X_test_tensor.size(0)) * torch.sum((new_predictions == original_preds).float())\n",
    "    \n",
    "    return fidelity_minus_score.item()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fidelity+ (Comprehensiveness) Score for Model 1 (Excluding Age): 0.00044232606887817383\n",
      "Fidelity- (Sufficiency) Score for Model 1 (Excluding Age): 5.960464477539063e-08\n",
      "Fidelity+ (Comprehensiveness) Score for Model 2 (Excluding Age, Sex, and Race): 5.960464477539063e-08\n",
      "Fidelity- (Sufficiency) Score for Model 2 (Excluding Age, Sex, and Race): 5.960464477539063e-08\n"
     ]
    }
   ],
   "source": [
    "# For model 1 (excluding age):\n",
    "original_preds_no_age = (model_no_age(torch.tensor(X_test_no_age.values, dtype=torch.float32)) > 0.5).int()\n",
    "\n",
    "# For model 2 (excluding age, sex, and race):\n",
    "original_preds_no_age_sex_race = (model_no_age_sex_race(torch.tensor(X_test_no_age_sex_race.values, dtype=torch.float32)) > 0.5).int()\n",
    "\n",
    "# Calculate fidelity+ and fidelity- for model_no_age (first model)\n",
    "fidelity_plus_score_no_age = fidelity_plus(model_no_age, X_test_no_age, original_preds_no_age, attributions_no_age, top_k=5000)\n",
    "fidelity_minus_score_no_age = fidelity_minus(model_no_age, X_test_no_age, original_preds_no_age, attributions_no_age, top_k=5000)\n",
    "\n",
    "# Calculate fidelity+ and fidelity- for model_no_age_sex_race (second model)\n",
    "fidelity_plus_score_no_age_sex_race = fidelity_plus(model_no_age_sex_race, X_test_no_age_sex_race, original_preds_no_age_sex_race, attributions_no_age_sex_race, top_k=5000)\n",
    "fidelity_minus_score_no_age_sex_race = fidelity_minus(model_no_age_sex_race, X_test_no_age_sex_race, original_preds_no_age_sex_race, attributions_no_age_sex_race, top_k=5000)\n",
    "\n",
    "# Print the results:\n",
    "print(f\"Fidelity+ (Comprehensiveness) Score for Model 1 (Excluding Age): {fidelity_plus_score_no_age}\")\n",
    "print(f\"Fidelity- (Sufficiency) Score for Model 1 (Excluding Age): {fidelity_minus_score_no_age}\")\n",
    "\n",
    "print(f\"Fidelity+ (Comprehensiveness) Score for Model 2 (Excluding Age, Sex, and Race): {fidelity_plus_score_no_age_sex_race}\")\n",
    "print(f\"Fidelity- (Sufficiency) Score for Model 2 (Excluding Age, Sex, and Race): {fidelity_minus_score_no_age_sex_race}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proteo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
