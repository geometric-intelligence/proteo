{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import train as proteo_train\n",
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from proteo.datasets.ftd import FTDDataset, reverse_log_transform\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "def load_checkpoint(relative_checkpoint_path, levels_up=5):\n",
    "    '''Load the checkpoint as a module. Note levels_up depends on the directory structure of the ray_results folder'''\n",
    "    # Get the current script directory\n",
    "    current_directory = os.getcwd()\n",
    "    \n",
    "    # Navigate up the specified number of levels\n",
    "    for _ in range(levels_up):\n",
    "        current_directory = os.path.dirname(current_directory)\n",
    "    \n",
    "    # Construct the full path to the checkpoint\n",
    "    checkpoint_path = os.path.join(current_directory,'scratch/lcornelis/outputs/ray_results/', relative_checkpoint_path)\n",
    "    print(f\"Loading checkpoint from: {checkpoint_path}\")\n",
    "\n",
    "    # Check if the file exists to avoid errors\n",
    "    if not os.path.isfile(checkpoint_path):\n",
    "        raise FileNotFoundError(f\"Checkpoint file not found: {checkpoint_path}\")\n",
    "    \n",
    "    module = proteo_train.Proteo.load_from_checkpoint(checkpoint_path)\n",
    "    return module\n",
    "\n",
    "# Load in the datasets from the config\n",
    "def load_config(module):\n",
    "    '''Load the config from the module  and return it'''\n",
    "    config = module.config\n",
    "    print(\"Config being used:\", config)\n",
    "    return config\n",
    "\n",
    "\n",
    "def load_model_and_predict(module, config, device = 'cuda'):\n",
    "    '''Run the module with the correct train and test datasets and return the predictions and targets'''\n",
    "    module.to(device)\n",
    "    module.eval()\n",
    "    train_dataset, test_dataset = proteo_train.construct_datasets(config)\n",
    "    train_loader, test_loader = proteo_train.construct_loaders(config, train_dataset, test_dataset)\n",
    "    # Get predictions and targets for the training set\n",
    "    train_preds, train_targets = [], []\n",
    "    for batch in train_loader:\n",
    "        batch.to(device)\n",
    "        # Forward pass\n",
    "        pred = module(batch)\n",
    "        target = batch.y.view(pred.shape)\n",
    "        \n",
    "        # Store predictions and targets\n",
    "        train_preds.append(pred.cpu())\n",
    "        train_targets.append(target.cpu())\n",
    "    train_preds = torch.cat(train_preds)\n",
    "    train_targets = torch.cat(train_targets)\n",
    "    \n",
    "    # Calculate MSE for training set\n",
    "    train_mse = F.mse_loss(train_preds, train_targets).item()\n",
    "    \n",
    "    # Get predictions and targets for the validation set\n",
    "    val_preds, val_targets = [], []\n",
    "    for batch in test_loader:\n",
    "        batch.to(device)\n",
    "        # Forward pass\n",
    "        pred = module(batch)\n",
    "        target = batch.y.view(pred.shape)\n",
    "        \n",
    "        # Store predictions and targets\n",
    "        val_preds.append(pred.cpu())\n",
    "        val_targets.append(target.cpu())\n",
    "    val_preds = torch.cat(val_preds)\n",
    "    val_targets = torch.cat(val_targets)\n",
    "    \n",
    "    # Calculate MSE for validation set\n",
    "    val_mse = F.mse_loss(val_preds, val_targets).item()\n",
    "    return train_preds, train_targets, train_mse, val_preds, val_targets, val_mse\n",
    "\n",
    "def full_load_and_run_and_convert(relative_checkpoint_path, device, mean, std, levels_up=5):\n",
    "    '''Call all the functions to load the checkpoint, run the model and convert the predictions back to the original units'''\n",
    "    module = load_checkpoint(relative_checkpoint_path, levels_up)\n",
    "    config = load_config(module)\n",
    "    train_preds, train_targets, train_mse, val_preds, val_targets, val_mse = load_model_and_predict(module, config, device)\n",
    "    train_preds = reverse_log_transform(train_preds, mean, std)\n",
    "    train_targets = reverse_log_transform(train_targets, mean, std)\n",
    "    train_mse = F.mse_loss(train_preds, train_targets)\n",
    "    train_rmse = torch.sqrt(train_mse)\n",
    "    val_preds = reverse_log_transform(val_preds, mean, std)\n",
    "    val_targets = reverse_log_transform(val_targets, mean, std)\n",
    "    val_mse = F.mse_loss(val_preds, val_targets)\n",
    "    val_rmse = torch.sqrt(val_mse)\n",
    "    print(\"Checkpoint path\", relative_checkpoint_path)\n",
    "    #print(\"Original Units Train preds:\", train_preds)\n",
    "    #print(\"Original Units Train targets:\", train_targets)\n",
    "    print(\"Original Units Train MSE:\", train_mse)\n",
    "    print(\"Original Units Train RMSE:\", train_rmse)\n",
    "    #print(\"Original Units Val preds:\", val_preds)\n",
    "    #print(\"Original Units Val targets:\", val_targets)\n",
    "    print(\"Original Units Val MSE:\", val_mse)\n",
    "    print(\"Original Units Val RMSE:\", val_rmse)\n",
    "    return train_preds, train_targets, train_mse, train_rmse, val_preds, val_targets, val_mse, val_rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint from: /scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-07-31_10-47-21/model=gat-v4,seed=19543_0_act=relu,adj_thresh=0.1000,batch_size=8,dropout=0,l1_lambda=0.0000,lr=0.1000,lr_scheduler=LambdaLR,modal_2024-07-31_10-47-21/checkpoint_000002/checkpoint.ckpt\n",
      "Config being used: gat_v4_weight_initializer=['uniform'] gat_hidden_channels=[8, 32, 128, 256] device=[0] root_dir='/home/lcornelis/code/proteo' checkpoint_every_n_epochs_train=1 l1_lambda=1e-05 pin_memory=True sex=['M'] wgcna_mergeCutHeight=0.25 y_val='nfl' log_every_n_steps=10 num_samples=1 gat_v4_heads=[[2, 3]] cpu_per_worker=16 nodes_count=1 adj_thresh=0.1 gat_heads=[1, 2, 4, 8] optimizer='Adam' checkpoint_dir='/scratch/lcornelis/outputs/checkpoints' num_to_keep=3 seed=19543 modality_choices=['plasma'] l1_lambda_min=1e-05 gat-v4={'hidden_channels': [8, 16], 'heads': [2, 3], 'use_layer_norm': True, 'which_layer': ['layer1', 'layer2', 'layer3'], 'fc_dim': [64, 128, 128, 32], 'fc_dropout': 0.1, 'fc_act': 'relu', 'weight_initializer': 'uniform', 'num_layers': None} lr=0.10000000000000005 wgcna_minModuleSize=10 gat_num_layers=[2, 4, 6, 12] model='gat-v4' dataset_name='ftd' y_val_choices=['nfl'] gat_v4_hidden_channels=[[8, 16]] accumulate_grad_batches=1 gat={'num_layers': 2, 'hidden_channels': 256, 'heads': 4, 'v2': True} trainer_accelerator='gpu' precision='32-true' gat_v4_fc_act=['relu'] batch_size_choices=[8] lr_scheduler='LambdaLR' num_workers=16 epochs=30 data_dir='/home/data/data_louisa' wandb_api_key_path='wandb_api_key.txt' dropout_choices=[0] dropout=0 gat_v4_fc_dim=[[64, 128, 128, 32]] ray_tmp_dir='/scratch/lcornelis/tmp' error_protein_file_name='bimodal_aptamers_for_removal.xlsx' act='relu' gcn_hidden_channels=[8, 32, 128] lr_max=0.1 gpu_per_worker=1 wandb_tmp_dir='/tmp' weight_decay=0 reduction_factor=8 lr_scheduler_choices=['LambdaLR'] model_grid_search=['gat-v4'] gcn_num_layers=[2, 3, 4] wandb_offline=False act_choices=['relu'] project='proteo' num_nodes=30 grace_period=30 adj_thresh_choices=[0.1] gcn={'num_layers': 3, 'hidden_channels': 32} lr_min=0.1 mutation_choices=[['GRN']] raw_file_name='ALLFTD_dataset_for_nina_louisa_071124.csv' sex_choices=[['M']] num_nodes_choices=[30] mutation=['GRN'] ray_results_dir='/scratch/lcornelis/outputs/ray_results' l1_lambda_max=1e-05 batch_size=8 gat_v4_fc_dropout=[0.1] use_progress_bar=True modality='plasma' sync_batchnorm=False output_dir='/scratch/lcornelis/outputs'\n",
      "Loading data from: /home/data/data_louisa/processed/ftd_y_val_nfl_adj_thresh_0.1_num_nodes_30_mutation_GRN_plasma_sex_M_train.pt\n",
      "Loading data from: /home/data/data_louisa/processed/ftd_y_val_nfl_adj_thresh_0.1_num_nodes_30_mutation_GRN_plasma_sex_M_test.pt\n",
      "Checkpoint path TorchTrainer_2024-07-31_10-47-21/model=gat-v4,seed=19543_0_act=relu,adj_thresh=0.1000,batch_size=8,dropout=0,l1_lambda=0.0000,lr=0.1000,lr_scheduler=LambdaLR,modal_2024-07-31_10-47-21/checkpoint_000002/checkpoint.ckpt\n",
      "Original Units Train MSE: tensor(317.1137, grad_fn=<MseLossBackward0>)\n",
      "Original Units Train RMSE: tensor(17.8077, grad_fn=<SqrtBackward0>)\n",
      "Original Units Val MSE: tensor(716.7650, grad_fn=<MseLossBackward0>)\n",
      "Original Units Val RMSE: tensor(26.7725, grad_fn=<SqrtBackward0>)\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "relative_checkpoint_path = 'TorchTrainer_2024-07-31_10-47-21/model=gat-v4,seed=19543_0_act=relu,adj_thresh=0.1000,batch_size=8,dropout=0,l1_lambda=0.0000,lr=0.1000,lr_scheduler=LambdaLR,modal_2024-07-31_10-47-21/checkpoint_000002/checkpoint.ckpt'\n",
    "train_preds, train_targets, train_mse, train_rmse, val_preds, val_targets, val_mse, val_rmse = full_load_and_run_and_convert(relative_checkpoint_path, device, 2.3840692826511245, 0.9650973053482799)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "716.7650146484375\n"
     ]
    }
   ],
   "source": [
    "#Sanity check\n",
    "def compute_manual_mse(val_preds, val_targets):\n",
    "    \"\"\"\n",
    "    Manually computes the Mean Squared Error (MSE) for the given predictions and targets.\n",
    "\n",
    "    Parameters:\n",
    "    val_preds (list of list of torch.Tensor): The predicted values.\n",
    "    val_targets (list of list of torch.Tensor): The true target values.\n",
    "\n",
    "    Returns:\n",
    "    float: The computed Mean Squared Error.\n",
    "    \"\"\"\n",
    "   # Compute the squared differences\n",
    "    squared_diffs = (val_preds - val_targets) ** 2\n",
    "\n",
    "    # Compute the mean of the squared differences\n",
    "    mse = squared_diffs.mean().item()\n",
    "\n",
    "    return mse\n",
    "\n",
    "print(compute_manual_mse(val_preds, val_targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint from: /scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-07-31_10-47-21/model=gat-v4,seed=19543_0_act=relu,adj_thresh=0.1000,batch_size=8,dropout=0,l1_lambda=0.0000,lr=0.1000,lr_scheduler=LambdaLR,modal_2024-07-31_10-47-21/checkpoint_000003/checkpoint.ckpt\n",
      "Checkpoint keys: dict_keys(['epoch', 'global_step', 'pytorch-lightning_version', 'state_dict', 'loops', 'callbacks', 'optimizer_states', 'lr_schedulers', 'hparams_name', 'hyper_parameters'])\n",
      "checkpoint state_dict keys: odict_keys(['model.convs.0.att_src', 'model.convs.0.att_dst', 'model.convs.0.bias', 'model.convs.0.lin.weight', 'model.convs.1.att_src', 'model.convs.1.att_dst', 'model.convs.1.bias', 'model.convs.1.lin.weight', 'model.pools.0.weight', 'model.pools.0.bias', 'model.pools.1.weight', 'model.pools.1.bias', 'model.layer_norm.weight', 'model.layer_norm.bias', 'model.encoder.0.0.weight', 'model.encoder.0.0.bias', 'model.encoder.1.0.weight', 'model.encoder.1.0.bias', 'model.encoder.2.0.weight', 'model.encoder.2.0.bias', 'model.encoder.3.0.weight', 'model.encoder.3.0.bias', 'model.encoder.4.weight', 'model.encoder.4.bias'])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import train as proteo_train\n",
    "\n",
    "# Define a function to load the checkpoint and calculate MSE\n",
    "def load_checkpoint_and_calculate_mse(relative_checkpoint_path, levels_up=5):\n",
    "    # Get the current script directory\n",
    "    current_directory = os.getcwd()\n",
    "    \n",
    "    # Navigate up the specified number of levels\n",
    "    for _ in range(levels_up):\n",
    "        current_directory = os.path.dirname(current_directory)\n",
    "    \n",
    "    # Construct the full path to the checkpoint\n",
    "    checkpoint_path = os.path.join(current_directory, relative_checkpoint_path)\n",
    "    print(f\"Loading checkpoint from: {checkpoint_path}\")\n",
    "\n",
    "    # Check if the file exists to avoid errors\n",
    "    if not os.path.isfile(checkpoint_path):\n",
    "        raise FileNotFoundError(f\"Checkpoint file not found: {checkpoint_path}\")\n",
    "\n",
    "    # Load the checkpoint\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    print(\"Checkpoint keys:\", checkpoint.keys())\n",
    "    print(\"checkpoint state_dict keys:\", checkpoint['state_dict'].keys())\n",
    "\n",
    "    module = proteo_train.Proteo.load_from_checkpoint(checkpoint_path)\n",
    "\n",
    "    # Access the attributes\n",
    "    # best_val_pred = module.best_val_pred\n",
    "    # print(\"best_val_pred:\", best_val_pred)\n",
    "    # # print(\"min_val loss:\", module.val_loss)\n",
    "    # best_val_target = module.best_val_target\n",
    "    # best_train_pred = module.best_train_pred\n",
    "    # best_train_target = module.best_train_target\n",
    "\n",
    "    # # Calculate MSE for validation and training\n",
    "    # mse_val = F.mse_loss(best_val_pred, best_val_target).item()\n",
    "    # mse_train = F.mse_loss(best_train_pred, best_train_target).item()\n",
    "\n",
    "    return module, checkpoint\n",
    "\n",
    "# Example usage\n",
    "relative_checkpoint_path = 'scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-07-31_10-47-21/model=gat-v4,seed=19543_0_act=relu,adj_thresh=0.1000,batch_size=8,dropout=0,l1_lambda=0.0000,lr=0.1000,lr_scheduler=LambdaLR,modal_2024-07-31_10-47-21/checkpoint_000003/checkpoint.ckpt'\n",
    "module, checkpoint = load_checkpoint_and_calculate_mse(relative_checkpoint_path)\n",
    "# print(f\"MSE Loss for validation set: {mse_val}\")\n",
    "# print(f\"MSE Loss for training set: {mse_train}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'training': True,\n",
       " '_parameters': OrderedDict(),\n",
       " '_buffers': OrderedDict(),\n",
       " '_non_persistent_buffers_set': set(),\n",
       " '_backward_pre_hooks': OrderedDict(),\n",
       " '_backward_hooks': OrderedDict(),\n",
       " '_is_full_backward_hook': None,\n",
       " '_forward_hooks': OrderedDict(),\n",
       " '_forward_hooks_with_kwargs': OrderedDict(),\n",
       " '_forward_hooks_always_called': OrderedDict(),\n",
       " '_forward_pre_hooks': OrderedDict(),\n",
       " '_forward_pre_hooks_with_kwargs': OrderedDict(),\n",
       " '_state_dict_hooks': OrderedDict(),\n",
       " '_state_dict_pre_hooks': OrderedDict(),\n",
       " '_load_state_dict_pre_hooks': OrderedDict(),\n",
       " '_load_state_dict_post_hooks': OrderedDict(),\n",
       " '_modules': OrderedDict([('model',\n",
       "               GATv4(\n",
       "                 (convs): ModuleList(\n",
       "                   (0): CustomGATConv(1, 8, heads=2)\n",
       "                   (1): CustomGATConv(16, 16, heads=3)\n",
       "                 )\n",
       "                 (pools): ModuleList(\n",
       "                   (0): Linear(in_features=16, out_features=1, bias=True)\n",
       "                   (1): Linear(in_features=48, out_features=1, bias=True)\n",
       "                 )\n",
       "                 (layer_norm): LayerNorm((30,), eps=1e-05, elementwise_affine=True)\n",
       "                 (encoder): Sequential(\n",
       "                   (0): Sequential(\n",
       "                     (0): Linear(in_features=90, out_features=64, bias=True)\n",
       "                     (1): ReLU()\n",
       "                     (2): AlphaDropout(p=0.1, inplace=True)\n",
       "                   )\n",
       "                   (1): Sequential(\n",
       "                     (0): Linear(in_features=64, out_features=128, bias=True)\n",
       "                     (1): ReLU()\n",
       "                     (2): AlphaDropout(p=0.1, inplace=True)\n",
       "                   )\n",
       "                   (2): Sequential(\n",
       "                     (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "                     (1): ReLU()\n",
       "                     (2): AlphaDropout(p=0.1, inplace=True)\n",
       "                   )\n",
       "                   (3): Sequential(\n",
       "                     (0): Linear(in_features=128, out_features=32, bias=True)\n",
       "                     (1): ReLU()\n",
       "                     (2): AlphaDropout(p=0.1, inplace=True)\n",
       "                   )\n",
       "                   (4): Linear(in_features=32, out_features=1, bias=True)\n",
       "                 )\n",
       "               ))]),\n",
       " 'prepare_data_per_node': True,\n",
       " 'allow_zero_length_dataloader_with_multiple_devices': False,\n",
       " '_log_hyperparams': True,\n",
       " '_dtype': torch.float32,\n",
       " '_device': device(type='cuda', index=0),\n",
       " '_trainer': None,\n",
       " '_example_input_array': None,\n",
       " '_automatic_optimization': True,\n",
       " '_strict_loading': None,\n",
       " '_current_fx_name': None,\n",
       " '_param_requires_grad_state': {},\n",
       " '_metric_attributes': None,\n",
       " '_compiler_ctx': None,\n",
       " '_fabric': None,\n",
       " '_fabric_optimizers': [],\n",
       " '_device_mesh': None,\n",
       " '_hparams_name': 'kwargs',\n",
       " '_hparams': \"avg_node_degree\":   0.9\n",
       " \"config\":            gat_v4_weight_initializer=['uniform'] gat_hidden_channels=[8, 32, 128, 256] device=[0] root_dir='/home/lcornelis/code/proteo' checkpoint_every_n_epochs_train=1 l1_lambda=1e-05 pin_memory=True sex=['M'] wgcna_mergeCutHeight=0.25 y_val='nfl' log_every_n_steps=10 num_samples=1 gat_v4_heads=[[2, 3]] cpu_per_worker=16 nodes_count=1 adj_thresh=0.1 gat_heads=[1, 2, 4, 8] optimizer='Adam' checkpoint_dir='/scratch/lcornelis/outputs/checkpoints' num_to_keep=3 seed=19543 modality_choices=['plasma'] l1_lambda_min=1e-05 gat-v4={'hidden_channels': [8, 16], 'heads': [2, 3], 'use_layer_norm': True, 'which_layer': ['layer1', 'layer2', 'layer3'], 'fc_dim': [64, 128, 128, 32], 'fc_dropout': 0.1, 'fc_act': 'relu', 'weight_initializer': 'uniform', 'num_layers': None} lr=0.10000000000000005 wgcna_minModuleSize=10 gat_num_layers=[2, 4, 6, 12] model='gat-v4' dataset_name='ftd' y_val_choices=['nfl'] gat_v4_hidden_channels=[[8, 16]] accumulate_grad_batches=1 gat={'num_layers': 2, 'hidden_channels': 256, 'heads': 4, 'v2': True} trainer_accelerator='gpu' precision='32-true' gat_v4_fc_act=['relu'] batch_size_choices=[8] lr_scheduler='LambdaLR' num_workers=16 epochs=30 data_dir='/home/data/data_louisa' wandb_api_key_path='wandb_api_key.txt' dropout_choices=[0] dropout=0 gat_v4_fc_dim=[[64, 128, 128, 32]] ray_tmp_dir='/scratch/lcornelis/tmp' error_protein_file_name='bimodal_aptamers_for_removal.xlsx' act='relu' gcn_hidden_channels=[8, 32, 128] lr_max=0.1 gpu_per_worker=1 wandb_tmp_dir='/tmp' weight_decay=0 reduction_factor=8 lr_scheduler_choices=['LambdaLR'] model_grid_search=['gat-v4'] gcn_num_layers=[2, 3, 4] wandb_offline=False act_choices=['relu'] project='proteo' num_nodes=30 grace_period=30 adj_thresh_choices=[0.1] gcn={'num_layers': 3, 'hidden_channels': 32} lr_min=0.1 mutation_choices=[['GRN']] raw_file_name='ALLFTD_dataset_for_nina_louisa_071124.csv' sex_choices=[['M']] num_nodes_choices=[30] mutation=['GRN'] ray_results_dir='/scratch/lcornelis/outputs/ray_results' l1_lambda_max=1e-05 batch_size=8 gat_v4_fc_dropout=[0.1] use_progress_bar=True modality='plasma' sync_batchnorm=False output_dir='/scratch/lcornelis/outputs'\n",
       " \"focal_loss_weight\": [1.0]\n",
       " \"in_channels\":       1\n",
       " \"out_channels\":      1\n",
       " \"pos_weight\":        1.0,\n",
       " '_hparams_initial': \"avg_node_degree\":   0.9\n",
       " \"config\":            gat_v4_weight_initializer=['uniform'] gat_hidden_channels=[8, 32, 128, 256] device=[0] root_dir='/home/lcornelis/code/proteo' checkpoint_every_n_epochs_train=1 l1_lambda=1e-05 pin_memory=True sex=['M'] wgcna_mergeCutHeight=0.25 y_val='nfl' log_every_n_steps=10 num_samples=1 gat_v4_heads=[[2, 3]] cpu_per_worker=16 nodes_count=1 adj_thresh=0.1 gat_heads=[1, 2, 4, 8] optimizer='Adam' checkpoint_dir='/scratch/lcornelis/outputs/checkpoints' num_to_keep=3 seed=19543 modality_choices=['plasma'] l1_lambda_min=1e-05 gat-v4={'hidden_channels': [8, 16], 'heads': [2, 3], 'use_layer_norm': True, 'which_layer': ['layer1', 'layer2', 'layer3'], 'fc_dim': [64, 128, 128, 32], 'fc_dropout': 0.1, 'fc_act': 'relu', 'weight_initializer': 'uniform', 'num_layers': None} lr=0.10000000000000005 wgcna_minModuleSize=10 gat_num_layers=[2, 4, 6, 12] model='gat-v4' dataset_name='ftd' y_val_choices=['nfl'] gat_v4_hidden_channels=[[8, 16]] accumulate_grad_batches=1 gat={'num_layers': 2, 'hidden_channels': 256, 'heads': 4, 'v2': True} trainer_accelerator='gpu' precision='32-true' gat_v4_fc_act=['relu'] batch_size_choices=[8] lr_scheduler='LambdaLR' num_workers=16 epochs=30 data_dir='/home/data/data_louisa' wandb_api_key_path='wandb_api_key.txt' dropout_choices=[0] dropout=0 gat_v4_fc_dim=[[64, 128, 128, 32]] ray_tmp_dir='/scratch/lcornelis/tmp' error_protein_file_name='bimodal_aptamers_for_removal.xlsx' act='relu' gcn_hidden_channels=[8, 32, 128] lr_max=0.1 gpu_per_worker=1 wandb_tmp_dir='/tmp' weight_decay=0 reduction_factor=8 lr_scheduler_choices=['LambdaLR'] model_grid_search=['gat-v4'] gcn_num_layers=[2, 3, 4] wandb_offline=False act_choices=['relu'] project='proteo' num_nodes=30 grace_period=30 adj_thresh_choices=[0.1] gcn={'num_layers': 3, 'hidden_channels': 32} lr_min=0.1 mutation_choices=[['GRN']] raw_file_name='ALLFTD_dataset_for_nina_louisa_071124.csv' sex_choices=[['M']] num_nodes_choices=[30] mutation=['GRN'] ray_results_dir='/scratch/lcornelis/outputs/ray_results' l1_lambda_max=1e-05 batch_size=8 gat_v4_fc_dropout=[0.1] use_progress_bar=True modality='plasma' sync_batchnorm=False output_dir='/scratch/lcornelis/outputs'\n",
       " \"focal_loss_weight\": [1.0]\n",
       " \"in_channels\":       1\n",
       " \"out_channels\":      1\n",
       " \"pos_weight\":        1.0,\n",
       " 'config': Config(gat_v4_weight_initializer=['uniform'], gat_hidden_channels=[8, 32, 128, 256], device=[0], root_dir='/home/lcornelis/code/proteo', checkpoint_every_n_epochs_train=1, l1_lambda=1e-05, pin_memory=True, sex=['M'], wgcna_mergeCutHeight=0.25, y_val='nfl', log_every_n_steps=10, num_samples=1, gat_v4_heads=[[2, 3]], cpu_per_worker=16, nodes_count=1, adj_thresh=0.1, gat_heads=[1, 2, 4, 8], optimizer='Adam', checkpoint_dir='/scratch/lcornelis/outputs/checkpoints', num_to_keep=3, seed=19543, modality_choices=['plasma'], l1_lambda_min=1e-05, gat-v4={'hidden_channels': [8, 16], 'heads': [2, 3], 'use_layer_norm': True, 'which_layer': ['layer1', 'layer2', 'layer3'], 'fc_dim': [64, 128, 128, 32], 'fc_dropout': 0.1, 'fc_act': 'relu', 'weight_initializer': 'uniform', 'num_layers': None}, lr=0.10000000000000005, wgcna_minModuleSize=10, gat_num_layers=[2, 4, 6, 12], model='gat-v4', dataset_name='ftd', y_val_choices=['nfl'], gat_v4_hidden_channels=[[8, 16]], accumulate_grad_batches=1, gat={'num_layers': 2, 'hidden_channels': 256, 'heads': 4, 'v2': True}, trainer_accelerator='gpu', precision='32-true', gat_v4_fc_act=['relu'], batch_size_choices=[8], lr_scheduler='LambdaLR', num_workers=16, epochs=30, data_dir='/home/data/data_louisa', wandb_api_key_path='wandb_api_key.txt', dropout_choices=[0], dropout=0, gat_v4_fc_dim=[[64, 128, 128, 32]], ray_tmp_dir='/scratch/lcornelis/tmp', error_protein_file_name='bimodal_aptamers_for_removal.xlsx', act='relu', gcn_hidden_channels=[8, 32, 128], lr_max=0.1, gpu_per_worker=1, wandb_tmp_dir='/tmp', weight_decay=0, reduction_factor=8, lr_scheduler_choices=['LambdaLR'], model_grid_search=['gat-v4'], gcn_num_layers=[2, 3, 4], wandb_offline=False, act_choices=['relu'], project='proteo', num_nodes=30, grace_period=30, adj_thresh_choices=[0.1], gcn={'num_layers': 3, 'hidden_channels': 32}, lr_min=0.1, mutation_choices=[['GRN']], raw_file_name='ALLFTD_dataset_for_nina_louisa_071124.csv', sex_choices=[['M']], num_nodes_choices=[30], mutation=['GRN'], ray_results_dir='/scratch/lcornelis/outputs/ray_results', l1_lambda_max=1e-05, batch_size=8, gat_v4_fc_dropout=[0.1], use_progress_bar=True, modality='plasma', sync_batchnorm=False, output_dir='/scratch/lcornelis/outputs'),\n",
       " 'config_model': Config(fc_dropout=0.1, fc_dim=[64, 128, 128, 32], weight_initializer='uniform', which_layer=['layer1', 'layer2', 'layer3'], fc_act='relu', hidden_channels=[8, 16], num_layers=None, use_layer_norm=True, heads=[2, 3]),\n",
       " 'avg_node_degree': 0.9,\n",
       " 'train_preds': [],\n",
       " 'val_preds': [],\n",
       " 'train_targets': [],\n",
       " 'val_targets': [],\n",
       " 'x0': [],\n",
       " 'x1': [],\n",
       " 'x2': [],\n",
       " 'multiscale': [],\n",
       " 'pos_weight': 1.0,\n",
       " 'focal_loss_weight': [1.0],\n",
       " 'min_val_loss': 1000,\n",
       " 'min_train_loss': 1000,\n",
       " 'best_val_pred': [],\n",
       " 'best_val_target': [],\n",
       " 'best_train_pred': [],\n",
       " 'best_train_target': [],\n",
       " 'best_val_epoch': 0,\n",
       " 'best_train_epoch': 0}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epoch': 3,\n",
       " 'global_step': 16,\n",
       " 'pytorch-lightning_version': '2.3.3',\n",
       " 'state_dict': OrderedDict([('model.convs.0.att_src',\n",
       "               tensor([[[ 0.8699, -0.1098,  0.5025,  0.1256,  0.5469,  0.2400,  0.1043,\n",
       "                         -0.4770],\n",
       "                        [-0.4824,  1.1463, -0.2332, -0.3317,  1.0416, -0.4451,  0.3276,\n",
       "                         -0.4540]]], device='cuda:0')),\n",
       "              ('model.convs.0.att_dst',\n",
       "               tensor([[[ 0.8882, -0.2228,  0.5346, -0.4571,  0.3048, -0.5855,  0.1434,\n",
       "                          0.3646],\n",
       "                        [ 1.1702,  0.3941,  0.3302,  1.2372, -0.0151,  1.1996,  0.4364,\n",
       "                          1.2554]]], device='cuda:0')),\n",
       "              ('model.convs.0.bias',\n",
       "               tensor([ 0.0028,  0.4199,  0.3917,  0.4135,  0.3705,  0.4011,  0.3794,  0.3819,\n",
       "                        0.3859, -0.0071,  0.3830,  0.3899, -0.0170,  0.4089,  0.3918,  0.3970],\n",
       "                      device='cuda:0')),\n",
       "              ('model.convs.0.lin.weight',\n",
       "               tensor([[-0.4711],\n",
       "                       [ 0.5418],\n",
       "                       [ 0.6337],\n",
       "                       [-0.3248],\n",
       "                       [ 0.3261],\n",
       "                       [-0.3545],\n",
       "                       [ 0.0595],\n",
       "                       [-0.0498],\n",
       "                       [ 1.4297],\n",
       "                       [-0.4477],\n",
       "                       [-0.4088],\n",
       "                       [ 0.3578],\n",
       "                       [-0.4146],\n",
       "                       [ 0.6445],\n",
       "                       [-0.0902],\n",
       "                       [ 0.9932]], device='cuda:0')),\n",
       "              ('model.convs.1.att_src',\n",
       "               tensor([[[1.1917, 0.7222, 0.7068, 0.9594, 0.4707, 0.5403, 0.9688, 0.4180,\n",
       "                         0.8757, 1.2718, 0.5402, 0.4622, 0.8397, 0.3495, 1.2319, 1.2646],\n",
       "                        [0.5263, 1.0612, 0.7606, 0.8045, 0.5437, 0.8426, 1.0572, 0.9204,\n",
       "                         0.4130, 0.6489, 0.9891, 1.0387, 0.8894, 0.3482, 0.9735, 1.2625],\n",
       "                        [1.2177, 0.9951, 1.2310, 0.8432, 0.3753, 0.3919, 0.9882, 0.5553,\n",
       "                         0.9253, 0.3193, 0.4283, 0.5522, 1.0356, 0.8077, 0.6964, 1.1380]]],\n",
       "                      device='cuda:0')),\n",
       "              ('model.convs.1.att_dst',\n",
       "               tensor([[[ 2.2851e-01,  6.6023e-02,  3.9240e-01,  4.2826e-01,  5.7137e-04,\n",
       "                          6.6089e-03,  1.5792e-01,  3.5261e-01, -2.7796e-01, -4.9618e-01,\n",
       "                         -1.7886e-01,  4.5658e-01,  3.0075e-01, -2.1293e-01,  1.1584e-01,\n",
       "                          2.8685e-01],\n",
       "                        [ 6.6336e-01,  8.6938e-01,  5.4534e-01,  8.1039e-01,  1.2287e+00,\n",
       "                          8.7012e-01,  9.3559e-01,  3.4151e-01,  1.3049e+00,  7.5255e-01,\n",
       "                          9.7020e-01,  7.6701e-01,  1.0992e+00,  1.0491e+00,  9.3689e-01,\n",
       "                          7.4619e-01],\n",
       "                        [ 4.2625e-01,  1.1540e+00,  6.3331e-01,  9.4307e-01,  3.6823e-01,\n",
       "                          8.4688e-01,  8.3515e-01,  6.8486e-01,  1.0401e+00,  5.9690e-01,\n",
       "                          5.8642e-01,  1.1928e+00,  1.0633e+00,  9.1337e-01,  1.0645e+00,\n",
       "                          7.8064e-01]]], device='cuda:0')),\n",
       "              ('model.convs.1.bias',\n",
       "               tensor([ 0.0154, -0.0762,  0.0667,  0.0027,  0.0416,  0.1768,  0.2033,  0.0201,\n",
       "                       -0.0549,  0.0112,  0.1035, -0.0531,  0.2069,  0.2060,  0.1768,  0.1701,\n",
       "                        0.1445,  0.1051,  0.0051,  0.0213,  0.0863, -0.0753,  0.1487, -0.0189,\n",
       "                        0.0113, -0.0688,  0.0204,  0.0948,  0.1361, -0.0152, -0.0658,  0.1871,\n",
       "                        0.1665,  0.1769,  0.1715,  0.1389, -0.0479,  0.2019,  0.2383,  0.1101,\n",
       "                        0.1474, -0.0009,  0.0324,  0.0064,  0.0050, -0.0374,  0.1750, -0.0283],\n",
       "                      device='cuda:0')),\n",
       "              ('model.convs.1.lin.weight',\n",
       "               tensor([[ 7.1736e-02,  1.3522e-01,  1.4893e-01, -3.3951e-01,  4.3563e-01,\n",
       "                        -2.6730e-01,  1.8069e-01,  9.4263e-02,  1.2589e+00, -4.4568e-02,\n",
       "                         5.5074e-01,  9.1714e-01,  3.1755e-02,  1.1874e+00,  4.8382e-01,\n",
       "                         8.9080e-01],\n",
       "                       [-1.1225e-01, -1.1668e-01,  2.0552e-01,  3.8664e-01,  4.7262e-01,\n",
       "                        -1.1558e-03, -3.5312e-01,  1.5646e-01,  5.2062e-01, -1.3866e-01,\n",
       "                         3.3847e-01,  8.1411e-01,  2.3972e-02,  1.0454e+00,  3.8623e-01,\n",
       "                         9.5999e-01],\n",
       "                       [ 5.5240e-03, -3.6466e-01, -1.6754e-01,  1.7917e-01, -3.2892e-01,\n",
       "                         4.7415e-01,  3.2269e-01,  3.3668e-02,  8.2663e-01,  9.4235e-02,\n",
       "                         3.6105e-01,  9.6732e-01, -1.8575e-02,  3.8204e-01,  9.4388e-01,\n",
       "                         3.3074e-01],\n",
       "                       [-1.2975e-01, -2.2817e-01,  3.4026e-02, -1.1158e-01, -7.3286e-02,\n",
       "                        -1.7952e-02, -2.2902e-01, -2.7818e-02,  3.5293e-01, -1.8764e-02,\n",
       "                         1.2850e+00,  1.1441e+00, -1.2425e-01,  1.1528e+00,  1.2045e+00,\n",
       "                         1.0641e+00],\n",
       "                       [-2.0865e-02, -1.9213e-01,  3.2530e-01, -2.5912e-01,  3.1009e-01,\n",
       "                        -1.6589e-01, -3.5941e-01, -2.6072e-01,  1.2773e+00, -1.7017e-02,\n",
       "                         1.0105e+00,  1.0046e+00, -1.9350e-02,  9.7070e-01,  9.9010e-01,\n",
       "                         4.9643e-01],\n",
       "                       [-1.3665e-01,  8.3065e-02,  7.5696e-02,  2.9580e-01,  4.3790e-01,\n",
       "                         3.0250e-01, -2.4153e-01, -7.1324e-02,  3.8906e-01,  3.1544e-02,\n",
       "                         6.8270e-01,  1.0324e+00, -3.9267e-02,  7.8237e-01,  4.2039e-01,\n",
       "                         1.2236e+00],\n",
       "                       [-2.4079e-02,  6.6247e-01,  5.0515e-01,  2.9759e-01,  1.6365e-01,\n",
       "                        -9.6337e-02, -1.3970e-01,  7.2776e-02,  8.0196e-01, -1.1919e-01,\n",
       "                         5.9702e-01,  1.1557e+00, -1.9466e-01,  1.0742e+00,  6.2523e-01,\n",
       "                         4.6547e-01],\n",
       "                       [ 5.2347e-02, -1.4587e-01,  2.8248e-03, -4.9217e-01,  2.4063e-01,\n",
       "                         1.6017e-01, -3.9568e-01, -4.0242e-01,  7.4293e-01, -2.2510e-01,\n",
       "                         8.9835e-01,  7.2549e-01,  7.9510e-02,  1.0693e+00,  1.2556e+00,\n",
       "                         6.2609e-01],\n",
       "                       [-1.5404e-01,  3.9655e-01, -1.9434e-01, -3.7716e-01,  2.0503e-01,\n",
       "                         3.5821e-03, -2.8433e-01, -1.4523e-01,  1.1764e+00, -1.9081e-01,\n",
       "                         1.1080e+00,  1.1859e+00, -1.0694e-01,  1.3110e+00,  1.3051e+00,\n",
       "                         6.6565e-01],\n",
       "                       [-1.9557e-01,  4.3264e-02, -3.1056e-01,  4.2416e-01,  6.0505e-02,\n",
       "                        -1.0687e-02,  4.2387e-01,  1.7176e-01,  1.2705e+00,  1.0251e-01,\n",
       "                         1.1734e+00,  7.0637e-01, -1.5970e-01,  5.1959e-01,  5.5419e-01,\n",
       "                         6.0439e-01],\n",
       "                       [ 1.4808e-03, -1.2909e-01,  3.6241e-01, -3.3544e-01, -3.2416e-02,\n",
       "                        -4.0991e-01, -4.7644e-01,  2.4383e-01,  3.2733e-01,  3.6580e-02,\n",
       "                         1.0059e+00,  6.2941e-01, -1.3987e-01,  8.8848e-01,  3.2001e-01,\n",
       "                         8.5221e-01],\n",
       "                       [ 3.7396e-02,  1.5417e-02, -2.8937e-01, -2.1435e-01, -6.0967e-02,\n",
       "                        -4.7940e-03,  3.0873e-01, -1.2389e-01,  4.3744e-01,  8.6756e-03,\n",
       "                         7.1066e-01,  8.4981e-01, -3.4211e-02,  4.0085e-01,  3.8926e-01,\n",
       "                         7.0715e-01],\n",
       "                       [ 1.0226e-01,  6.6708e-01, -1.2138e-01, -3.7732e-01, -3.1482e-01,\n",
       "                        -1.8233e-01, -3.8826e-01, -2.4523e-01,  1.0347e+00,  9.4430e-02,\n",
       "                         1.1447e+00,  8.3396e-01,  9.0812e-02,  6.6889e-01,  3.2880e-01,\n",
       "                         1.2310e+00],\n",
       "                       [-2.7045e-03,  4.6978e-01, -1.3683e-01, -2.8394e-01,  6.3203e-01,\n",
       "                         8.9733e-02, -2.4257e-01,  3.5455e-01,  4.6364e-01, -4.6638e-02,\n",
       "                         5.1484e-01,  6.1425e-01,  4.2639e-02,  4.3793e-01,  6.1457e-01,\n",
       "                         1.0559e+00],\n",
       "                       [ 1.9529e-02,  5.7343e-01,  2.7771e-01,  3.8345e-01,  3.2533e-01,\n",
       "                        -2.8569e-01, -4.8652e-01, -1.6342e-01,  4.0555e-01, -2.0668e-01,\n",
       "                         1.2685e+00,  4.2564e-01,  9.7674e-03,  5.2275e-01,  1.1847e+00,\n",
       "                         3.5710e-01],\n",
       "                       [ 4.5650e-02,  7.0470e-02, -1.5244e-01,  3.2563e-01, -8.6147e-02,\n",
       "                        -4.1409e-01, -1.8819e-01, -5.3462e-02,  1.2254e+00,  1.3102e-02,\n",
       "                         3.5991e-01,  4.7668e-01,  6.2557e-02,  3.6897e-01,  7.5625e-01,\n",
       "                         1.3147e+00],\n",
       "                       [ 9.1972e-03, -8.9056e-02, -3.6483e-03,  3.9168e-01, -3.1400e-01,\n",
       "                        -3.5453e-01,  3.7409e-01,  1.2046e-02,  4.3822e-01, -2.2279e-02,\n",
       "                         1.2710e+00,  7.6577e-01,  3.8044e-02,  3.9605e-01,  1.2190e+00,\n",
       "                         4.8065e-01],\n",
       "                       [-9.9200e-02,  5.3986e-02, -6.3836e-02,  1.1156e-02,  1.0228e-01,\n",
       "                        -4.8981e-01,  1.1445e-01,  1.1347e-01,  4.3920e-01,  3.3848e-02,\n",
       "                         4.3509e-01,  1.2359e+00,  3.8849e-02,  1.0372e+00,  6.5057e-01,\n",
       "                         1.2073e+00],\n",
       "                       [ 2.7467e-02,  1.4301e-01, -1.8629e-02, -8.9204e-02, -2.9662e-01,\n",
       "                         4.7395e-02, -1.8762e-01, -4.6794e-01,  8.7391e-01,  4.5062e-02,\n",
       "                         3.2143e-01,  1.0681e+00, -1.9287e-01,  1.3115e+00,  9.9709e-01,\n",
       "                         1.0232e+00],\n",
       "                       [-2.5846e-02,  2.2496e-01,  3.6715e-01, -4.7315e-01,  3.8723e-01,\n",
       "                         2.6781e-01, -4.0068e-01,  2.0762e-01,  1.0107e+00, -3.6481e-02,\n",
       "                         1.2287e+00,  3.2660e-01,  2.6352e-02,  1.0783e+00,  7.8388e-01,\n",
       "                         4.7024e-01],\n",
       "                       [ 4.0056e-02,  3.3422e-01, -9.2732e-02,  3.7934e-01,  7.1754e-02,\n",
       "                         3.8389e-02, -1.2138e-01, -3.4320e-01,  4.5783e-01,  8.4839e-03,\n",
       "                         3.4952e-01,  4.8763e-01,  6.5753e-02,  1.1808e+00,  1.0578e+00,\n",
       "                         8.2767e-01],\n",
       "                       [-3.1775e-02, -1.9312e-01, -3.8861e-01, -4.8064e-01, -3.9037e-01,\n",
       "                        -2.1943e-01,  3.4106e-01,  2.1436e-01,  7.2864e-01, -4.8626e-02,\n",
       "                         1.1688e+00,  4.3982e-01, -1.2847e-01,  1.1607e+00,  9.4521e-01,\n",
       "                         3.9922e-01],\n",
       "                       [-1.1988e-02, -1.7812e-02,  6.0793e-01,  3.3811e-01, -6.2777e-03,\n",
       "                         2.3059e-01, -2.1983e-01, -2.9804e-01,  3.6252e-01,  8.0966e-02,\n",
       "                         1.2440e+00,  9.7963e-01,  3.8640e-02,  8.3150e-01,  1.2111e+00,\n",
       "                         6.5451e-01],\n",
       "                       [ 2.6995e-03, -3.6488e-03,  4.5555e-01,  2.7665e-01, -3.3201e-01,\n",
       "                        -1.1997e-01,  5.4174e-02, -1.8762e-01,  3.7764e-01, -8.9788e-02,\n",
       "                         3.3655e-01,  1.1540e+00, -1.5016e-01,  7.0170e-01,  7.5259e-01,\n",
       "                         6.8372e-01],\n",
       "                       [-1.1263e-01,  3.1261e-01, -3.1341e-01, -1.6695e-02, -2.6748e-01,\n",
       "                        -3.9642e-01,  2.3550e-01, -2.2336e-01,  6.2664e-01,  4.5504e-02,\n",
       "                         7.6239e-01,  9.1920e-01,  2.3262e-02,  8.9220e-01,  1.0926e+00,\n",
       "                         9.0537e-01],\n",
       "                       [ 4.2389e-02, -3.1747e-01,  8.8054e-02, -1.0833e-01,  3.8200e-01,\n",
       "                        -2.6030e-02,  1.8263e-01,  4.3090e-01,  5.3258e-01, -2.0006e-01,\n",
       "                         1.1650e+00,  8.3085e-01, -7.6755e-02,  8.1616e-01,  3.7510e-01,\n",
       "                         3.9611e-01],\n",
       "                       [-1.3581e-01,  1.0655e+00,  5.2217e-01,  5.2215e-01,  1.2508e+00,\n",
       "                         1.1414e+00,  5.7690e-01,  6.3234e-01,  1.5649e-02,  2.2487e-02,\n",
       "                        -4.7849e-01,  5.4582e-02,  4.6208e-02,  5.5871e-02,  1.8323e-01,\n",
       "                        -3.9683e-01],\n",
       "                       [-1.9337e-01, -5.0136e-01, -6.2181e-02, -3.3573e-01, -3.9316e-01,\n",
       "                         4.1019e-01,  6.0901e-02, -2.8268e-01,  9.7651e-01, -1.7719e-01,\n",
       "                         7.3601e-01,  9.5771e-01, -1.1119e-01,  1.1074e+00,  7.0648e-01,\n",
       "                         8.8765e-01],\n",
       "                       [-8.5611e-02,  4.5726e-01, -1.0388e-01,  4.5639e-01, -2.5713e-01,\n",
       "                         2.5608e-01, -2.8318e-01, -3.9379e-03,  1.2369e+00,  4.9464e-02,\n",
       "                         9.5133e-01,  1.2744e+00, -4.6856e-02,  1.0382e+00,  4.9147e-01,\n",
       "                         1.0747e+00],\n",
       "                       [-1.5918e-01,  4.5140e-01, -2.4116e-01,  1.9959e-01, -3.4585e-01,\n",
       "                        -1.9770e-01, -4.1517e-01,  2.0924e-01,  9.0130e-01, -1.6595e-01,\n",
       "                         8.4872e-01,  5.8663e-01,  3.7073e-02,  9.0606e-01,  4.0905e-01,\n",
       "                         1.3076e+00],\n",
       "                       [-1.5475e-01,  3.0583e-01,  4.1046e-01,  1.5445e-01, -2.5538e-02,\n",
       "                         9.0969e-02,  2.0429e-01,  2.8042e-01,  7.0004e-01, -3.5314e-02,\n",
       "                         4.2696e-01,  3.8325e-01, -1.5429e-01,  9.0047e-01,  4.2342e-01,\n",
       "                         6.1157e-01],\n",
       "                       [-3.3039e-02, -2.6486e-02,  1.5432e-01, -1.0545e-01, -3.0813e-01,\n",
       "                        -9.8120e-02, -4.6161e-01, -1.7609e-01,  1.1023e+00,  8.4598e-02,\n",
       "                         1.2289e+00,  6.9098e-01,  2.2358e-02,  4.0070e-01,  4.2724e-01,\n",
       "                         3.5137e-01],\n",
       "                       [ 1.5834e-02,  6.6536e-01,  3.5643e-01,  4.5723e-01,  5.9453e-01,\n",
       "                        -4.8269e-01,  4.3741e-01, -2.6967e-01,  4.2943e-01, -1.0051e-01,\n",
       "                         1.1386e+00,  3.2133e-01,  7.4181e-02,  7.2200e-01,  1.1633e+00,\n",
       "                         7.7839e-01],\n",
       "                       [-4.6613e-02,  2.9707e-01,  6.1402e-01, -4.3877e-01,  5.8898e-01,\n",
       "                        -1.5380e-01,  1.4991e-01,  4.7526e-01,  8.0565e-01, -1.6847e-01,\n",
       "                         6.8888e-01,  5.0817e-01,  4.7645e-02,  1.0933e+00,  1.0376e+00,\n",
       "                         9.6279e-01],\n",
       "                       [ 6.9346e-02, -2.1498e-01, -7.6434e-02, -4.1419e-02,  5.8131e-01,\n",
       "                        -2.9000e-02, -1.9885e-01, -3.8090e-02,  1.0837e+00,  9.3918e-02,\n",
       "                         1.0163e+00,  1.1369e+00, -1.7241e-01,  6.4891e-01,  6.6903e-01,\n",
       "                         1.2070e+00],\n",
       "                       [-1.2504e-02, -1.8971e-01,  1.8318e-01,  2.6482e-01,  3.9278e-01,\n",
       "                        -4.4808e-01,  3.0155e-01, -3.2890e-02,  7.1449e-01, -1.2064e-02,\n",
       "                         9.7032e-01,  9.1126e-01, -4.0417e-03,  9.3587e-01,  1.0689e+00,\n",
       "                         9.7622e-01],\n",
       "                       [-5.1501e-03,  2.2574e-01, -2.5183e-01,  3.8389e-01, -1.9392e-02,\n",
       "                         7.6063e-03,  4.4675e-01,  4.0637e-01,  9.7445e-01, -1.7869e-01,\n",
       "                         1.1518e+00,  8.1862e-01,  6.3806e-03,  7.8897e-01,  4.1199e-01,\n",
       "                         3.3335e-01],\n",
       "                       [-2.3037e-02, -1.3841e-01,  5.6669e-01, -1.3834e-01,  4.0895e-01,\n",
       "                        -2.1298e-02, -2.9747e-01,  6.8040e-02,  1.0392e+00, -5.8738e-02,\n",
       "                         5.6883e-01,  8.6143e-01,  2.1476e-02,  8.8746e-01,  3.4399e-01,\n",
       "                         1.0825e+00],\n",
       "                       [ 2.0129e-02, -1.3807e-01,  6.4568e-01,  1.8037e-01,  2.4481e-01,\n",
       "                         2.7824e-01,  1.8329e-01, -3.2549e-02,  5.1127e-01,  1.0593e-02,\n",
       "                         4.5863e-01,  4.0386e-01,  8.8307e-03,  1.0047e+00,  6.7807e-01,\n",
       "                         5.4146e-01],\n",
       "                       [-1.4694e-01, -1.5923e-01,  2.5635e-01, -2.6600e-01,  6.4952e-01,\n",
       "                        -8.5625e-02,  3.1884e-01, -1.1893e-01,  8.8642e-01, -1.4262e-01,\n",
       "                         6.5139e-01,  1.2528e+00, -1.5038e-01,  1.2590e+00,  1.2512e+00,\n",
       "                         4.1932e-01],\n",
       "                       [ 9.2629e-02, -2.7425e-01, -7.7972e-02, -2.2426e-01, -1.4638e-01,\n",
       "                         3.0482e-01, -2.8589e-01,  4.3616e-02,  7.6682e-01,  5.1140e-02,\n",
       "                         7.0700e-01,  1.1614e+00, -2.1021e-01,  9.0958e-01,  9.6006e-01,\n",
       "                         1.1057e+00],\n",
       "                       [-9.5277e-02, -3.4338e-01, -2.7273e-01, -1.0611e-03, -7.8319e-02,\n",
       "                        -4.2521e-01,  2.7549e-01,  3.5166e-01,  1.0968e+00, -5.4308e-02,\n",
       "                         1.2394e+00,  9.1833e-01, -1.3755e-01,  1.2984e+00,  3.7779e-01,\n",
       "                         4.6390e-01],\n",
       "                       [ 5.4512e-02,  3.8877e-01,  4.6370e-01, -1.1602e-01,  3.9314e-01,\n",
       "                        -4.2108e-01, -2.6114e-01,  2.6783e-01,  3.4814e-01,  2.1485e-02,\n",
       "                         7.1918e-01,  4.2111e-01,  1.6979e-02,  7.9853e-01,  6.0126e-01,\n",
       "                         1.0481e+00],\n",
       "                       [ 9.1638e-02, -4.4327e-01,  4.6049e-01, -4.3011e-01,  2.4298e-01,\n",
       "                        -1.1272e-01, -3.6909e-01,  4.6909e-02,  1.1865e+00,  2.0790e-02,\n",
       "                         8.3188e-01,  1.1967e+00, -1.0152e-01,  8.4526e-01,  4.0961e-01,\n",
       "                         1.2834e+00],\n",
       "                       [-9.3461e-02,  3.0817e-01, -4.9252e-01,  4.6254e-01, -3.1020e-01,\n",
       "                        -2.9223e-01,  4.4208e-01,  2.7518e-01,  1.0227e+00,  3.6358e-02,\n",
       "                         1.1321e+00,  1.0608e+00, -3.3602e-02,  6.0096e-01,  1.0979e+00,\n",
       "                         9.3436e-01],\n",
       "                       [ 3.5379e-02, -2.0671e-01, -3.0402e-01, -3.5074e-01,  1.5908e-01,\n",
       "                         2.3807e-01,  7.2662e-03,  1.9889e-01,  6.6937e-01, -3.0393e-02,\n",
       "                         1.0105e+00,  1.0078e+00, -1.7113e-02,  7.6377e-01,  7.4791e-01,\n",
       "                         1.1649e+00],\n",
       "                       [ 1.0081e-01, -2.8995e-01, -2.5610e-01, -4.0657e-01,  4.4205e-01,\n",
       "                         4.1135e-01,  4.4076e-01,  4.3168e-01,  1.0796e+00, -2.8407e-02,\n",
       "                         1.2033e+00,  9.3742e-01,  5.1421e-02,  7.7606e-01,  1.1347e+00,\n",
       "                         7.7915e-01],\n",
       "                       [-3.0917e-02,  2.8386e-01, -4.0190e-01, -4.1234e-01,  1.1584e-01,\n",
       "                        -4.9884e-01,  2.0277e-02, -4.7154e-01,  9.1425e-01,  1.7423e-02,\n",
       "                         1.2285e+00,  6.8144e-01,  4.5769e-02,  5.4337e-01,  6.7423e-01,\n",
       "                         7.2287e-01]], device='cuda:0')),\n",
       "              ('model.pools.0.weight',\n",
       "               tensor([[-0.1163, -0.4239, -0.4751,  0.3938,  0.0738,  0.0506, -0.2292, -0.4918,\n",
       "                         1.2921, -0.0316,  0.7499,  0.6540,  0.4399,  0.8005,  0.9052,  1.0883]],\n",
       "                      device='cuda:0')),\n",
       "              ('model.pools.0.bias', tensor([0.3874], device='cuda:0')),\n",
       "              ('model.pools.1.weight',\n",
       "               tensor([[ 0.9590, -0.1283,  1.0043,  0.4156,  0.4681,  0.4570,  0.5731,  1.0084,\n",
       "                         0.8613,  0.9355,  0.2088,  0.0261,  1.2970,  0.6097,  0.4518,  1.3081,\n",
       "                         0.1984,  1.0083,  0.5370, -0.2219,  0.2832,  0.8167,  0.3687, -0.1515,\n",
       "                         0.9866,  0.0267,  0.3702,  0.9976,  1.0060,  0.4962, -0.1699,  1.3003,\n",
       "                         0.4830,  0.5049,  1.1642,  1.1487, -0.0359,  1.2726,  0.6404,  1.1117,\n",
       "                         1.2148,  0.7029,  0.1347,  0.9630,  0.6314,  0.6962,  1.1360,  0.7280]],\n",
       "                      device='cuda:0')),\n",
       "              ('model.pools.1.bias', tensor([0.2097], device='cuda:0')),\n",
       "              ('model.layer_norm.weight',\n",
       "               tensor([0.4899, 0.6833, 0.6833, 0.4896, 0.4896, 0.4896, 0.6832, 0.4897, 0.4897,\n",
       "                       0.6832, 0.4896, 0.4901, 0.6834, 0.6833, 0.6833, 0.6832, 0.6835, 0.6833,\n",
       "                       0.4896, 0.6832, 0.6833, 0.6833, 0.6839, 0.6831, 0.4897, 0.4898, 0.4898,\n",
       "                       0.6831, 1.3137, 0.4898], device='cuda:0')),\n",
       "              ('model.layer_norm.bias',\n",
       "               tensor([-0.5102,  0.3167, -0.3167, -0.3167,  0.5102, -0.5102, -0.3167, -0.3167,\n",
       "                        0.5102, -0.3167,  0.5103, -0.5102, -0.5102, -0.3167,  0.3167,  0.3167,\n",
       "                       -0.3167, -0.5106,  0.5103, -0.3167, -0.3167,  0.3167,  0.3166, -0.3167,\n",
       "                        0.5101,  0.5102,  0.5102, -0.5103,  0.5102,  0.5102], device='cuda:0')),\n",
       "              ('model.encoder.0.0.weight',\n",
       "               tensor([[-0.4830,  0.5258, -0.4381,  ..., -0.4092,  0.4276,  0.3620],\n",
       "                       [-0.5188,  0.5598, -0.5616,  ..., -0.2571,  0.2031,  0.4476],\n",
       "                       [ 0.3256, -0.4137,  0.5006,  ...,  0.3992,  0.4222, -0.4339],\n",
       "                       ...,\n",
       "                       [-0.4008,  0.3866, -0.2587,  ..., -0.2367, -0.4671,  0.2770],\n",
       "                       [-0.3966,  0.4903, -0.5041,  ..., -0.4852, -0.4561,  0.4126],\n",
       "                       [-0.3811,  0.3222, -0.3170,  ..., -0.3310, -0.4462,  0.4781]],\n",
       "                      device='cuda:0')),\n",
       "              ('model.encoder.0.0.bias',\n",
       "               tensor([-0.4668, -0.5850,  0.4689, -0.3211, -0.3593, -0.3853, -0.3867, -0.3432,\n",
       "                       -0.2280, -0.2907, -0.3442, -0.3680, -0.2834, -0.2824, -0.3994, -0.4129,\n",
       "                        0.4098, -0.5285,  0.4982, -0.3631, -0.3564, -0.5737, -0.4609, -0.5945,\n",
       "                       -0.2143, -0.4115, -0.2436, -0.5039, -0.4068, -0.4763, -0.2964, -0.6170,\n",
       "                       -0.2669, -0.4815, -0.6216, -0.2822, -0.3925, -0.3853, -0.3334, -0.4454,\n",
       "                       -0.4894, -0.4189, -0.4469, -0.5863, -0.2476, -0.4148, -0.2455, -0.6108,\n",
       "                       -0.5329, -0.4655, -0.3364, -0.2993, -0.3250,  0.4140, -0.4189, -0.4155,\n",
       "                       -0.4316, -0.5457, -0.4583, -0.3373, -0.2911, -0.3170, -0.3730, -0.4272],\n",
       "                      device='cuda:0')),\n",
       "              ('model.encoder.1.0.weight',\n",
       "               tensor([[ 0.4469,  0.4070,  0.5987,  ...,  0.3895,  0.5302,  0.4931],\n",
       "                       [ 0.5903,  0.4769,  0.2720,  ...,  0.3679,  0.3963,  0.2331],\n",
       "                       [-0.4529, -0.4106, -0.4613,  ..., -0.4295, -0.4243, -0.4785],\n",
       "                       ...,\n",
       "                       [-0.2807, -0.3537, -0.3391,  ..., -0.3123, -0.3530, -0.1920],\n",
       "                       [-0.1943, -0.2130, -0.1461,  ..., -0.1860, -0.6303, -0.1433],\n",
       "                       [-0.3077,  0.3872, -0.3316,  ..., -0.4617, -0.4599, -0.3859]],\n",
       "                      device='cuda:0')),\n",
       "              ('model.encoder.1.0.bias',\n",
       "               tensor([ 0.5857,  0.3298, -0.4832, -0.2361, -0.3867, -0.3682, -0.2590, -0.3263,\n",
       "                       -0.5930, -0.6970, -0.5639, -0.5767, -0.3185, -0.4730, -0.7832, -0.5488,\n",
       "                       -0.4070, -0.4218, -0.3419, -0.3116, -0.4284, -0.4602,  0.5629, -0.4023,\n",
       "                       -0.4206, -0.5514, -0.2469, -0.2566, -0.4464,  0.5045, -0.2062, -0.1187,\n",
       "                       -0.2054, -0.3010, -0.3170, -0.1937, -0.4948,  0.5337, -0.5040, -0.3453,\n",
       "                       -0.2185, -0.8756, -0.6133, -0.6739, -0.3583, -0.4311, -0.1944, -0.3186,\n",
       "                       -0.3182, -0.4915, -0.2618, -0.5477, -0.4900, -0.2205, -0.5807, -0.3853,\n",
       "                       -0.2089, -0.2315, -0.3955, -0.6416, -0.3677, -0.5061, -0.2142, -0.6039,\n",
       "                       -0.3053, -0.4681, -0.2573, -0.2915, -0.1988, -0.2248, -0.1922, -0.3775,\n",
       "                       -0.5230, -0.2014, -0.3232,  0.4662, -0.4246, -0.4072, -0.3189, -0.4418,\n",
       "                       -0.3942, -0.6528, -0.1963, -0.1437, -0.0380, -0.4027, -0.0468, -0.2220,\n",
       "                        0.5195, -0.5140, -0.1269, -0.4994, -0.1964, -0.4830,  0.4588, -0.2594,\n",
       "                       -0.5722, -0.5010, -0.3627, -0.4389, -0.5443, -0.2721, -0.2979, -0.6138,\n",
       "                       -0.4116, -0.2426, -0.5498, -0.3211, -0.4244, -0.2681, -0.1113, -0.3468,\n",
       "                        0.5259, -0.3904,  0.2686, -0.5697, -0.4060, -0.2484, -0.5125, -0.5160,\n",
       "                       -0.5004, -0.2972, -0.5005,  0.6210, -0.3733, -0.3935, -0.1220, -0.3954],\n",
       "                      device='cuda:0')),\n",
       "              ('model.encoder.2.0.weight',\n",
       "               tensor([[-0.4795, -0.5352, -0.4795,  ..., -0.3809,  0.3937, -0.4195],\n",
       "                       [-0.2335, -0.6471,  0.6971,  ...,  0.0381, -0.5749,  0.0127],\n",
       "                       [-0.5383, -0.4133, -0.4401,  ..., -0.4512, -0.4223,  0.3694],\n",
       "                       ...,\n",
       "                       [-0.4615, -0.3637, -0.3745,  ...,  0.3833, -0.5197, -0.4610],\n",
       "                       [ 0.4892,  0.2327,  0.5838,  ...,  0.3720,  0.5209, -0.2499],\n",
       "                       [-0.5593, -0.3487, -0.5311,  ...,  0.5694, -0.2773, -0.4723]],\n",
       "                      device='cuda:0')),\n",
       "              ('model.encoder.2.0.bias',\n",
       "               tensor([-0.4798, -0.6774, -0.3944, -0.5526, -0.2651, -0.4200, -0.5704, -0.2420,\n",
       "                        0.4705, -0.2953, -0.3994,  0.2624, -0.3065, -0.3491,  0.5087, -0.4854,\n",
       "                       -0.4777, -0.2431, -0.5671, -0.3672, -0.2312, -0.3908, -0.2937, -0.4050,\n",
       "                       -0.4167,  0.4923, -0.3314, -0.6302, -0.4888, -0.3551,  0.5521, -0.2802,\n",
       "                       -0.5971, -0.3062, -0.2651, -0.4228,  0.4705,  0.4320, -0.5145, -0.3276,\n",
       "                       -0.5955, -0.3433, -0.4031, -0.2616, -0.5948, -0.2985, -0.5391, -0.3033,\n",
       "                       -0.2945, -0.3917,  0.0325, -0.2320, -0.6144, -0.5345, -0.4622, -0.3902,\n",
       "                       -0.6107, -0.3677, -0.5236, -0.3890,  0.4592, -0.4145, -0.4037, -0.4433,\n",
       "                       -0.3677,  0.5209, -0.2667, -0.5261, -0.3977, -0.3095, -0.4372, -0.4350,\n",
       "                       -0.2956, -0.3632, -0.4552, -0.3614, -0.3867, -0.5081, -0.2504, -0.3247,\n",
       "                       -0.3323, -0.3936, -0.3640, -0.4071, -0.2354, -0.4096, -0.3978, -0.5368,\n",
       "                       -0.2465,  0.5701, -0.4453, -0.3147, -0.4580, -0.3504, -0.4709, -0.3893,\n",
       "                       -0.2791, -0.2939, -0.5697,  0.5142, -0.2735, -0.5777, -0.3836, -0.3783,\n",
       "                       -0.5968, -0.4805, -0.4818, -0.3769, -0.4048,  0.3633, -0.4861, -0.2625,\n",
       "                       -0.3337, -0.7360, -0.4173, -0.5330, -0.2297, -0.4101,  0.4924, -0.3438,\n",
       "                        0.4980, -0.4022, -0.3809, -0.3788, -0.3136, -0.5411,  0.5761, -0.5133],\n",
       "                      device='cuda:0')),\n",
       "              ('model.encoder.3.0.weight',\n",
       "               tensor([[-0.3421,  0.4297,  0.3897,  ...,  0.4475, -0.4741,  0.4030],\n",
       "                       [-0.2926, -0.3196, -0.4330,  ...,  0.3957, -0.2691,  0.5569],\n",
       "                       [-0.4854, -0.3915,  0.4377,  ..., -0.4983, -0.4222, -0.4357],\n",
       "                       ...,\n",
       "                       [-0.3868, -0.4828,  0.4727,  ...,  0.4539, -0.4986, -0.3952],\n",
       "                       [-0.5127, -0.5086, -0.4553,  ...,  0.5150, -0.4796, -0.5125],\n",
       "                       [-0.4961, -0.5340, -0.5210,  ...,  0.5074, -0.3821, -0.5561]],\n",
       "                      device='cuda:0')),\n",
       "              ('model.encoder.3.0.bias',\n",
       "               tensor([-0.3629, -0.3604, -0.4974, -0.2746, -0.5392, -0.4961, -0.3200, -0.5230,\n",
       "                       -0.3545, -0.4342, -0.4084, -0.2883, -0.3043,  0.2421, -0.4686, -0.3190,\n",
       "                       -0.3100, -0.5207, -0.3956, -0.4622, -0.5333, -0.4848, -0.3191, -0.3343,\n",
       "                       -0.4845, -0.2309, -0.2616, -0.4807, -0.2951, -0.5196, -0.5434, -0.5394],\n",
       "                      device='cuda:0')),\n",
       "              ('model.encoder.4.weight',\n",
       "               tensor([[ 0.5737,  0.2405,  0.0151,  0.0422,  1.1278,  1.2945, -0.2295,  0.4269,\n",
       "                        -0.1368,  0.5501,  0.9376,  0.2154,  0.5603, -0.4166,  0.6569, -0.3014,\n",
       "                         0.5105,  0.4474,  0.4973,  0.8146,  0.7387,  1.0560, -0.1424,  0.0937,\n",
       "                         0.6073,  0.1036,  0.1108, -0.2918,  0.0224,  1.0422,  0.1376,  0.8495]],\n",
       "                      device='cuda:0')),\n",
       "              ('model.encoder.4.bias', tensor([-0.3038], device='cuda:0'))]),\n",
       " 'loops': {'fit_loop': {'state_dict': {},\n",
       "   'epoch_loop.state_dict': {'_batches_that_stepped': 15},\n",
       "   'epoch_loop.batch_progress': {'total': {'ready': 16,\n",
       "     'completed': 16,\n",
       "     'started': 16,\n",
       "     'processed': 16},\n",
       "    'current': {'ready': 4, 'completed': 4, 'started': 4, 'processed': 4},\n",
       "    'is_last_batch': True},\n",
       "   'epoch_loop.scheduler_progress': {'total': {'ready': 4, 'completed': 4},\n",
       "    'current': {'ready': 1, 'completed': 1}},\n",
       "   'epoch_loop.automatic_optimization.state_dict': {},\n",
       "   'epoch_loop.automatic_optimization.optim_progress': {'optimizer': {'step': {'total': {'ready': 16,\n",
       "       'completed': 16},\n",
       "      'current': {'ready': 4, 'completed': 4}},\n",
       "     'zero_grad': {'total': {'ready': 16, 'completed': 16, 'started': 16},\n",
       "      'current': {'ready': 4, 'completed': 4, 'started': 4}}}},\n",
       "   'epoch_loop.manual_optimization.state_dict': {},\n",
       "   'epoch_loop.manual_optimization.optim_step_progress': {'total': {'ready': 0,\n",
       "     'completed': 0},\n",
       "    'current': {'ready': 0, 'completed': 0}},\n",
       "   'epoch_loop.val_loop.state_dict': {},\n",
       "   'epoch_loop.val_loop.batch_progress': {'total': {'ready': 1,\n",
       "     'completed': 1,\n",
       "     'started': 1,\n",
       "     'processed': 1},\n",
       "    'current': {'ready': 1, 'completed': 1, 'started': 1, 'processed': 1},\n",
       "    'is_last_batch': True},\n",
       "   'epoch_progress': {'total': {'ready': 4,\n",
       "     'completed': 3,\n",
       "     'started': 4,\n",
       "     'processed': 3},\n",
       "    'current': {'ready': 4, 'completed': 3, 'started': 4, 'processed': 3}}},\n",
       "  'validate_loop': {'state_dict': {},\n",
       "   'batch_progress': {'total': {'ready': 0,\n",
       "     'completed': 0,\n",
       "     'started': 0,\n",
       "     'processed': 0},\n",
       "    'current': {'ready': 0, 'completed': 0, 'started': 0, 'processed': 0},\n",
       "    'is_last_batch': False}},\n",
       "  'test_loop': {'state_dict': {},\n",
       "   'batch_progress': {'total': {'ready': 0,\n",
       "     'completed': 0,\n",
       "     'started': 0,\n",
       "     'processed': 0},\n",
       "    'current': {'ready': 0, 'completed': 0, 'started': 0, 'processed': 0},\n",
       "    'is_last_batch': False}},\n",
       "  'predict_loop': {'state_dict': {},\n",
       "   'batch_progress': {'total': {'ready': 0,\n",
       "     'completed': 0,\n",
       "     'started': 0,\n",
       "     'processed': 0},\n",
       "    'current': {'ready': 0, 'completed': 0, 'started': 0, 'processed': 0}}}},\n",
       " 'callbacks': {\"ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}\": {'monitor': None,\n",
       "   'best_model_score': None,\n",
       "   'best_model_path': '/scratch/lcornelis/tmp/session_2024-07-31_10-47-18_326539_1590544/artifacts/2024-07-31_10-47-21/TorchTrainer_2024-07-31_10-47-21/working_dirs/model=gat-v4,seed=19543_0_act=relu,adj_thresh=0.1000,batch_size=8,dropout=0,l1_lambda=0.0000,lr=0.1000,lr_scheduler=LambdaLR,modal_2024-07-31_10-47-21/lightning_logs/version_0/checkpoints/epoch=2-step=12.ckpt',\n",
       "   'current_score': None,\n",
       "   'dirpath': '/scratch/lcornelis/tmp/session_2024-07-31_10-47-18_326539_1590544/artifacts/2024-07-31_10-47-21/TorchTrainer_2024-07-31_10-47-21/working_dirs/model=gat-v4,seed=19543_0_act=relu,adj_thresh=0.1000,batch_size=8,dropout=0,l1_lambda=0.0000,lr=0.1000,lr_scheduler=LambdaLR,modal_2024-07-31_10-47-21/lightning_logs/version_0/checkpoints',\n",
       "   'best_k_models': {},\n",
       "   'kth_best_model_path': '',\n",
       "   'kth_value': tensor(inf),\n",
       "   'last_model_path': ''}},\n",
       " 'optimizer_states': [{'state': {0: {'step': tensor(16.),\n",
       "     'exp_avg': tensor([[[-9.1445e-01,  1.0453e+01,  1.1502e+01,  6.7254e-01,  8.0220e+00,\n",
       "                3.3969e-01,  5.0162e+00,  3.7287e+00],\n",
       "              [ 2.2905e+02, -7.5417e+00,  1.1749e+00,  1.7219e+02, -7.4508e-02,\n",
       "                5.1843e+01,  7.3104e+01,  1.3056e+02]]], device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([[[5.5886e-01, 1.8625e+02, 2.2427e+02, 1.6129e+00, 1.1174e+02,\n",
       "               7.2363e-01, 4.5776e+01, 2.6264e+01],\n",
       "              [9.8954e+04, 1.0964e+02, 2.2497e+00, 5.5830e+04, 5.8162e-02,\n",
       "               5.0822e+03, 1.0049e+04, 3.2170e+04]]], device='cuda:0')},\n",
       "    1: {'step': tensor(16.),\n",
       "     'exp_avg': tensor([[[ 7.7276e-03, -1.0405e-02, -1.2052e-02,  5.1579e-03, -6.5022e-03,\n",
       "                5.6874e-03, -1.7283e-03,  1.3545e-04],\n",
       "              [-2.6715e-04,  2.1761e-05,  1.1459e-05, -1.9068e-04, -8.6999e-08,\n",
       "               -5.7808e-05, -7.3514e-05, -1.5080e-04]]], device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([[[1.1247e-05, 2.2317e-05, 2.9846e-05, 4.9294e-06, 8.9793e-06,\n",
       "               6.0271e-06, 7.9511e-07, 4.8538e-08],\n",
       "              [1.2793e-07, 1.6467e-10, 1.4717e-11, 7.2062e-08, 1.2406e-11,\n",
       "               6.5531e-09, 1.2929e-08, 4.1558e-08]]], device='cuda:0')},\n",
       "    2: {'step': tensor(16.),\n",
       "     'exp_avg': tensor([-1.2262e-06, -1.4249e-04, -1.6160e-04, -1.2611e-04, -2.1467e-04,\n",
       "             -1.1958e-04, -1.6117e-04, -1.4943e-04, -1.6198e-04, -1.2261e-06,\n",
       "             -1.5588e-04, -1.5372e-04,  3.1310e-06, -1.5182e-04, -1.5456e-04,\n",
       "             -1.7698e-04], device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([1.4895e-12, 4.2720e-08, 5.3044e-08, 3.3741e-08, 8.9587e-08, 3.0531e-08,\n",
       "             5.2165e-08, 4.5396e-08, 4.9576e-08, 1.4895e-12, 5.0429e-08, 4.4589e-08,\n",
       "             1.4895e-12, 4.3782e-08, 4.7048e-08, 5.8479e-08], device='cuda:0')},\n",
       "    3: {'step': tensor(16.),\n",
       "     'exp_avg': tensor([[  5.1859],\n",
       "             [ 12.2044],\n",
       "             [ 15.8837],\n",
       "             [ 70.8571],\n",
       "             [ 55.5201],\n",
       "             [ 46.5406],\n",
       "             [ 26.0609],\n",
       "             [  1.9243],\n",
       "             [-42.9958],\n",
       "             [164.8312],\n",
       "             [ 19.1420],\n",
       "             [  1.5567],\n",
       "             [129.0923],\n",
       "             [-27.0836],\n",
       "             [147.0688],\n",
       "             [-34.2917]], device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([[3.8020e+01],\n",
       "             [2.5673e+02],\n",
       "             [4.0857e+02],\n",
       "             [9.4208e+03],\n",
       "             [5.7416e+03],\n",
       "             [4.0386e+03],\n",
       "             [1.2286e+03],\n",
       "             [4.7420e+00],\n",
       "             [3.4513e+03],\n",
       "             [5.1260e+04],\n",
       "             [6.8511e+02],\n",
       "             [4.9377e+00],\n",
       "             [3.1467e+04],\n",
       "             [1.3727e+03],\n",
       "             [4.0762e+04],\n",
       "             [2.1957e+03]], device='cuda:0')},\n",
       "    4: {'step': tensor(16.),\n",
       "     'exp_avg': tensor([[[-0.0625, -0.0335, -0.0342, -0.0452, -0.0599, -0.0381, -0.0465,\n",
       "               -0.0403, -0.0705, -0.0464, -0.0175, -0.0205, -0.0519, -0.0271,\n",
       "               -0.0137, -0.0528],\n",
       "              [-0.0246, -0.0470, -0.0550, -0.0365, -0.0299, -0.0242, -0.0355,\n",
       "               -0.0337, -0.0418, -0.0248, -0.0387, -0.0467, -0.0665, -0.0430,\n",
       "               -0.0274, -0.0311],\n",
       "              [-0.0415, -0.0703, -0.0898, -0.0715, -0.0525, -0.0772, -0.0328,\n",
       "               -0.0836, -0.0766, -0.0640, -0.0374, -0.0962, -0.0821, -0.0662,\n",
       "               -0.0810, -0.0523]]], device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([[[0.0071, 0.0020, 0.0021, 0.0037, 0.0066, 0.0026, 0.0039, 0.0030,\n",
       "               0.0091, 0.0039, 0.0005, 0.0008, 0.0049, 0.0013, 0.0003, 0.0051],\n",
       "              [0.0011, 0.0040, 0.0055, 0.0024, 0.0016, 0.0010, 0.0023, 0.0021,\n",
       "               0.0032, 0.0011, 0.0029, 0.0039, 0.0081, 0.0033, 0.0014, 0.0017],\n",
       "              [0.0032, 0.0091, 0.0148, 0.0094, 0.0050, 0.0109, 0.0019, 0.0129,\n",
       "               0.0107, 0.0074, 0.0025, 0.0169, 0.0123, 0.0080, 0.0120, 0.0050]]],\n",
       "            device='cuda:0')},\n",
       "    5: {'step': tensor(16.),\n",
       "     'exp_avg': tensor([[[ 1.4529e-04,  1.0601e-04,  7.4306e-05,  8.3816e-05,  1.2283e-04,\n",
       "                1.1051e-04,  1.4759e-04,  8.9636e-05,  1.1915e-04,  9.1828e-05,\n",
       "                6.6148e-05,  7.1268e-05,  1.1215e-04,  9.7590e-05,  9.9077e-05,\n",
       "                1.0516e-04],\n",
       "              [-1.1497e-04, -1.7171e-04, -1.6101e-04, -1.8422e-04, -1.3823e-04,\n",
       "               -8.2452e-05, -1.6722e-04, -1.5135e-04, -1.4314e-04, -1.3748e-04,\n",
       "               -1.5304e-04, -1.1508e-04, -2.0665e-04, -1.4626e-04, -1.7608e-04,\n",
       "               -1.1353e-04],\n",
       "              [-7.4994e-04, -8.8545e-04, -7.0070e-04, -6.8494e-04, -5.7774e-04,\n",
       "               -7.5335e-04, -5.7699e-04, -7.8609e-04, -5.2952e-04, -4.9301e-04,\n",
       "               -6.4560e-04, -7.3518e-04, -6.3567e-04, -5.2031e-04, -6.7383e-04,\n",
       "               -4.6535e-04]]], device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([[[3.0412e-08, 1.5543e-08, 7.3014e-09, 9.0388e-09, 2.1237e-08,\n",
       "               1.7115e-08, 3.2297e-08, 1.0633e-08, 2.5674e-08, 1.6023e-08,\n",
       "               8.1029e-09, 6.5730e-09, 1.7059e-08, 1.7699e-08, 1.3957e-08,\n",
       "               1.4870e-08],\n",
       "              [2.9101e-08, 6.2676e-08, 5.5824e-08, 7.1700e-08, 4.1558e-08,\n",
       "               1.5986e-08, 5.9281e-08, 4.9072e-08, 4.4375e-08, 4.0854e-08,\n",
       "               4.9417e-08, 2.9761e-08, 8.9795e-08, 4.6590e-08, 6.5575e-08,\n",
       "               2.8802e-08],\n",
       "              [1.0322e-06, 1.4264e-06, 8.9056e-07, 8.5681e-07, 6.1376e-07,\n",
       "               1.0268e-06, 6.1153e-07, 1.1289e-06, 5.1088e-07, 4.4296e-07,\n",
       "               7.6241e-07, 9.7471e-07, 7.3948e-07, 4.9514e-07, 8.3082e-07,\n",
       "               3.9607e-07]]], device='cuda:0')},\n",
       "    6: {'step': tensor(16.),\n",
       "     'exp_avg': tensor([ 5.9390e-06,  2.6377e-06,  5.6549e-06,  1.2127e-06,  4.4805e-07,\n",
       "              4.6585e-06,  4.2636e-06,  5.9161e-06,  2.5559e-06,  5.9617e-06,\n",
       "              5.4057e-06,  4.2811e-06,  4.1898e-06,  4.2201e-06,  4.6598e-06,\n",
       "              4.7358e-06,  5.0347e-06,  5.3852e-06, -1.2356e-06, -3.4067e-06,\n",
       "              5.5351e-06,  2.6234e-06,  4.9884e-06, -2.4759e-06,  5.9610e-06,\n",
       "              2.6118e-06, -1.2016e-06,  5.4575e-06,  5.1096e-06,  5.7291e-07,\n",
       "              1.0949e-06,  4.5051e-06,  4.7885e-06,  4.6599e-06,  4.7113e-06,\n",
       "              5.0834e-06,  1.0369e-06,  4.2741e-06,  3.5657e-06,  5.3475e-06,\n",
       "              4.9995e-06, -2.5335e-06,  5.8649e-06,  5.9849e-06,  1.1124e-06,\n",
       "             -2.4459e-06,  4.6712e-06, -1.4815e-06], device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([7.1994e-12, 4.4585e-12, 9.2285e-12, 1.4826e-12, 1.7312e-12, 1.8844e-11,\n",
       "             2.3638e-11, 7.3448e-12, 4.7838e-12, 7.0565e-12, 1.1374e-11, 5.2396e-12,\n",
       "             2.4483e-11, 2.4207e-11, 1.8845e-11, 1.7855e-11, 1.4844e-11, 1.1463e-11,\n",
       "             1.4903e-12, 2.2802e-12, 1.0270e-11, 4.4600e-12, 1.5287e-11, 2.6530e-12,\n",
       "             7.0560e-12, 4.5670e-12, 1.4409e-12, 1.0805e-11, 1.3976e-11, 1.5551e-12,\n",
       "             4.1024e-12, 2.0501e-11, 1.7374e-11, 1.8844e-11, 1.8091e-11, 1.4195e-11,\n",
       "             4.3572e-12, 2.3346e-11, 3.3598e-11, 1.1752e-11, 1.5067e-11, 2.7901e-12,\n",
       "             7.7955e-12, 6.9149e-12, 2.1203e-12, 2.5209e-12, 1.8585e-11, 3.2475e-12],\n",
       "            device='cuda:0')},\n",
       "    7: {'step': tensor(16.),\n",
       "     'exp_avg': tensor([[-2.8894e-06,  3.3579e-01,  3.6647e-01,  3.3097e-02,  2.6119e-01,\n",
       "               2.2193e-02,  1.7398e-01,  1.3668e-01, -6.5881e-01, -4.2928e-07,\n",
       "              -3.1202e-03, -4.9496e-01, -4.0790e-06, -1.4901e-01, -2.1037e-01,\n",
       "              -3.7488e-01],\n",
       "             [-3.2465e-06,  1.9122e-01,  2.0988e-01,  1.7363e-02,  1.4629e-01,\n",
       "               1.1649e-02,  9.3339e-02,  7.0969e-02, -3.4264e-01, -1.2187e-06,\n",
       "              -1.6157e-03, -2.5690e-01,  1.9942e-06, -7.7726e-02, -1.0905e-01,\n",
       "              -1.9509e-01],\n",
       "             [-2.4516e-06,  3.6738e-01,  4.0100e-01,  3.6128e-02,  2.8586e-01,\n",
       "               2.4246e-02,  1.9012e-01,  1.4907e-01, -6.9454e-01, -1.7597e-06,\n",
       "              -3.2941e-03, -5.2191e-01, -2.1756e-06, -1.5701e-01, -2.2182e-01,\n",
       "              -3.9509e-01],\n",
       "             [-1.2259e-06, -9.7108e-03, -1.1351e-02,  2.8750e-05, -6.1502e-03,\n",
       "               1.1904e-05, -1.3746e-03,  6.0058e-04, -2.0767e-02, -2.7036e-07,\n",
       "              -9.1271e-05, -1.5772e-02, -3.2378e-06, -4.6373e-03, -6.7747e-03,\n",
       "              -1.1861e-02],\n",
       "             [ 1.1644e-06,  2.4576e-02,  2.6136e-02,  3.3007e-03,  2.0624e-02,\n",
       "               2.2138e-03,  1.6135e-02,  1.4061e-02, -6.4190e-02,  1.1705e-06,\n",
       "              -2.9866e-04, -4.8470e-02,  1.1725e-06, -1.4395e-02, -2.0649e-02,\n",
       "              -3.6455e-02],\n",
       "             [-1.2383e-06,  5.6530e-01,  6.1894e-01,  5.3164e-02,  4.3593e-01,\n",
       "               3.5688e-02,  2.8327e-01,  2.1825e-01, -1.0154e+00, -4.8562e-06,\n",
       "              -4.8115e-03, -7.6227e-01,  1.7002e-06, -2.2988e-01, -3.2377e-01,\n",
       "              -5.7777e-01],\n",
       "             [-3.4911e-07,  6.3931e-01,  6.9989e-01,  6.0251e-02,  4.9302e-01,\n",
       "               4.0422e-02,  3.2073e-01,  2.4741e-01, -1.1639e+00, -3.2224e-06,\n",
       "              -5.5179e-03, -8.7368e-01, -1.0830e-08, -2.6352e-01, -3.7112e-01,\n",
       "              -6.6231e-01],\n",
       "             [-4.8898e-06,  3.6977e-01,  4.0362e-01,  3.6341e-02,  2.8787e-01,\n",
       "               2.4409e-02,  1.9139e-01,  1.5000e-01, -6.8945e-01, -2.7131e-08,\n",
       "              -3.2683e-03, -5.1811e-01, -1.7523e-06, -1.5583e-01, -2.2018e-01,\n",
       "              -3.9214e-01],\n",
       "             [-2.2955e-06,  2.7432e-01,  2.9923e-01,  2.7207e-02,  2.1375e-01,\n",
       "               1.8263e-02,  1.4282e-01,  1.1243e-01, -5.3472e-01, -1.2104e-06,\n",
       "              -2.5321e-03, -4.0184e-01, -3.2227e-06, -1.2087e-01, -1.7081e-01,\n",
       "              -3.0421e-01],\n",
       "             [-1.2334e-06,  3.2048e-01,  3.4972e-01,  3.1649e-02,  2.4931e-01,\n",
       "               2.1221e-02,  1.6620e-01,  1.3066e-01, -6.3515e-01, -1.7597e-06,\n",
       "              -3.0068e-03, -4.7720e-01, -2.2609e-06, -1.4365e-01, -2.0283e-01,\n",
       "              -3.6143e-01],\n",
       "             [-2.4494e-06,  4.0795e-01,  4.4687e-01,  3.8088e-02,  3.1413e-01,\n",
       "               2.5561e-02,  2.0338e-01,  1.5628e-01, -7.2665e-01, -1.0668e-06,\n",
       "              -3.4413e-03, -5.4536e-01, -1.2050e-06, -1.6456e-01, -2.3161e-01,\n",
       "              -4.1350e-01],\n",
       "             [-1.0846e-06,  2.9046e-01,  3.1836e-01,  2.6846e-02,  2.2321e-01,\n",
       "               1.8033e-02,  1.4379e-01,  1.1003e-01, -5.1402e-01,  5.3280e-08,\n",
       "              -2.4287e-03, -3.8567e-01,  1.6774e-06, -1.1646e-01, -1.6375e-01,\n",
       "              -2.9253e-01],\n",
       "             [-1.7914e-06,  5.5211e-01,  6.0301e-01,  5.3796e-02,  4.2879e-01,\n",
       "               3.6101e-02,  2.8385e-01,  2.2183e-01, -1.0392e+00, -1.7527e-06,\n",
       "              -4.9277e-03, -7.8081e-01, -1.7401e-06, -2.3499e-01, -3.3182e-01,\n",
       "              -5.9121e-01],\n",
       "             [-2.1679e-07,  6.6292e-01,  7.2567e-01,  6.2497e-02,  5.1159e-01,\n",
       "               4.1970e-02,  3.3289e-01,  2.5672e-01, -1.1872e+00, -3.2230e-06,\n",
       "              -5.6257e-03, -8.9129e-01, -2.8481e-06, -2.6874e-01, -3.7856e-01,\n",
       "              -6.7547e-01],\n",
       "             [-4.1164e-06,  5.5747e-01,  6.1039e-01,  5.2431e-02,  4.2957e-01,\n",
       "               3.5165e-02,  2.7919e-01,  2.1527e-01, -1.0364e+00, -1.2043e-06,\n",
       "              -4.9020e-03, -7.7786e-01,  2.0161e-06, -2.3472e-01, -3.3041e-01,\n",
       "              -5.8984e-01],\n",
       "             [-1.7219e-07,  5.5942e-01,  6.1101e-01,  5.4522e-02,  4.3427e-01,\n",
       "               3.6560e-02,  2.8748e-01,  2.2474e-01, -1.0656e+00, -2.2246e-06,\n",
       "              -5.0545e-03, -8.0046e-01, -2.8417e-06, -2.4105e-01, -3.4017e-01,\n",
       "              -6.0633e-01],\n",
       "             [ 3.4479e-08,  4.0020e-01,  4.3840e-01,  3.7357e-02,  3.0815e-01,\n",
       "               2.5066e-02,  1.9948e-01,  1.5323e-01, -7.1533e-01,  2.1204e-06,\n",
       "              -3.3833e-03, -5.3687e-01, -4.8539e-06, -1.6200e-01, -2.2799e-01,\n",
       "              -4.0705e-01],\n",
       "             [-3.2543e-06,  3.6556e-01,  3.9904e-01,  3.5962e-02,  2.8433e-01,\n",
       "               2.4117e-02,  1.8918e-01,  1.4841e-01, -7.0891e-01, -4.8621e-06,\n",
       "              -3.3555e-03, -5.3257e-01,  2.0122e-06, -1.6033e-01, -2.2632e-01,\n",
       "              -4.0334e-01],\n",
       "             [ 1.2980e-06,  6.6727e-02,  7.2246e-02,  7.3382e-03,  5.3096e-02,\n",
       "               4.9280e-03,  3.7469e-02,  3.0654e-02, -1.5255e-01, -1.5052e-07,\n",
       "              -7.1795e-04, -1.1479e-01, -3.3640e-08, -3.4414e-02, -4.8834e-02,\n",
       "              -8.6766e-02],\n",
       "             [-8.0025e-07,  1.3049e-01,  1.4348e-01,  1.1523e-02,  9.9223e-02,\n",
       "               7.7407e-03,  6.2466e-02,  4.7006e-02, -2.3454e-01,  1.1699e-06,\n",
       "              -1.1014e-03, -1.7568e-01, -4.0998e-06, -5.3282e-02, -7.4538e-02,\n",
       "              -1.3360e-01],\n",
       "             [-2.8913e-06,  4.5642e-01,  4.9987e-01,  4.2732e-02,  3.5166e-01,\n",
       "               2.8686e-02,  2.2797e-01,  1.7530e-01, -8.1055e-01,  2.0045e-06,\n",
       "              -3.8425e-03, -6.0837e-01, -2.8510e-06, -1.8354e-01, -2.5837e-01,\n",
       "              -4.6121e-01],\n",
       "             [-8.0599e-07,  2.4645e-01,  2.6879e-01,  2.4535e-02,  1.9220e-01,\n",
       "               1.6461e-02,  1.2871e-01,  1.0144e-01, -4.7943e-01, -4.3312e-07,\n",
       "              -2.2718e-03, -3.6037e-01, -1.2045e-06, -1.0833e-01, -1.5319e-01,\n",
       "              -2.7271e-01],\n",
       "             [-4.1180e-06,  5.0516e-01,  5.5322e-01,  4.7408e-02,  3.8917e-01,\n",
       "               3.1818e-02,  2.5266e-01,  1.9458e-01, -9.2784e-01,  6.9524e-07,\n",
       "              -4.3905e-03, -6.9639e-01, -4.8465e-06, -2.1013e-01, -2.9578e-01,\n",
       "              -5.2803e-01],\n",
       "             [ 3.9321e-08,  1.7483e-01,  1.9198e-01,  1.5783e-02,  1.3348e-01,\n",
       "               1.0577e-02,  8.4970e-02,  6.4459e-02, -3.1977e-01, -3.2344e-06,\n",
       "              -1.5067e-03, -2.3967e-01, -2.2730e-06, -7.2575e-02, -1.0173e-01,\n",
       "              -1.8210e-01],\n",
       "             [-2.2969e-06,  3.5656e-01,  3.8915e-01,  3.5077e-02,  2.7762e-01,\n",
       "               2.3537e-02,  1.8466e-01,  1.4474e-01, -6.6301e-01,  2.0016e-06,\n",
       "              -3.1438e-03, -4.9837e-01, -2.2325e-06, -1.4979e-01, -2.1182e-01,\n",
       "              -3.7706e-01],\n",
       "             [-4.8848e-06,  2.9187e-01,  3.1997e-01,  2.6973e-02,  2.2424e-01,\n",
       "               1.8108e-02,  1.4443e-01,  1.1053e-01, -5.1703e-01, -1.2157e-06,\n",
       "              -2.4468e-03, -3.8790e-01, -3.2308e-06, -1.1716e-01, -1.6470e-01,\n",
       "              -2.9426e-01],\n",
       "             [-2.2881e-06, -4.0619e-02, -4.5097e-02, -2.9497e-03, -3.0132e-02,\n",
       "              -1.9907e-03, -1.7144e-02, -1.1698e-02,  3.5231e-02,  1.8025e-07,\n",
       "               1.5833e-04,  2.6297e-02,  6.4964e-07,  8.0328e-03,  1.1102e-02,\n",
       "               1.9995e-02],\n",
       "             [-5.3048e-08,  3.6117e-01,  3.9427e-01,  3.5515e-02,  2.8092e-01,\n",
       "               2.3840e-02,  1.8690e-01,  1.4659e-01, -6.9289e-01, -1.2063e-06,\n",
       "              -3.2863e-03, -5.2063e-01, -2.2599e-06, -1.5665e-01, -2.2128e-01,\n",
       "              -3.9419e-01],\n",
       "             [-3.2538e-06,  3.6663e-01,  4.0020e-01,  3.6047e-02,  2.8520e-01,\n",
       "               2.4191e-02,  1.8967e-01,  1.4874e-01, -6.9879e-01, -2.8621e-06,\n",
       "              -3.3136e-03, -5.2513e-01,  1.6912e-06, -1.5795e-01, -2.2320e-01,\n",
       "              -3.9751e-01],\n",
       "             [-1.2270e-06,  4.2673e-02,  4.5890e-02,  5.0433e-03,  3.4662e-02,\n",
       "               3.3771e-03,  2.5334e-02,  2.1184e-02, -9.3192e-02, -1.2202e-06,\n",
       "              -4.3572e-04, -7.0275e-02, -4.8733e-06, -2.0941e-02, -2.9909e-02,\n",
       "              -5.2927e-02],\n",
       "             [-1.2266e-06,  1.6265e-01,  1.7867e-01,  1.4619e-02,  1.2404e-01,\n",
       "               9.8051e-03,  7.8782e-02,  5.9683e-02, -3.0011e-01, -7.9385e-07,\n",
       "              -1.4121e-03, -2.2491e-01, -2.2798e-06, -6.8128e-02, -9.5463e-02,\n",
       "              -1.7092e-01],\n",
       "             [-4.6023e-07,  5.5076e-01,  6.0161e-01,  5.3664e-02,  4.2759e-01,\n",
       "               3.6010e-02,  2.8310e-01,  2.2128e-01, -1.0525e+00, -1.3120e-07,\n",
       "              -4.9887e-03, -7.9082e-01,  2.1659e-07, -2.3796e-01, -3.3611e-01,\n",
       "              -5.9876e-01],\n",
       "             [ 1.6553e-07,  5.7818e-01,  6.3306e-01,  5.4392e-02,  4.4548e-01,\n",
       "               3.6471e-02,  2.8960e-01,  2.2335e-01, -1.0800e+00, -3.2222e-06,\n",
       "              -5.1131e-03, -8.1060e-01, -1.7441e-06, -2.4460e-01, -3.4432e-01,\n",
       "              -6.1470e-01],\n",
       "             [-4.5863e-07,  5.9499e-01,  6.5142e-01,  5.5980e-02,  4.5862e-01,\n",
       "               3.7558e-02,  2.9818e-01,  2.2994e-01, -1.0941e+00, -1.2033e-06,\n",
       "              -5.1844e-03, -8.2126e-01, -2.8476e-06, -2.4777e-01, -3.4884e-01,\n",
       "              -6.2268e-01],\n",
       "             [-2.8925e-06,  4.6650e-01,  5.0943e-01,  4.5614e-02,  3.6226e-01,\n",
       "               3.0591e-02,  2.4026e-01,  1.8815e-01, -9.0696e-01,  6.9576e-07,\n",
       "              -4.3009e-03, -6.8121e-01, -1.1904e-06, -2.0520e-01, -2.8949e-01,\n",
       "              -5.1612e-01],\n",
       "             [-1.4776e-07,  4.5738e-01,  4.9945e-01,  4.4728e-02,  3.5542e-01,\n",
       "               2.9997e-02,  2.3572e-01,  1.8449e-01, -8.7379e-01, -2.1808e-06,\n",
       "              -4.1417e-03, -6.5655e-01, -4.0729e-06, -1.9755e-01, -2.7903e-01,\n",
       "              -4.9710e-01],\n",
       "             [ 9.9433e-08,  2.5302e-01,  2.7741e-01,  2.3264e-02,  1.9428e-01,\n",
       "               1.5621e-02,  1.2477e-01,  9.5238e-02, -4.3875e-01, -3.6418e-08,\n",
       "              -2.0731e-03, -3.2910e-01,  1.9961e-06, -9.9433e-02, -1.3970e-01,\n",
       "              -2.4969e-01],\n",
       "             [ 1.6503e-06,  5.3869e-01,  5.8832e-01,  5.2504e-02,  4.1866e-01,\n",
       "               3.5254e-02,  2.7714e-01,  2.1651e-01, -9.9693e-01, -3.2219e-06,\n",
       "              -4.7267e-03, -7.4901e-01,  2.0190e-06, -2.2539e-01, -3.1826e-01,\n",
       "              -5.6706e-01],\n",
       "             [-4.1196e-06,  6.8475e-01,  7.4959e-01,  6.4580e-02,  5.2811e-01,\n",
       "               4.3330e-02,  3.4371e-01,  2.6522e-01, -1.2482e+00, -2.3324e-07,\n",
       "              -5.9232e-03, -9.3703e-01, -1.8684e-06, -2.8261e-01, -3.9803e-01,\n",
       "              -7.1034e-01],\n",
       "             [-1.2363e-06,  4.3742e-01,  4.7760e-01,  4.2796e-02,  3.4014e-01,\n",
       "               2.8725e-02,  2.2564e-01,  1.7656e-01, -8.1617e-01, -2.2682e-06,\n",
       "              -3.8732e-03, -6.1333e-01, -1.1955e-06, -1.8447e-01, -2.6066e-01,\n",
       "              -4.6424e-01],\n",
       "             [-1.7905e-06,  5.0212e-01,  5.4837e-01,  4.9004e-02,  3.9000e-01,\n",
       "               3.2885e-02,  2.5839e-01,  2.0211e-01, -9.5098e-01, -1.3441e-07,\n",
       "              -4.5142e-03, -7.1441e-01, -1.1901e-06, -2.1508e-01, -3.0359e-01,\n",
       "              -5.4106e-01],\n",
       "             [-3.2495e-06,  1.7664e-01,  1.9240e-01,  1.7866e-02,  1.3842e-01,\n",
       "               1.1983e-02,  9.3380e-02,  7.3935e-02, -3.3093e-01, -3.2349e-06,\n",
       "              -1.5669e-03, -2.4880e-01, -1.2108e-06, -7.4731e-02, -1.0574e-01,\n",
       "              -1.8817e-01],\n",
       "             [-2.8862e-06,  3.6234e-01,  3.9697e-01,  3.3714e-02,  2.7887e-01,\n",
       "               2.2624e-02,  1.8022e-01,  1.3827e-01, -6.3808e-01,  1.3119e-06,\n",
       "              -3.0215e-03, -4.7881e-01, -1.7859e-06, -1.4453e-01, -2.0331e-01,\n",
       "              -3.6310e-01],\n",
       "             [-1.7864e-06,  3.4025e-01,  3.7134e-01,  3.3507e-02,  2.6493e-01,\n",
       "               2.2492e-02,  1.7635e-01,  1.3838e-01, -6.4450e-01,  2.0016e-06,\n",
       "              -3.0533e-03, -4.8433e-01, -2.2631e-06, -1.4567e-01, -2.0583e-01,\n",
       "              -3.6660e-01],\n",
       "             [-3.2485e-06,  1.2655e-01,  1.3767e-01,  1.3072e-02,  9.9179e-02,\n",
       "               8.7378e-03,  6.7723e-02,  5.4247e-02, -2.7912e-01, -1.8082e-06,\n",
       "              -1.3199e-03, -2.0978e-01, -3.2290e-06, -6.3103e-02, -8.9208e-02,\n",
       "              -1.5888e-01],\n",
       "             [ 1.9799e-06,  1.6961e-01,  1.8475e-01,  1.7178e-02,  1.3268e-01,\n",
       "               1.1528e-02,  8.9655e-02,  7.1190e-02, -3.4422e-01,  1.6749e-06,\n",
       "              -1.6298e-03, -2.5871e-01, -1.1972e-07, -7.7801e-02, -1.0998e-01,\n",
       "              -1.9586e-01],\n",
       "             [ 6.6101e-07,  4.5006e-01,  4.9141e-01,  4.4021e-02,  3.4986e-01,\n",
       "               2.9555e-02,  2.3208e-01,  1.8165e-01, -8.5277e-01, -4.4500e-08,\n",
       "              -4.0408e-03, -6.4070e-01, -1.2682e-07, -1.9282e-01, -2.7227e-01,\n",
       "              -4.8512e-01],\n",
       "             [ 3.6584e-06,  1.8576e-01,  2.0241e-01,  1.8733e-02,  1.4498e-01,\n",
       "               1.2546e-02,  9.7790e-02,  7.7607e-02, -3.9767e-01,  1.8961e-07,\n",
       "              -1.8779e-03, -2.9877e-01, -4.8611e-06, -8.9951e-02, -1.2701e-01,\n",
       "              -2.2636e-01]], device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([[1.5787e-12, 2.4255e-01, 2.9164e-01, 2.0649e-03, 1.4264e-01, 9.2855e-04,\n",
       "              5.8958e-02, 3.4496e-02, 8.1777e-01, 1.6048e-12, 1.8438e-05, 4.6089e-01,\n",
       "              1.6141e-12, 4.1937e-02, 8.3223e-02, 2.6494e-01],\n",
       "             [1.5854e-12, 6.6641e-02, 8.0122e-02, 5.6752e-04, 3.9221e-02, 2.5536e-04,\n",
       "              1.6213e-02, 9.4814e-03, 2.2021e-01, 1.5934e-12, 4.9638e-06, 1.2411e-01,\n",
       "              1.5963e-12, 1.1292e-02, 2.2406e-02, 7.1331e-02],\n",
       "             [1.5786e-12, 2.8873e-01, 3.4712e-01, 2.4583e-03, 1.7010e-01, 1.1069e-03,\n",
       "              7.0294e-02, 4.1066e-02, 9.0960e-01, 1.6051e-12, 2.0545e-05, 5.1260e-01,\n",
       "              1.6145e-12, 4.6634e-02, 9.2515e-02, 2.9456e-01],\n",
       "             [1.5864e-12, 1.3404e-05, 1.8110e-05, 1.8422e-09, 5.2160e-06, 3.1509e-11,\n",
       "              4.4243e-07, 9.0337e-08, 8.2319e-04, 1.5917e-12, 1.8541e-08, 4.6538e-04,\n",
       "              1.5937e-12, 4.2602e-05, 8.5378e-05, 2.7058e-04],\n",
       "             [1.5858e-12, 2.4366e-03, 2.9320e-03, 2.0607e-05, 1.4309e-03, 9.2707e-06,\n",
       "              5.8921e-04, 3.4424e-04, 7.8435e-03, 1.5917e-12, 1.7710e-07, 4.4202e-03,\n",
       "              1.5937e-12, 4.0222e-04, 7.9800e-04, 2.5407e-03],\n",
       "             [1.5750e-12, 6.2517e-01, 7.5155e-01, 5.3240e-03, 3.6858e-01, 2.3988e-03,\n",
       "              1.5233e-01, 8.8948e-02, 1.9401e+00, 1.6116e-12, 4.3765e-05, 1.0933e+00,\n",
       "              1.6249e-12, 9.9455e-02, 1.9728e-01, 6.2815e-01],\n",
       "             [1.5750e-12, 8.0296e-01, 9.6532e-01, 6.8381e-03, 4.7303e-01, 3.0788e-03,\n",
       "              1.9551e-01, 1.1423e-01, 2.5484e+00, 1.6095e-12, 5.7534e-05, 1.4361e+00,\n",
       "              1.6215e-12, 1.3066e-01, 2.5921e-01, 8.2528e-01],\n",
       "             [1.5784e-12, 2.9241e-01, 3.5153e-01, 2.4895e-03, 1.7243e-01, 1.1219e-03,\n",
       "              7.1248e-02, 4.1593e-02, 8.9648e-01, 1.6041e-12, 2.0224e-05, 5.0517e-01,\n",
       "              1.6129e-12, 4.5955e-02, 9.1150e-02, 2.9024e-01],\n",
       "             [1.5802e-12, 1.6393e-01, 1.9710e-01, 1.3955e-03, 9.6475e-02, 6.2792e-04,\n",
       "              3.9872e-02, 2.3314e-02, 5.3914e-01, 1.6017e-12, 1.2156e-05, 3.0385e-01,\n",
       "              1.6092e-12, 2.7646e-02, 5.4854e-02, 1.7464e-01],\n",
       "             [1.5795e-12, 2.2159e-01, 2.6645e-01, 1.8864e-03, 1.3026e-01, 8.4806e-04,\n",
       "              5.3844e-02, 3.1515e-02, 7.6012e-01, 1.6052e-12, 1.7125e-05, 4.2841e-01,\n",
       "              1.6147e-12, 3.8984e-02, 7.7366e-02, 2.4629e-01],\n",
       "             [1.5806e-12, 3.2107e-01, 3.8598e-01, 2.7344e-03, 1.8928e-01, 1.2318e-03,\n",
       "              7.8225e-02, 4.5680e-02, 9.9297e-01, 1.6005e-12, 2.2417e-05, 5.5956e-01,\n",
       "              1.6073e-12, 5.0904e-02, 1.0098e-01, 3.2151e-01],\n",
       "             [1.5832e-12, 1.5953e-01, 1.9178e-01, 1.3586e-03, 9.4062e-02, 6.1220e-04,\n",
       "              3.8875e-02, 2.2700e-02, 4.9654e-01, 1.5961e-12, 1.1187e-05, 2.7981e-01,\n",
       "              1.6005e-12, 2.5454e-02, 5.0489e-02, 1.6076e-01],\n",
       "             [1.5746e-12, 6.4063e-01, 7.7019e-01, 5.4544e-03, 3.7743e-01, 2.4564e-03,\n",
       "              1.5598e-01, 9.1129e-02, 2.0359e+00, 1.6125e-12, 4.5901e-05, 1.1473e+00,\n",
       "              1.6263e-12, 1.0438e-01, 2.0706e-01, 6.5928e-01],\n",
       "             [1.5748e-12, 8.6440e-01, 1.0391e+00, 7.3610e-03, 5.0983e-01, 3.3177e-03,\n",
       "              2.1069e-01, 1.2299e-01, 2.6525e+00, 1.6088e-12, 5.9802e-05, 1.4947e+00,\n",
       "              1.6204e-12, 1.3597e-01, 2.6968e-01, 8.5873e-01],\n",
       "             [1.5771e-12, 6.0813e-01, 7.3115e-01, 5.1782e-03, 3.5798e-01, 2.3308e-03,\n",
       "              1.4798e-01, 8.6528e-02, 2.0198e+00, 1.6081e-12, 4.5423e-05, 1.1383e+00,\n",
       "              1.6193e-12, 1.0357e-01, 2.0549e-01, 6.5422e-01],\n",
       "             [1.5739e-12, 6.5763e-01, 7.9066e-01, 5.5993e-03, 3.8711e-01, 2.5196e-03,\n",
       "              1.5999e-01, 9.3538e-02, 2.1390e+00, 1.6132e-12, 4.8289e-05, 1.2055e+00,\n",
       "              1.6275e-12, 1.0968e-01, 2.1763e-01, 6.9284e-01],\n",
       "             [1.5782e-12, 3.0866e-01, 3.7105e-01, 2.6284e-03, 1.8200e-01, 1.1846e-03,\n",
       "              7.5219e-02, 4.3919e-02, 9.6233e-01, 1.6048e-12, 2.1669e-05, 5.4229e-01,\n",
       "              1.6141e-12, 4.9331e-02, 9.7848e-02, 3.1157e-01],\n",
       "             [1.5782e-12, 2.8614e-01, 3.4409e-01, 2.4357e-03, 1.6842e-01, 1.0966e-03,\n",
       "              6.9633e-02, 4.0705e-02, 9.4688e-01, 1.6054e-12, 2.1315e-05, 5.3363e-01,\n",
       "              1.6150e-12, 4.8548e-02, 9.6328e-02, 3.0667e-01],\n",
       "             [1.5850e-12, 1.1945e-02, 1.4374e-02, 1.0150e-04, 7.0041e-03, 4.5611e-05,\n",
       "              2.8962e-03, 1.6965e-03, 4.3985e-02, 1.5942e-12, 9.9140e-07, 2.4792e-02,\n",
       "              1.5974e-12, 2.2559e-03, 4.4790e-03, 1.4255e-02],\n",
       "             [1.5865e-12, 2.9425e-02, 3.5394e-02, 2.5050e-04, 1.7291e-02, 1.1267e-04,\n",
       "              7.1532e-03, 4.1866e-03, 1.0294e-01, 1.5911e-12, 2.3185e-06, 5.8021e-02,\n",
       "              1.5927e-12, 5.2790e-03, 1.0478e-02, 3.3353e-02],\n",
       "             [1.5770e-12, 4.0384e-01, 4.8546e-01, 3.4393e-03, 2.3813e-01, 1.5496e-03,\n",
       "              9.8409e-02, 5.7453e-02, 1.2358e+00, 1.6068e-12, 2.7935e-05, 6.9637e-01,\n",
       "              1.6172e-12, 6.3346e-02, 1.2565e-01, 4.0009e-01],\n",
       "             [1.5811e-12, 1.3333e-01, 1.6033e-01, 1.1349e-03, 7.8482e-02, 5.1090e-04,\n",
       "              3.2443e-02, 1.8962e-02, 4.3374e-01, 1.6008e-12, 9.7923e-06, 2.4444e-01,\n",
       "              1.6078e-12, 2.2238e-02, 4.4125e-02, 1.4048e-01],\n",
       "             [1.5757e-12, 4.9717e-01, 5.9779e-01, 4.2333e-03, 2.9281e-01, 1.9065e-03,\n",
       "              1.2106e-01, 7.0743e-02, 1.6190e+00, 1.6099e-12, 3.6453e-05, 9.1238e-01,\n",
       "              1.6222e-12, 8.3003e-02, 1.6468e-01, 5.2430e-01],\n",
       "             [1.5827e-12, 5.5073e-02, 6.6240e-02, 4.6891e-04, 3.2368e-02, 2.1092e-04,\n",
       "              1.3391e-02, 7.8365e-03, 1.9166e-01, 1.5971e-12, 4.3195e-06, 1.0802e-01,\n",
       "              1.6020e-12, 9.8279e-03, 1.9507e-02, 6.2092e-02],\n",
       "             [1.5789e-12, 2.7220e-01, 3.2722e-01, 2.3175e-03, 1.6055e-01, 1.0445e-03,\n",
       "              6.6332e-02, 3.8717e-02, 8.2972e-01, 1.6038e-12, 1.8717e-05, 4.6755e-01,\n",
       "              1.6125e-12, 4.2531e-02, 8.4356e-02, 2.6861e-01],\n",
       "             [1.5830e-12, 1.6099e-01, 1.9355e-01, 1.3711e-03, 9.4872e-02, 6.1752e-04,\n",
       "              3.9215e-02, 2.2904e-02, 5.0228e-01, 1.5963e-12, 1.1354e-05, 2.8305e-01,\n",
       "              1.6008e-12, 2.5749e-02, 5.1083e-02, 1.6264e-01],\n",
       "             [1.5871e-12, 1.9428e-03, 2.3284e-03, 1.6482e-05, 1.1689e-03, 7.5261e-06,\n",
       "              4.7875e-04, 2.7516e-04, 2.3184e-03, 1.5906e-12, 5.1819e-08, 1.3039e-03,\n",
       "              1.5920e-12, 1.1838e-04, 2.3297e-04, 7.4494e-04],\n",
       "             [1.5789e-12, 2.7927e-01, 3.3582e-01, 2.3775e-03, 1.6439e-01, 1.0702e-03,\n",
       "              6.7961e-02, 3.9721e-02, 9.0514e-01, 1.6059e-12, 2.0448e-05, 5.1010e-01,\n",
       "              1.6158e-12, 4.6407e-02, 9.2084e-02, 2.9315e-01],\n",
       "             [1.5786e-12, 2.8745e-01, 3.4563e-01, 2.4472e-03, 1.6929e-01, 1.1019e-03,\n",
       "              6.9976e-02, 4.0886e-02, 9.2099e-01, 1.6054e-12, 2.0788e-05, 5.1902e-01,\n",
       "              1.6150e-12, 4.7217e-02, 9.3681e-02, 2.9825e-01],\n",
       "             [1.5854e-12, 5.6291e-03, 6.7678e-03, 4.7772e-05, 3.3213e-03, 2.1555e-05,\n",
       "              1.3693e-03, 7.9828e-04, 1.6499e-02, 1.5920e-12, 3.7086e-07, 9.2962e-03,\n",
       "              1.5940e-12, 8.4563e-04, 1.6765e-03, 5.3398e-03],\n",
       "             [1.5858e-12, 4.7244e-02, 5.6831e-02, 4.0223e-04, 2.7748e-02, 1.8086e-04,\n",
       "              1.1482e-02, 6.7226e-03, 1.6876e-01, 1.5927e-12, 3.7994e-06, 9.5118e-02,\n",
       "              1.5952e-12, 8.6545e-03, 1.7180e-02, 5.4682e-02],\n",
       "             [1.5750e-12, 6.3745e-01, 7.6651e-01, 5.4267e-03, 3.7531e-01, 2.4436e-03,\n",
       "              1.5516e-01, 9.0685e-02, 2.0888e+00, 1.6141e-12, 4.7041e-05, 1.1771e+00,\n",
       "              1.6289e-12, 1.0709e-01, 2.1248e-01, 6.7647e-01],\n",
       "             [1.5769e-12, 6.5444e-01, 7.8685e-01, 5.5728e-03, 3.8511e-01, 2.5073e-03,\n",
       "              1.5920e-01, 9.3119e-02, 2.1933e+00, 1.6097e-12, 4.9413e-05, 1.2361e+00,\n",
       "              1.6218e-12, 1.1246e-01, 2.2315e-01, 7.1045e-01],\n",
       "             [1.5764e-12, 6.9356e-01, 8.3382e-01, 5.9062e-03, 4.0841e-01, 2.6585e-03,\n",
       "              1.6881e-01, 9.8677e-02, 2.2515e+00, 1.6091e-12, 5.0799e-05, 1.2689e+00,\n",
       "              1.6209e-12, 1.1543e-01, 2.2903e-01, 7.2921e-01],\n",
       "             [1.5760e-12, 4.6040e-01, 5.5359e-01, 3.9199e-03, 2.7078e-01, 1.7627e-03,\n",
       "              1.1193e-01, 6.5489e-02, 1.5488e+00, 1.6104e-12, 3.4983e-05, 8.7291e-01,\n",
       "              1.6231e-12, 7.9418e-02, 1.5761e-01, 5.0175e-01],\n",
       "             [1.5764e-12, 4.4261e-01, 5.3213e-01, 3.7682e-03, 2.6064e-01, 1.6963e-03,\n",
       "              1.0772e-01, 6.2961e-02, 1.4394e+00, 1.6090e-12, 3.2445e-05, 8.1118e-01,\n",
       "              1.6207e-12, 7.3797e-02, 1.4641e-01, 4.6618e-01],\n",
       "             [1.5841e-12, 1.1965e-01, 1.4382e-01, 1.0191e-03, 7.0591e-02, 4.5931e-04,\n",
       "              2.9169e-02, 1.7023e-02, 3.6153e-01, 1.5947e-12, 8.1598e-06, 2.0372e-01,\n",
       "              1.5982e-12, 1.8531e-02, 3.6753e-02, 1.1704e-01],\n",
       "             [1.5747e-12, 6.1014e-01, 7.3342e-01, 5.1948e-03, 3.5986e-01, 2.3413e-03,\n",
       "              1.4869e-01, 8.6790e-02, 1.8735e+00, 1.6100e-12, 4.2238e-05, 1.0557e+00,\n",
       "              1.6224e-12, 9.6029e-02, 1.9047e-01, 6.0652e-01],\n",
       "             [1.5742e-12, 9.2246e-01, 1.1090e+00, 7.8563e-03, 5.4334e-01, 3.5362e-03,\n",
       "              2.2456e-01, 1.3123e-01, 2.9313e+00, 1.6117e-12, 6.6283e-05, 1.6519e+00,\n",
       "              1.6251e-12, 1.5028e-01, 2.9816e-01, 9.4930e-01],\n",
       "             [1.5769e-12, 4.0541e-01, 4.8736e-01, 3.4519e-03, 2.3898e-01, 1.5549e-03,\n",
       "              9.8745e-02, 5.7663e-02, 1.2563e+00, 1.6069e-12, 2.8383e-05, 7.0796e-01,\n",
       "              1.6174e-12, 6.4401e-02, 1.2775e-01, 4.0678e-01],\n",
       "             [1.5754e-12, 5.3150e-01, 6.3900e-01, 4.5257e-03, 3.1296e-01, 2.0367e-03,\n",
       "              1.2934e-01, 7.5597e-02, 1.7039e+00, 1.6107e-12, 3.8532e-05, 9.6026e-01,\n",
       "              1.6234e-12, 8.7358e-02, 1.7333e-01, 5.5185e-01],\n",
       "             [1.5826e-12, 7.0591e-02, 8.4850e-02, 6.0089e-04, 4.1662e-02, 2.7089e-04,\n",
       "              1.7207e-02, 1.0036e-02, 2.0668e-01, 1.5967e-12, 4.6732e-06, 1.1646e-01,\n",
       "              1.6013e-12, 1.0593e-02, 2.1008e-02, 6.6899e-02],\n",
       "             [1.5817e-12, 2.5149e-01, 3.0230e-01, 2.1420e-03, 1.4833e-01, 9.6509e-04,\n",
       "              6.1292e-02, 3.5779e-02, 7.6536e-01, 1.5986e-12, 1.7292e-05, 4.3128e-01,\n",
       "              1.6043e-12, 3.9231e-02, 7.7816e-02, 2.4779e-01],\n",
       "             [1.5791e-12, 2.4860e-01, 2.9886e-01, 2.1164e-03, 1.4652e-01, 9.5338e-04,\n",
       "              6.0543e-02, 3.5361e-02, 7.8333e-01, 1.6037e-12, 1.7658e-05, 4.4142e-01,\n",
       "              1.6124e-12, 4.0155e-02, 7.9657e-02, 2.5364e-01],\n",
       "             [1.5835e-12, 3.7790e-02, 4.5463e-02, 3.2156e-04, 2.2120e-02, 1.4409e-04,\n",
       "              9.1476e-03, 5.3724e-03, 1.4682e-01, 1.5975e-12, 3.3219e-06, 8.2765e-02,\n",
       "              1.6026e-12, 7.5322e-03, 1.4961e-02, 4.7608e-02],\n",
       "             [1.5825e-12, 6.5377e-02, 7.8619e-02, 5.5647e-04, 3.8417e-02, 2.5006e-04,\n",
       "              1.5879e-02, 9.2956e-03, 2.2339e-01, 1.5980e-12, 5.0540e-06, 1.2590e-01,\n",
       "              1.6035e-12, 1.1455e-02, 2.2738e-02, 7.2380e-02],\n",
       "             [1.5764e-12, 4.2903e-01, 5.1578e-01, 3.6526e-03, 2.5277e-01, 1.6450e-03,\n",
       "              1.0446e-01, 6.1029e-02, 1.3707e+00, 1.6078e-12, 3.0887e-05, 7.7241e-01,\n",
       "              1.6188e-12, 7.0267e-02, 1.3940e-01, 4.4386e-01],\n",
       "             [1.5820e-12, 7.7761e-02, 9.3538e-02, 6.6173e-04, 4.5581e-02, 2.9693e-04,\n",
       "              1.8850e-02, 1.1060e-02, 2.9781e-01, 1.5999e-12, 6.7010e-06, 1.6787e-01,\n",
       "              1.6064e-12, 1.5276e-02, 3.0333e-02, 9.6543e-02]], device='cuda:0')},\n",
       "    8: {'step': tensor(16.),\n",
       "     'exp_avg': tensor([[ 3.5562e-06,  6.7626e+01,  7.4147e+01,  6.3479e+00,  5.2524e+01,\n",
       "               4.2386e+00,  3.3841e+01,  2.5760e+01, -1.9242e+01,  7.3844e-06,\n",
       "              -9.0023e-02, -1.4292e+01,  6.9836e-06, -4.4329e+00, -6.0207e+00,\n",
       "              -1.1011e+01]], device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([[3.9796e-12, 8.7989e+03, 1.0595e+04, 7.5925e+01, 5.2792e+03, 3.3851e+01,\n",
       "              2.1628e+03, 1.2409e+03, 6.7472e+02, 2.2097e-12, 1.5272e-02, 3.8066e+02,\n",
       "              3.6199e-12, 3.4655e+01, 6.8516e+01, 2.1935e+02]], device='cuda:0')},\n",
       "    9: {'step': tensor(16.),\n",
       "     'exp_avg': tensor([-1.5290e-05], device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([9.8181e-10], device='cuda:0')},\n",
       "    10: {'step': tensor(16.),\n",
       "     'exp_avg': tensor([[-0.4387,  0.3321, -0.3946, -0.8438, -0.8130,  0.1804,  0.5295, -0.4365,\n",
       "              -1.1570, -0.3433,  0.6230,  0.3122, -0.6289,  0.8452,  1.3208, -0.8128,\n",
       "               0.3130, -0.3618, -1.1357,  0.5990,  0.3271, -0.1662,  0.3642,  0.2245,\n",
       "              -0.4670,  0.6944, -0.2393, -1.2733, -1.2250, -0.4931,  1.1241, -0.1999,\n",
       "               1.5833,  0.8071, -1.0038, -0.1783,  0.2482, -0.1656,  1.1882, -0.2946,\n",
       "              -1.1696, -0.7089,  1.2770, -1.1792, -0.9245, -0.6856, -0.6698, -0.2840]],\n",
       "            device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([[0.3433, 0.2160, 0.3220, 1.4007, 1.2269, 0.0668, 0.5896, 0.3627, 2.5022,\n",
       "              0.2323, 0.7378, 0.1728, 0.7330, 1.3883, 3.4032, 1.2642, 0.1761, 0.2479,\n",
       "              2.4447, 0.7164, 0.2072, 0.0673, 0.2704, 0.1007, 0.4217, 0.9038, 0.0610,\n",
       "              3.1554, 2.8209, 0.4678, 2.4503, 0.0782, 4.9281, 1.3211, 1.9032, 0.0564,\n",
       "              0.1131, 0.0426, 2.7353, 0.1504, 2.6371, 0.9978, 3.1912, 2.6081, 1.6520,\n",
       "              0.9205, 0.8680, 0.1563]], device='cuda:0')},\n",
       "    11: {'step': tensor(16.),\n",
       "     'exp_avg': tensor([4.1490e-06], device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([2.5072e-11], device='cuda:0')},\n",
       "    12: {'step': tensor(16.),\n",
       "     'exp_avg': tensor([286.3380, 565.3758, 460.2909, 103.7380, 134.3492, 365.3518, 295.4071,\n",
       "             113.2367, 340.8665, 346.4137, 242.8708, 110.5096, 303.4960, 281.0898,\n",
       "             169.7942, 208.3086, 297.3826, 119.9327, 273.3178, 368.8508, 264.0218,\n",
       "             560.7908,  22.4137, 237.1571,  51.7710, 485.7571, 280.8971, 208.8219,\n",
       "             -21.8179, 284.7253], device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([157797.1719, 608737.8125, 405451.5625,  20316.5391,  34416.7852,\n",
       "             251762.7188, 162950.7812,  24186.6328, 220333.8125, 229460.6406,\n",
       "             112182.6797,  23697.1797, 177230.3125, 151083.6406,  54691.6445,\n",
       "              82145.0078, 171547.7188,  27510.7324, 141825.4844, 256146.2031,\n",
       "             132234.5156, 601042.2500,    891.3104, 105576.0391,   5104.5830,\n",
       "             450101.5938, 151324.9219,  81236.2500,   1125.5286, 155324.7656],\n",
       "            device='cuda:0')},\n",
       "    13: {'step': tensor(16.),\n",
       "     'exp_avg': tensor([ 289.7335, -348.5346,  341.3071,  110.5262, -221.3059,  290.2114,\n",
       "              322.8340,  107.3567, -305.6354,  335.5077, -284.5461,  200.3772,\n",
       "              281.9554,  300.3427, -249.3171, -335.6747,  305.4130,   40.4509,\n",
       "             -315.8653,  358.1011,  378.8187, -292.8539, -188.0318,  157.3586,\n",
       "             -159.2984, -314.8304, -217.0891,  300.2527, -272.3729, -278.5084],\n",
       "            device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([160573.2656, 231762.8594, 222456.9062,  23558.0098,  94167.1328,\n",
       "             161246.3281, 199216.3281,  22227.2012, 178674.7812, 214830.7344,\n",
       "             154351.9062,  77041.3672, 152282.0469, 172316.5469, 119215.6094,\n",
       "             215273.2500, 178415.7188,   3071.3511, 189693.0000, 244799.9062,\n",
       "             273598.2812, 164325.8281,  67999.5156,  47118.0352,  48915.9609,\n",
       "             189546.3594,  90571.0078, 171906.7812, 141776.5938, 148424.8125],\n",
       "            device='cuda:0')},\n",
       "    14: {'step': tensor(16.),\n",
       "     'exp_avg': tensor([[ 2.7996e-04, -3.5768e-04,  4.2295e-04,  ...,  3.8638e-04,\n",
       "              -1.2576e-04, -2.5643e-04],\n",
       "             [ 9.8557e-03, -4.7035e-02,  3.6751e-02,  ..., -4.7048e-02,\n",
       "               1.0861e-01, -4.0924e-04],\n",
       "             [-3.4698e+00,  6.9448e+00, -5.9063e+00,  ..., -3.1676e+00,\n",
       "              -5.4845e-01,  2.2921e+00],\n",
       "             ...,\n",
       "             [ 5.7623e+00, -1.1998e+01,  1.2584e+01,  ...,  7.0792e+00,\n",
       "               3.5082e-01, -7.0507e+00],\n",
       "             [ 5.6863e+01, -1.1986e+02,  1.1457e+02,  ...,  6.8021e+01,\n",
       "               8.2422e+00, -5.9914e+01],\n",
       "             [ 6.7816e+01, -1.3620e+02,  1.3093e+02,  ...,  7.5866e+01,\n",
       "               6.5222e+00, -7.0146e+01]], device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([[1.9262e-07, 3.1065e-07, 4.3147e-07,  ..., 3.6134e-07, 4.1545e-08,\n",
       "              1.6186e-07],\n",
       "             [9.5427e-06, 1.7200e-04, 1.0057e-04,  ..., 1.6676e-04, 9.0919e-04,\n",
       "              1.5458e-06],\n",
       "             [2.1377e+01, 8.4790e+01, 6.0615e+01,  ..., 2.3957e+01, 4.4427e-01,\n",
       "              9.8159e+00],\n",
       "             ...,\n",
       "             [6.2580e+01, 2.7135e+02, 2.9846e+02,  ..., 9.4458e+01, 2.3051e-01,\n",
       "              9.3702e+01],\n",
       "             [6.0924e+03, 2.7067e+04, 2.4732e+04,  ..., 8.7180e+03, 1.2800e+02,\n",
       "              6.7637e+03],\n",
       "             [8.6653e+03, 3.4953e+04, 3.2299e+04,  ..., 1.0845e+04, 8.0151e+01,\n",
       "              9.2712e+03]], device='cuda:0')},\n",
       "    15: {'step': tensor(16.),\n",
       "     'exp_avg': tensor([ 2.6718e-04,  5.6971e-02, -4.1120e+00,  5.1306e+01,  2.9019e+01,\n",
       "              2.5812e+01,  4.2257e+01,  6.1102e+01,  4.0389e+01,  1.5016e+01,\n",
       "              1.4629e-05,  2.4502e-04,  6.4559e+01,  8.7726e+01, -8.5298e-04,\n",
       "              2.1348e+00, -1.6494e+01,  2.6388e-01, -8.5607e+00,  3.5719e+00,\n",
       "              5.4769e+01,  7.4798e-03,  1.4828e-01,  1.4635e-01,  7.8417e+01,\n",
       "              6.2331e+01,  5.0157e+01,  2.0701e+01,  2.9395e+01,  3.2412e-01,\n",
       "              4.0863e+01,  1.5827e-01,  5.2293e+01,  7.0501e+01,  2.0433e-01,\n",
       "              5.9725e-02,  4.0858e+01,  8.5796e+01,  6.9729e+01,  1.1101e-05,\n",
       "              2.1075e-04,  3.0862e-04,  1.6111e-01,  3.2080e-02,  5.6908e+01,\n",
       "              3.8330e+01,  8.4919e+01,  1.8800e-01,  9.5807e-02,  6.0993e+01,\n",
       "              4.4073e+01,  7.8525e+01,  8.6205e+01, -3.0606e+01,  5.4737e+01,\n",
       "              2.3887e+01,  2.4293e+01,  4.4869e-04,  5.6536e+01,  4.0454e-03,\n",
       "              2.3319e+01,  6.9305e+00,  6.7659e+01,  7.7645e+01], device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([1.7589e-07, 2.4362e-04, 2.6364e+01, 4.9597e+03, 1.5863e+03, 1.2554e+03,\n",
       "             3.3646e+03, 7.0346e+03, 3.0734e+03, 4.2467e+02, 1.1853e-09, 1.4817e-07,\n",
       "             7.8528e+03, 1.4501e+04, 5.1096e-07, 8.5867e+00, 5.1306e+02, 8.5871e-03,\n",
       "             1.3244e+02, 2.4039e+01, 5.6520e+03, 6.6055e-06, 2.6999e-03, 2.6222e-03,\n",
       "             1.1585e+04, 7.3203e+03, 4.7401e+03, 7.9497e+02, 1.6281e+03, 1.9795e-01,\n",
       "             3.1454e+03, 3.0693e-03, 5.1516e+03, 9.3653e+03, 5.1380e-03, 2.3099e-03,\n",
       "             3.1450e+03, 1.3869e+04, 9.1613e+03, 8.4416e-10, 1.1114e-07, 2.3288e-07,\n",
       "             3.1802e-03, 1.2483e-04, 6.1015e+03, 2.7683e+03, 1.3587e+04, 4.3342e-03,\n",
       "             1.1207e-03, 7.0096e+03, 3.6600e+03, 1.1618e+04, 1.4002e+04, 1.8245e+03,\n",
       "             5.6452e+03, 1.0751e+03, 1.1120e+03, 4.8455e-07, 6.0226e+03, 2.0341e-05,\n",
       "             1.0244e+03, 9.0537e+01, 8.6253e+03, 1.1359e+04], device='cuda:0')},\n",
       "    16: {'step': tensor(16.),\n",
       "     'exp_avg': tensor([[-3.3585e-01, -5.0644e-03, -1.9055e+00,  ..., -3.2454e+00,\n",
       "              -1.6495e-01, -1.2256e+00],\n",
       "             [-1.2260e+00, -1.0467e+00, -4.1335e+00,  ..., -4.1555e+01,\n",
       "              -1.8380e+00, -5.9707e+00],\n",
       "             [ 3.2383e-05,  1.5557e-04,  3.2383e-05,  ...,  1.6994e-04,\n",
       "               3.2795e-05,  3.2383e-05],\n",
       "             ...,\n",
       "             [ 2.5422e+00,  2.5420e+00,  7.9149e+00,  ...,  9.8479e+01,\n",
       "               4.5562e+00,  1.3744e+01],\n",
       "             [-1.5490e-02, -1.5267e-02, -6.5083e-01,  ..., -1.5379e-02,\n",
       "               1.3993e-01, -1.5476e-02],\n",
       "             [ 3.2496e-07, -6.4806e-05,  3.2496e-07,  ...,  2.6628e-05,\n",
       "              -8.6817e-08, -8.6817e-08]], device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([[8.5378e-02, 9.1151e-02, 3.5249e+00,  ..., 1.9326e+01, 2.8284e-01,\n",
       "              2.6955e+00],\n",
       "             [2.4724e+00, 2.4750e+00, 1.7560e+01,  ..., 3.2455e+03, 8.3376e+00,\n",
       "              6.6182e+01],\n",
       "             [3.7801e-09, 6.2130e-08, 3.7801e-09,  ..., 7.3535e-08, 3.8577e-09,\n",
       "              3.7801e-09],\n",
       "             ...,\n",
       "             [1.2175e+01, 1.2175e+01, 1.1807e+02,  ..., 1.8273e+04, 3.9155e+01,\n",
       "              3.5590e+02],\n",
       "             [8.5017e-05, 8.5193e-05, 1.4911e-01,  ..., 8.5076e-05, 6.8852e-03,\n",
       "              8.5021e-05],\n",
       "             [1.6027e-10, 1.2300e-08, 1.6027e-10,  ..., 2.7786e-09, 1.4485e-10,\n",
       "              1.4485e-10]], device='cuda:0')},\n",
       "    17: {'step': tensor(16.),\n",
       "     'exp_avg': tensor([-1.4258e+00, -7.2822e+00,  2.4208e-04,  2.4371e+01,  6.8395e-04,\n",
       "              2.6179e+01, -9.2548e-02,  2.7834e+01,  2.6558e-01,  5.3965e-02,\n",
       "              1.7216e-05,  4.4484e-04,  2.1761e+01,  3.9016e-04,  3.7475e-02,\n",
       "              1.8942e-04,  1.1157e-04,  1.8737e-04,  1.8266e+01,  2.2849e+01,\n",
       "              1.8295e+01,  2.3307e-04, -1.6495e+01,  5.0769e-05,  1.7030e+01,\n",
       "              1.5633e-01,  1.4614e-01,  2.3599e+01,  3.3177e-01, -1.0439e+01,\n",
       "              2.3075e+01,  1.1199e-01,  2.6943e+01,  1.7717e+01,  2.1796e+01,\n",
       "              1.9364e+01,  5.5244e-04, -1.5629e+01,  2.8791e-04,  5.3861e-04,\n",
       "              1.5167e-01,  7.4796e-02,  4.3416e-02,  1.8182e-04,  2.9248e+01,\n",
       "              8.8623e-05,  1.9186e+01, -6.3366e-02,  2.2989e+01,  6.7345e-04,\n",
       "              3.9179e+00,  1.9103e-01,  8.9142e-05,  1.7354e+01,  2.2171e-01,\n",
       "              5.1636e-05,  1.1884e+01, -1.0797e-01,  2.0489e+01,  4.9639e-01,\n",
       "              1.4569e-04,  1.2392e-04,  1.9147e+01,  2.0994e-02,  2.9505e+01,\n",
       "              2.5399e-01,  1.6056e+01,  2.5426e+01,  1.9691e+01,  2.6195e+01,\n",
       "              2.2459e+01,  1.3613e+01,  8.0215e-04,  5.5113e-03,  2.3275e+01,\n",
       "             -1.4366e+01,  2.4914e+01,  6.9734e-04,  1.0985e+01,  2.0223e-04,\n",
       "              2.6818e-04,  4.2698e-03,  1.7885e+00,  1.3738e-01,  2.3291e-01,\n",
       "              2.6349e+01, -1.0894e-01,  5.9696e-03, -1.8960e+00,  8.9555e-05,\n",
       "              2.8967e-01,  2.5912e-04, -1.4448e-01,  2.0889e-04, -1.2634e+01,\n",
       "              1.8138e+01,  3.6143e-04,  3.1076e-04,  1.1667e-01,  1.6116e-04,\n",
       "              6.3341e-04,  2.4244e+01,  1.1515e-02,  1.0814e-01,  2.9796e-04,\n",
       "              1.3237e+01,  2.4864e-04,  2.7403e+01,  8.4911e-04,  2.3430e+01,\n",
       "              1.3613e-01,  2.7746e+01, -9.3864e+00,  2.5345e+01, -4.7441e-04,\n",
       "              2.1785e-04,  1.8049e+01,  4.5636e+00,  2.3327e-01,  3.0303e-05,\n",
       "              1.0575e-04,  3.4199e+01,  6.8702e-05, -1.9517e+01,  2.3440e+01,\n",
       "              1.5695e+01, -9.5508e-02,  4.2028e-05], device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([3.2120e+00, 9.4237e+01, 1.4527e-07, 1.1192e+03, 1.1124e-06, 1.2921e+03,\n",
       "             8.7931e-03, 1.4601e+03, 2.4759e-02, 1.1889e-03, 1.4722e-09, 4.7641e-07,\n",
       "             8.9225e+02, 3.6830e-07, 4.9141e-04, 9.0515e-08, 3.3195e-08, 8.8644e-08,\n",
       "             6.2876e+02, 9.7558e+02, 6.3090e+02, 1.3498e-07, 5.1932e+02, 8.0114e-09,\n",
       "             5.4650e+02, 8.4448e-03, 7.9775e-03, 1.0430e+03, 1.4690e-02, 2.0123e+02,\n",
       "             1.0033e+03, 1.0608e-02, 1.3682e+03, 5.9143e+02, 8.9527e+02, 7.0683e+02,\n",
       "             7.2976e-07, 4.4899e+02, 2.0340e-07, 6.9301e-07, 2.0175e-02, 1.8714e-03,\n",
       "             9.4805e-04, 3.1451e-08, 1.6118e+03, 2.1671e-08, 6.9365e+02, 5.3514e-03,\n",
       "             9.9580e+02, 1.0790e-06, 2.8927e+01, 1.2833e-02, 2.1904e-08, 5.6098e+02,\n",
       "             1.7217e-02, 8.2497e-09, 2.6624e+02, 4.1405e-03, 7.9105e+02, 2.0601e-02,\n",
       "             5.4521e-08, 4.0407e-08, 6.9086e+02, 1.7938e-04, 1.6347e+03, 2.0035e-02,\n",
       "             4.8570e+02, 1.2182e+03, 7.3061e+02, 1.2930e+03, 9.5048e+02, 3.4341e+02,\n",
       "             1.5250e-06, 1.6126e-04, 1.0207e+03, 3.7956e+02, 1.1696e+03, 1.1559e-06,\n",
       "             2.2382e+02, 1.0265e-07, 1.7718e-07, 6.7404e-06, 6.0278e+00, 3.6328e-03,\n",
       "             7.3768e-03, 1.3082e+03, 4.2464e-03, 3.5855e-05, 6.1178e+00, 2.2091e-08,\n",
       "             1.1466e-02, 1.6574e-07, 1.2403e-02, 1.0926e-07, 2.9149e+02, 6.1987e+02,\n",
       "             3.1706e-07, 2.3603e-07, 2.7970e-02, 6.6453e-08, 9.5588e-07, 1.1075e+03,\n",
       "             1.3335e-04, 2.8356e-03, 2.1746e-07, 3.3008e+02, 1.5299e-07, 1.4149e+03,\n",
       "             1.7069e-06, 1.0345e+03, 1.8770e-02, 1.4506e+03, 1.6548e+02, 1.2104e+03,\n",
       "             3.6461e-07, 1.1847e-07, 6.1379e+02, 3.9242e+01, 1.6629e-02, 3.4005e-09,\n",
       "             3.0039e-08, 2.2038e+03, 1.3652e-08, 7.0688e+02, 1.0353e+03, 4.6409e+02,\n",
       "             3.2406e-03, 5.8039e-09], device='cuda:0')},\n",
       "    18: {'step': tensor(16.),\n",
       "     'exp_avg': tensor([[ 9.8252e-05,  1.6576e-04,  9.8252e-05,  ...,  9.8664e-05,\n",
       "              -9.4986e-04,  5.2742e-04],\n",
       "             [ 4.4039e-03,  3.9036e-03, -2.3788e-03,  ..., -8.0080e-04,\n",
       "               1.2798e-03,  7.9611e-05],\n",
       "             [ 1.3299e-04,  2.4301e-04,  7.2746e-05,  ...,  7.5069e-05,\n",
       "               1.6359e-04, -1.8278e-05],\n",
       "             ...,\n",
       "             [ 1.3699e-05,  1.7683e-05,  2.2401e-05,  ..., -2.9533e-04,\n",
       "               1.8805e-05,  2.1989e-05],\n",
       "             [-1.4484e+01, -2.0410e+01, -9.8993e-01,  ..., -7.8074e+01,\n",
       "              -9.8631e-01,  7.1863e-01],\n",
       "             [ 4.3360e+00,  4.9573e+00,  2.1073e-01,  ..., -1.8709e+00,\n",
       "               2.0449e-01,  2.0905e-01]], device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([[2.6208e-08, 7.0116e-08, 2.6208e-08,  ..., 2.6411e-08, 2.1318e-06,\n",
       "              6.6605e-07],\n",
       "             [3.8192e-05, 1.5025e-05, 5.2576e-06,  ..., 3.1985e-06, 2.8643e-06,\n",
       "              8.5540e-08],\n",
       "             [4.6156e-08, 1.4634e-07, 1.5131e-08,  ..., 1.6015e-08, 6.8380e-08,\n",
       "              1.5990e-09],\n",
       "             ...,\n",
       "             [1.0897e-09, 1.5273e-09, 2.1409e-09,  ..., 2.1373e-07, 1.6639e-09,\n",
       "              2.0832e-09],\n",
       "             [4.1142e+02, 7.9790e+02, 1.8340e+00,  ..., 1.1481e+04, 1.8340e+00,\n",
       "              9.5961e-01],\n",
       "             [3.5376e+01, 4.6332e+01, 8.1343e-02,  ..., 6.5871e+00, 8.1347e-02,\n",
       "              8.1326e-02]], device='cuda:0')},\n",
       "    19: {'step': tensor(16.),\n",
       "     'exp_avg': tensor([ 6.4876e-04,  2.2822e-03,  2.4805e-04,  6.9202e-04,  1.1536e+01,\n",
       "              4.3948e-04,  8.8731e-03,  1.0626e+01, -4.5270e+00, -3.7925e-02,\n",
       "              3.1888e+00,  2.4053e-02,  9.6444e+00,  7.0790e+00, -6.9299e+00,\n",
       "              7.5312e-04,  6.7459e-03,  1.0554e+01,  4.7027e-03,  4.0161e-05,\n",
       "              2.7402e-02,  1.2472e+01,  9.7236e+00,  5.8141e-04,  1.2121e-03,\n",
       "             -1.1269e+00,  6.6203e+00,  6.3963e-03,  1.1913e-03,  2.1531e+00,\n",
       "             -8.4939e+00, -3.1705e-02,  6.8416e-03,  7.5564e+00,  8.6295e+00,\n",
       "              3.5585e+00, -4.1699e+00, -1.1735e+00,  2.1082e-03,  1.1519e+01,\n",
       "              3.4598e-03,  5.2177e+00,  1.5729e-01,  7.3863e+00,  4.8552e-03,\n",
       "              6.1364e+00,  1.1225e+01,  1.1139e+01,  9.5181e+00,  1.2999e+01,\n",
       "              5.2776e-02,  7.5207e+00,  3.7653e-02,  1.2434e-03,  7.9527e-04,\n",
       "              1.9284e-03,  1.5140e-01, -1.8605e-03,  4.2183e-03,  1.1020e+01,\n",
       "             -6.6560e+00,  6.5252e-04,  8.4102e+00,  1.1642e-03,  1.9502e+00,\n",
       "             -1.6381e+00,  9.2197e+00,  2.8535e-04,  2.1459e+00,  2.4183e+00,\n",
       "              8.3835e-04,  1.3788e-03,  8.9832e+00,  8.0243e+00,  1.0168e-03,\n",
       "              7.2700e+00,  2.2710e-03,  1.1908e-03,  1.0700e+01,  4.2414e+00,\n",
       "              2.7872e-03,  4.3521e+00,  7.0580e-03,  4.7841e-04,  6.7228e+00,\n",
       "              4.3975e-04,  1.0824e+01,  7.7130e-04,  8.6107e+00, -3.7689e+00,\n",
       "              1.6930e-03,  7.5531e+00,  1.0191e-03,  1.0431e+01,  2.7930e-03,\n",
       "              1.1155e+01,  1.1856e+01,  2.2187e+00,  1.5742e-03, -2.9868e+00,\n",
       "              3.5931e+00,  2.4803e-03,  1.0180e+01,  5.6562e+00,  2.3224e-03,\n",
       "              5.5953e-04,  1.2270e-03,  6.1831e+00,  1.0650e+01, -5.5222e+00,\n",
       "              1.3520e-03,  8.3452e+00,  1.0266e+01,  7.6173e-03,  5.3367e-04,\n",
       "              2.7352e-04,  9.2078e+00,  2.0164e-03, -1.2419e+00,  4.6368e+00,\n",
       "             -1.5690e+00,  1.0946e+01,  1.3105e-03,  2.7847e-04,  8.1812e+00,\n",
       "              1.7791e-04, -6.0430e+00,  1.2830e+00], device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([1.0022e-06, 5.0220e-06, 1.5229e-07, 1.1385e-06, 2.4959e+02, 4.6519e-07,\n",
       "             7.3231e-05, 2.1637e+02, 3.6582e+01, 9.8103e-05, 1.8635e+01, 7.1807e-03,\n",
       "             1.7431e+02, 9.7425e+01, 8.6604e+01, 1.3460e-06, 5.0391e-05, 2.0822e+02,\n",
       "             1.6566e-05, 5.3784e-09, 1.0764e-03, 2.9159e+02, 1.7821e+02, 8.0715e-07,\n",
       "             3.4591e-06, 1.6688e+00, 8.2304e+01, 3.1520e-05, 3.3423e-06, 8.7667e+00,\n",
       "             1.3767e+02, 1.1661e-04, 6.4625e-05, 1.0664e+02, 1.4333e+02, 2.3859e+01,\n",
       "             3.0771e+01, 2.2410e+00, 1.0406e-05, 2.5328e+02, 1.2980e-05, 5.0999e+01,\n",
       "             4.5779e-02, 1.0201e+02, 2.8774e-05, 7.0787e+01, 2.3651e+02, 2.3341e+02,\n",
       "             1.6824e+02, 3.2345e+02, 2.8976e-03, 1.0663e+02, 5.9466e-04, 2.2374e-06,\n",
       "             1.4992e-06, 8.7129e-06, 3.4555e-03, 4.2187e-06, 2.2305e-05, 2.3206e+02,\n",
       "             8.2116e+01, 1.0137e-06, 1.3328e+02, 3.1927e-06, 7.1667e+00, 5.7020e+00,\n",
       "             1.6020e+02, 1.9990e-07, 8.5074e+00, 1.1031e+01, 1.6643e-06, 4.4688e-06,\n",
       "             1.5503e+02, 1.2150e+02, 2.4405e-06, 9.9585e+01, 1.2069e-05, 3.3394e-06,\n",
       "             2.1410e+02, 3.3598e+01, 1.0484e-05, 3.5499e+01, 5.3271e-05, 5.4968e-07,\n",
       "             8.5078e+01, 4.6576e-07, 2.1958e+02, 1.4111e-06, 1.3898e+02, 2.8131e+01,\n",
       "             6.7230e-06, 1.0752e+02, 2.4512e-06, 2.0729e+02, 1.3873e-05, 2.3453e+02,\n",
       "             2.6800e+02, 9.2814e+00, 2.4303e-06, 1.5607e+01, 2.4383e+01, 4.3747e-06,\n",
       "             1.9413e+02, 6.0280e+01, 6.5180e-06, 7.4834e-07, 3.5438e-06, 7.1509e+01,\n",
       "             2.1223e+02, 5.6856e+01, 4.2977e-06, 1.3127e+02, 1.9838e+02, 3.1252e-05,\n",
       "             6.8167e-07, 1.8410e-07, 1.5863e+02, 9.5229e-06, 3.4210e+00, 4.0547e+01,\n",
       "             3.5533e+00, 2.2480e+02, 4.0394e-06, 1.9063e-07, 1.2529e+02, 8.0270e-08,\n",
       "             6.9907e+01, 3.0998e+00], device='cuda:0')},\n",
       "    20: {'step': tensor(16.),\n",
       "     'exp_avg': tensor([[ 9.8103e-03,  5.9169e-03,  5.2951e-03,  ...,  5.5637e-03,\n",
       "               5.0143e-01,  5.8585e-03],\n",
       "             [ 1.7665e+00,  7.3714e-02,  1.8988e+00,  ..., -2.7138e+00,\n",
       "               1.9450e+02, -1.1235e+00],\n",
       "             [ 6.5515e-04,  2.5214e-03, -5.7516e-03,  ...,  1.1176e-03,\n",
       "               1.1248e-03,  6.5897e-04],\n",
       "             ...,\n",
       "             [ 6.1585e-03,  6.9008e-03, -4.9979e-04,  ..., -4.3543e-03,\n",
       "               3.2495e-03,  4.5825e-03],\n",
       "             [ 5.0021e-03,  4.3371e-03,  4.4964e-03,  ..., -7.8348e-03,\n",
       "               2.0718e-03,  3.6025e-03],\n",
       "             [ 2.4306e-03,  9.1204e-04,  3.3130e-03,  ..., -3.4951e-03,\n",
       "               2.1474e-04,  1.4470e-03]], device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([[2.9027e-05, 1.4760e-05, 1.6029e-05,  ..., 1.5261e-05, 4.7584e-02,\n",
       "              1.4803e-05],\n",
       "             [6.8309e+00, 4.8849e-03, 6.8292e+00,  ..., 1.2913e+01, 7.1254e+04,\n",
       "              2.4375e+00],\n",
       "             [1.0218e-06, 1.4867e-05, 7.7088e-05,  ..., 2.9440e-06, 2.9819e-06,\n",
       "              1.0336e-06],\n",
       "             ...,\n",
       "             [8.8364e-05, 1.1092e-04, 5.9906e-07,  ..., 4.4221e-05, 2.4658e-05,\n",
       "              4.8969e-05],\n",
       "             [5.8329e-05, 4.3872e-05, 4.7148e-05,  ..., 1.4294e-04, 1.0052e-05,\n",
       "              3.0292e-05],\n",
       "             [1.3819e-05, 1.9668e-06, 2.5629e-05,  ..., 2.8516e-05, 1.1523e-07,\n",
       "              4.9191e-06]], device='cuda:0')},\n",
       "    21: {'step': tensor(16.),\n",
       "     'exp_avg': tensor([ 3.7465e-02,  1.1837e+01,  4.0864e-03,  5.9256e+00,  3.2495e-03,\n",
       "              7.1817e-03,  3.3060e+00,  1.4945e-04,  3.7718e+00,  2.5010e-04,\n",
       "              1.1537e-02,  9.9696e+00,  1.3456e+01, -2.4123e-01,  5.8389e-03,\n",
       "              1.7821e+00,  1.2644e+01,  7.4841e-04,  1.4625e+01,  9.9230e-03,\n",
       "              1.4425e-03,  1.4966e-02,  4.8698e+00,  9.1182e+00,  8.8330e+00,\n",
       "              8.2058e+00,  8.1826e+00,  5.0994e-03,  7.8398e+00,  1.3188e-02,\n",
       "              8.4916e-03,  2.3954e-03], device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([5.6122e-04, 2.6024e+02, 3.8956e-05, 6.6361e+01, 2.4658e-05, 1.2012e-04,\n",
       "             2.0599e+01, 5.7570e-08, 2.7305e+01, 1.5474e-07, 3.0976e-04, 1.8466e+02,\n",
       "             3.3249e+02, 1.3902e+00, 7.9441e-05, 5.9873e+00, 3.0187e+02, 1.3294e-06,\n",
       "             3.9501e+02, 2.2919e-04, 4.8888e-06, 5.2108e-04, 4.4699e+01, 1.5646e+02,\n",
       "             1.4673e+02, 1.2712e+02, 1.2617e+02, 6.0616e-05, 1.1559e+02, 4.0463e-04,\n",
       "             1.6788e-04, 1.3423e-05], device='cuda:0')},\n",
       "    22: {'step': tensor(16.),\n",
       "     'exp_avg': tensor([[-3.1068e+00,  1.9460e+03,  2.8879e+00,  1.2088e+03, -8.9139e-01,\n",
       "              -3.9641e+00,  5.2212e+02,  3.6489e+00,  9.0344e+01, -5.7463e+00,\n",
       "              -4.9952e+00,  8.9385e+02,  6.8161e+02,  5.5875e+01, -3.2272e-01,\n",
       "               5.2430e+02,  8.5296e+02, -9.9301e-01,  1.7080e+03, -1.1504e+00,\n",
       "              -4.6483e-01, -2.6153e-01,  9.2959e+02,  1.9016e+03,  7.1196e+01,\n",
       "               1.2943e+03,  4.9543e+02,  2.7221e+00,  1.5426e+03, -3.4536e-01,\n",
       "               3.8030e+00, -1.0256e+00]], device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([[2.4270e+01, 7.0803e+06, 1.8810e+01, 2.7538e+06, 1.8863e+00, 3.1157e+01,\n",
       "              5.1364e+05, 1.8828e+01, 1.4564e+04, 7.1145e+01, 5.5997e+01, 1.4945e+06,\n",
       "              8.7038e+05, 1.8334e+04, 4.7222e-01, 5.1745e+05, 1.3723e+06, 9.2378e-01,\n",
       "              5.4712e+06, 1.8536e+00, 1.1070e+00, 8.9845e-01, 1.6307e+06, 6.8160e+06,\n",
       "              9.5697e+03, 3.1589e+06, 4.6356e+05, 1.8816e+01, 4.4737e+06, 4.5389e-01,\n",
       "              1.8842e+01, 3.5887e+00]], device='cuda:0')},\n",
       "    23: {'step': tensor(16.),\n",
       "     'exp_avg': tensor([17.9300], device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([716.9049], device='cuda:0')}},\n",
       "   'param_groups': [{'lr': 0.08387096774193553,\n",
       "     'betas': (0.9, 0.999),\n",
       "     'eps': 1e-08,\n",
       "     'weight_decay': 0,\n",
       "     'amsgrad': False,\n",
       "     'maximize': False,\n",
       "     'foreach': None,\n",
       "     'capturable': False,\n",
       "     'differentiable': False,\n",
       "     'fused': None,\n",
       "     'initial_lr': 0.10000000000000005,\n",
       "     'params': [0,\n",
       "      1,\n",
       "      2,\n",
       "      3,\n",
       "      4,\n",
       "      5,\n",
       "      6,\n",
       "      7,\n",
       "      8,\n",
       "      9,\n",
       "      10,\n",
       "      11,\n",
       "      12,\n",
       "      13,\n",
       "      14,\n",
       "      15,\n",
       "      16,\n",
       "      17,\n",
       "      18,\n",
       "      19,\n",
       "      20,\n",
       "      21,\n",
       "      22,\n",
       "      23]}]}],\n",
       " 'lr_schedulers': [{'base_lrs': [0.10000000000000005],\n",
       "   'last_epoch': 4,\n",
       "   'verbose': False,\n",
       "   '_step_count': 5,\n",
       "   '_get_lr_called_within_step': False,\n",
       "   '_last_lr': [0.08387096774193553],\n",
       "   'lr_lambdas': [None]}],\n",
       " 'hparams_name': 'kwargs',\n",
       " 'hyper_parameters': {'config': Config(gat_v4_weight_initializer=['uniform'], gat_hidden_channels=[8, 32, 128, 256], device=[0], root_dir='/home/lcornelis/code/proteo', checkpoint_every_n_epochs_train=1, l1_lambda=1e-05, pin_memory=True, sex=['M'], wgcna_mergeCutHeight=0.25, y_val='nfl', log_every_n_steps=10, num_samples=1, gat_v4_heads=[[2, 3]], cpu_per_worker=16, nodes_count=1, adj_thresh=0.1, gat_heads=[1, 2, 4, 8], optimizer='Adam', checkpoint_dir='/scratch/lcornelis/outputs/checkpoints', num_to_keep=3, seed=19543, modality_choices=['plasma'], l1_lambda_min=1e-05, gat-v4={'hidden_channels': [8, 16], 'heads': [2, 3], 'use_layer_norm': True, 'which_layer': ['layer1', 'layer2', 'layer3'], 'fc_dim': [64, 128, 128, 32], 'fc_dropout': 0.1, 'fc_act': 'relu', 'weight_initializer': 'uniform', 'num_layers': None}, lr=0.10000000000000005, wgcna_minModuleSize=10, gat_num_layers=[2, 4, 6, 12], model='gat-v4', dataset_name='ftd', y_val_choices=['nfl'], gat_v4_hidden_channels=[[8, 16]], accumulate_grad_batches=1, gat={'num_layers': 2, 'hidden_channels': 256, 'heads': 4, 'v2': True}, trainer_accelerator='gpu', precision='32-true', gat_v4_fc_act=['relu'], batch_size_choices=[8], lr_scheduler='LambdaLR', num_workers=16, epochs=30, data_dir='/home/data/data_louisa', wandb_api_key_path='wandb_api_key.txt', dropout_choices=[0], dropout=0, gat_v4_fc_dim=[[64, 128, 128, 32]], ray_tmp_dir='/scratch/lcornelis/tmp', error_protein_file_name='bimodal_aptamers_for_removal.xlsx', act='relu', gcn_hidden_channels=[8, 32, 128], lr_max=0.1, gpu_per_worker=1, wandb_tmp_dir='/tmp', weight_decay=0, reduction_factor=8, lr_scheduler_choices=['LambdaLR'], model_grid_search=['gat-v4'], gcn_num_layers=[2, 3, 4], wandb_offline=False, act_choices=['relu'], project='proteo', num_nodes=30, grace_period=30, adj_thresh_choices=[0.1], gcn={'num_layers': 3, 'hidden_channels': 32}, lr_min=0.1, mutation_choices=[['GRN']], raw_file_name='ALLFTD_dataset_for_nina_louisa_071124.csv', sex_choices=[['M']], num_nodes_choices=[30], mutation=['GRN'], ray_results_dir='/scratch/lcornelis/outputs/ray_results', l1_lambda_max=1e-05, batch_size=8, gat_v4_fc_dropout=[0.1], use_progress_bar=True, modality='plasma', sync_batchnorm=False, output_dir='/scratch/lcornelis/outputs'),\n",
       "  'in_channels': 1,\n",
       "  'out_channels': 1,\n",
       "  'avg_node_degree': 0.9,\n",
       "  'pos_weight': 1.0,\n",
       "  'focal_loss_weight': [1.0]}}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in train and test datasets using config\n",
    "# run model and get val_targets val_preds train_targets train_preds\n",
    "# find loss for each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proteo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
