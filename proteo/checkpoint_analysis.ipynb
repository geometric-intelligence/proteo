{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import train as proteo_train\n",
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from proteo.datasets.ftd import FTDDataset, reverse_log_transform\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "from scipy.stats import zscore\n",
    "\n",
    "\n",
    "def load_checkpoint(relative_checkpoint_path):\n",
    "    '''Load the checkpoint as a module. Note levels_up depends on the directory structure of the ray_results folder'''\n",
    "    relative_checkpoint_path = os.path.join(relative_checkpoint_path, 'checkpoint.ckpt')\n",
    "    # Check if the file exists to avoid errors\n",
    "    if not os.path.isfile(relative_checkpoint_path):\n",
    "        raise FileNotFoundError(f\"Checkpoint file not found: {relative_checkpoint_path}\")\n",
    "    module = proteo_train.Proteo.load_from_checkpoint(relative_checkpoint_path)\n",
    "    return module\n",
    "\n",
    "# Load in the datasets from the config\n",
    "def load_config(module):\n",
    "    '''Load the config from the module  and return it'''\n",
    "    config = module.config\n",
    "    return config\n",
    "\n",
    "\n",
    "def load_model_and_predict(module, config, device = 'cuda'):\n",
    "    '''Run the module with the correct train and test datasets and return the predictions and targets'''\n",
    "    module.to(device)\n",
    "    module.eval()\n",
    "    #pl.seed_everything(config.seed)\n",
    "    train_dataset, test_dataset = proteo_train.construct_datasets(config)\n",
    "    train_loader, test_loader = proteo_train.construct_loaders(config, train_dataset, test_dataset)\n",
    "    # Get predictions and targets for the training set\n",
    "    train_preds, train_targets = [], []\n",
    "    for batch in train_loader:\n",
    "        batch.to(device)\n",
    "        with torch.no_grad():\n",
    "        # Forward pass\n",
    "            pred = module(batch)\n",
    "            target = batch.y.view(pred.shape)\n",
    "        \n",
    "        # Store predictions and targets\n",
    "        train_preds.append(pred.cpu())\n",
    "        train_targets.append(target.cpu())\n",
    "    train_preds = torch.cat(train_preds)\n",
    "    train_targets = torch.cat(train_targets)\n",
    "    \n",
    "    # Calculate MSE for training set\n",
    "    train_mse = F.mse_loss(train_preds, train_targets).item()\n",
    "    \n",
    "    # Get predictions and targets for the validation set\n",
    "    val_preds, val_targets = [], []\n",
    "    for batch in test_loader:\n",
    "        batch.to(device)\n",
    "        # Forward pass\n",
    "        pred = module(batch)\n",
    "        target = batch.y.view(pred.shape)\n",
    "        \n",
    "        # Store predictions and targets\n",
    "        val_preds.append(pred.cpu())\n",
    "        val_targets.append(target.cpu())\n",
    "    val_preds = torch.cat(val_preds)\n",
    "    val_targets = torch.cat(val_targets)\n",
    "    \n",
    "    # Calculate MSE for validation set\n",
    "    val_mse = F.mse_loss(val_preds, val_targets).item()\n",
    "    print(\"Normalized Val MSE:\", val_mse)\n",
    "    print(\"Normalized train MSE:\", train_mse)\n",
    "    return train_preds, train_targets, train_mse, val_preds, val_targets, val_mse\n",
    "\n",
    "def full_load_and_run_and_convert(relative_checkpoint_path, device, mean, std):\n",
    "    '''Call all the functions to load the checkpoint, run the model and convert the predictions back to the original units'''\n",
    "    module = load_checkpoint(relative_checkpoint_path)\n",
    "    config = load_config(module)\n",
    "    train_preds, train_targets, train_mse, val_preds, val_targets, val_mse = load_model_and_predict(module, config, device)\n",
    "    train_preds = reverse_log_transform(train_preds, mean, std)\n",
    "    train_targets = reverse_log_transform(train_targets, mean, std)\n",
    "    train_mse = F.mse_loss(train_preds, train_targets)\n",
    "    train_rmse = torch.sqrt(train_mse)\n",
    "    val_preds = reverse_log_transform(val_preds, mean, std)\n",
    "    val_targets = reverse_log_transform(val_targets, mean, std)\n",
    "    val_mse = F.mse_loss(val_preds, val_targets)\n",
    "    val_rmse = torch.sqrt(val_mse)\n",
    "    print(val_preds.view(-1).detach().cpu().numpy())\n",
    "    val_z_scores = zscore(val_preds.view(-1).detach().cpu().numpy() - val_targets.view(-1).detach().cpu().numpy(), ddof=1)\n",
    "    #print(\"Original Units Train preds:\", train_preds)\n",
    "    #print(\"Original Units Train targets:\", train_targets)\n",
    "    #print(\"Original Units Train MSE:\", train_mse)\n",
    "    #print(\"Original Units Train RMSE:\", train_rmse)\n",
    "    #print(\"Original Units Val preds:\", val_preds)\n",
    "    #print(\"Original Units Val targets:\", val_targets)\n",
    "    print(\"Original Units Val MSE:\", val_mse)\n",
    "    print(\"Original Units Val RMSE:\", val_rmse)\n",
    "    print(\"Val Z scores:\", val_z_scores)\n",
    "    return [train_preds, train_targets, train_mse, train_rmse, val_preds, val_targets, val_mse, val_rmse, val_z_scores]\n",
    "\n",
    "def process_checkpoints(checkpoint_paths, mean_dict, std_dict, device):\n",
    "    results = []\n",
    "    i = 1\n",
    "    for checkpoint_path in checkpoint_paths:\n",
    "        print(f\"Loading checkpoint from: {checkpoint_path}\")\n",
    "        module = load_checkpoint(checkpoint_path)\n",
    "        config = load_config(module)\n",
    "        #print(\"Config being used:\", config)\n",
    "        print(f\"{i} best checkpoint for {config.sex} and {config.modality}\")\n",
    "        key = f\"{config.sex}_{config.modality}\"\n",
    "        mean = mean_dict[key]\n",
    "        std = std_dict[key]\n",
    "        \n",
    "        result = full_load_and_run_and_convert(checkpoint_path, device, mean, std)\n",
    "        results.append(result)\n",
    "        i += 1\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint from: /scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_10-30-17/model=gat-v4,seed=3784_347_act=elu,adj_thresh=0.0500,batch_size=8,dropout=0.1000,l1_lambda=0.0010,lr=0.0007,lr_scheduler=CosineAnn_2024-08-01_11-17-45/checkpoint_000101\n",
      "1 best checkpoint for ['M'] and csf\n",
      "Loading data from: /home/data/data_louisa/processed/ftd_y_val_nfl_adj_thresh_0.05_num_nodes_150_mutation_C9orf72_csf_sex_M_train.pt\n",
      "Loading data from: /home/data/data_louisa/processed/ftd_y_val_nfl_adj_thresh_0.05_num_nodes_150_mutation_C9orf72_csf_sex_M_test.pt\n",
      "Normalized Val MSE: 0.06449513137340546\n",
      "Normalized train MSE: 0.15109355747699738\n",
      "[ 3.5153    7.955807  5.813492 11.785532 17.050365]\n",
      "Original Units Val MSE: tensor(4.6682, grad_fn=<MseLossBackward0>)\n",
      "Original Units Val RMSE: tensor(2.1606, grad_fn=<SqrtBackward0>)\n",
      "Val Z scores: [ 0.65391517 -1.2735126   0.33508742 -0.80584943  1.0903596 ]\n",
      "Loading checkpoint from: /scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_10-30-17/model=gat-v4,seed=36658_797_act=leaky_relu,adj_thresh=0.7000,batch_size=16,dropout=0.1000,l1_lambda=0.0002,lr=0.0010,lr_scheduler=_2024-08-01_13-15-10/checkpoint_000132\n",
      "2 best checkpoint for ['M'] and csf\n",
      "Loading data from: /home/data/data_louisa/processed/ftd_y_val_nfl_adj_thresh_0.7_num_nodes_150_mutation_C9orf72_csf_sex_M_train.pt\n",
      "Loading data from: /home/data/data_louisa/processed/ftd_y_val_nfl_adj_thresh_0.7_num_nodes_150_mutation_C9orf72_csf_sex_M_test.pt\n",
      "Normalized Val MSE: 0.48812779784202576\n",
      "Normalized train MSE: 1.0713725090026855\n",
      "[8.078319 8.359328 8.205642 8.418733 8.506824]\n",
      "Original Units Val MSE: tensor(24.8225, grad_fn=<MseLossBackward0>)\n",
      "Original Units Val RMSE: tensor(4.9822, grad_fn=<SqrtBackward0>)\n",
      "Val Z scores: [ 1.3158479  -0.31053892  0.76790833 -0.8149238  -0.9582934 ]\n",
      "Loading checkpoint from: /scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_10-30-17/model=gat-v4,seed=43041_59_act=leaky_relu,adj_thresh=0.1000,batch_size=32,dropout=0.2000,l1_lambda=0.0033,lr=0.0122,lr_scheduler=C_2024-08-01_10-30-18/checkpoint_000006\n",
      "3 best checkpoint for ['M'] and csf\n",
      "Loading data from: /home/data/data_louisa/processed/ftd_y_val_nfl_adj_thresh_0.1_num_nodes_30_mutation_C9orf72_csf_sex_M_train.pt\n",
      "Loading data from: /home/data/data_louisa/processed/ftd_y_val_nfl_adj_thresh_0.1_num_nodes_30_mutation_C9orf72_csf_sex_M_test.pt\n",
      "Normalized Val MSE: 0.5045854449272156\n",
      "Normalized train MSE: 1.0368807315826416\n",
      "[8.349751 8.415799 8.293927 8.526059 8.468008]\n",
      "Original Units Val MSE: tensor(25.3133, grad_fn=<MseLossBackward0>)\n",
      "Original Units Val RMSE: tensor(5.0312, grad_fn=<SqrtBackward0>)\n",
      "Val Z scores: [ 1.3262857  -0.31287074  0.7535629  -0.79947776 -0.9675001 ]\n",
      "Loading checkpoint from: /scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_10-30-17/model=gat-v4,seed=15140_461_act=tanh,adj_thresh=0.5000,batch_size=8,dropout=0.1000,l1_lambda=0.0001,lr=0.0002,lr_scheduler=CosineA_2024-08-01_11-48-59/checkpoint_000016\n",
      "1 best checkpoint for ['F'] and csf\n",
      "Loading data from: /home/data/data_louisa/processed/ftd_y_val_nfl_adj_thresh_0.5_num_nodes_10_mutation_C9orf72_csf_sex_F_train.pt\n",
      "Loading data from: /home/data/data_louisa/processed/ftd_y_val_nfl_adj_thresh_0.5_num_nodes_10_mutation_C9orf72_csf_sex_F_test.pt\n",
      "Normalized Val MSE: 0.36567676067352295\n",
      "Normalized train MSE: 0.9450468420982361\n",
      "[ 9.240113   5.892234   5.930637   6.2529807  6.5837812 10.928167\n",
      "  8.538054   6.8154254  8.322461 ]\n",
      "Original Units Val MSE: tensor(79.8927, grad_fn=<MseLossBackward0>)\n",
      "Original Units Val RMSE: tensor(8.9383, grad_fn=<SqrtBackward0>)\n",
      "Val Z scores: [-0.02990345  0.36557683  0.07770658  0.6950302   0.38300645 -2.5564427\n",
      "  0.7978288   0.23855527  0.02864225]\n",
      "Loading checkpoint from: /scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_10-30-17/model=gat-v4,seed=29159_100_act=sigmoid,adj_thresh=0.1000,batch_size=50,dropout=0.1000,l1_lambda=0.0004,lr=0.0005,lr_scheduler=Lam_2024-08-01_10-30-18/checkpoint_000249\n",
      "2 best checkpoint for ['F'] and plasma\n",
      "Loading data from: /home/data/data_louisa/processed/ftd_y_val_nfl_adj_thresh_0.1_num_nodes_150_mutation_C9orf72_plasma_sex_F_train.pt\n",
      "Loading data from: /home/data/data_louisa/processed/ftd_y_val_nfl_adj_thresh_0.1_num_nodes_150_mutation_C9orf72_plasma_sex_F_test.pt\n",
      "Normalized Val MSE: 0.30560287833213806\n",
      "Normalized train MSE: 0.7147945761680603\n",
      "[13.941537  10.510754  30.217531   9.8441105  8.58408   21.923168\n",
      " 25.473434  29.662582  11.942662  10.134536  13.085564  28.563044\n",
      " 20.757145  18.917728   7.6995015]\n",
      "Original Units Val MSE: tensor(85.1494, grad_fn=<MseLossBackward0>)\n",
      "Original Units Val RMSE: tensor(9.2276, grad_fn=<SqrtBackward0>)\n",
      "Val Z scores: [ 0.18772842  0.39204198 -1.0421914  -0.01887734  0.19714513  0.6050593\n",
      "  1.1039592  -0.3935356   0.5825434   0.24791226  0.12406038 -3.1294029\n",
      "  0.42415932  0.7456609  -0.02626331]\n",
      "Loading checkpoint from: /scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_10-30-17/model=gat-v4,seed=44912_137_act=leaky_relu,adj_thresh=0.9000,batch_size=8,dropout=0,l1_lambda=0.0037,lr=0.0229,lr_scheduler=StepLR_2024-08-01_10-30-18/checkpoint_000009\n",
      "3 best checkpoint for ['F'] and csf\n",
      "Loading data from: /home/data/data_louisa/processed/ftd_y_val_nfl_adj_thresh_0.9_num_nodes_150_mutation_C9orf72_csf_sex_F_train.pt\n",
      "Loading data from: /home/data/data_louisa/processed/ftd_y_val_nfl_adj_thresh_0.9_num_nodes_150_mutation_C9orf72_csf_sex_F_test.pt\n",
      "Normalized Val MSE: 0.5370379686355591\n",
      "Normalized train MSE: 1.1349607706069946\n",
      "[8.711784 8.762735 8.720394 8.398679 8.124364 8.971519 8.699408 8.653441\n",
      " 9.0058  ]\n",
      "Original Units Val MSE: tensor(95.4852, grad_fn=<MseLossBackward0>)\n",
      "Original Units Val RMSE: tensor(9.7717, grad_fn=<SqrtBackward0>)\n",
      "Val Z scores: [-0.18203166  0.50039524  0.2380422   0.72061133  0.3855547  -2.5550945\n",
      "  0.61713594  0.28700525 -0.01161841]\n",
      "Loading checkpoint from: /scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_10-30-17/model=gat-v4,seed=40910_881_act=tanh,adj_thresh=0.7000,batch_size=16,dropout=0.1000,l1_lambda=0.0000,lr=0.0037,lr_scheduler=Cosine_2024-08-01_13-32-59/checkpoint_000039\n",
      "1 best checkpoint for ['M', 'F'] and csf\n",
      "Loading data from: /home/data/data_louisa/processed/ftd_y_val_nfl_adj_thresh_0.7_num_nodes_30_mutation_C9orf72_csf_sex_M,F_train.pt\n",
      "Loading data from: /home/data/data_louisa/processed/ftd_y_val_nfl_adj_thresh_0.7_num_nodes_30_mutation_C9orf72_csf_sex_M,F_test.pt\n",
      "Normalized Val MSE: 0.1276329606771469\n",
      "Normalized train MSE: 0.29277917742729187\n",
      "[ 4.4068055  6.804485  20.145092  13.985803  48.058838  52.437057\n",
      "  4.7286654 20.50367    5.821023   6.832498   5.6627746  4.874128\n",
      "  5.4088717]\n",
      "Original Units Val MSE: tensor(60.1464, grad_fn=<MseLossBackward0>)\n",
      "Original Units Val RMSE: tensor(7.7554, grad_fn=<SqrtBackward0>)\n",
      "Val Z scores: [-0.02260416  0.1072783  -0.0690027   0.63216335  1.4961797   1.7857127\n",
      " -0.13647299 -2.3811991  -0.3057437  -0.471948   -0.13742478 -0.3153914\n",
      " -0.18154691]\n",
      "Loading checkpoint from: /scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_10-30-17/model=gat-v4,seed=42404_611_act=leaky_relu,adj_thresh=0.9000,batch_size=16,dropout=0.2000,l1_lambda=0.0000,lr=0.0061,lr_scheduler=_2024-08-01_12-24-45/checkpoint_000146\n",
      "2 best checkpoint for ['M', 'F'] and csf\n",
      "Loading data from: /home/data/data_louisa/processed/ftd_y_val_nfl_adj_thresh_0.9_num_nodes_10_mutation_C9orf72_csf_sex_M,F_train.pt\n",
      "Loading data from: /home/data/data_louisa/processed/ftd_y_val_nfl_adj_thresh_0.9_num_nodes_10_mutation_C9orf72_csf_sex_M,F_test.pt\n",
      "Normalized Val MSE: 0.17307625710964203\n",
      "Normalized train MSE: 0.5733414888381958\n",
      "[ 2.7891128  5.871027  24.960968   9.750901  45.524784  60.982365\n",
      "  3.1795125 18.623095   3.4568956  6.4091573  5.091896   3.2782202\n",
      "  6.2289643]\n",
      "Original Units Val MSE: tensor(87.5495, grad_fn=<MseLossBackward0>)\n",
      "Original Units Val RMSE: tensor(9.3568, grad_fn=<SqrtBackward0>)\n",
      "Val Z scores: [-0.15820447  0.01919154  0.47107616  0.10685313  0.9912454   2.3776581\n",
      " -0.24439986 -2.1181111  -0.46763128 -0.4025182  -0.14371166 -0.3958557\n",
      " -0.03559178]\n",
      "Loading checkpoint from: /scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_10-30-17/model=gat-v4,seed=40995_232_act=relu,adj_thresh=0.9000,batch_size=8,dropout=0,l1_lambda=0.0001,lr=0.0004,lr_scheduler=ReduceLROnPl_2024-08-01_10-40-25/checkpoint_000027\n",
      "3 best checkpoint for ['M', 'F'] and plasma\n",
      "Loading data from: /home/data/data_louisa/processed/ftd_y_val_nfl_adj_thresh_0.9_num_nodes_1000_mutation_C9orf72_plasma_sex_M,F_train.pt\n",
      "Loading data from: /home/data/data_louisa/processed/ftd_y_val_nfl_adj_thresh_0.9_num_nodes_1000_mutation_C9orf72_plasma_sex_M,F_test.pt\n",
      "Normalized Val MSE: 0.6721312999725342\n",
      "Normalized train MSE: 0.45841774344444275\n",
      "[12.444145  13.18088   25.809322  10.483014  16.291386  11.497565\n",
      "  5.9324737  4.859363  19.435556  21.671103  19.182562   6.1143208\n",
      " 14.426516   5.7170067 20.046776   6.76013    8.378976   5.9896665\n",
      " 14.081887   4.300649   6.138682  18.579123   4.733747  18.142595\n",
      "  3.6443188  5.268112 ]\n",
      "Original Units Val MSE: tensor(562.9792, grad_fn=<MseLossBackward0>)\n",
      "Original Units Val RMSE: tensor(23.7272, grad_fn=<SqrtBackward0>)\n",
      "Val Z scores: [ 0.1581034   0.50334084 -0.21174422 -2.950676    0.58314633  0.62483084\n",
      "  0.29766166  0.35691616  0.5107412  -2.4007494   0.7108592   0.23361629\n",
      " -1.1617275   0.4071541   0.8318669   0.46665692  0.46784633  0.4516398\n",
      "  0.26012188  0.2569373   0.44343844 -2.179178    0.30633652  0.51170564\n",
      "  0.15841495  0.36274135]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[[tensor([[  5.8184],\n",
       "          [ 70.6321],\n",
       "          [  7.2476],\n",
       "          [  6.9193],\n",
       "          [  5.3588],\n",
       "          [  6.3820],\n",
       "          [ 10.0662],\n",
       "          [  5.8440],\n",
       "          [  5.7913],\n",
       "          [  4.2404],\n",
       "          [  6.5051],\n",
       "          [  4.4764],\n",
       "          [ 15.7411],\n",
       "          [  6.2532],\n",
       "          [  8.6289],\n",
       "          [ 69.8403],\n",
       "          [  4.7678],\n",
       "          [192.6585],\n",
       "          [  6.4075],\n",
       "          [113.3991],\n",
       "          [  8.4937],\n",
       "          [  5.6313],\n",
       "          [ 31.8740],\n",
       "          [  6.1263],\n",
       "          [  4.2468],\n",
       "          [  4.3882],\n",
       "          [  5.5273],\n",
       "          [  4.8352],\n",
       "          [  4.3488],\n",
       "          [  5.4444],\n",
       "          [ 89.9066],\n",
       "          [  9.1867],\n",
       "          [  4.6255],\n",
       "          [  4.2695],\n",
       "          [  7.8667],\n",
       "          [ 65.0458],\n",
       "          [  4.1354],\n",
       "          [  5.5514],\n",
       "          [  5.8448],\n",
       "          [133.3592],\n",
       "          [  7.5410],\n",
       "          [  9.0281],\n",
       "          [  7.0236],\n",
       "          [  7.2100],\n",
       "          [ 97.0730],\n",
       "          [  9.2109],\n",
       "          [  8.7248],\n",
       "          [  7.8984],\n",
       "          [  4.5582],\n",
       "          [171.0465],\n",
       "          [  4.7723],\n",
       "          [  4.5406]]),\n",
       "  tensor([[ 13.3339],\n",
       "          [ 62.0507],\n",
       "          [  5.4880],\n",
       "          [  5.3294],\n",
       "          [  4.5072],\n",
       "          [  3.3249],\n",
       "          [  9.7706],\n",
       "          [  3.6285],\n",
       "          [  7.3740],\n",
       "          [  2.7168],\n",
       "          [ 13.0544],\n",
       "          [  4.7009],\n",
       "          [ 10.8005],\n",
       "          [  4.0740],\n",
       "          [  9.8314],\n",
       "          [ 26.6115],\n",
       "          [  7.8981],\n",
       "          [ 56.1249],\n",
       "          [ 12.6793],\n",
       "          [ 85.7042],\n",
       "          [ 15.0883],\n",
       "          [  9.7408],\n",
       "          [ 12.8974],\n",
       "          [  9.6421],\n",
       "          [  4.0191],\n",
       "          [  7.0016],\n",
       "          [  5.6627],\n",
       "          [  3.6066],\n",
       "          [  8.5655],\n",
       "          [  9.7635],\n",
       "          [ 43.6218],\n",
       "          [ 12.2691],\n",
       "          [  3.1793],\n",
       "          [  3.0679],\n",
       "          [ 15.8086],\n",
       "          [ 86.6399],\n",
       "          [  4.2755],\n",
       "          [  7.9659],\n",
       "          [  5.6098],\n",
       "          [ 48.2977],\n",
       "          [ 12.2466],\n",
       "          [ 14.2499],\n",
       "          [  7.8378],\n",
       "          [ 15.4106],\n",
       "          [121.6692],\n",
       "          [ 12.3482],\n",
       "          [ 14.2380],\n",
       "          [ 11.4970],\n",
       "          [  2.5693],\n",
       "          [ 78.9355],\n",
       "          [  5.8636],\n",
       "          [  3.6037]]),\n",
       "  tensor(792.7916),\n",
       "  tensor(28.1566),\n",
       "  tensor([[ 4.4068],\n",
       "          [ 6.8045],\n",
       "          [20.1451],\n",
       "          [13.9858],\n",
       "          [48.0588],\n",
       "          [52.4371],\n",
       "          [ 4.7287],\n",
       "          [20.5037],\n",
       "          [ 5.8210],\n",
       "          [ 6.8325],\n",
       "          [ 5.6628],\n",
       "          [ 4.8741],\n",
       "          [ 5.4089]], grad_fn=<ExpBackward0>),\n",
       "  tensor([[ 2.9927],\n",
       "          [ 4.3643],\n",
       "          [19.0975],\n",
       "          [ 7.3990],\n",
       "          [34.6463],\n",
       "          [36.7372],\n",
       "          [ 4.2141],\n",
       "          [37.7225],\n",
       "          [ 6.6437],\n",
       "          [ 8.9682],\n",
       "          [ 5.1557],\n",
       "          [ 5.7730],\n",
       "          [ 5.2504]]),\n",
       "  tensor(60.1464, grad_fn=<MseLossBackward0>),\n",
       "  tensor(7.7554, grad_fn=<SqrtBackward0>),\n",
       "  array([-0.02260416,  0.1072783 , -0.0690027 ,  0.63216335,  1.4961797 ,\n",
       "          1.7857127 , -0.13647299, -2.3811991 , -0.3057437 , -0.471948  ,\n",
       "         -0.13742478, -0.3153914 , -0.18154691], dtype=float32)],\n",
       " [tensor([[100.6331],\n",
       "          [  4.7107],\n",
       "          [  5.6517],\n",
       "          [  2.6553],\n",
       "          [  3.2925],\n",
       "          [  2.9252],\n",
       "          [  5.3071],\n",
       "          [  4.3018],\n",
       "          [127.6609],\n",
       "          [  3.5126],\n",
       "          [  6.5936],\n",
       "          [  3.0780],\n",
       "          [  6.1219],\n",
       "          [  6.0240],\n",
       "          [ 67.2579],\n",
       "          [  2.9435],\n",
       "          [276.7057],\n",
       "          [  3.9828],\n",
       "          [  3.4325],\n",
       "          [  7.3073],\n",
       "          [ 10.3726],\n",
       "          [208.1300],\n",
       "          [  2.9056],\n",
       "          [ 10.5667],\n",
       "          [  3.6258],\n",
       "          [ 20.8522],\n",
       "          [  2.7162],\n",
       "          [317.6333],\n",
       "          [  7.2692],\n",
       "          [  4.0181],\n",
       "          [  5.1990],\n",
       "          [  6.8579],\n",
       "          [ 18.5513],\n",
       "          [  2.4015],\n",
       "          [  4.6731],\n",
       "          [  3.5617],\n",
       "          [  4.7852],\n",
       "          [  4.9493],\n",
       "          [ 32.6545],\n",
       "          [  3.8807],\n",
       "          [  6.0565],\n",
       "          [167.1786],\n",
       "          [ 14.0099],\n",
       "          [  3.2013],\n",
       "          [139.0009],\n",
       "          [111.7838],\n",
       "          [  3.8792],\n",
       "          [  6.3799],\n",
       "          [  6.3487],\n",
       "          [  3.1475],\n",
       "          [  5.5779],\n",
       "          [  4.4189]]),\n",
       "  tensor([[ 62.0507],\n",
       "          [ 13.0544],\n",
       "          [ 12.2466],\n",
       "          [  4.7009],\n",
       "          [  3.6066],\n",
       "          [  5.8636],\n",
       "          [ 11.4970],\n",
       "          [  5.6098],\n",
       "          [ 43.6218],\n",
       "          [  7.3740],\n",
       "          [  9.6421],\n",
       "          [  2.7168],\n",
       "          [  5.3294],\n",
       "          [  4.0740],\n",
       "          [ 26.6115],\n",
       "          [  4.2755],\n",
       "          [ 48.2977],\n",
       "          [  9.7408],\n",
       "          [  7.0016],\n",
       "          [ 15.0883],\n",
       "          [ 14.2380],\n",
       "          [ 78.9355],\n",
       "          [  8.5655],\n",
       "          [ 15.8086],\n",
       "          [  3.1793],\n",
       "          [ 10.8005],\n",
       "          [  3.6037],\n",
       "          [ 56.1249],\n",
       "          [  5.4880],\n",
       "          [  5.6627],\n",
       "          [  2.5693],\n",
       "          [ 14.2499],\n",
       "          [  9.7706],\n",
       "          [  4.0191],\n",
       "          [ 12.6793],\n",
       "          [  7.9659],\n",
       "          [  9.7635],\n",
       "          [  7.8378],\n",
       "          [ 12.8974],\n",
       "          [  4.5072],\n",
       "          [ 15.4106],\n",
       "          [ 85.7042],\n",
       "          [ 12.2691],\n",
       "          [  3.0679],\n",
       "          [121.6692],\n",
       "          [ 86.6399],\n",
       "          [ 13.3339],\n",
       "          [  9.8314],\n",
       "          [ 12.3482],\n",
       "          [  7.8981],\n",
       "          [  3.6285],\n",
       "          [  3.3249]]),\n",
       "  tensor(3007.9124),\n",
       "  tensor(54.8444),\n",
       "  tensor([[ 2.7891],\n",
       "          [ 5.8710],\n",
       "          [24.9610],\n",
       "          [ 9.7509],\n",
       "          [45.5248],\n",
       "          [60.9824],\n",
       "          [ 3.1795],\n",
       "          [18.6231],\n",
       "          [ 3.4569],\n",
       "          [ 6.4092],\n",
       "          [ 5.0919],\n",
       "          [ 3.2782],\n",
       "          [ 6.2290]], grad_fn=<ExpBackward0>),\n",
       "  tensor([[ 2.9927],\n",
       "          [ 4.3643],\n",
       "          [19.0975],\n",
       "          [ 7.3990],\n",
       "          [34.6463],\n",
       "          [36.7372],\n",
       "          [ 4.2141],\n",
       "          [37.7225],\n",
       "          [ 6.6437],\n",
       "          [ 8.9682],\n",
       "          [ 5.1557],\n",
       "          [ 5.7730],\n",
       "          [ 5.2504]]),\n",
       "  tensor(87.5495, grad_fn=<MseLossBackward0>),\n",
       "  tensor(9.3568, grad_fn=<SqrtBackward0>),\n",
       "  array([-0.15820447,  0.01919154,  0.47107616,  0.10685313,  0.9912454 ,\n",
       "          2.3776581 , -0.24439986, -2.1181111 , -0.46763128, -0.4025182 ,\n",
       "         -0.14371166, -0.3958557 , -0.03559178], dtype=float32)],\n",
       " [tensor([[23.9019],\n",
       "          [31.0216],\n",
       "          [ 5.4007],\n",
       "          [42.2850],\n",
       "          [ 4.7129],\n",
       "          [ 3.0430],\n",
       "          [ 5.2225],\n",
       "          [13.1153],\n",
       "          [37.5442],\n",
       "          [ 7.6970],\n",
       "          [26.1867],\n",
       "          [18.6918],\n",
       "          [12.1528],\n",
       "          [17.1333],\n",
       "          [12.9113],\n",
       "          [14.0660],\n",
       "          [39.0438],\n",
       "          [ 9.6187],\n",
       "          [14.3441],\n",
       "          [ 7.7157],\n",
       "          [42.4994],\n",
       "          [15.0537],\n",
       "          [ 8.4112],\n",
       "          [19.7767],\n",
       "          [ 7.5359],\n",
       "          [ 4.8455],\n",
       "          [ 2.7623],\n",
       "          [18.0697],\n",
       "          [15.9190],\n",
       "          [12.9194],\n",
       "          [17.7982],\n",
       "          [11.3409],\n",
       "          [10.5946],\n",
       "          [ 5.2411],\n",
       "          [ 6.8119],\n",
       "          [11.8205],\n",
       "          [ 7.1151],\n",
       "          [30.8346],\n",
       "          [ 9.0280],\n",
       "          [ 9.6813],\n",
       "          [16.4712],\n",
       "          [22.1367],\n",
       "          [11.4440],\n",
       "          [12.8298],\n",
       "          [ 7.5695],\n",
       "          [11.1837],\n",
       "          [14.3018],\n",
       "          [37.6461],\n",
       "          [ 5.6883],\n",
       "          [10.4687],\n",
       "          [12.0422],\n",
       "          [20.5474],\n",
       "          [25.1835],\n",
       "          [15.3204],\n",
       "          [ 9.7766],\n",
       "          [ 6.6240],\n",
       "          [ 7.3478],\n",
       "          [23.7320],\n",
       "          [ 4.1299],\n",
       "          [18.9119],\n",
       "          [20.0980],\n",
       "          [11.2959],\n",
       "          [23.1290],\n",
       "          [ 5.3377],\n",
       "          [18.7061],\n",
       "          [ 7.3641],\n",
       "          [20.5967],\n",
       "          [32.9302],\n",
       "          [ 8.5681],\n",
       "          [24.1244],\n",
       "          [ 6.3301],\n",
       "          [15.0096],\n",
       "          [10.4103],\n",
       "          [ 5.5699],\n",
       "          [23.5281],\n",
       "          [19.0811],\n",
       "          [ 5.7826],\n",
       "          [42.7781],\n",
       "          [ 4.3447],\n",
       "          [ 6.8951],\n",
       "          [25.3918],\n",
       "          [14.3024],\n",
       "          [ 4.7543],\n",
       "          [ 5.4313],\n",
       "          [ 6.8080],\n",
       "          [30.8479],\n",
       "          [23.3282],\n",
       "          [30.8664],\n",
       "          [ 4.1647],\n",
       "          [10.5820],\n",
       "          [32.7182],\n",
       "          [22.7001],\n",
       "          [31.3647],\n",
       "          [21.9374],\n",
       "          [ 7.6788],\n",
       "          [ 7.1081],\n",
       "          [ 7.7936],\n",
       "          [ 6.1051],\n",
       "          [ 5.3121],\n",
       "          [ 3.7202],\n",
       "          [18.6101],\n",
       "          [16.5633],\n",
       "          [ 3.5563],\n",
       "          [11.9057]]),\n",
       "  tensor([[ 12.2466],\n",
       "          [  8.9682],\n",
       "          [  5.3472],\n",
       "          [ 29.3262],\n",
       "          [  3.0679],\n",
       "          [  5.8636],\n",
       "          [  5.6627],\n",
       "          [ 14.2380],\n",
       "          [ 86.9963],\n",
       "          [  4.2755],\n",
       "          [ 15.1537],\n",
       "          [  9.8250],\n",
       "          [ 10.0284],\n",
       "          [ 50.9844],\n",
       "          [ 11.6381],\n",
       "          [ 12.2534],\n",
       "          [121.6693],\n",
       "          [ 14.2500],\n",
       "          [  4.8821],\n",
       "          [  3.6038],\n",
       "          [ 43.6218],\n",
       "          [ 34.6463],\n",
       "          [  4.5072],\n",
       "          [ 12.3482],\n",
       "          [  5.1557],\n",
       "          [  4.2141],\n",
       "          [  2.7168],\n",
       "          [ 35.8369],\n",
       "          [  7.3990],\n",
       "          [ 86.6399],\n",
       "          [ 12.9842],\n",
       "          [ 51.8456],\n",
       "          [  5.4880],\n",
       "          [  3.1793],\n",
       "          [  7.8491],\n",
       "          [  5.7471],\n",
       "          [  5.0906],\n",
       "          [ 25.4345],\n",
       "          [  7.2139],\n",
       "          [ 22.2033],\n",
       "          [ 42.5923],\n",
       "          [ 62.0508],\n",
       "          [  9.7408],\n",
       "          [  4.8431],\n",
       "          [  5.2504],\n",
       "          [  5.9304],\n",
       "          [ 13.2403],\n",
       "          [ 50.8154],\n",
       "          [ 12.6793],\n",
       "          [  9.7635],\n",
       "          [  7.9659],\n",
       "          [ 37.8491],\n",
       "          [ 45.1765],\n",
       "          [  9.1602],\n",
       "          [ 15.4107],\n",
       "          [  3.6493],\n",
       "          [  4.7883],\n",
       "          [ 36.7372],\n",
       "          [  5.3294],\n",
       "          [  9.4270],\n",
       "          [217.9214],\n",
       "          [ 10.4782],\n",
       "          [ 20.3512],\n",
       "          [  4.7009],\n",
       "          [  8.6323],\n",
       "          [ 10.9660],\n",
       "          [ 37.5502],\n",
       "          [ 31.1457],\n",
       "          [ 10.7692],\n",
       "          [ 22.5964],\n",
       "          [  4.5836],\n",
       "          [ 26.6115],\n",
       "          [  9.6421],\n",
       "          [  6.6437],\n",
       "          [ 56.1249],\n",
       "          [  7.0704],\n",
       "          [  6.8134],\n",
       "          [ 10.8005],\n",
       "          [  4.3643],\n",
       "          [  8.1207],\n",
       "          [ 55.4448],\n",
       "          [ 11.4970],\n",
       "          [  3.6066],\n",
       "          [  2.8347],\n",
       "          [  5.6098],\n",
       "          [ 17.3871],\n",
       "          [ 13.0544],\n",
       "          [ 12.4091],\n",
       "          [  5.7730],\n",
       "          [  7.3741],\n",
       "          [ 14.1357],\n",
       "          [ 33.1908],\n",
       "          [ 19.5722],\n",
       "          [ 78.9355],\n",
       "          [  8.2616],\n",
       "          [  7.8981],\n",
       "          [  4.0191],\n",
       "          [  5.4946],\n",
       "          [ 10.0876],\n",
       "          [  5.0523],\n",
       "          [ 12.8974],\n",
       "          [ 19.0975],\n",
       "          [  3.6028],\n",
       "          [ 12.2691]]),\n",
       "  tensor(681.2524),\n",
       "  tensor(26.1008),\n",
       "  tensor([[12.4441],\n",
       "          [13.1809],\n",
       "          [25.8093],\n",
       "          [10.4830],\n",
       "          [16.2914],\n",
       "          [11.4976],\n",
       "          [ 5.9325],\n",
       "          [ 4.8594],\n",
       "          [19.4356],\n",
       "          [21.6711],\n",
       "          [19.1826],\n",
       "          [ 6.1143],\n",
       "          [14.4265],\n",
       "          [ 5.7170],\n",
       "          [20.0468],\n",
       "          [ 6.7601],\n",
       "          [ 8.3790],\n",
       "          [ 5.9897],\n",
       "          [14.0819],\n",
       "          [ 4.3006],\n",
       "          [ 6.1387],\n",
       "          [18.5791],\n",
       "          [ 4.7337],\n",
       "          [18.1426],\n",
       "          [ 3.6443],\n",
       "          [ 5.2681]], grad_fn=<ExpBackward0>),\n",
       "  tensor([[15.8086],\n",
       "          [ 8.5655],\n",
       "          [37.7225],\n",
       "          [85.7042],\n",
       "          [ 9.8314],\n",
       "          [ 4.0741],\n",
       "          [ 6.0712],\n",
       "          [ 3.6285],\n",
       "          [14.6491],\n",
       "          [84.1812],\n",
       "          [ 9.7706],\n",
       "          [ 7.7334],\n",
       "          [48.2977],\n",
       "          [ 3.3249],\n",
       "          [ 7.8378],\n",
       "          [ 2.9927],\n",
       "          [ 4.5840],\n",
       "          [ 2.5693],\n",
       "          [15.0883],\n",
       "          [ 5.3807],\n",
       "          [ 2.9079],\n",
       "          [75.9678],\n",
       "          [ 4.6719],\n",
       "          [13.3339],\n",
       "          [ 7.0016],\n",
       "          [ 3.9026]]),\n",
       "  tensor(562.9792, grad_fn=<MseLossBackward0>),\n",
       "  tensor(23.7272, grad_fn=<SqrtBackward0>),\n",
       "  array([ 0.1581034 ,  0.50334084, -0.21174422, -2.950676  ,  0.58314633,\n",
       "          0.62483084,  0.29766166,  0.35691616,  0.5107412 , -2.4007494 ,\n",
       "          0.7108592 ,  0.23361629, -1.1617275 ,  0.4071541 ,  0.8318669 ,\n",
       "          0.46665692,  0.46784633,  0.4516398 ,  0.26012188,  0.2569373 ,\n",
       "          0.44343844, -2.179178  ,  0.30633652,  0.51170564,  0.15841495,\n",
       "          0.36274135], dtype=float32)]]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "c9_mean_dict = {\"['M']_csf\":2.20139473218633, \n",
    "                \"['F']_plasma\":2.5069125020915246,\n",
    "                \"['F']_csf\":2.3905483112831987,\n",
    "                \"['M', 'F']_plasma\":2.4382370774886417,\n",
    "                \"['M', 'F']_csf\":2.323617044833538}\n",
    "c9_std_dict = {\"['M']_csf\":0.9414006476156331,\n",
    "                \"['F']_plasma\":0.9801098341235991,\n",
    "                \"['F']_csf\":0.95108017948172,\n",
    "                \"['M', 'F']_plasma\":0.9639665529956777,\n",
    "                \"['M', 'F']_csf\":0.951972757962228}\n",
    "\n",
    "c9_BEST_RUNS_M=[\n",
    "    '/scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_10-30-17/model=gat-v4,seed=3784_347_act=elu,adj_thresh=0.0500,batch_size=8,dropout=0.1000,l1_lambda=0.0010,lr=0.0007,lr_scheduler=CosineAnn_2024-08-01_11-17-45/checkpoint_000101',\n",
    "    '/scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_10-30-17/model=gat-v4,seed=36658_797_act=leaky_relu,adj_thresh=0.7000,batch_size=16,dropout=0.1000,l1_lambda=0.0002,lr=0.0010,lr_scheduler=_2024-08-01_13-15-10/checkpoint_000132',\n",
    "    '/scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_10-30-17/model=gat-v4,seed=43041_59_act=leaky_relu,adj_thresh=0.1000,batch_size=32,dropout=0.2000,l1_lambda=0.0033,lr=0.0122,lr_scheduler=C_2024-08-01_10-30-18/checkpoint_000006'\n",
    "]\n",
    "c9_BEST_RUNS_F= [\n",
    "    '/scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_10-30-17/model=gat-v4,seed=15140_461_act=tanh,adj_thresh=0.5000,batch_size=8,dropout=0.1000,l1_lambda=0.0001,lr=0.0002,lr_scheduler=CosineA_2024-08-01_11-48-59/checkpoint_000016',\n",
    "    '/scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_10-30-17/model=gat-v4,seed=29159_100_act=sigmoid,adj_thresh=0.1000,batch_size=50,dropout=0.1000,l1_lambda=0.0004,lr=0.0005,lr_scheduler=Lam_2024-08-01_10-30-18/checkpoint_000249',\n",
    "    '/scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_10-30-17/model=gat-v4,seed=44912_137_act=leaky_relu,adj_thresh=0.9000,batch_size=8,dropout=0,l1_lambda=0.0037,lr=0.0229,lr_scheduler=StepLR_2024-08-01_10-30-18/checkpoint_000009'\n",
    "]\n",
    "c9_BEST_RUNS_M_F= [\n",
    "    '/scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_10-30-17/model=gat-v4,seed=40910_881_act=tanh,adj_thresh=0.7000,batch_size=16,dropout=0.1000,l1_lambda=0.0000,lr=0.0037,lr_scheduler=Cosine_2024-08-01_13-32-59/checkpoint_000039',\n",
    "    '/scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_10-30-17/model=gat-v4,seed=42404_611_act=leaky_relu,adj_thresh=0.9000,batch_size=16,dropout=0.2000,l1_lambda=0.0000,lr=0.0061,lr_scheduler=_2024-08-01_12-24-45/checkpoint_000146',\n",
    "    '/scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_10-30-17/model=gat-v4,seed=40995_232_act=relu,adj_thresh=0.9000,batch_size=8,dropout=0,l1_lambda=0.0001,lr=0.0004,lr_scheduler=ReduceLROnPl_2024-08-01_10-40-25/checkpoint_000027'\n",
    "]\n",
    "process_checkpoints(c9_BEST_RUNS_M, c9_mean_dict, c9_std_dict, device)\n",
    "process_checkpoints(c9_BEST_RUNS_F, c9_mean_dict, c9_std_dict, device)\n",
    "process_checkpoints(c9_BEST_RUNS_M_F, c9_mean_dict, c9_std_dict, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint from: /scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_10-30-17/model=gat-v4,seed=62542_686_act=leaky_relu,adj_thresh=0.0500,batch_size=8,dropout=0.2000,l1_lambda=0.0000,lr=0.0053,lr_scheduler=R_2024-08-01_12-44-53/checkpoint_000024\n",
      "1 best checkpoint for ['M'] and plasma\n",
      "Loading data from: /home/data/data_louisa/processed/ftd_y_val_nfl_adj_thresh_0.05_num_nodes_150_mutation_MAPT_plasma_sex_M_train.pt\n",
      "Loading data from: /home/data/data_louisa/processed/ftd_y_val_nfl_adj_thresh_0.05_num_nodes_150_mutation_MAPT_plasma_sex_M_test.pt\n",
      "Normalized Val MSE: 0.3830680847167969\n",
      "Normalized train MSE: 0.18608273565769196\n",
      "Original Units Val MSE: tensor(60.0437, grad_fn=<MseLossBackward0>)\n",
      "Original Units Val RMSE: tensor(7.7488, grad_fn=<SqrtBackward0>)\n",
      "Loading checkpoint from: /scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_10-30-17/model=gat-v4,seed=8990_704_act=leaky_relu,adj_thresh=0.7000,batch_size=32,dropout=0.2000,l1_lambda=0.0002,lr=0.0011,lr_scheduler=L_2024-08-01_12-49-21/checkpoint_000027\n",
      "2 best checkpoint for ['M'] and plasma\n",
      "Loading data from: /home/data/data_louisa/processed/ftd_y_val_nfl_adj_thresh_0.7_num_nodes_150_mutation_MAPT_plasma_sex_M_train.pt\n",
      "Loading data from: /home/data/data_louisa/processed/ftd_y_val_nfl_adj_thresh_0.7_num_nodes_150_mutation_MAPT_plasma_sex_M_test.pt\n",
      "Normalized Val MSE: 0.49430108070373535\n",
      "Normalized train MSE: 0.678686261177063\n",
      "Original Units Val MSE: tensor(82.9257, grad_fn=<MseLossBackward0>)\n",
      "Original Units Val RMSE: tensor(9.1064, grad_fn=<SqrtBackward0>)\n",
      "Loading checkpoint from: /scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_10-30-17/model=gat-v4,seed=16742_1047_act=sigmoid,adj_thresh=0.5000,batch_size=16,dropout=0.0500,l1_lambda=0.0000,lr=0.0000,lr_scheduler=La_2024-08-01_14-01-42/checkpoint_000000\n",
      "3 best checkpoint for ['M'] and csf\n",
      "Loading data from: /home/data/data_louisa/processed/ftd_y_val_nfl_adj_thresh_0.5_num_nodes_10_mutation_MAPT_csf_sex_M_train.pt\n",
      "Loading data from: /home/data/data_louisa/processed/ftd_y_val_nfl_adj_thresh_0.5_num_nodes_10_mutation_MAPT_csf_sex_M_test.pt\n",
      "Normalized Val MSE: 0.8483567237854004\n",
      "Normalized train MSE: 1.4755191802978516\n",
      "Original Units Val MSE: tensor(51.0883, grad_fn=<MseLossBackward0>)\n",
      "Original Units Val RMSE: tensor(7.1476, grad_fn=<SqrtBackward0>)\n",
      "Loading checkpoint from: /scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_10-30-17/model=gat-v4,seed=37235_729_act=leaky_relu,adj_thresh=0.9000,batch_size=32,dropout=0,l1_lambda=0.0001,lr=0.0007,lr_scheduler=Reduc_2024-08-01_12-56-46/checkpoint_000015\n",
      "1 best checkpoint for ['F'] and csf\n",
      "Loading data from: /home/data/data_louisa/processed/ftd_y_val_nfl_adj_thresh_0.9_num_nodes_30_mutation_MAPT_csf_sex_F_train.pt\n",
      "Loading data from: /home/data/data_louisa/processed/ftd_y_val_nfl_adj_thresh_0.9_num_nodes_30_mutation_MAPT_csf_sex_F_test.pt\n",
      "Normalized Val MSE: 0.6870711445808411\n",
      "Normalized train MSE: 0.828177809715271\n",
      "Original Units Val MSE: tensor(31.4001, grad_fn=<MseLossBackward0>)\n",
      "Original Units Val RMSE: tensor(5.6036, grad_fn=<SqrtBackward0>)\n",
      "Loading checkpoint from: /scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_10-30-17/model=gat-v4,seed=46905_207_act=sigmoid,adj_thresh=0.1000,batch_size=32,dropout=0.3000,l1_lambda=0.0003,lr=0.0006,lr_scheduler=Ste_2024-08-01_10-31-43/checkpoint_000028\n",
      "2 best checkpoint for ['F'] and csf\n",
      "Loading data from: /home/data/data_louisa/processed/ftd_y_val_nfl_adj_thresh_0.1_num_nodes_1000_mutation_MAPT_csf_sex_F_train.pt\n",
      "Loading data from: /home/data/data_louisa/processed/ftd_y_val_nfl_adj_thresh_0.1_num_nodes_1000_mutation_MAPT_csf_sex_F_test.pt\n",
      "Normalized Val MSE: 0.73563152551651\n",
      "Normalized train MSE: 0.9793577790260315\n",
      "Original Units Val MSE: tensor(29.2236, grad_fn=<MseLossBackward0>)\n",
      "Original Units Val RMSE: tensor(5.4059, grad_fn=<SqrtBackward0>)\n",
      "Loading checkpoint from: /scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_10-30-17/model=gat-v4,seed=14399_99_act=tanh,adj_thresh=0.7000,batch_size=50,dropout=0.1000,l1_lambda=0.0000,lr=0.0019,lr_scheduler=CosineA_2024-08-01_10-30-18/checkpoint_000027\n",
      "3 best checkpoint for ['F'] and csf\n",
      "Loading data from: /home/data/data_louisa/processed/ftd_y_val_nfl_adj_thresh_0.7_num_nodes_1000_mutation_MAPT_csf_sex_F_train.pt\n",
      "Loading data from: /home/data/data_louisa/processed/ftd_y_val_nfl_adj_thresh_0.7_num_nodes_1000_mutation_MAPT_csf_sex_F_test.pt\n",
      "Normalized Val MSE: 0.7490021586418152\n",
      "Normalized train MSE: 1.0109697580337524\n",
      "Original Units Val MSE: tensor(29.5140, grad_fn=<MseLossBackward0>)\n",
      "Original Units Val RMSE: tensor(5.4327, grad_fn=<SqrtBackward0>)\n",
      "Loading checkpoint from: /scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_10-30-17/model=gat-v4,seed=23432_69_act=sigmoid,adj_thresh=0.9000,batch_size=50,dropout=0,l1_lambda=0.0003,lr=0.0057,lr_scheduler=ReduceLRO_2024-08-01_10-30-18/checkpoint_000009\n",
      "1 best checkpoint for ['M', 'F'] and csf\n",
      "Loading data from: /home/data/data_louisa/processed/ftd_y_val_nfl_adj_thresh_0.9_num_nodes_10_mutation_MAPT_csf_sex_M,F_train.pt\n",
      "Loading data from: /home/data/data_louisa/processed/ftd_y_val_nfl_adj_thresh_0.9_num_nodes_10_mutation_MAPT_csf_sex_M,F_test.pt\n",
      "Normalized Val MSE: 0.4312096834182739\n",
      "Normalized train MSE: 0.8306846618652344\n",
      "Original Units Val MSE: tensor(25.6324, grad_fn=<MseLossBackward0>)\n",
      "Original Units Val RMSE: tensor(5.0628, grad_fn=<SqrtBackward0>)\n",
      "Loading checkpoint from: /scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_10-30-17/model=gat-v4,seed=35171_951_act=elu,adj_thresh=0.9000,batch_size=16,dropout=0.0500,l1_lambda=0.0001,lr=0.0019,lr_scheduler=StepLR,_2024-08-01_13-46-49/checkpoint_000008\n",
      "2 best checkpoint for ['M', 'F'] and csf\n",
      "Loading data from: /home/data/data_louisa/processed/ftd_y_val_nfl_adj_thresh_0.9_num_nodes_10_mutation_MAPT_csf_sex_M,F_train.pt\n",
      "Loading data from: /home/data/data_louisa/processed/ftd_y_val_nfl_adj_thresh_0.9_num_nodes_10_mutation_MAPT_csf_sex_M,F_test.pt\n",
      "Normalized Val MSE: 0.5411474704742432\n",
      "Normalized train MSE: 0.8842386603355408\n",
      "Original Units Val MSE: tensor(31.2821, grad_fn=<MseLossBackward0>)\n",
      "Original Units Val RMSE: tensor(5.5930, grad_fn=<SqrtBackward0>)\n",
      "Loading checkpoint from: /scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_10-30-17/model=gat-v4,seed=25447_249_act=sigmoid,adj_thresh=0.7000,batch_size=32,dropout=0.2000,l1_lambda=0.0001,lr=0.0101,lr_scheduler=Ste_2024-08-01_10-47-31/checkpoint_000002\n",
      "3 best checkpoint for ['M', 'F'] and csf\n",
      "Loading data from: /home/data/data_louisa/processed/ftd_y_val_nfl_adj_thresh_0.7_num_nodes_150_mutation_MAPT_csf_sex_M,F_train.pt\n",
      "Loading data from: /home/data/data_louisa/processed/ftd_y_val_nfl_adj_thresh_0.7_num_nodes_150_mutation_MAPT_csf_sex_M,F_test.pt\n",
      "Normalized Val MSE: 0.5563220381736755\n",
      "Normalized train MSE: 0.8081437349319458\n",
      "Original Units Val MSE: tensor(28.9913, grad_fn=<MseLossBackward0>)\n",
      "Original Units Val RMSE: tensor(5.3844, grad_fn=<SqrtBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(tensor([[ 5.3603],\n",
       "          [ 5.6851],\n",
       "          [ 6.6921],\n",
       "          [ 5.3087],\n",
       "          [ 6.5727],\n",
       "          [ 9.3294],\n",
       "          [ 5.5381],\n",
       "          [ 5.8862],\n",
       "          [ 6.4908],\n",
       "          [ 5.1970],\n",
       "          [ 7.6585],\n",
       "          [ 8.3916],\n",
       "          [ 5.0310],\n",
       "          [ 5.0351],\n",
       "          [ 7.3955],\n",
       "          [10.9128],\n",
       "          [ 6.7094],\n",
       "          [ 6.4397],\n",
       "          [ 9.3152],\n",
       "          [ 8.3094],\n",
       "          [ 5.8805],\n",
       "          [ 5.8522],\n",
       "          [ 8.1659],\n",
       "          [ 5.6992],\n",
       "          [ 5.1975],\n",
       "          [ 8.6050],\n",
       "          [ 5.4215],\n",
       "          [ 6.4946],\n",
       "          [ 6.6584],\n",
       "          [ 9.4137],\n",
       "          [ 5.3420],\n",
       "          [ 5.0834],\n",
       "          [ 9.2575],\n",
       "          [ 5.9569],\n",
       "          [ 6.1477],\n",
       "          [ 9.2359],\n",
       "          [ 6.7914],\n",
       "          [ 7.8718],\n",
       "          [ 5.4672],\n",
       "          [ 5.6368],\n",
       "          [ 6.1177]]),\n",
       "  tensor([[ 2.7373],\n",
       "          [ 1.4759],\n",
       "          [ 5.9444],\n",
       "          [ 1.8875],\n",
       "          [13.3588],\n",
       "          [22.1398],\n",
       "          [ 2.5440],\n",
       "          [14.0459],\n",
       "          [ 9.9528],\n",
       "          [ 4.5166],\n",
       "          [12.9873],\n",
       "          [21.7942],\n",
       "          [ 4.4892],\n",
       "          [ 5.7691],\n",
       "          [ 4.4464],\n",
       "          [24.6015],\n",
       "          [ 4.8879],\n",
       "          [ 8.5448],\n",
       "          [24.8486],\n",
       "          [17.1284],\n",
       "          [ 8.5715],\n",
       "          [ 4.8226],\n",
       "          [12.7782],\n",
       "          [ 5.3738],\n",
       "          [ 4.5311],\n",
       "          [15.1597],\n",
       "          [ 3.5725],\n",
       "          [14.4771],\n",
       "          [ 3.6518],\n",
       "          [20.1041],\n",
       "          [ 4.8740],\n",
       "          [ 5.0684],\n",
       "          [15.1858],\n",
       "          [ 9.8332],\n",
       "          [20.6275],\n",
       "          [15.1033],\n",
       "          [10.1167],\n",
       "          [ 2.9428],\n",
       "          [19.4275],\n",
       "          [ 8.7210],\n",
       "          [10.1045]]),\n",
       "  tensor(45.8646),\n",
       "  tensor(6.7723),\n",
       "  tensor([[5.5336],\n",
       "          [8.5044],\n",
       "          [5.9174],\n",
       "          [8.0379],\n",
       "          [7.4872],\n",
       "          [9.9498],\n",
       "          [5.0797],\n",
       "          [5.2569],\n",
       "          [5.2732],\n",
       "          [7.6932],\n",
       "          [5.9791]], grad_fn=<ExpBackward0>),\n",
       "  tensor([[ 6.9884],\n",
       "          [ 4.1530],\n",
       "          [ 6.6709],\n",
       "          [12.2773],\n",
       "          [ 6.6486],\n",
       "          [23.9309],\n",
       "          [ 2.7222],\n",
       "          [ 4.4517],\n",
       "          [ 4.8222],\n",
       "          [13.6437],\n",
       "          [ 3.8883]]),\n",
       "  tensor(25.6324, grad_fn=<MseLossBackward0>),\n",
       "  tensor(5.0628, grad_fn=<SqrtBackward0>)),\n",
       " (tensor([[5.7582],\n",
       "          [5.5703],\n",
       "          [5.8613],\n",
       "          [7.0601],\n",
       "          [5.1839],\n",
       "          [6.2071],\n",
       "          [9.8495],\n",
       "          [5.8163],\n",
       "          [6.9415],\n",
       "          [6.5195],\n",
       "          [7.8057],\n",
       "          [7.2991],\n",
       "          [6.3064],\n",
       "          [5.6189],\n",
       "          [6.5078],\n",
       "          [5.8120],\n",
       "          [6.8048],\n",
       "          [7.8396],\n",
       "          [5.2450],\n",
       "          [6.7131],\n",
       "          [6.7394],\n",
       "          [4.7712],\n",
       "          [6.1941],\n",
       "          [8.1046],\n",
       "          [8.1502],\n",
       "          [8.9439],\n",
       "          [6.4840],\n",
       "          [6.7016],\n",
       "          [8.2839],\n",
       "          [6.3966],\n",
       "          [7.5075],\n",
       "          [6.5659],\n",
       "          [7.8111],\n",
       "          [7.2866],\n",
       "          [8.6710],\n",
       "          [9.1507],\n",
       "          [7.0449],\n",
       "          [7.3788],\n",
       "          [5.1367],\n",
       "          [7.2861],\n",
       "          [6.6478]]),\n",
       "  tensor([[ 9.8332],\n",
       "          [ 4.5311],\n",
       "          [ 1.4759],\n",
       "          [13.3588],\n",
       "          [ 4.4892],\n",
       "          [ 8.7210],\n",
       "          [24.6015],\n",
       "          [ 8.5448],\n",
       "          [ 8.5715],\n",
       "          [ 4.8879],\n",
       "          [15.1597],\n",
       "          [21.7942],\n",
       "          [19.4275],\n",
       "          [ 3.5725],\n",
       "          [ 2.7373],\n",
       "          [ 4.5166],\n",
       "          [ 5.0684],\n",
       "          [14.4771],\n",
       "          [ 4.8740],\n",
       "          [ 3.6518],\n",
       "          [14.0459],\n",
       "          [ 5.7691],\n",
       "          [10.1167],\n",
       "          [15.1033],\n",
       "          [15.1858],\n",
       "          [12.7782],\n",
       "          [ 9.9528],\n",
       "          [ 4.8226],\n",
       "          [ 2.9428],\n",
       "          [ 5.3738],\n",
       "          [12.9873],\n",
       "          [ 2.5440],\n",
       "          [17.1284],\n",
       "          [ 4.4464],\n",
       "          [22.1398],\n",
       "          [24.8486],\n",
       "          [ 5.9444],\n",
       "          [20.6275],\n",
       "          [ 1.8875],\n",
       "          [20.1041],\n",
       "          [10.1045]]),\n",
       "  tensor(48.4719),\n",
       "  tensor(6.9622),\n",
       "  tensor([[6.6428],\n",
       "          [9.7500],\n",
       "          [6.1095],\n",
       "          [7.9982],\n",
       "          [8.5793],\n",
       "          [8.5476],\n",
       "          [4.8705],\n",
       "          [5.1103],\n",
       "          [5.9513],\n",
       "          [7.3284],\n",
       "          [6.6172]], grad_fn=<ExpBackward0>),\n",
       "  tensor([[ 6.9884],\n",
       "          [ 4.1530],\n",
       "          [ 6.6709],\n",
       "          [12.2773],\n",
       "          [ 6.6486],\n",
       "          [23.9309],\n",
       "          [ 2.7222],\n",
       "          [ 4.4517],\n",
       "          [ 4.8222],\n",
       "          [13.6437],\n",
       "          [ 3.8883]]),\n",
       "  tensor(31.2821, grad_fn=<MseLossBackward0>),\n",
       "  tensor(5.5930, grad_fn=<SqrtBackward0>)),\n",
       " (tensor([[ 8.0695],\n",
       "          [ 5.8113],\n",
       "          [10.3233],\n",
       "          [ 8.6410],\n",
       "          [ 7.4221],\n",
       "          [ 7.6340],\n",
       "          [ 7.5141],\n",
       "          [ 7.1420],\n",
       "          [ 7.6845],\n",
       "          [ 6.5889],\n",
       "          [ 7.1944],\n",
       "          [ 8.7479],\n",
       "          [10.3404],\n",
       "          [ 8.2273],\n",
       "          [ 6.1175],\n",
       "          [ 8.1304],\n",
       "          [ 5.9214],\n",
       "          [ 6.8464],\n",
       "          [ 6.8018],\n",
       "          [ 5.9054],\n",
       "          [ 8.0176],\n",
       "          [ 5.9227],\n",
       "          [ 6.4198],\n",
       "          [ 8.3552],\n",
       "          [ 8.1393],\n",
       "          [ 7.1029],\n",
       "          [ 6.7705],\n",
       "          [ 7.5053],\n",
       "          [ 6.9511],\n",
       "          [ 7.7843],\n",
       "          [ 8.4543],\n",
       "          [ 7.7673],\n",
       "          [ 7.0485],\n",
       "          [ 5.7720],\n",
       "          [ 6.7144],\n",
       "          [ 7.9902],\n",
       "          [ 6.3831],\n",
       "          [ 6.5467],\n",
       "          [ 9.2737],\n",
       "          [ 6.4962],\n",
       "          [ 8.6730]]),\n",
       "  tensor([[20.6275],\n",
       "          [ 4.4892],\n",
       "          [15.1033],\n",
       "          [15.1858],\n",
       "          [ 2.9428],\n",
       "          [12.9873],\n",
       "          [ 9.8332],\n",
       "          [10.1167],\n",
       "          [14.0459],\n",
       "          [ 5.3738],\n",
       "          [ 8.5715],\n",
       "          [15.1597],\n",
       "          [21.7942],\n",
       "          [22.1398],\n",
       "          [ 4.8740],\n",
       "          [ 4.4464],\n",
       "          [ 5.7691],\n",
       "          [ 4.8879],\n",
       "          [ 2.5440],\n",
       "          [ 4.5166],\n",
       "          [17.1284],\n",
       "          [ 1.8875],\n",
       "          [ 1.4759],\n",
       "          [24.6015],\n",
       "          [20.1041],\n",
       "          [ 8.5448],\n",
       "          [ 3.6518],\n",
       "          [ 9.9528],\n",
       "          [10.1045],\n",
       "          [19.4275],\n",
       "          [24.8486],\n",
       "          [13.3588],\n",
       "          [ 3.5725],\n",
       "          [ 2.7373],\n",
       "          [ 8.7210],\n",
       "          [ 5.9444],\n",
       "          [ 4.8226],\n",
       "          [ 5.0684],\n",
       "          [12.7782],\n",
       "          [ 4.5311],\n",
       "          [14.4771]]),\n",
       "  tensor(44.2672),\n",
       "  tensor(6.6534),\n",
       "  tensor([[6.9232],\n",
       "          [7.4925],\n",
       "          [6.8383],\n",
       "          [7.7440],\n",
       "          [7.0386],\n",
       "          [9.0121],\n",
       "          [6.7575],\n",
       "          [6.0530],\n",
       "          [6.4515],\n",
       "          [8.0892],\n",
       "          [7.3653]], grad_fn=<ExpBackward0>),\n",
       "  tensor([[ 6.9884],\n",
       "          [ 4.1530],\n",
       "          [ 6.6709],\n",
       "          [12.2773],\n",
       "          [ 6.6486],\n",
       "          [23.9309],\n",
       "          [ 2.7222],\n",
       "          [ 4.4517],\n",
       "          [ 4.8222],\n",
       "          [13.6437],\n",
       "          [ 3.8883]]),\n",
       "  tensor(28.9913, grad_fn=<MseLossBackward0>),\n",
       "  tensor(5.3844, grad_fn=<SqrtBackward0>))]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "MAPT_mean_dict = {\"['M']_csf\":2.080694213697065, \n",
    "                \"['M']_plasma\":2.1657279439973016,\n",
    "                \"['F']_csf\":2.0152637385189265,\n",
    "                \"['M', 'F']_csf\": 2.0454624193703754}\n",
    "MAPT_std_dict = {\"['M']_csf\":0.6213240141321779,\n",
    "                \"['M']_plasma\":0.6840496344783593,\n",
    "                \"['F']_csf\":0.7999340389937927,\n",
    "                \"['M', 'F']_csf\":0.7237378322971036}\n",
    "\n",
    "MAPT_BEST_RUNS_M=[\n",
    "    '/scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_10-30-17/model=gat-v4,seed=62542_686_act=leaky_relu,adj_thresh=0.0500,batch_size=8,dropout=0.2000,l1_lambda=0.0000,lr=0.0053,lr_scheduler=R_2024-08-01_12-44-53/checkpoint_000024',\n",
    "    '/scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_10-30-17/model=gat-v4,seed=8990_704_act=leaky_relu,adj_thresh=0.7000,batch_size=32,dropout=0.2000,l1_lambda=0.0002,lr=0.0011,lr_scheduler=L_2024-08-01_12-49-21/checkpoint_000027',\n",
    "    '/scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_10-30-17/model=gat-v4,seed=16742_1047_act=sigmoid,adj_thresh=0.5000,batch_size=16,dropout=0.0500,l1_lambda=0.0000,lr=0.0000,lr_scheduler=La_2024-08-01_14-01-42/checkpoint_000000'\n",
    "]\n",
    "    \n",
    "MAPT_BEST_RUNS_F= [\n",
    "    '/scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_10-30-17/model=gat-v4,seed=37235_729_act=leaky_relu,adj_thresh=0.9000,batch_size=32,dropout=0,l1_lambda=0.0001,lr=0.0007,lr_scheduler=Reduc_2024-08-01_12-56-46/checkpoint_000015',\n",
    "    '/scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_10-30-17/model=gat-v4,seed=46905_207_act=sigmoid,adj_thresh=0.1000,batch_size=32,dropout=0.3000,l1_lambda=0.0003,lr=0.0006,lr_scheduler=Ste_2024-08-01_10-31-43/checkpoint_000028',\n",
    "    '/scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_10-30-17/model=gat-v4,seed=14399_99_act=tanh,adj_thresh=0.7000,batch_size=50,dropout=0.1000,l1_lambda=0.0000,lr=0.0019,lr_scheduler=CosineA_2024-08-01_10-30-18/checkpoint_000027'\n",
    "]\n",
    "\n",
    "MAPT_BEST_RUNS_M_F= [\n",
    "    '/scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_10-30-17/model=gat-v4,seed=23432_69_act=sigmoid,adj_thresh=0.9000,batch_size=50,dropout=0,l1_lambda=0.0003,lr=0.0057,lr_scheduler=ReduceLRO_2024-08-01_10-30-18/checkpoint_000009',\n",
    "    '/scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_10-30-17/model=gat-v4,seed=35171_951_act=elu,adj_thresh=0.9000,batch_size=16,dropout=0.0500,l1_lambda=0.0001,lr=0.0019,lr_scheduler=StepLR,_2024-08-01_13-46-49/checkpoint_000008',\n",
    "    '/scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_10-30-17/model=gat-v4,seed=25447_249_act=sigmoid,adj_thresh=0.7000,batch_size=32,dropout=0.2000,l1_lambda=0.0001,lr=0.0101,lr_scheduler=Ste_2024-08-01_10-47-31/checkpoint_000002'\n",
    "]\n",
    "\n",
    "process_checkpoints(MAPT_BEST_RUNS_M, MAPT_mean_dict, MAPT_std_dict, device)\n",
    "process_checkpoints(MAPT_BEST_RUNS_F, MAPT_mean_dict, MAPT_std_dict, device)\n",
    "process_checkpoints(MAPT_BEST_RUNS_M_F, MAPT_mean_dict, MAPT_std_dict, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint from: /scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_10-30-17/model=gat-v4,seed=52208_883_act=relu,adj_thresh=0.7000,batch_size=8,dropout=0,l1_lambda=0.0002,lr=0.0010,lr_scheduler=ReduceLROnPl_2024-08-01_13-33-15/checkpoint_000020\n",
      "1 best checkpoint for ['M'] and csf\n",
      "Loading data from: /home/data/data_louisa/processed/ftd_y_val_nfl_adj_thresh_0.7_num_nodes_10_mutation_GRN_csf_sex_M_train.pt\n",
      "Loading data from: /home/data/data_louisa/processed/ftd_y_val_nfl_adj_thresh_0.7_num_nodes_10_mutation_GRN_csf_sex_M_test.pt\n",
      "Normalized Val MSE: 0.0497010201215744\n",
      "Normalized train MSE: 0.7081002593040466\n",
      "Original Units Val MSE: tensor(0.2582, grad_fn=<MseLossBackward0>)\n",
      "Original Units Val RMSE: tensor(0.5081, grad_fn=<SqrtBackward0>)\n",
      "Loading checkpoint from: /scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_10-30-17/model=gat-v4,seed=10511_829_act=sigmoid,adj_thresh=0.9000,batch_size=8,dropout=0.3000,l1_lambda=0.0052,lr=0.0010,lr_scheduler=Redu_2024-08-01_13-24-19/checkpoint_000003\n",
      "2 best checkpoint for ['M'] and csf\n",
      "Loading data from: /home/data/data_louisa/processed/ftd_y_val_nfl_adj_thresh_0.9_num_nodes_30_mutation_GRN_csf_sex_M_train.pt\n",
      "Loading data from: /home/data/data_louisa/processed/ftd_y_val_nfl_adj_thresh_0.9_num_nodes_30_mutation_GRN_csf_sex_M_test.pt\n",
      "Normalized Val MSE: 0.17164771258831024\n",
      "Normalized train MSE: 0.6563622355461121\n",
      "Original Units Val MSE: tensor(1.8549, grad_fn=<MseLossBackward0>)\n",
      "Original Units Val RMSE: tensor(1.3619, grad_fn=<SqrtBackward0>)\n",
      "Loading checkpoint from: /scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_10-30-17/model=gat-v4,seed=7148_163_act=sigmoid,adj_thresh=0.1000,batch_size=32,dropout=0.0500,l1_lambda=0.0183,lr=0.0192,lr_scheduler=Step_2024-08-01_10-30-18/checkpoint_000005\n",
      "3 best checkpoint for ['M'] and csf\n",
      "Loading data from: /home/data/data_louisa/processed/ftd_y_val_nfl_adj_thresh_0.1_num_nodes_10_mutation_GRN_csf_sex_M_train.pt\n",
      "Loading data from: /home/data/data_louisa/processed/ftd_y_val_nfl_adj_thresh_0.1_num_nodes_10_mutation_GRN_csf_sex_M_test.pt\n",
      "Normalized Val MSE: 0.22492647171020508\n",
      "Normalized train MSE: 1.5601261854171753\n",
      "Original Units Val MSE: tensor(4.8309, grad_fn=<MseLossBackward0>)\n",
      "Original Units Val RMSE: tensor(2.1979, grad_fn=<SqrtBackward0>)\n",
      "Loading checkpoint from: /scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_17-06-03/model=gat-v4,seed=6059_182_act=relu,adj_thresh=0.1000,batch_size=16,dropout=0.3000,l1_lambda=0.0001,lr=0.0011,lr_scheduler=CosineA_2024-08-01_17-06-04/checkpoint_000065\n",
      "1 best checkpoint for ['F'] and plasma\n",
      "Loading data from: /home/data/data_louisa/processed/ftd_y_val_nfl_adj_thresh_0.1_num_nodes_30_mutation_GRN_plasma_sex_F_train.pt\n",
      "Loading data from: /home/data/data_louisa/processed/ftd_y_val_nfl_adj_thresh_0.1_num_nodes_30_mutation_GRN_plasma_sex_F_test.pt\n",
      "Normalized Val MSE: 0.07332743704319\n",
      "Normalized train MSE: 0.43438684940338135\n",
      "Original Units Val MSE: tensor(274.4327, grad_fn=<MseLossBackward0>)\n",
      "Original Units Val RMSE: tensor(16.5660, grad_fn=<SqrtBackward0>)\n",
      "Loading checkpoint from: /scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_17-06-03/model=gat-v4,seed=42177_32_act=leaky_relu,adj_thresh=0.0500,batch_size=8,dropout=0.1000,l1_lambda=0.0000,lr=0.0072,lr_scheduler=La_2024-08-01_17-06-04/checkpoint_000104\n",
      "2 best checkpoint for ['F'] and plasma\n",
      "Loading data from: /home/data/data_louisa/processed/ftd_y_val_nfl_adj_thresh_0.05_num_nodes_1000_mutation_GRN_plasma_sex_F_train.pt\n",
      "Loading data from: /home/data/data_louisa/processed/ftd_y_val_nfl_adj_thresh_0.05_num_nodes_1000_mutation_GRN_plasma_sex_F_test.pt\n",
      "Normalized Val MSE: 0.07383512705564499\n",
      "Normalized train MSE: 0.1407872438430786\n",
      "Original Units Val MSE: tensor(298.8770, grad_fn=<MseLossBackward0>)\n",
      "Original Units Val RMSE: tensor(17.2881, grad_fn=<SqrtBackward0>)\n",
      "Loading checkpoint from: /scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_17-06-03/model=gat-v4,seed=41068_56_act=tanh,adj_thresh=0.0500,batch_size=50,dropout=0,l1_lambda=0.0011,lr=0.0096,lr_scheduler=CosineAnneal_2024-08-01_17-06-04/checkpoint_000066\n",
      "3 best checkpoint for ['F'] and plasma\n",
      "Loading data from: /home/data/data_louisa/processed/ftd_y_val_nfl_adj_thresh_0.05_num_nodes_10_mutation_GRN_plasma_sex_F_train.pt\n",
      "Loading data from: /home/data/data_louisa/processed/ftd_y_val_nfl_adj_thresh_0.05_num_nodes_10_mutation_GRN_plasma_sex_F_test.pt\n",
      "Normalized Val MSE: 0.15480871498584747\n",
      "Normalized train MSE: 0.4351668357849121\n",
      "Original Units Val MSE: tensor(415.8345, grad_fn=<MseLossBackward0>)\n",
      "Original Units Val RMSE: tensor(20.3920, grad_fn=<SqrtBackward0>)\n",
      "Loading checkpoint from: /scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_10-30-17/model=gat-v4,seed=59173_241_act=tanh,adj_thresh=0.1000,batch_size=32,dropout=0.0500,l1_lambda=0.0000,lr=0.0064,lr_scheduler=Lambda_2024-08-01_10-44-20/checkpoint_000017\n",
      "4 best checkpoint for ['F'] and csf\n",
      "Loading data from: /home/data/data_louisa/processed/ftd_y_val_nfl_adj_thresh_0.1_num_nodes_30_mutation_GRN_csf_sex_F_train.pt\n",
      "Loading data from: /home/data/data_louisa/processed/ftd_y_val_nfl_adj_thresh_0.1_num_nodes_30_mutation_GRN_csf_sex_F_test.pt\n",
      "Normalized Val MSE: 0.49168848991394043\n",
      "Normalized train MSE: 0.5584195852279663\n",
      "Original Units Val MSE: tensor(4412.1221, grad_fn=<MseLossBackward0>)\n",
      "Original Units Val RMSE: tensor(66.4238, grad_fn=<SqrtBackward0>)\n",
      "Loading checkpoint from: /scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_10-30-17/model=gat-v4,seed=39163_985_act=leaky_relu,adj_thresh=0.9000,batch_size=8,dropout=0.0500,l1_lambda=0.0000,lr=0.0041,lr_scheduler=R_2024-08-01_13-53-51/checkpoint_000019\n",
      "1 best checkpoint for ['M', 'F'] and csf\n",
      "Loading data from: /home/data/data_louisa/processed/ftd_y_val_nfl_adj_thresh_0.9_num_nodes_10_mutation_GRN_csf_sex_M,F_train.pt\n",
      "Loading data from: /home/data/data_louisa/processed/ftd_y_val_nfl_adj_thresh_0.9_num_nodes_10_mutation_GRN_csf_sex_M,F_test.pt\n",
      "Normalized Val MSE: 0.1153869777917862\n",
      "Normalized train MSE: 0.6506036520004272\n",
      "Original Units Val MSE: tensor(157.5311, grad_fn=<MseLossBackward0>)\n",
      "Original Units Val RMSE: tensor(12.5511, grad_fn=<SqrtBackward0>)\n",
      "Loading checkpoint from: /scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_10-30-17/model=gat-v4,seed=63998_355_act=elu,adj_thresh=0.1000,batch_size=8,dropout=0,l1_lambda=0.0001,lr=0.0108,lr_scheduler=ReduceLROnPla_2024-08-01_11-20-27/checkpoint_000003\n",
      "2 best checkpoint for ['M', 'F'] and csf\n",
      "Loading data from: /home/data/data_louisa/processed/ftd_y_val_nfl_adj_thresh_0.1_num_nodes_10_mutation_GRN_csf_sex_M,F_train.pt\n",
      "Loading data from: /home/data/data_louisa/processed/ftd_y_val_nfl_adj_thresh_0.1_num_nodes_10_mutation_GRN_csf_sex_M,F_test.pt\n",
      "Normalized Val MSE: 0.11639781296253204\n",
      "Normalized train MSE: 0.2161395102739334\n",
      "Original Units Val MSE: tensor(74.0087, grad_fn=<MseLossBackward0>)\n",
      "Original Units Val RMSE: tensor(8.6028, grad_fn=<SqrtBackward0>)\n",
      "Loading checkpoint from: /scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_10-30-17/model=gat-v4,seed=14600_751_act=tanh,adj_thresh=0.7000,batch_size=32,dropout=0.0500,l1_lambda=0.0011,lr=0.0236,lr_scheduler=Cosine_2024-08-01_12-59-43/checkpoint_000042\n",
      "3 best checkpoint for ['M', 'F'] and csf\n",
      "Loading data from: /home/data/data_louisa/processed/ftd_y_val_nfl_adj_thresh_0.7_num_nodes_30_mutation_GRN_csf_sex_M,F_train.pt\n",
      "Loading data from: /home/data/data_louisa/processed/ftd_y_val_nfl_adj_thresh_0.7_num_nodes_30_mutation_GRN_csf_sex_M,F_test.pt\n",
      "Normalized Val MSE: 0.1435537338256836\n",
      "Normalized train MSE: 0.2351238876581192\n",
      "Original Units Val MSE: tensor(230.8784, grad_fn=<MseLossBackward0>)\n",
      "Original Units Val RMSE: tensor(15.1947, grad_fn=<SqrtBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(tensor([[38.1163],\n",
       "          [ 4.3769],\n",
       "          [ 9.2230],\n",
       "          [ 7.9793],\n",
       "          [33.8475],\n",
       "          [13.0684],\n",
       "          [43.1009],\n",
       "          [32.2196],\n",
       "          [ 0.3669],\n",
       "          [15.1122],\n",
       "          [20.5845],\n",
       "          [14.0804],\n",
       "          [ 4.1669],\n",
       "          [48.3165],\n",
       "          [ 0.6697],\n",
       "          [ 2.2397],\n",
       "          [ 0.7753],\n",
       "          [36.7248],\n",
       "          [ 2.0329],\n",
       "          [ 5.7276],\n",
       "          [ 0.9056],\n",
       "          [40.8088],\n",
       "          [ 3.1494],\n",
       "          [ 5.8064],\n",
       "          [39.7984]]),\n",
       "  tensor([[80.2171],\n",
       "          [ 7.9675],\n",
       "          [11.2010],\n",
       "          [10.8412],\n",
       "          [92.7933],\n",
       "          [ 6.9760],\n",
       "          [44.1702],\n",
       "          [35.0793],\n",
       "          [ 2.8600],\n",
       "          [ 6.0449],\n",
       "          [21.8106],\n",
       "          [11.1943],\n",
       "          [ 3.2937],\n",
       "          [84.4435],\n",
       "          [ 2.2781],\n",
       "          [ 9.1830],\n",
       "          [ 4.5831],\n",
       "          [73.4552],\n",
       "          [ 6.6160],\n",
       "          [13.1766],\n",
       "          [ 5.1185],\n",
       "          [95.4446],\n",
       "          [ 5.8523],\n",
       "          [ 4.8881],\n",
       "          [41.2233]]),\n",
       "  tensor(449.0646),\n",
       "  tensor(21.1911),\n",
       "  tensor([[39.4750],\n",
       "          [13.6242],\n",
       "          [52.9532],\n",
       "          [11.5989],\n",
       "          [14.7677],\n",
       "          [42.8506],\n",
       "          [40.9360]], grad_fn=<ExpBackward0>),\n",
       "  tensor([[41.9474],\n",
       "          [10.4173],\n",
       "          [82.9245],\n",
       "          [11.3758],\n",
       "          [ 6.2857],\n",
       "          [53.5672],\n",
       "          [39.8413]]),\n",
       "  tensor(157.5311, grad_fn=<MseLossBackward0>),\n",
       "  tensor(12.5511, grad_fn=<SqrtBackward0>)),\n",
       " (tensor([[ 6.0029],\n",
       "          [14.1770],\n",
       "          [ 7.6247],\n",
       "          [21.3782],\n",
       "          [62.4471],\n",
       "          [55.9568],\n",
       "          [46.1209],\n",
       "          [11.4199],\n",
       "          [50.2309],\n",
       "          [14.9679],\n",
       "          [ 7.1377],\n",
       "          [ 5.9914],\n",
       "          [ 5.4554],\n",
       "          [12.9554],\n",
       "          [42.8928],\n",
       "          [ 5.7789],\n",
       "          [10.9689],\n",
       "          [54.4983],\n",
       "          [10.4491],\n",
       "          [10.0588],\n",
       "          [57.6765],\n",
       "          [ 7.7451],\n",
       "          [16.5793],\n",
       "          [11.7234],\n",
       "          [49.7303]]),\n",
       "  tensor([[ 4.5831],\n",
       "          [ 6.9760],\n",
       "          [ 6.6160],\n",
       "          [21.8106],\n",
       "          [44.1702],\n",
       "          [95.4446],\n",
       "          [35.0793],\n",
       "          [10.8412],\n",
       "          [73.4552],\n",
       "          [11.1943],\n",
       "          [ 9.1830],\n",
       "          [ 2.2781],\n",
       "          [ 2.8600],\n",
       "          [11.2010],\n",
       "          [92.7933],\n",
       "          [ 5.1185],\n",
       "          [ 3.2937],\n",
       "          [41.2233],\n",
       "          [13.1766],\n",
       "          [ 4.8881],\n",
       "          [84.4435],\n",
       "          [ 5.8523],\n",
       "          [ 6.0449],\n",
       "          [ 7.9675],\n",
       "          [80.2171]]),\n",
       "  tensor(287.4573),\n",
       "  tensor(16.9546),\n",
       "  tensor([[48.5811],\n",
       "          [14.5617],\n",
       "          [64.6582],\n",
       "          [14.6092],\n",
       "          [15.3011],\n",
       "          [52.0367],\n",
       "          [45.2398]], grad_fn=<ExpBackward0>),\n",
       "  tensor([[41.9474],\n",
       "          [10.4173],\n",
       "          [82.9245],\n",
       "          [11.3758],\n",
       "          [ 6.2857],\n",
       "          [53.5672],\n",
       "          [39.8413]]),\n",
       "  tensor(74.0087, grad_fn=<MseLossBackward0>),\n",
       "  tensor(8.6028, grad_fn=<SqrtBackward0>)),\n",
       " (tensor([[14.4146],\n",
       "          [ 3.7328],\n",
       "          [60.7470],\n",
       "          [ 4.2358],\n",
       "          [66.0060],\n",
       "          [ 3.0484],\n",
       "          [39.3110],\n",
       "          [ 2.4002],\n",
       "          [ 3.4162],\n",
       "          [53.9031],\n",
       "          [ 5.2225],\n",
       "          [ 2.7087],\n",
       "          [63.9536],\n",
       "          [ 2.3333],\n",
       "          [84.5024],\n",
       "          [ 2.2054],\n",
       "          [ 2.8943],\n",
       "          [17.0415],\n",
       "          [54.5857],\n",
       "          [ 5.1335],\n",
       "          [59.5195],\n",
       "          [ 6.2747],\n",
       "          [ 3.5461],\n",
       "          [ 3.6632],\n",
       "          [ 3.2118]]),\n",
       "  tensor([[11.1943],\n",
       "          [13.1766],\n",
       "          [80.2171],\n",
       "          [ 6.0449],\n",
       "          [73.4552],\n",
       "          [ 5.1185],\n",
       "          [41.2233],\n",
       "          [ 2.2781],\n",
       "          [ 4.8881],\n",
       "          [44.1702],\n",
       "          [ 6.9760],\n",
       "          [ 6.6160],\n",
       "          [95.4446],\n",
       "          [ 4.5831],\n",
       "          [84.4435],\n",
       "          [ 2.8600],\n",
       "          [ 9.1830],\n",
       "          [21.8106],\n",
       "          [92.7933],\n",
       "          [10.8412],\n",
       "          [35.0793],\n",
       "          [11.2010],\n",
       "          [ 3.2937],\n",
       "          [ 7.9675],\n",
       "          [ 5.8523]]),\n",
       "  tensor(154.3848),\n",
       "  tensor(12.4252),\n",
       "  tensor([[62.5812],\n",
       "          [ 9.4163],\n",
       "          [86.0614],\n",
       "          [ 4.9689],\n",
       "          [ 4.7554],\n",
       "          [63.7642],\n",
       "          [71.9689]], grad_fn=<ExpBackward0>),\n",
       "  tensor([[41.9474],\n",
       "          [10.4173],\n",
       "          [82.9245],\n",
       "          [11.3758],\n",
       "          [ 6.2857],\n",
       "          [53.5672],\n",
       "          [39.8413]]),\n",
       "  tensor(230.8784, grad_fn=<MseLossBackward0>),\n",
       "  tensor(15.1947, grad_fn=<SqrtBackward0>))]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "59173\n",
    "GRN_mean_dict = {\"['M']_csf\": 2.178815827183045,\n",
    "                \"['F']_plasma\":3.120974866855634,\n",
    "                \"['F']_csf\": 3.2586357196385385,\n",
    "                \"['M', 'F']_csf\":2.752470145050026}\n",
    "GRN_std_dict = {\"['M']_csf\":0.7776541040264751,\n",
    "                \"['F']_plasma\":1.2401561087499366,\n",
    "                \"['F']_csf\":1.1764975422138229,\n",
    "                \"['M', 'F']_csf\":1.1441881493582908}\n",
    "\n",
    "GRN_BEST_RUNS_M=[\n",
    "    '/scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_10-30-17/model=gat-v4,seed=52208_883_act=relu,adj_thresh=0.7000,batch_size=8,dropout=0,l1_lambda=0.0002,lr=0.0010,lr_scheduler=ReduceLROnPl_2024-08-01_13-33-15/checkpoint_000020',\n",
    "    '/scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_10-30-17/model=gat-v4,seed=10511_829_act=sigmoid,adj_thresh=0.9000,batch_size=8,dropout=0.3000,l1_lambda=0.0052,lr=0.0010,lr_scheduler=Redu_2024-08-01_13-24-19/checkpoint_000003',\n",
    "    '/scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_10-30-17/model=gat-v4,seed=7148_163_act=sigmoid,adj_thresh=0.1000,batch_size=32,dropout=0.0500,l1_lambda=0.0183,lr=0.0192,lr_scheduler=Step_2024-08-01_10-30-18/checkpoint_000005',\n",
    "\n",
    "]\n",
    "GRN_BEST_RUNS_F= [\n",
    "    '/scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_17-06-03/model=gat-v4,seed=6059_182_act=relu,adj_thresh=0.1000,batch_size=16,dropout=0.3000,l1_lambda=0.0001,lr=0.0011,lr_scheduler=CosineA_2024-08-01_17-06-04/checkpoint_000065',\n",
    "    '/scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_17-06-03/model=gat-v4,seed=42177_32_act=leaky_relu,adj_thresh=0.0500,batch_size=8,dropout=0.1000,l1_lambda=0.0000,lr=0.0072,lr_scheduler=La_2024-08-01_17-06-04/checkpoint_000104',\n",
    "    '/scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_17-06-03/model=gat-v4,seed=41068_56_act=tanh,adj_thresh=0.0500,batch_size=50,dropout=0,l1_lambda=0.0011,lr=0.0096,lr_scheduler=CosineAnneal_2024-08-01_17-06-04/checkpoint_000066',\n",
    "    '/scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_10-30-17/model=gat-v4,seed=59173_241_act=tanh,adj_thresh=0.1000,batch_size=32,dropout=0.0500,l1_lambda=0.0000,lr=0.0064,lr_scheduler=Lambda_2024-08-01_10-44-20/checkpoint_000017'\n",
    "]\n",
    "\n",
    "GRN_BEST_RUNS_M_F= [\n",
    "    '/scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_10-30-17/model=gat-v4,seed=39163_985_act=leaky_relu,adj_thresh=0.9000,batch_size=8,dropout=0.0500,l1_lambda=0.0000,lr=0.0041,lr_scheduler=R_2024-08-01_13-53-51/checkpoint_000019',\n",
    "    '/scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_10-30-17/model=gat-v4,seed=63998_355_act=elu,adj_thresh=0.1000,batch_size=8,dropout=0,l1_lambda=0.0001,lr=0.0108,lr_scheduler=ReduceLROnPla_2024-08-01_11-20-27/checkpoint_000003',\n",
    "    '/scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_10-30-17/model=gat-v4,seed=14600_751_act=tanh,adj_thresh=0.7000,batch_size=32,dropout=0.0500,l1_lambda=0.0011,lr=0.0236,lr_scheduler=Cosine_2024-08-01_12-59-43/checkpoint_000042'\n",
    "]\n",
    "process_checkpoints(GRN_BEST_RUNS_M, GRN_mean_dict, GRN_std_dict, device)\n",
    "process_checkpoints(GRN_BEST_RUNS_F, GRN_mean_dict, GRN_std_dict, device)\n",
    "process_checkpoints(GRN_BEST_RUNS_M_F, GRN_mean_dict, GRN_std_dict, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from: /home/data/data_louisa/processed/ftd_y_val_nfl_adj_thresh_0.1_num_nodes_7000_mutation_GRN,MAPT,C9orf72,CTL_csf_sex_M,F_train.pt\n",
      "Loading data from: /home/data/data_louisa/processed/ftd_y_val_nfl_adj_thresh_0.1_num_nodes_7000_mutation_GRN,MAPT,C9orf72,CTL_csf_sex_M,F_test.pt\n",
      "Normalized Val MSE: 0.2927090525627136\n",
      "Normalized train MSE: 0.617820680141449\n",
      "[12.8441     7.547421  24.042095   8.60323    2.8657448  8.574525\n",
      "  8.2060995  7.1123953  4.2857413  4.868487   7.256487  26.50609\n",
      "  3.3411803  4.6200047 12.720614  10.906545  11.41021    6.950218\n",
      " 22.184828   6.3320675  5.952338   3.8900576  3.638758   8.249515\n",
      "  6.3946753  6.4177427 13.000436  15.254776   3.7150073  5.184722\n",
      " 12.785116   6.6820416  3.2877386 10.367632   3.3027148  8.719203\n",
      "  3.1877406 23.381384   3.6926875 16.874008  10.855891   6.439096\n",
      "  4.7240305  5.3021173  9.031043 ]\n",
      "Original Units Val MSE: tensor(143.7400, grad_fn=<MseLossBackward0>)\n",
      "Original Units Val RMSE: tensor(11.9892, grad_fn=<SqrtBackward0>)\n",
      "Val Z scores: [ 0.08007377 -0.35723084 -5.62651    -0.13323633  0.16462387 -0.83845824\n",
      "  0.27037883  0.2325868   0.35803923  0.31581715 -0.13154203 -0.40049595\n",
      "  0.46219546  0.3163388   0.27837238  0.55491704  0.6093877   0.56537336\n",
      " -0.9533663   0.31877628  0.3090361   0.39018396  0.3041441  -0.2944469\n",
      "  0.4369149  -0.8787028  -2.0129097  -0.26389265  0.22393832  0.06741583\n",
      "  0.46897683  0.41799524  0.07926784  0.32405224  0.33311775  0.06185825\n",
      "  0.31169698  1.106292    0.33067942  0.5276192   0.18146028  0.4802631\n",
      "  0.20408231  0.3690941   0.4358215 ]\n",
      "Loading data from: /home/data/data_louisa/processed/ftd_y_val_nfl_adj_thresh_0.9_num_nodes_7000_mutation_GRN,MAPT,C9orf72,CTL_csf_sex_M,F_train.pt\n",
      "Loading data from: /home/data/data_louisa/processed/ftd_y_val_nfl_adj_thresh_0.9_num_nodes_7000_mutation_GRN,MAPT,C9orf72,CTL_csf_sex_M,F_test.pt\n",
      "Normalized Val MSE: 0.4130514860153198\n",
      "Normalized train MSE: 0.7219048142433167\n",
      "[10.093795   8.871278  14.806372  10.252817   3.4402876  9.581103\n",
      "  8.030844   6.218267   4.3695927  6.007982   8.567073  14.762646\n",
      "  6.0879207  6.0602736 12.012389   9.414133   9.580892   8.089884\n",
      " 13.189226   5.5780663  5.713679   5.756123   3.7177777  9.9422655\n",
      "  7.7054715  8.680217  11.049767  12.272555   3.4432724  6.2666297\n",
      " 10.816934   7.1487017  4.4349046 11.084625   3.6864433  7.977692\n",
      "  2.9814968 16.189873   3.4076412 11.905483   9.332827   6.9749413\n",
      "  5.3752203  7.8630705  7.208075 ]\n",
      "Original Units Val MSE: tensor(188.5184, grad_fn=<MseLossBackward0>)\n",
      "Original Units Val RMSE: tensor(13.7302, grad_fn=<SqrtBackward0>)\n",
      "Val Z scores: [-0.0781883  -0.15381734 -5.5869656   0.06780753  0.24818802 -0.6009571\n",
      "  0.2843276   0.19660704  0.3810391   0.4239414   0.04359909 -1.182426\n",
      "  0.67447287  0.4472003   0.2509535   0.43464223  0.45699275  0.6433606\n",
      " -1.4602009   0.283006    0.3135082   0.5444015   0.333289   -0.07065444\n",
      "  0.5433943  -0.5411361  -1.8576932  -0.39817917  0.23618412  0.20118502\n",
      "  0.32301882  0.46277052  0.21655206  0.3991537   0.38186076  0.0580741\n",
      "  0.3183049   0.4873815   0.32902032  0.14713453  0.10398062  0.5227601\n",
      "  0.28868958  0.5785358   0.3048772 ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[tensor([[ 7.1584],\n",
       "         [ 6.2554],\n",
       "         [ 7.3279],\n",
       "         [ 8.2751],\n",
       "         [ 8.5814],\n",
       "         [ 6.3054],\n",
       "         [10.1999],\n",
       "         [ 5.9420],\n",
       "         [ 6.7957],\n",
       "         [ 7.0562],\n",
       "         [ 3.7080],\n",
       "         [ 4.1676],\n",
       "         [ 8.6563],\n",
       "         [ 5.6867],\n",
       "         [11.1634],\n",
       "         [ 4.2039],\n",
       "         [12.5305],\n",
       "         [ 5.1367],\n",
       "         [ 4.7781],\n",
       "         [ 7.9725],\n",
       "         [10.9752],\n",
       "         [ 3.5311],\n",
       "         [ 8.2834],\n",
       "         [ 6.6194],\n",
       "         [ 3.3504],\n",
       "         [ 2.7081],\n",
       "         [10.7249],\n",
       "         [ 6.8032],\n",
       "         [ 5.2956],\n",
       "         [ 5.8516],\n",
       "         [ 4.4133],\n",
       "         [ 5.6812],\n",
       "         [ 5.6982],\n",
       "         [ 4.8222],\n",
       "         [ 3.3666],\n",
       "         [ 9.5943],\n",
       "         [10.1314],\n",
       "         [ 3.6116],\n",
       "         [ 7.1521],\n",
       "         [ 6.2965],\n",
       "         [ 4.2400],\n",
       "         [14.8351],\n",
       "         [ 7.4228],\n",
       "         [ 7.2173],\n",
       "         [ 5.2459],\n",
       "         [ 4.9058],\n",
       "         [ 5.4745],\n",
       "         [ 7.0776],\n",
       "         [ 2.0127],\n",
       "         [ 6.8131],\n",
       "         [ 9.3403],\n",
       "         [ 2.7393],\n",
       "         [11.7738],\n",
       "         [12.9211],\n",
       "         [13.8139],\n",
       "         [ 6.3209],\n",
       "         [ 8.3376],\n",
       "         [11.1345],\n",
       "         [ 1.8959],\n",
       "         [15.1225],\n",
       "         [ 7.1668],\n",
       "         [12.2767],\n",
       "         [ 8.9327],\n",
       "         [ 9.9005],\n",
       "         [ 5.8894],\n",
       "         [11.2206],\n",
       "         [ 3.9186],\n",
       "         [ 9.2237],\n",
       "         [ 2.9178],\n",
       "         [ 6.3875],\n",
       "         [ 5.1497],\n",
       "         [ 3.8977],\n",
       "         [ 3.7305],\n",
       "         [ 1.6268],\n",
       "         [ 8.9210],\n",
       "         [ 2.9386],\n",
       "         [ 9.9419],\n",
       "         [ 6.9611],\n",
       "         [ 9.1923],\n",
       "         [12.6529],\n",
       "         [ 4.3496],\n",
       "         [ 7.0608],\n",
       "         [11.2055],\n",
       "         [13.0443],\n",
       "         [12.1951],\n",
       "         [12.4044],\n",
       "         [ 5.7971],\n",
       "         [10.7073],\n",
       "         [ 6.3303],\n",
       "         [10.8101],\n",
       "         [ 7.5596],\n",
       "         [ 9.3180],\n",
       "         [14.3918],\n",
       "         [14.1013],\n",
       "         [ 4.9656],\n",
       "         [ 4.8320],\n",
       "         [ 7.2656],\n",
       "         [ 3.2378],\n",
       "         [ 7.5093],\n",
       "         [ 4.9724],\n",
       "         [ 4.6509],\n",
       "         [ 6.7646],\n",
       "         [ 2.9784],\n",
       "         [ 8.4440],\n",
       "         [ 7.8293],\n",
       "         [ 5.3915],\n",
       "         [ 4.8682],\n",
       "         [ 4.1414],\n",
       "         [ 3.6820],\n",
       "         [ 2.1688],\n",
       "         [ 9.0132],\n",
       "         [ 4.4248],\n",
       "         [ 6.5258],\n",
       "         [ 8.0482],\n",
       "         [ 7.8404],\n",
       "         [ 8.0260],\n",
       "         [ 2.9513],\n",
       "         [ 9.1881],\n",
       "         [ 8.8788],\n",
       "         [12.8189],\n",
       "         [ 4.5384],\n",
       "         [ 6.3053],\n",
       "         [ 7.0206],\n",
       "         [ 7.3920],\n",
       "         [ 5.9062],\n",
       "         [ 9.6915],\n",
       "         [12.8679],\n",
       "         [ 6.3725],\n",
       "         [ 9.4000],\n",
       "         [14.6732],\n",
       "         [ 2.3475],\n",
       "         [ 5.8442],\n",
       "         [12.5155],\n",
       "         [ 8.4824],\n",
       "         [15.3489],\n",
       "         [ 2.8354],\n",
       "         [ 2.5820],\n",
       "         [ 5.7176],\n",
       "         [ 9.7960],\n",
       "         [ 1.9967],\n",
       "         [ 6.1023],\n",
       "         [ 6.6176],\n",
       "         [ 2.9841],\n",
       "         [ 9.7346],\n",
       "         [ 4.8324],\n",
       "         [ 2.2792],\n",
       "         [ 2.9824],\n",
       "         [15.7064],\n",
       "         [ 2.9201],\n",
       "         [ 8.4298],\n",
       "         [ 3.7895],\n",
       "         [ 6.3031],\n",
       "         [10.5878],\n",
       "         [ 7.9843],\n",
       "         [ 7.0943],\n",
       "         [ 8.2549],\n",
       "         [ 7.7786],\n",
       "         [ 3.4084],\n",
       "         [ 8.1855],\n",
       "         [ 8.4070],\n",
       "         [ 6.4064],\n",
       "         [ 6.2617],\n",
       "         [10.2963],\n",
       "         [ 4.6675],\n",
       "         [ 3.7670],\n",
       "         [11.4305],\n",
       "         [10.5787],\n",
       "         [11.3645],\n",
       "         [ 6.0432],\n",
       "         [ 7.9820],\n",
       "         [ 2.0232],\n",
       "         [ 6.0424],\n",
       "         [ 4.4318],\n",
       "         [ 8.3134],\n",
       "         [ 5.9363],\n",
       "         [ 3.6146],\n",
       "         [ 4.9340],\n",
       "         [ 4.6860],\n",
       "         [ 7.8185]]),\n",
       " tensor([[ 14.4016],\n",
       "         [  5.0684],\n",
       "         [  4.8222],\n",
       "         [ 85.7042],\n",
       "         [  8.7210],\n",
       "         [  3.6037],\n",
       "         [ 15.0883],\n",
       "         [  4.9069],\n",
       "         [  4.8881],\n",
       "         [  6.6437],\n",
       "         [  4.5896],\n",
       "         [  9.6421],\n",
       "         [  8.0067],\n",
       "         [  7.0365],\n",
       "         [ 41.9473],\n",
       "         [  4.1744],\n",
       "         [  7.9675],\n",
       "         [  5.7730],\n",
       "         [  2.8114],\n",
       "         [ 56.1249],\n",
       "         [ 15.8086],\n",
       "         [  4.1341],\n",
       "         [ 13.1766],\n",
       "         [  7.3740],\n",
       "         [  3.3693],\n",
       "         [  4.2809],\n",
       "         [ 13.3588],\n",
       "         [  3.3249],\n",
       "         [ 10.7287],\n",
       "         [  8.8680],\n",
       "         [  5.5243],\n",
       "         [  9.7635],\n",
       "         [  3.2937],\n",
       "         [  4.2027],\n",
       "         [ 10.6730],\n",
       "         [ 62.0507],\n",
       "         [  9.9528],\n",
       "         [  4.5765],\n",
       "         [ 15.1033],\n",
       "         [  6.6160],\n",
       "         [  6.9591],\n",
       "         [ 82.9245],\n",
       "         [  9.8332],\n",
       "         [  2.7222],\n",
       "         [  7.5283],\n",
       "         [  2.7168],\n",
       "         [  4.2141],\n",
       "         [  6.6709],\n",
       "         [  2.3723],\n",
       "         [  9.4036],\n",
       "         [  6.0449],\n",
       "         [  4.8015],\n",
       "         [ 41.2233],\n",
       "         [ 44.1702],\n",
       "         [ 11.3758],\n",
       "         [ 86.6399],\n",
       "         [  6.9884],\n",
       "         [ 43.6218],\n",
       "         [  2.2080],\n",
       "         [ 10.8005],\n",
       "         [ 10.0625],\n",
       "         [ 13.0544],\n",
       "         [ 19.0975],\n",
       "         [  9.1830],\n",
       "         [  5.1185],\n",
       "         [ 80.2171],\n",
       "         [  8.5448],\n",
       "         [  5.9444],\n",
       "         [  4.6870],\n",
       "         [  6.6486],\n",
       "         [  5.1557],\n",
       "         [  3.0204],\n",
       "         [  3.1938],\n",
       "         [  3.9373],\n",
       "         [  7.3990],\n",
       "         [  3.0380],\n",
       "         [  9.7706],\n",
       "         [  8.6358],\n",
       "         [  3.5725],\n",
       "         [ 73.4551],\n",
       "         [  8.4900],\n",
       "         [ 10.1167],\n",
       "         [ 24.6015],\n",
       "         [ 14.2380],\n",
       "         [ 24.8486],\n",
       "         [ 26.6115],\n",
       "         [  5.6098],\n",
       "         [ 13.3339],\n",
       "         [  2.7373],\n",
       "         [ 22.1398],\n",
       "         [  4.5072],\n",
       "         [  5.4880],\n",
       "         [ 19.4275],\n",
       "         [ 95.4445],\n",
       "         [  5.3738],\n",
       "         [  4.2506],\n",
       "         [  9.2071],\n",
       "         [  6.3309],\n",
       "         [  3.6518],\n",
       "         [  4.0045],\n",
       "         [  4.6946],\n",
       "         [  5.6356],\n",
       "         [  2.1860],\n",
       "         [ 14.3599],\n",
       "         [  5.6627],\n",
       "         [  7.0016],\n",
       "         [  4.8514],\n",
       "         [  2.9927],\n",
       "         [  3.1793],\n",
       "         [  5.2097],\n",
       "         [ 53.5672],\n",
       "         [  4.0191],\n",
       "         [  4.5311],\n",
       "         [ 84.4434],\n",
       "         [ 11.2784],\n",
       "         [  9.7408],\n",
       "         [  4.3306],\n",
       "         [  4.0740],\n",
       "         [ 78.9355],\n",
       "         [ 11.1943],\n",
       "         [  4.5831],\n",
       "         [  9.3809],\n",
       "         [  7.8152],\n",
       "         [  6.9760],\n",
       "         [  1.8875],\n",
       "         [ 10.4173],\n",
       "         [ 37.7225],\n",
       "         [  5.7691],\n",
       "         [ 23.9309],\n",
       "         [ 35.0793],\n",
       "         [  2.4436],\n",
       "         [  2.5440],\n",
       "         [  6.2857],\n",
       "         [ 17.1284],\n",
       "         [ 14.4771],\n",
       "         [  4.9680],\n",
       "         [  4.3265],\n",
       "         [  5.8640],\n",
       "         [ 12.2691],\n",
       "         [  7.1822],\n",
       "         [  4.1530],\n",
       "         [  7.0325],\n",
       "         [  2.2781],\n",
       "         [ 12.3482],\n",
       "         [  4.2755],\n",
       "         [  3.0419],\n",
       "         [  6.1126],\n",
       "         [ 20.6275],\n",
       "         [  5.3757],\n",
       "         [  9.2476],\n",
       "         [  6.8371],\n",
       "         [  4.4892],\n",
       "         [  9.8314],\n",
       "         [ 12.6793],\n",
       "         [  8.1047],\n",
       "         [ 16.6183],\n",
       "         [  4.8879],\n",
       "         [  2.6037],\n",
       "         [ 12.8974],\n",
       "         [  9.4545],\n",
       "         [ 48.2977],\n",
       "         [ 10.6098],\n",
       "         [  8.9682],\n",
       "         [  6.0964],\n",
       "         [  4.8273],\n",
       "         [121.6692],\n",
       "         [ 11.2010],\n",
       "         [ 12.7782],\n",
       "         [  4.8740],\n",
       "         [  8.7043],\n",
       "         [  4.1750],\n",
       "         [  6.0746],\n",
       "         [  5.9804],\n",
       "         [  8.5715],\n",
       "         [  8.3577],\n",
       "         [  7.1664],\n",
       "         [  5.2504],\n",
       "         [  2.5693],\n",
       "         [  2.9428]]),\n",
       " tensor(396.7242),\n",
       " tensor(19.9179),\n",
       " tensor([[10.0938],\n",
       "         [ 8.8713],\n",
       "         [14.8064],\n",
       "         [10.2528],\n",
       "         [ 3.4403],\n",
       "         [ 9.5811],\n",
       "         [ 8.0308],\n",
       "         [ 6.2183],\n",
       "         [ 4.3696],\n",
       "         [ 6.0080],\n",
       "         [ 8.5671],\n",
       "         [14.7626],\n",
       "         [ 6.0879],\n",
       "         [ 6.0603],\n",
       "         [12.0124],\n",
       "         [ 9.4141],\n",
       "         [ 9.5809],\n",
       "         [ 8.0899],\n",
       "         [13.1892],\n",
       "         [ 5.5781],\n",
       "         [ 5.7137],\n",
       "         [ 5.7561],\n",
       "         [ 3.7178],\n",
       "         [ 9.9423],\n",
       "         [ 7.7055],\n",
       "         [ 8.6802],\n",
       "         [11.0498],\n",
       "         [12.2726],\n",
       "         [ 3.4433],\n",
       "         [ 6.2666],\n",
       "         [10.8169],\n",
       "         [ 7.1487],\n",
       "         [ 4.4349],\n",
       "         [11.0846],\n",
       "         [ 3.6864],\n",
       "         [ 7.9777],\n",
       "         [ 2.9815],\n",
       "         [16.1899],\n",
       "         [ 3.4076],\n",
       "         [11.9055],\n",
       "         [ 9.3328],\n",
       "         [ 6.9749],\n",
       "         [ 5.3752],\n",
       "         [ 7.8631],\n",
       "         [ 7.2081]], grad_fn=<ExpBackward0>),\n",
       " tensor([[15.4106],\n",
       "         [15.1858],\n",
       "         [92.7933],\n",
       "         [13.6437],\n",
       "         [ 4.4517],\n",
       "         [21.7942],\n",
       "         [ 8.5655],\n",
       "         [ 7.9101],\n",
       "         [ 3.6285],\n",
       "         [ 4.7009],\n",
       "         [12.2773],\n",
       "         [34.6463],\n",
       "         [ 1.4759],\n",
       "         [ 4.4464],\n",
       "         [12.9873],\n",
       "         [ 7.9659],\n",
       "         [ 7.8378],\n",
       "         [ 3.8883],\n",
       "         [36.7372],\n",
       "         [ 6.1302],\n",
       "         [ 5.8634],\n",
       "         [ 2.8600],\n",
       "         [ 3.6066],\n",
       "         [15.1597],\n",
       "         [ 4.8226],\n",
       "         [20.1041],\n",
       "         [39.8413],\n",
       "         [21.8106],\n",
       "         [ 4.6130],\n",
       "         [ 7.8981],\n",
       "         [10.8412],\n",
       "         [ 5.3294],\n",
       "         [ 5.8636],\n",
       "         [10.1045],\n",
       "         [ 2.9345],\n",
       "         [11.4970],\n",
       "         [ 3.0679],\n",
       "         [14.0459],\n",
       "         [ 3.3527],\n",
       "         [14.2499],\n",
       "         [12.2466],\n",
       "         [ 4.3643],\n",
       "         [ 5.8523],\n",
       "         [ 4.5166],\n",
       "         [ 7.4716]]),\n",
       " tensor(188.5184, grad_fn=<MseLossBackward0>),\n",
       " tensor(13.7302, grad_fn=<SqrtBackward0>),\n",
       " array([-0.0781883 , -0.15381734, -5.5869656 ,  0.06780753,  0.24818802,\n",
       "        -0.6009571 ,  0.2843276 ,  0.19660704,  0.3810391 ,  0.4239414 ,\n",
       "         0.04359909, -1.182426  ,  0.67447287,  0.4472003 ,  0.2509535 ,\n",
       "         0.43464223,  0.45699275,  0.6433606 , -1.4602009 ,  0.283006  ,\n",
       "         0.3135082 ,  0.5444015 ,  0.333289  , -0.07065444,  0.5433943 ,\n",
       "        -0.5411361 , -1.8576932 , -0.39817917,  0.23618412,  0.20118502,\n",
       "         0.32301882,  0.46277052,  0.21655206,  0.3991537 ,  0.38186076,\n",
       "         0.0580741 ,  0.3183049 ,  0.4873815 ,  0.32902032,  0.14713453,\n",
       "         0.10398062,  0.5227601 ,  0.28868958,  0.5785358 ,  0.3048772 ],\n",
       "       dtype=float32)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "full_load_and_run_and_convert('/scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-13_15-49-20/model=gat-v4,seed=31061_269_act=sigmoid,adj_thresh=0.1000,batch_size=8,dropout=0.1000,l1_lambda=0.0008,lr=0.0000,lr_scheduler=Lamb_2024-08-13_16-58-56/checkpoint_000005', device, 2.124088581365514, 0.8733420033790319)\n",
    "full_load_and_run_and_convert('/scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-13_15-49-20/model=gat-v4,seed=55118_1133_act=relu,adj_thresh=0.9000,batch_size=32,dropout=0.2000,l1_lambda=0.0001,lr=0.0000,lr_scheduler=Lambd_2024-08-14_01-14-01/checkpoint_000001',device, 2.124088581365514, 0.8733420033790319)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "716.7650146484375\n"
     ]
    }
   ],
   "source": [
    "#Sanity check\n",
    "def compute_manual_mse(val_preds, val_targets):\n",
    "    \"\"\"\n",
    "    Manually computes the Mean Squared Error (MSE) for the given predictions and targets.\n",
    "\n",
    "    Parameters:\n",
    "    val_preds (list of list of torch.Tensor): The predicted values.\n",
    "    val_targets (list of list of torch.Tensor): The true target values.\n",
    "\n",
    "    Returns:\n",
    "    float: The computed Mean Squared Error.\n",
    "    \"\"\"\n",
    "   # Compute the squared differences\n",
    "    squared_diffs = (val_preds - val_targets) ** 2\n",
    "\n",
    "    # Compute the mean of the squared differences\n",
    "    mse = squared_diffs.mean().item()\n",
    "\n",
    "    return mse\n",
    "\n",
    "print(compute_manual_mse(val_preds, val_targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint from: /scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-07-31_15-31-35/model=gat-v4,seed=19543_0_act=relu,adj_thresh=0.1000,batch_size=8,dropout=0,l1_lambda=0.0000,lr=0.1000,lr_scheduler=LambdaLR,modal_2024-07-31_15-31-36/checkpoint_000001/checkpoint.ckpt\n",
      "Checkpoint keys: dict_keys(['epoch', 'global_step', 'pytorch-lightning_version', 'state_dict', 'loops', 'callbacks', 'optimizer_states', 'lr_schedulers', 'hparams_name', 'hyper_parameters'])\n",
      "checkpoint state_dict keys: odict_keys(['model.convs.0.att_src', 'model.convs.0.att_dst', 'model.convs.0.bias', 'model.convs.0.lin.weight', 'model.convs.1.att_src', 'model.convs.1.att_dst', 'model.convs.1.bias', 'model.convs.1.lin.weight', 'model.pools.0.weight', 'model.pools.0.bias', 'model.pools.1.weight', 'model.pools.1.bias', 'model.layer_norm.weight', 'model.layer_norm.bias', 'model.encoder.0.0.weight', 'model.encoder.0.0.bias', 'model.encoder.1.0.weight', 'model.encoder.1.0.bias', 'model.encoder.2.0.weight', 'model.encoder.2.0.bias', 'model.encoder.3.0.weight', 'model.encoder.3.0.bias', 'model.encoder.4.weight', 'model.encoder.4.bias'])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import train as proteo_train\n",
    "\n",
    "# Define a function to load the checkpoint and calculate MSE\n",
    "def load_checkpoint_and_calculate_mse(relative_checkpoint_path, levels_up=5):\n",
    "    # Get the current script directory\n",
    "    current_directory = os.getcwd()\n",
    "    \n",
    "    # Navigate up the specified number of levels\n",
    "    for _ in range(levels_up):\n",
    "        current_directory = os.path.dirname(current_directory)\n",
    "    \n",
    "    # Construct the full path to the checkpoint\n",
    "    checkpoint_path = os.path.join(current_directory, relative_checkpoint_path)\n",
    "    print(f\"Loading checkpoint from: {checkpoint_path}\")\n",
    "\n",
    "    # Check if the file exists to avoid errors\n",
    "    if not os.path.isfile(checkpoint_path):\n",
    "        raise FileNotFoundError(f\"Checkpoint file not found: {checkpoint_path}\")\n",
    "\n",
    "    # Load the checkpoint\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    print(\"Checkpoint keys:\", checkpoint.keys())\n",
    "    print(\"checkpoint state_dict keys:\", checkpoint['state_dict'].keys())\n",
    "\n",
    "    module = proteo_train.Proteo.load_from_checkpoint(checkpoint_path)\n",
    "\n",
    "    # Access the attributes\n",
    "    # best_val_pred = module.best_val_pred\n",
    "    # print(\"best_val_pred:\", best_val_pred)\n",
    "    # # print(\"min_val loss:\", module.val_loss)\n",
    "    # best_val_target = module.best_val_target\n",
    "    # best_train_pred = module.best_train_pred\n",
    "    # best_train_target = module.best_train_target\n",
    "\n",
    "    # # Calculate MSE for validation and training\n",
    "    # mse_val = F.mse_loss(best_val_pred, best_val_target).item()\n",
    "    # mse_train = F.mse_loss(best_train_pred, best_train_target).item()\n",
    "\n",
    "    return module, checkpoint\n",
    "\n",
    "# Example usage\n",
    "relative_checkpoint_path = '/scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-07-31_16-47-02/model=gat-v4,seed=19543_0_act=relu,adj_thresh=0.1000,batch_size=8,dropout=0,l1_lambda=0.0000,lr=0.1000,lr_scheduler=LambdaLR,modal_2024-07-31_16-47-02/checkpoint_000001/checkpoint.cpkt'\n",
    "module, checkpoint = load_checkpoint_and_calculate_mse(relative_checkpoint_path)\n",
    "# print(f\"MSE Loss for validation set: {mse_val}\")\n",
    "# print(f\"MSE Loss for training set: {mse_train}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'training': True,\n",
       " '_parameters': OrderedDict(),\n",
       " '_buffers': OrderedDict(),\n",
       " '_non_persistent_buffers_set': set(),\n",
       " '_backward_pre_hooks': OrderedDict(),\n",
       " '_backward_hooks': OrderedDict(),\n",
       " '_is_full_backward_hook': None,\n",
       " '_forward_hooks': OrderedDict(),\n",
       " '_forward_hooks_with_kwargs': OrderedDict(),\n",
       " '_forward_hooks_always_called': OrderedDict(),\n",
       " '_forward_pre_hooks': OrderedDict(),\n",
       " '_forward_pre_hooks_with_kwargs': OrderedDict(),\n",
       " '_state_dict_hooks': OrderedDict(),\n",
       " '_state_dict_pre_hooks': OrderedDict(),\n",
       " '_load_state_dict_pre_hooks': OrderedDict(),\n",
       " '_load_state_dict_post_hooks': OrderedDict(),\n",
       " '_modules': OrderedDict([('model',\n",
       "               GATv4(\n",
       "                 (convs): ModuleList(\n",
       "                   (0): CustomGATConv(1, 8, heads=2)\n",
       "                   (1): CustomGATConv(16, 16, heads=3)\n",
       "                 )\n",
       "                 (pools): ModuleList(\n",
       "                   (0): Linear(in_features=16, out_features=1, bias=True)\n",
       "                   (1): Linear(in_features=48, out_features=1, bias=True)\n",
       "                 )\n",
       "                 (layer_norm): LayerNorm((30,), eps=1e-05, elementwise_affine=True)\n",
       "                 (encoder): Sequential(\n",
       "                   (0): Sequential(\n",
       "                     (0): Linear(in_features=90, out_features=64, bias=True)\n",
       "                     (1): ReLU()\n",
       "                     (2): AlphaDropout(p=0.1, inplace=True)\n",
       "                   )\n",
       "                   (1): Sequential(\n",
       "                     (0): Linear(in_features=64, out_features=128, bias=True)\n",
       "                     (1): ReLU()\n",
       "                     (2): AlphaDropout(p=0.1, inplace=True)\n",
       "                   )\n",
       "                   (2): Sequential(\n",
       "                     (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "                     (1): ReLU()\n",
       "                     (2): AlphaDropout(p=0.1, inplace=True)\n",
       "                   )\n",
       "                   (3): Sequential(\n",
       "                     (0): Linear(in_features=128, out_features=32, bias=True)\n",
       "                     (1): ReLU()\n",
       "                     (2): AlphaDropout(p=0.1, inplace=True)\n",
       "                   )\n",
       "                   (4): Linear(in_features=32, out_features=1, bias=True)\n",
       "                 )\n",
       "               ))]),\n",
       " 'prepare_data_per_node': True,\n",
       " 'allow_zero_length_dataloader_with_multiple_devices': False,\n",
       " '_log_hyperparams': True,\n",
       " '_dtype': torch.float32,\n",
       " '_device': device(type='cuda', index=0),\n",
       " '_trainer': None,\n",
       " '_example_input_array': None,\n",
       " '_automatic_optimization': True,\n",
       " '_strict_loading': None,\n",
       " '_current_fx_name': None,\n",
       " '_param_requires_grad_state': {},\n",
       " '_metric_attributes': None,\n",
       " '_compiler_ctx': None,\n",
       " '_fabric': None,\n",
       " '_fabric_optimizers': [],\n",
       " '_device_mesh': None,\n",
       " '_hparams_name': 'kwargs',\n",
       " '_hparams': \"avg_node_degree\":   0.9\n",
       " \"config\":            gat_v4_weight_initializer=['uniform'] gat_hidden_channels=[8, 32, 128, 256] device=[0] root_dir='/home/lcornelis/code/proteo' checkpoint_every_n_epochs_train=1 l1_lambda=1e-05 pin_memory=True sex=['M'] wgcna_mergeCutHeight=0.25 y_val='nfl' log_every_n_steps=10 num_samples=1 gat_v4_heads=[[2, 3]] cpu_per_worker=16 nodes_count=1 adj_thresh=0.1 gat_heads=[1, 2, 4, 8] optimizer='Adam' checkpoint_dir='/scratch/lcornelis/outputs/checkpoints' num_to_keep=3 seed=19543 modality_choices=['plasma'] l1_lambda_min=1e-05 gat-v4={'hidden_channels': [8, 16], 'heads': [2, 3], 'use_layer_norm': True, 'which_layer': ['layer1', 'layer2', 'layer3'], 'fc_dim': [64, 128, 128, 32], 'fc_dropout': 0.1, 'fc_act': 'relu', 'weight_initializer': 'uniform', 'num_layers': None} lr=0.10000000000000005 wgcna_minModuleSize=10 gat_num_layers=[2, 4, 6, 12] model='gat-v4' dataset_name='ftd' y_val_choices=['nfl'] gat_v4_hidden_channels=[[8, 16]] accumulate_grad_batches=1 gat={'num_layers': 2, 'hidden_channels': 256, 'heads': 4, 'v2': True} trainer_accelerator='gpu' precision='32-true' gat_v4_fc_act=['relu'] batch_size_choices=[8] lr_scheduler='LambdaLR' num_workers=16 epochs=30 data_dir='/home/data/data_louisa' wandb_api_key_path='wandb_api_key.txt' dropout_choices=[0] dropout=0 gat_v4_fc_dim=[[64, 128, 128, 32]] ray_tmp_dir='/scratch/lcornelis/tmp' error_protein_file_name='bimodal_aptamers_for_removal.xlsx' act='relu' gcn_hidden_channels=[8, 32, 128] lr_max=0.1 gpu_per_worker=1 wandb_tmp_dir='/tmp' weight_decay=0 reduction_factor=8 lr_scheduler_choices=['LambdaLR'] model_grid_search=['gat-v4'] gcn_num_layers=[2, 3, 4] wandb_offline=False act_choices=['relu'] project='proteo' num_nodes=30 grace_period=30 adj_thresh_choices=[0.1] gcn={'num_layers': 3, 'hidden_channels': 32} lr_min=0.1 mutation_choices=[['GRN']] raw_file_name='ALLFTD_dataset_for_nina_louisa_071124.csv' sex_choices=[['M']] num_nodes_choices=[30] mutation=['GRN'] ray_results_dir='/scratch/lcornelis/outputs/ray_results' l1_lambda_max=1e-05 batch_size=8 gat_v4_fc_dropout=[0.1] use_progress_bar=True modality='plasma' sync_batchnorm=False output_dir='/scratch/lcornelis/outputs'\n",
       " \"focal_loss_weight\": [1.0]\n",
       " \"in_channels\":       1\n",
       " \"out_channels\":      1\n",
       " \"pos_weight\":        1.0,\n",
       " '_hparams_initial': \"avg_node_degree\":   0.9\n",
       " \"config\":            gat_v4_weight_initializer=['uniform'] gat_hidden_channels=[8, 32, 128, 256] device=[0] root_dir='/home/lcornelis/code/proteo' checkpoint_every_n_epochs_train=1 l1_lambda=1e-05 pin_memory=True sex=['M'] wgcna_mergeCutHeight=0.25 y_val='nfl' log_every_n_steps=10 num_samples=1 gat_v4_heads=[[2, 3]] cpu_per_worker=16 nodes_count=1 adj_thresh=0.1 gat_heads=[1, 2, 4, 8] optimizer='Adam' checkpoint_dir='/scratch/lcornelis/outputs/checkpoints' num_to_keep=3 seed=19543 modality_choices=['plasma'] l1_lambda_min=1e-05 gat-v4={'hidden_channels': [8, 16], 'heads': [2, 3], 'use_layer_norm': True, 'which_layer': ['layer1', 'layer2', 'layer3'], 'fc_dim': [64, 128, 128, 32], 'fc_dropout': 0.1, 'fc_act': 'relu', 'weight_initializer': 'uniform', 'num_layers': None} lr=0.10000000000000005 wgcna_minModuleSize=10 gat_num_layers=[2, 4, 6, 12] model='gat-v4' dataset_name='ftd' y_val_choices=['nfl'] gat_v4_hidden_channels=[[8, 16]] accumulate_grad_batches=1 gat={'num_layers': 2, 'hidden_channels': 256, 'heads': 4, 'v2': True} trainer_accelerator='gpu' precision='32-true' gat_v4_fc_act=['relu'] batch_size_choices=[8] lr_scheduler='LambdaLR' num_workers=16 epochs=30 data_dir='/home/data/data_louisa' wandb_api_key_path='wandb_api_key.txt' dropout_choices=[0] dropout=0 gat_v4_fc_dim=[[64, 128, 128, 32]] ray_tmp_dir='/scratch/lcornelis/tmp' error_protein_file_name='bimodal_aptamers_for_removal.xlsx' act='relu' gcn_hidden_channels=[8, 32, 128] lr_max=0.1 gpu_per_worker=1 wandb_tmp_dir='/tmp' weight_decay=0 reduction_factor=8 lr_scheduler_choices=['LambdaLR'] model_grid_search=['gat-v4'] gcn_num_layers=[2, 3, 4] wandb_offline=False act_choices=['relu'] project='proteo' num_nodes=30 grace_period=30 adj_thresh_choices=[0.1] gcn={'num_layers': 3, 'hidden_channels': 32} lr_min=0.1 mutation_choices=[['GRN']] raw_file_name='ALLFTD_dataset_for_nina_louisa_071124.csv' sex_choices=[['M']] num_nodes_choices=[30] mutation=['GRN'] ray_results_dir='/scratch/lcornelis/outputs/ray_results' l1_lambda_max=1e-05 batch_size=8 gat_v4_fc_dropout=[0.1] use_progress_bar=True modality='plasma' sync_batchnorm=False output_dir='/scratch/lcornelis/outputs'\n",
       " \"focal_loss_weight\": [1.0]\n",
       " \"in_channels\":       1\n",
       " \"out_channels\":      1\n",
       " \"pos_weight\":        1.0,\n",
       " 'config': Config(gat_v4_weight_initializer=['uniform'], gat_hidden_channels=[8, 32, 128, 256], device=[0], root_dir='/home/lcornelis/code/proteo', checkpoint_every_n_epochs_train=1, l1_lambda=1e-05, pin_memory=True, sex=['M'], wgcna_mergeCutHeight=0.25, y_val='nfl', log_every_n_steps=10, num_samples=1, gat_v4_heads=[[2, 3]], cpu_per_worker=16, nodes_count=1, adj_thresh=0.1, gat_heads=[1, 2, 4, 8], optimizer='Adam', checkpoint_dir='/scratch/lcornelis/outputs/checkpoints', num_to_keep=3, seed=19543, modality_choices=['plasma'], l1_lambda_min=1e-05, gat-v4={'hidden_channels': [8, 16], 'heads': [2, 3], 'use_layer_norm': True, 'which_layer': ['layer1', 'layer2', 'layer3'], 'fc_dim': [64, 128, 128, 32], 'fc_dropout': 0.1, 'fc_act': 'relu', 'weight_initializer': 'uniform', 'num_layers': None}, lr=0.10000000000000005, wgcna_minModuleSize=10, gat_num_layers=[2, 4, 6, 12], model='gat-v4', dataset_name='ftd', y_val_choices=['nfl'], gat_v4_hidden_channels=[[8, 16]], accumulate_grad_batches=1, gat={'num_layers': 2, 'hidden_channels': 256, 'heads': 4, 'v2': True}, trainer_accelerator='gpu', precision='32-true', gat_v4_fc_act=['relu'], batch_size_choices=[8], lr_scheduler='LambdaLR', num_workers=16, epochs=30, data_dir='/home/data/data_louisa', wandb_api_key_path='wandb_api_key.txt', dropout_choices=[0], dropout=0, gat_v4_fc_dim=[[64, 128, 128, 32]], ray_tmp_dir='/scratch/lcornelis/tmp', error_protein_file_name='bimodal_aptamers_for_removal.xlsx', act='relu', gcn_hidden_channels=[8, 32, 128], lr_max=0.1, gpu_per_worker=1, wandb_tmp_dir='/tmp', weight_decay=0, reduction_factor=8, lr_scheduler_choices=['LambdaLR'], model_grid_search=['gat-v4'], gcn_num_layers=[2, 3, 4], wandb_offline=False, act_choices=['relu'], project='proteo', num_nodes=30, grace_period=30, adj_thresh_choices=[0.1], gcn={'num_layers': 3, 'hidden_channels': 32}, lr_min=0.1, mutation_choices=[['GRN']], raw_file_name='ALLFTD_dataset_for_nina_louisa_071124.csv', sex_choices=[['M']], num_nodes_choices=[30], mutation=['GRN'], ray_results_dir='/scratch/lcornelis/outputs/ray_results', l1_lambda_max=1e-05, batch_size=8, gat_v4_fc_dropout=[0.1], use_progress_bar=True, modality='plasma', sync_batchnorm=False, output_dir='/scratch/lcornelis/outputs'),\n",
       " 'config_model': Config(fc_dropout=0.1, fc_dim=[64, 128, 128, 32], weight_initializer='uniform', which_layer=['layer1', 'layer2', 'layer3'], fc_act='relu', hidden_channels=[8, 16], num_layers=None, use_layer_norm=True, heads=[2, 3]),\n",
       " 'avg_node_degree': 0.9,\n",
       " 'train_preds': [],\n",
       " 'val_preds': [],\n",
       " 'train_targets': [],\n",
       " 'val_targets': [],\n",
       " 'x0': [],\n",
       " 'x1': [],\n",
       " 'x2': [],\n",
       " 'multiscale': [],\n",
       " 'pos_weight': 1.0,\n",
       " 'focal_loss_weight': [1.0],\n",
       " 'min_val_loss': 1000,\n",
       " 'min_train_loss': 1000,\n",
       " 'best_val_pred': [],\n",
       " 'best_val_target': [],\n",
       " 'best_train_pred': [],\n",
       " 'best_train_target': [],\n",
       " 'best_val_epoch': 0,\n",
       " 'best_train_epoch': 0}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epoch': 1,\n",
       " 'global_step': 8,\n",
       " 'pytorch-lightning_version': '2.3.3',\n",
       " 'state_dict': OrderedDict([('model.convs.0.att_src',\n",
       "               tensor([[[ 0.6818,  0.0561,  0.6685,  0.3070,  0.7125,  0.4150,  0.2690,\n",
       "                         -0.2861],\n",
       "                        [-0.2914,  0.9814, -0.0518, -0.1408,  0.3510, -0.2540,  0.5184,\n",
       "                         -0.2630]]], device='cuda:0')),\n",
       "              ('model.convs.0.att_dst',\n",
       "               tensor([[[ 0.8912, -0.2167,  0.5399, -0.1660,  0.3122, -0.2951,  0.1650,\n",
       "                          0.5460],\n",
       "                        [ 1.0074,  0.5066,  0.3665,  1.0729,  0.2071,  1.0349,  0.2690,\n",
       "                          1.0922]]], device='cuda:0')),\n",
       "              ('model.convs.0.bias',\n",
       "               tensor([-0.0016,  0.2387,  0.2148,  0.2318,  0.1968,  0.2223,  0.2042,  0.2067,\n",
       "                        0.2075, -0.0101,  0.2075,  0.2105,  0.2058,  0.2272,  0.2135,  0.2171],\n",
       "                      device='cuda:0')),\n",
       "              ('model.convs.0.lin.weight',\n",
       "               tensor([[-0.2747],\n",
       "                       [ 0.7066],\n",
       "                       [ 0.7997],\n",
       "                       [-0.1340],\n",
       "                       [ 0.5177],\n",
       "                       [-0.1635],\n",
       "                       [ 0.2512],\n",
       "                       [ 0.1101],\n",
       "                       [ 1.2385],\n",
       "                       [-0.2567],\n",
       "                       [-0.2180],\n",
       "                       [ 0.5406],\n",
       "                       [-0.2236],\n",
       "                       [ 0.4800],\n",
       "                       [ 0.1008],\n",
       "                       [ 0.8289]], device='cuda:0')),\n",
       "              ('model.convs.1.att_src',\n",
       "               tensor([[[1.0275, 0.5577, 0.5425, 0.7948, 0.3066, 0.3760, 0.8046, 0.2538,\n",
       "                         0.7116, 1.1075, 0.3752, 0.2974, 0.6756, 0.1849, 1.0669, 1.1004],\n",
       "                        [0.3614, 0.8969, 0.5968, 0.6395, 0.3789, 0.6781, 0.8925, 0.7558,\n",
       "                         0.2489, 0.4834, 0.8252, 0.8750, 0.7255, 0.1840, 0.8078, 1.0982],\n",
       "                        [1.0532, 0.8308, 1.0668, 0.6789, 0.2108, 0.2277, 0.8233, 0.3911,\n",
       "                         0.7611, 0.1549, 0.2636, 0.3881, 0.8713, 0.6433, 0.5321, 0.9736]]],\n",
       "                      device='cuda:0')),\n",
       "              ('model.convs.1.att_dst',\n",
       "               tensor([[[0.8691, 0.6961, 1.0142, 1.0584, 0.6388, 0.6385, 0.7971, 0.9807,\n",
       "                         0.3522, 0.1389, 0.4226, 1.0692, 0.9349, 0.4062, 0.7369, 0.9201],\n",
       "                        [0.4954, 0.7028, 0.3788, 0.6439, 1.0613, 0.7012, 0.7688, 0.1747,\n",
       "                         1.1378, 0.5853, 0.8032, 0.5995, 0.9331, 0.8822, 0.7703, 0.5779],\n",
       "                        [0.2614, 0.9890, 0.4682, 0.7781, 0.2033, 0.6818, 0.6701, 0.5199,\n",
       "                         0.8749, 0.4317, 0.4214, 1.0276, 0.8983, 0.7483, 0.8996, 0.6155]]],\n",
       "                      device='cuda:0')),\n",
       "              ('model.convs.1.bias',\n",
       "               tensor([ 0.0259,  0.0188,  0.0345, -0.0023, -0.0155, -0.0085, -0.0145,  0.0348,\n",
       "                        0.0304,  0.0262,  0.0225,  0.0197,  0.0355,  0.0046, -0.0231, -0.0146,\n",
       "                       -0.0085,  0.0423,  0.0451, -0.0270, -0.0114,  0.0390,  0.0294,  0.0533,\n",
       "                        0.0439,  0.0459, -0.0094, -0.0195,  0.0108, -0.0066,  0.0281,  0.0175,\n",
       "                        0.0045, -0.0258,  0.0419,  0.0190,  0.0435, -0.0049, -0.0022,  0.0310,\n",
       "                       -0.0203,  0.0246,  0.0303,  0.0305,  0.0606,  0.0531, -0.0049,  0.0532],\n",
       "                      device='cuda:0')),\n",
       "              ('model.convs.1.lin.weight',\n",
       "               tensor([[-6.1789e-02,  3.2537e-01,  3.1245e-01, -1.4879e-01,  6.2613e-01,\n",
       "                        -7.6595e-02,  3.7200e-01,  2.8607e-01,  1.0946e+00,  5.1263e-02,\n",
       "                         3.8707e-01,  7.5295e-01,  8.1540e-01,  1.0228e+00,  3.1976e-01,\n",
       "                         7.2641e-01],\n",
       "                       [ 8.0462e-02,  7.4923e-02,  3.9717e-01,  5.7739e-01,  6.6411e-01,\n",
       "                         1.8960e-01, -1.6194e-01,  3.4741e-01,  3.5658e-01,  3.2658e-01,\n",
       "                         1.7487e-01,  6.5015e-01,  4.8669e-01,  8.8121e-01,  2.2233e-01,\n",
       "                         7.9592e-01],\n",
       "                       [-5.4787e-02, -1.7452e-01, -4.0066e-03,  3.6991e-01, -1.3842e-01,\n",
       "                         6.6489e-01,  5.1400e-01,  2.2546e-01,  6.6229e-01, -1.2439e-01,\n",
       "                         1.9736e-01,  8.0312e-01,  1.5757e-01,  2.1747e-01,  7.7982e-01,\n",
       "                         1.6635e-01],\n",
       "                       [ 3.3565e-01, -7.6811e-02,  1.8208e-01,  9.0041e-02, -2.8528e-01,\n",
       "                         3.6721e-01, -3.0266e-02,  3.4870e-01,  1.8523e-01,  3.9882e-02,\n",
       "                         1.1283e+00,  9.7768e-01,  8.1971e-01,  9.8342e-01,  1.0393e+00,\n",
       "                         8.9602e-01],\n",
       "                       [-8.3597e-02, -5.6796e-03,  5.1126e-01, -6.8543e-02,  4.9811e-01,\n",
       "                         2.4712e-02, -1.6763e-01, -6.6246e-02,  1.1119e+00, -7.7936e-02,\n",
       "                         8.4879e-01,  8.3962e-01,  5.3172e-01,  8.0456e-01,  8.2557e-01,\n",
       "                         3.3084e-01],\n",
       "                       [ 3.2889e-01,  2.4728e-01,  2.3987e-01,  4.8654e-01,  6.0219e-01,\n",
       "                         4.9324e-01, -5.0379e-02,  1.2001e-01,  2.2488e-01, -9.1733e-02,\n",
       "                         5.1895e-01,  8.6833e-01,  3.9100e-01,  6.1802e-01,  2.5641e-01,\n",
       "                         1.0594e+00],\n",
       "                       [-2.8237e-02,  8.2666e-01,  6.6929e-01,  4.8833e-01,  3.2791e-01,\n",
       "                         9.4391e-02,  5.1456e-02,  2.6413e-01,  6.3778e-01,  7.5601e-02,\n",
       "                         4.3326e-01,  9.9159e-01,  1.1278e+00,  9.0982e-01,  4.6125e-01,\n",
       "                         3.0125e-01],\n",
       "                       [-7.9173e-02,  4.4135e-02,  1.6634e-01, -3.0145e-01,  4.3109e-01,\n",
       "                         3.5091e-01, -2.0437e-01, -2.1063e-01,  5.7857e-01,  3.5037e-01,\n",
       "                         7.3467e-01,  5.6129e-01,  5.4390e-01,  9.0472e-01,  1.0916e+00,\n",
       "                         4.6168e-01],\n",
       "                       [ 1.8318e-01,  5.8674e-01, -4.3542e-03, -1.8643e-01,  3.9555e-01,\n",
       "                         1.9433e-01, -9.3008e-02,  4.6639e-02,  1.0120e+00,  2.7417e-01,\n",
       "                         9.4436e-01,  1.0217e+00,  8.3782e-01,  1.1464e+00,  1.1411e+00,\n",
       "                         5.0122e-01],\n",
       "                       [ 2.6993e-01,  2.3349e-01, -1.3734e-01,  6.1490e-01,  2.5105e-01,\n",
       "                         1.8006e-01,  6.1518e-01,  3.6357e-01,  1.1062e+00, -1.1610e-01,\n",
       "                         1.0098e+00,  5.4218e-01,  9.2764e-01,  3.5500e-01,  3.9014e-01,\n",
       "                         4.3998e-01],\n",
       "                       [-5.7937e-02,  6.2023e-02,  5.5346e-01, -1.4472e-01,  1.5873e-01,\n",
       "                        -2.1920e-01, -2.8521e-01,  4.3509e-01,  1.6317e-01, -5.0245e-02,\n",
       "                         8.4219e-01,  4.6536e-01,  1.0751e+00,  7.2416e-01,  1.5604e-01,\n",
       "                         6.8802e-01],\n",
       "                       [-5.3703e-02,  2.0671e-01, -9.8078e-02, -2.3637e-02,  1.3031e-01,\n",
       "                         1.8595e-01,  4.9995e-01,  6.7261e-02,  2.7332e-01, -2.6724e-02,\n",
       "                         5.4704e-01,  6.8578e-01,  3.8651e-01,  2.3658e-01,  2.2531e-01,\n",
       "                         5.4300e-01],\n",
       "                       [-1.2625e-01,  8.3075e-01,  4.2194e-02, -1.8660e-01, -1.5091e-01,\n",
       "                         8.3820e-03, -1.9707e-01, -5.3533e-02,  8.7044e-01, -1.2201e-01,\n",
       "                         9.8095e-01,  6.6980e-01,  5.5789e-01,  5.0437e-01,  1.6476e-01,\n",
       "                         1.0666e+00],\n",
       "                       [ 3.9707e-02,  6.3395e-01,  2.7295e-02, -9.3213e-02,  7.9628e-01,\n",
       "                         2.8047e-01, -5.1423e-02,  5.4591e-01,  2.9945e-01,  1.4810e-01,\n",
       "                         3.5107e-01,  4.5017e-01,  6.6818e-01,  2.7357e-01,  4.5058e-01,\n",
       "                         8.9165e-01],\n",
       "                       [ 4.7607e-02,  7.3774e-01,  4.4192e-01,  5.7419e-01,  4.8977e-01,\n",
       "                        -9.4977e-02, -2.9531e-01,  2.7908e-02,  2.4138e-01,  2.5806e-01,\n",
       "                         1.1048e+00,  2.6158e-01,  4.7928e-01,  3.5841e-01,  1.0207e+00,\n",
       "                         1.9289e-01],\n",
       "                       [-1.2323e-01,  2.3414e-01,  1.1138e-02,  5.1637e-01,  7.7759e-02,\n",
       "                        -2.2337e-01,  2.8335e-03,  1.3823e-01,  1.0611e+00, -4.2548e-02,\n",
       "                         1.9616e-01,  3.1252e-01,  6.8873e-01,  2.0445e-01,  5.9222e-01,\n",
       "                         1.1504e+00],\n",
       "                       [-8.2269e-03,  1.0148e-01,  1.6072e-01,  5.8242e-01, -1.2309e-01,\n",
       "                        -1.6382e-01,  5.6530e-01,  2.0329e-01,  2.7407e-01, -5.0663e-03,\n",
       "                         1.1073e+00,  6.0172e-01,  6.4172e-01,  2.3175e-01,  1.0551e+00,\n",
       "                         3.1647e-01],\n",
       "                       [ 9.2765e-02,  2.4335e-01,  9.9624e-02,  2.0190e-01,  2.9261e-01,\n",
       "                        -2.9909e-01,  3.0571e-01,  3.0523e-01,  2.7487e-01, -9.0866e-02,\n",
       "                         2.7141e-01,  1.0718e+00,  5.0720e-01,  8.7260e-01,  4.8652e-01,\n",
       "                         1.0429e+00],\n",
       "                       [-1.0747e-01,  3.3175e-01,  1.6985e-01,  1.0153e-01, -1.0712e-01,\n",
       "                         2.3820e-01,  3.7530e-03, -2.7521e-01,  7.0924e-01, -1.1747e-01,\n",
       "                         1.5831e-01,  9.0371e-01,  1.1342e+00,  1.1464e+00,  8.3291e-01,\n",
       "                         8.5850e-01],\n",
       "                       [-8.3544e-02,  4.1696e-01,  5.5923e-01, -2.8244e-01,  5.7896e-01,\n",
       "                         4.5857e-01, -2.0962e-01,  3.9820e-01,  8.4677e-01, -9.7585e-02,\n",
       "                         1.0654e+00,  1.6275e-01,  8.0893e-01,  9.1433e-01,  6.2007e-01,\n",
       "                         3.0630e-01],\n",
       "                       [-7.0392e-02,  4.9858e-01,  7.1534e-02,  5.7008e-01,  2.3622e-01,\n",
       "                         2.2913e-01,  6.9814e-02, -1.5193e-01,  2.9367e-01, -4.2914e-02,\n",
       "                         1.8581e-01,  3.2357e-01,  6.9095e-01,  1.0165e+00,  8.9382e-01,\n",
       "                         6.6348e-01],\n",
       "                       [-9.1428e-02, -3.0039e-03, -1.9863e-01, -2.8992e-01, -1.9991e-01,\n",
       "                        -2.8740e-02,  5.3236e-01,  4.0624e-01,  5.6427e-01,  4.6337e-02,\n",
       "                         1.0052e+00,  2.7561e-01,  1.0864e+00,  9.9614e-01,  7.8114e-01,\n",
       "                         2.3480e-01],\n",
       "                       [ 1.5823e-02,  1.4643e-01,  7.7213e-01,  5.2885e-01,  1.5802e-01,\n",
       "                         4.2133e-01, -2.8676e-02, -1.0677e-01,  1.9836e-01, -6.3353e-02,\n",
       "                         1.0802e+00,  8.1558e-01,  6.4320e-01,  6.6718e-01,  1.0471e+00,\n",
       "                         4.9031e-01],\n",
       "                       [ 1.0024e-02,  1.8798e-01,  6.4722e-01,  4.6741e-01, -1.4054e-01,\n",
       "                         7.0739e-02,  2.4527e-01,  3.1747e-03,  2.1365e-01,  1.0402e-01,\n",
       "                         1.7304e-01,  9.9013e-01,  9.3846e-01,  5.3760e-01,  5.8874e-01,\n",
       "                         5.1971e-01],\n",
       "                       [ 2.2454e-01,  5.0284e-01, -1.4982e-01,  1.7405e-01, -7.6939e-02,\n",
       "                        -2.0570e-01,  4.2681e-01, -3.1569e-02,  4.6229e-01, -1.0122e-01,\n",
       "                         5.9872e-01,  7.5500e-01,  4.1563e-01,  7.2763e-01,  9.2856e-01,\n",
       "                         7.4097e-01],\n",
       "                       [-8.7878e-02, -1.2619e-01,  2.7934e-01,  8.2400e-02,  5.7327e-01,\n",
       "                         1.6471e-01,  3.7383e-01,  6.2203e-01,  3.6847e-01,  2.6509e-01,\n",
       "                         1.0014e+00,  6.6684e-01,  8.6832e-01,  6.5191e-01,  2.1117e-01,\n",
       "                         2.3197e-01],\n",
       "                       [ 2.0167e-01,  8.9660e-01,  3.5287e-01,  3.5829e-01,  1.0833e+00,\n",
       "                         9.7756e-01,  4.1247e-01,  4.7035e-01,  2.0534e-01,  3.0840e-02,\n",
       "                        -2.9043e-01,  2.4465e-01, -3.0218e-01,  2.4498e-01,  3.7365e-01,\n",
       "                        -2.0722e-01],\n",
       "                       [ 3.8382e-01, -3.1117e-01,  1.0137e-01, -1.4501e-01, -2.0265e-01,\n",
       "                         6.0093e-01,  2.5217e-01, -9.0923e-02,  8.1218e-01,  2.8764e-01,\n",
       "                         5.7233e-01,  7.9353e-01,  9.7602e-01,  9.4282e-01,  5.4244e-01,\n",
       "                         7.2327e-01],\n",
       "                       [ 1.0640e-01,  6.4738e-01,  5.9631e-02,  6.4713e-01, -6.6647e-02,\n",
       "                         4.4682e-01, -9.1903e-02,  1.8783e-01,  1.0726e+00, -5.3999e-02,\n",
       "                         7.8765e-01,  1.1102e+00,  3.7974e-01,  8.7364e-01,  3.2741e-01,\n",
       "                         9.1035e-01],\n",
       "                       [ 3.0623e-01,  6.3933e-01, -5.3601e-02,  3.9040e-01, -1.5687e-01,\n",
       "                        -7.0999e-03, -2.2357e-01,  4.0273e-01,  7.3623e-01,  2.9932e-01,\n",
       "                         6.8632e-01,  4.2192e-01,  6.3763e-01,  7.4047e-01,  2.4466e-01,\n",
       "                         1.1424e+00],\n",
       "                       [ 3.1066e-01,  4.9755e-01,  6.0222e-01,  3.4521e-01,  1.6600e-01,\n",
       "                         2.8173e-01,  3.9538e-01,  4.7118e-01,  5.3607e-01, -9.0838e-02,\n",
       "                         2.6352e-01,  2.1935e-01,  9.3491e-01,  7.3639e-01,  2.5958e-01,\n",
       "                         4.4757e-01],\n",
       "                       [ 5.5597e-02,  1.3717e-01,  3.1788e-01,  8.5282e-02, -1.4423e-01,\n",
       "                         9.2605e-02, -2.7042e-01,  1.5581e-02,  9.3803e-01, -7.2307e-02,\n",
       "                         1.0651e+00,  5.2684e-01,  3.2238e-01,  2.3622e-01,  2.6320e-01,\n",
       "                         1.8704e-01],\n",
       "                       [ 2.0437e-02,  8.2966e-01,  5.2065e-01,  6.4797e-01,  7.5894e-01,\n",
       "                        -2.9197e-01,  6.2863e-01, -7.8341e-02,  2.6526e-01,  9.4292e-02,\n",
       "                         9.7485e-01,  1.5727e-01,  5.4041e-01,  5.5766e-01,  9.9932e-01,\n",
       "                         6.1418e-01],\n",
       "                       [ 4.2404e-02,  4.6133e-01,  7.7823e-01, -2.4805e-01,  7.5333e-01,\n",
       "                         3.6918e-02,  3.4113e-01,  6.6660e-01,  6.4147e-01,  2.9623e-01,\n",
       "                         5.2513e-01,  3.4410e-01,  6.7323e-01,  9.2891e-01,  8.7367e-01,\n",
       "                         7.9857e-01],\n",
       "                       [-6.4963e-02, -5.1305e-02,  8.7132e-02,  1.4932e-01,  7.4525e-01,\n",
       "                         1.6174e-01, -7.5785e-03,  1.5364e-01,  9.1941e-01, -5.0252e-02,\n",
       "                         8.5261e-01,  9.7274e-01,  1.0399e+00,  4.8435e-01,  5.0499e-01,\n",
       "                         1.0426e+00],\n",
       "                       [-2.3129e-02, -2.6016e-02,  3.4675e-01,  4.5557e-01,  5.5676e-01,\n",
       "                        -2.5736e-01,  4.9284e-01,  1.5886e-01,  5.5016e-01,  5.7016e-02,\n",
       "                         8.0660e-01,  7.4709e-01,  7.7972e-01,  7.7132e-01,  9.0483e-01,\n",
       "                         8.1184e-01],\n",
       "                       [-1.5376e-02,  4.1715e-01, -6.0401e-02,  5.7464e-01,  1.7197e-01,\n",
       "                         1.9836e-01,  6.3797e-01,  5.9748e-01,  8.1034e-01,  3.9749e-01,\n",
       "                         9.8818e-01,  6.5461e-01,  4.6975e-01,  6.2472e-01,  2.4805e-01,\n",
       "                         1.6921e-01],\n",
       "                       [ 7.1472e-03,  2.5287e-02,  7.3029e-01,  5.2384e-02,  5.7289e-01,\n",
       "                         1.6944e-01, -1.0625e-01,  2.5976e-01,  8.7490e-01,  1.3609e-01,\n",
       "                         4.0510e-01,  6.9725e-01,  4.9180e-01,  7.2291e-01,  1.7993e-01,\n",
       "                         9.1813e-01],\n",
       "                       [ 4.7645e-02,  2.6112e-02,  8.0982e-01,  3.7111e-01,  4.0908e-01,\n",
       "                         4.6897e-01,  3.7436e-01,  1.5881e-01,  3.4708e-01, -9.3791e-02,\n",
       "                         2.9486e-01,  2.3979e-01,  2.6902e-01,  8.4037e-01,  5.1409e-01,\n",
       "                         3.7723e-01],\n",
       "                       [ 3.1859e-01,  4.4834e-03,  4.1992e-01, -7.5275e-02,  8.1353e-01,\n",
       "                         1.0510e-01,  5.1014e-01,  7.2824e-02,  7.2208e-01,  1.9530e-01,\n",
       "                         4.8768e-01,  1.0886e+00,  1.0630e+00,  1.0944e+00,  1.0871e+00,\n",
       "                         2.5494e-01],\n",
       "                       [-6.4572e-02, -1.1057e-01,  8.5611e-02, -3.3536e-02,  1.7557e-02,\n",
       "                         4.9556e-01, -9.4643e-02,  2.3534e-01,  6.0250e-01, -1.0670e-01,\n",
       "                         5.4327e-01,  9.9727e-01,  1.0021e+00,  7.4503e-01,  7.9601e-01,\n",
       "                         9.4132e-01],\n",
       "                       [ 9.7156e-02, -1.5339e-01, -8.2892e-02,  1.8969e-01,  1.1208e-01,\n",
       "                        -2.3451e-01,  4.6688e-01,  5.4376e-01,  9.3226e-01,  1.3946e-01,\n",
       "                         1.0759e+00,  7.5403e-01,  1.0783e+00,  1.1336e+00,  2.1366e-01,\n",
       "                         2.9932e-01],\n",
       "                       [-5.4709e-02,  5.7997e-01,  6.5488e-01,  7.4711e-02,  5.8435e-01,\n",
       "                        -2.3037e-01, -6.9903e-02,  4.5906e-01,  1.8399e-01, -1.0932e-01,\n",
       "                         5.5551e-01,  2.5707e-01,  1.6536e-01,  6.3421e-01,  4.3730e-01,\n",
       "                         8.8396e-01],\n",
       "                       [-6.4474e-02, -2.5300e-01,  6.2420e-01, -2.3939e-01,  4.3356e-01,\n",
       "                         7.8004e-02, -1.7776e-01,  2.3874e-01,  1.0221e+00, -1.2595e-01,\n",
       "                         6.6821e-01,  1.0325e+00,  9.8608e-01,  6.8065e-01,  2.4554e-01,\n",
       "                         1.1189e+00],\n",
       "                       [ 9.9066e-02,  4.9792e-01, -3.0293e-01,  6.5331e-01, -1.1997e-01,\n",
       "                        -1.0157e-01,  6.3349e-01,  4.6744e-01,  8.5826e-01,  1.0325e-03,\n",
       "                         9.6870e-01,  8.9656e-01,  9.1134e-01,  4.3616e-01,  9.3381e-01,\n",
       "                         7.6981e-01],\n",
       "                       [-1.1852e-01, -1.6734e-02, -1.1419e-01, -1.6003e-01,  3.4947e-01,\n",
       "                         4.2883e-01,  1.9866e-01,  3.9098e-01,  5.0491e-01,  5.7703e-03,\n",
       "                         8.4698e-01,  8.4353e-01,  3.6388e-01,  5.9902e-01,  5.8381e-01,\n",
       "                         1.0004e+00],\n",
       "                       [-5.3341e-02, -1.2626e-01, -9.2537e-02, -2.1584e-01,  6.0601e-01,\n",
       "                         6.0209e-01,  6.3205e-01,  6.2344e-01,  9.1527e-01, -6.5925e-03,\n",
       "                         1.0396e+00,  7.7323e-01,  5.7603e-01,  6.1150e-01,  9.7067e-01,\n",
       "                         6.1477e-01],\n",
       "                       [ 2.2653e-02,  4.7389e-01, -2.1200e-01, -2.2163e-01,  3.0626e-01,\n",
       "                        -3.0814e-01,  2.1165e-01, -2.7951e-01,  7.4982e-01,  2.8117e-02,\n",
       "                         1.0650e+00,  5.1720e-01,  6.4846e-01,  3.7866e-01,  5.1017e-01,\n",
       "                         5.5838e-01]], device='cuda:0')),\n",
       "              ('model.pools.0.weight',\n",
       "               tensor([[ 0.4060, -0.2327, -0.2839,  0.5846,  0.2651,  0.2414, -0.0378, -0.3005,\n",
       "                         1.1013,  0.4775,  0.5591,  0.4634,  0.9739,  0.6093,  0.7148,  0.8974]],\n",
       "                      device='cuda:0')),\n",
       "              ('model.pools.0.bias', tensor([-0.1132], device='cuda:0')),\n",
       "              ('model.pools.1.weight',\n",
       "               tensor([[ 0.7945,  0.0357,  0.8407,  0.2521,  0.3038,  0.6476,  0.7370,  0.8442,\n",
       "                         0.6971,  0.7716,  0.3729,  0.1908,  1.1325,  0.7739,  0.6159,  1.1438,\n",
       "                         0.3900,  0.8443,  0.3728, -0.0579,  0.4740,  0.6538,  0.5594,  0.0392,\n",
       "                         0.8226,  0.1911,  0.2036,  0.8334,  0.8417,  0.3319, -0.0058,  1.1360,\n",
       "                         0.6471,  0.6689,  1.0000,  0.9846,  0.1288,  1.1072,  0.8045,  0.9476,\n",
       "                         1.0507,  0.5390,  0.2988,  0.7987,  0.4674,  0.5322,  0.9721,  0.5639]],\n",
       "                      device='cuda:0')),\n",
       "              ('model.pools.1.bias', tensor([-0.0190], device='cuda:0')),\n",
       "              ('model.layer_norm.weight',\n",
       "               tensor([0.6804, 0.8471, 0.8471, 0.6804, 0.6804, 0.6804, 0.8470, 0.6804, 0.6804,\n",
       "                       0.8470, 0.6804, 0.6804, 0.8470, 0.8471, 0.8470, 0.8471, 0.8471, 0.8471,\n",
       "                       0.6804, 0.8471, 0.8471, 0.8471, 0.8471, 0.8471, 0.6804, 0.6804, 0.6804,\n",
       "                       0.8471, 1.1529, 0.6804], device='cuda:0')),\n",
       "              ('model.layer_norm.bias',\n",
       "               tensor([-0.3196,  0.1529, -0.1529, -0.1529,  0.3196, -0.3196, -0.1529, -0.1530,\n",
       "                        0.3196, -0.1529,  0.3196, -0.3196, -0.3196, -0.1530,  0.1530,  0.1529,\n",
       "                       -0.1529, -0.3196,  0.3196, -0.1529, -0.1529,  0.1529,  0.1530, -0.1529,\n",
       "                        0.3196,  0.3196,  0.3196, -0.3196,  0.3196,  0.3196], device='cuda:0')),\n",
       "              ('model.encoder.0.0.weight',\n",
       "               tensor([[-0.3118,  0.3542, -0.2663,  ..., -0.2376,  0.2587,  0.1907],\n",
       "                       [-0.2175,  0.2472, -0.2465,  ..., -0.3083,  0.2546,  0.3754],\n",
       "                       [ 0.1608, -0.2232,  0.3099,  ...,  0.2172,  0.2532, -0.2464],\n",
       "                       ...,\n",
       "                       [-0.2368,  0.2226, -0.0948,  ..., -0.0727, -0.2776,  0.1130],\n",
       "                       [-0.2327,  0.2996, -0.3134,  ..., -0.2944, -0.2654,  0.2487],\n",
       "                       [-0.2172,  0.1583, -0.1531,  ..., -0.1671, -0.2554,  0.2874]],\n",
       "                      device='cuda:0')),\n",
       "              ('model.encoder.0.0.bias',\n",
       "               tensor([-0.2957, -0.2709,  0.2742, -0.1572, -0.1954, -0.2215, -0.2228, -0.1793,\n",
       "                       -0.0641, -0.1270, -0.2000, -0.1968, -0.1195, -0.1185, -0.2798,  0.2635,\n",
       "                        0.2195, -0.3121,  0.3077, -0.1992, -0.1925, -0.3384, -0.2267, -0.3597,\n",
       "                       -0.0504, -0.2476, -0.0797, -0.3130, -0.2429,  0.1831, -0.1325, -0.3823,\n",
       "                       -0.1030, -0.2908, -0.3881, -0.1783, -0.2287, -0.2214, -0.1695, -0.3014,\n",
       "                       -0.3189, -0.2475, -0.2124, -0.3518, -0.0837, -0.2509, -0.0816, -0.3761,\n",
       "                       -0.2981, -0.2748, -0.1725, -0.1354, -0.1611,  0.2245, -0.2550, -0.2516,\n",
       "                       -0.2409, -0.3739, -0.2675, -0.1594, -0.1273, -0.1531, -0.2091, -0.2365],\n",
       "                      device='cuda:0')),\n",
       "              ('model.encoder.1.0.weight',\n",
       "               tensor([[ 0.2577,  0.2492,  0.4155,  ...,  0.1981,  0.4044,  0.3009],\n",
       "                       [ 0.3951,  0.2850,  0.0971,  ...,  0.2040,  0.2455,  0.0687],\n",
       "                       [-0.2935, -0.2409, -0.3020,  ..., -0.2595, -0.2648, -0.3192],\n",
       "                       ...,\n",
       "                       [-0.1167, -0.1897, -0.1761,  ..., -0.1484, -0.1892, -0.0281],\n",
       "                       [-0.3764, -0.3598, -0.3269,  ..., -0.3420, -0.3591, -0.3198],\n",
       "                       [-0.2017,  0.2218, -0.2256,  ..., -0.3046, -0.3574, -0.2834]],\n",
       "                      device='cuda:0')),\n",
       "              ('model.encoder.1.0.bias',\n",
       "               tensor([ 0.3938,  0.1650, -0.3123, -0.0722, -0.2145, -0.2042, -0.2071, -0.1625,\n",
       "                       -0.2829, -0.2033, -0.4128, -0.4048, -0.1547, -0.3013, -0.3767, -0.4771,\n",
       "                       -0.2385, -0.2516, -0.1779, -0.1476, -0.2646, -0.2894,  0.3728, -0.2386,\n",
       "                       -0.2567, -0.2159, -0.2915, -0.0927, -0.1542,  0.3129, -0.0422, -0.1254,\n",
       "                       -0.0415, -0.1371, -0.1531, -0.0296, -0.3227,  0.3420, -0.3328, -0.1731,\n",
       "                       -0.0955, -0.4057, -0.3520, -0.1978, -0.1944, -0.2638, -0.0306, -0.2479,\n",
       "                       -0.1543, -0.3192, -0.0979, -0.0951, -0.3227, -0.0564, -0.2703, -0.2215,\n",
       "                       -0.0448, -0.3693, -0.2316, -0.4097, -0.1977, -0.3372, -0.0503, -0.1899,\n",
       "                       -0.1414, -0.0067, -0.0934, -0.1276, -0.0349, -0.0610, -0.0284, -0.2135,\n",
       "                       -0.3505,  0.1834, -0.1594,  0.2747, -0.2607, -0.2349, -0.1548, -0.2714,\n",
       "                       -0.2231, -0.2509, -0.0325, -0.1085, -0.1011, -0.2389, -0.1835, -0.1404,\n",
       "                        0.3281, -0.3466, -0.2604, -0.3284, -0.1496, -0.3124,  0.2674, -0.0955,\n",
       "                       -0.4006, -0.3296, -0.4133, -0.2690, -0.3721, -0.1082, -0.2442, -0.2913,\n",
       "                       -0.2403, -0.0788, -0.3788, -0.1573, -0.2519, -0.1042, -0.1047, -0.1829,\n",
       "                        0.3332, -0.2265, -0.2152, -0.3991, -0.2421, -0.0846, -0.2778, -0.3573,\n",
       "                       -0.3322, -0.1333, -0.3346,  0.4299, -0.2094, -0.2295, -0.2969, -0.2333],\n",
       "                      device='cuda:0')),\n",
       "              ('model.encoder.2.0.weight',\n",
       "               tensor([[-0.3116, -0.3653, -0.3116,  ..., -0.2130,  0.2212, -0.2475],\n",
       "                       [-0.0764, -0.3087,  0.4356,  ...,  0.0026, -0.4267,  0.1908],\n",
       "                       [-0.3691, -0.2424, -0.2739,  ..., -0.2848, -0.2524,  0.2174],\n",
       "                       ...,\n",
       "                       [-0.3140, -0.2122, -0.2197,  ...,  0.2124, -0.3673, -0.3064],\n",
       "                       [ 0.3004,  0.0700,  0.3924,  ...,  0.2081,  0.3296, -0.0855],\n",
       "                       [-0.3687, -0.1848, -0.3410,  ...,  0.3786, -0.1126, -0.2819]],\n",
       "                      device='cuda:0')),\n",
       "              ('model.encoder.2.0.bias',\n",
       "               tensor([-0.3076, -0.3718, -0.2235, -0.3803, -0.1010, -0.2482, -0.3071, -0.0781,\n",
       "                        0.2805, -0.4538, -0.2342, -0.1713, -0.1424, -0.1854,  0.3183, -0.3131,\n",
       "                       -0.1867, -0.0788, -0.2941, -0.2077, -0.3425, -0.2267, -0.1298, -0.2329,\n",
       "                       -0.2736,  0.2990, -0.1673, -0.3340, -0.3162, -0.1914,  0.3621, -0.3184,\n",
       "                       -0.3758, -0.1419, -0.1010, -0.2321,  0.2803,  0.2464, -0.3417, -0.1637,\n",
       "                       -0.3345, -0.1791,  0.2308, -0.0974, -0.3263, -0.1345, -0.3481, -0.1393,\n",
       "                       -0.1299, -0.2279, -0.3281, -0.0682, -0.2735, -0.2988, -0.2898, -0.2174,\n",
       "                       -0.4516, -0.2858, -0.3201, -0.2251,  0.2701, -0.2423, -0.2399, -0.2706,\n",
       "                       -0.2038,  0.3360, -0.1028,  0.0968, -0.2329, -0.1456, -0.2648, -0.2624,\n",
       "                       -0.1316, -0.1994, -0.2826, -0.1975, -0.2139, -0.3355, -0.0861, -0.1604,\n",
       "                       -0.0281, -0.2295, -0.0512, -0.2352, -0.0715, -0.2377, -0.2336, -0.3645,\n",
       "                       -0.0823,  0.3823, -0.3547, -0.1508, -0.2854, -0.1861, -0.3443, -0.2254,\n",
       "                       -0.1151, -0.1300, -0.2844,  0.3240, -0.1096, -0.2836, -0.2194, -0.2144,\n",
       "                       -0.3581, -0.3084, -0.3092, -0.2126, -0.2406,  0.1997, -0.3134, -0.0986,\n",
       "                       -0.1698, -0.3857, -0.2452, -0.3619, -0.0654, -0.2373,  0.3084, -0.1799,\n",
       "                        0.3053, -0.2381, -0.2083, -0.2079, -0.1493, -0.3710,  0.3861, -0.3226],\n",
       "                      device='cuda:0')),\n",
       "              ('model.encoder.3.0.weight',\n",
       "               tensor([[-0.2617,  0.3182,  0.2676,  ...,  0.3259, -0.3590,  0.2886],\n",
       "                       [-0.1314, -0.1124, -0.2434,  ...,  0.2329, -0.1053,  0.3767],\n",
       "                       [-0.3132, -0.2186,  0.2647,  ..., -0.3257, -0.2496, -0.2634],\n",
       "                       ...,\n",
       "                       [-0.2138, -0.3098,  0.3007,  ...,  0.2810, -0.3257, -0.2222],\n",
       "                       [-0.3398, -0.3357, -0.2823,  ...,  0.3420, -0.3068, -0.3396],\n",
       "                       [-0.3232, -0.3615, -0.3480,  ...,  0.3345, -0.2119, -0.3834]],\n",
       "                      device='cuda:0')),\n",
       "              ('model.encoder.3.0.bias',\n",
       "               tensor([-0.2946, -0.1966, -0.3245, -0.1110, -0.3663, -0.3230, -0.1561, -0.3534,\n",
       "                       -0.1908, -0.2633, -0.2353, -0.1242, -0.1402,  0.1564, -0.2956, -0.1551,\n",
       "                       -0.1462, -0.3483, -0.2318, -0.2892, -0.3606, -0.3117, -0.1552, -0.1704,\n",
       "                       -0.2938, -0.0670, -0.0977, -0.3078, -0.1314, -0.3465, -0.3704, -0.3665],\n",
       "                      device='cuda:0')),\n",
       "              ('model.encoder.4.weight',\n",
       "               tensor([[ 0.3901,  0.4044,  0.1967,  0.2329,  0.9586,  1.1057, -0.0656,  0.5906,\n",
       "                         0.0553,  0.3685,  0.7775,  0.4062,  0.7243, -0.2794,  0.5203, -0.1106,\n",
       "                         0.6743,  0.2463,  0.6612,  0.6275,  0.5381,  0.8999,  0.0214,  0.2844,\n",
       "                         0.7713,  0.2675,  0.3015, -0.1120,  0.1863,  0.8431,  0.3391,  0.6872]],\n",
       "                      device='cuda:0')),\n",
       "              ('model.encoder.4.bias', tensor([-0.1516], device='cuda:0'))]),\n",
       " 'loops': {'fit_loop': {'state_dict': {},\n",
       "   'epoch_loop.state_dict': {'_batches_that_stepped': 7},\n",
       "   'epoch_loop.batch_progress': {'total': {'ready': 8,\n",
       "     'completed': 8,\n",
       "     'started': 8,\n",
       "     'processed': 8},\n",
       "    'current': {'ready': 4, 'completed': 4, 'started': 4, 'processed': 4},\n",
       "    'is_last_batch': True},\n",
       "   'epoch_loop.scheduler_progress': {'total': {'ready': 2, 'completed': 2},\n",
       "    'current': {'ready': 1, 'completed': 1}},\n",
       "   'epoch_loop.automatic_optimization.state_dict': {},\n",
       "   'epoch_loop.automatic_optimization.optim_progress': {'optimizer': {'step': {'total': {'ready': 8,\n",
       "       'completed': 8},\n",
       "      'current': {'ready': 4, 'completed': 4}},\n",
       "     'zero_grad': {'total': {'ready': 8, 'completed': 8, 'started': 8},\n",
       "      'current': {'ready': 4, 'completed': 4, 'started': 4}}}},\n",
       "   'epoch_loop.manual_optimization.state_dict': {},\n",
       "   'epoch_loop.manual_optimization.optim_step_progress': {'total': {'ready': 0,\n",
       "     'completed': 0},\n",
       "    'current': {'ready': 0, 'completed': 0}},\n",
       "   'epoch_loop.val_loop.state_dict': {},\n",
       "   'epoch_loop.val_loop.batch_progress': {'total': {'ready': 1,\n",
       "     'completed': 1,\n",
       "     'started': 1,\n",
       "     'processed': 1},\n",
       "    'current': {'ready': 1, 'completed': 1, 'started': 1, 'processed': 1},\n",
       "    'is_last_batch': True},\n",
       "   'epoch_progress': {'total': {'ready': 2,\n",
       "     'completed': 1,\n",
       "     'started': 2,\n",
       "     'processed': 1},\n",
       "    'current': {'ready': 2, 'completed': 1, 'started': 2, 'processed': 1}}},\n",
       "  'validate_loop': {'state_dict': {},\n",
       "   'batch_progress': {'total': {'ready': 0,\n",
       "     'completed': 0,\n",
       "     'started': 0,\n",
       "     'processed': 0},\n",
       "    'current': {'ready': 0, 'completed': 0, 'started': 0, 'processed': 0},\n",
       "    'is_last_batch': False}},\n",
       "  'test_loop': {'state_dict': {},\n",
       "   'batch_progress': {'total': {'ready': 0,\n",
       "     'completed': 0,\n",
       "     'started': 0,\n",
       "     'processed': 0},\n",
       "    'current': {'ready': 0, 'completed': 0, 'started': 0, 'processed': 0},\n",
       "    'is_last_batch': False}},\n",
       "  'predict_loop': {'state_dict': {},\n",
       "   'batch_progress': {'total': {'ready': 0,\n",
       "     'completed': 0,\n",
       "     'started': 0,\n",
       "     'processed': 0},\n",
       "    'current': {'ready': 0, 'completed': 0, 'started': 0, 'processed': 0}}}},\n",
       " 'callbacks': {\"ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}\": {'monitor': None,\n",
       "   'best_model_score': None,\n",
       "   'best_model_path': '/scratch/lcornelis/tmp/session_2024-07-31_15-31-32_784450_1871092/artifacts/2024-07-31_15-31-35/TorchTrainer_2024-07-31_15-31-35/working_dirs/model=gat-v4,seed=19543_0_act=relu,adj_thresh=0.1000,batch_size=8,dropout=0,l1_lambda=0.0000,lr=0.1000,lr_scheduler=LambdaLR,modal_2024-07-31_15-31-36/lightning_logs/version_0/checkpoints/epoch=0-step=4.ckpt',\n",
       "   'current_score': None,\n",
       "   'dirpath': '/scratch/lcornelis/tmp/session_2024-07-31_15-31-32_784450_1871092/artifacts/2024-07-31_15-31-35/TorchTrainer_2024-07-31_15-31-35/working_dirs/model=gat-v4,seed=19543_0_act=relu,adj_thresh=0.1000,batch_size=8,dropout=0,l1_lambda=0.0000,lr=0.1000,lr_scheduler=LambdaLR,modal_2024-07-31_15-31-36/lightning_logs/version_0/checkpoints',\n",
       "   'best_k_models': {},\n",
       "   'kth_best_model_path': '',\n",
       "   'kth_value': tensor(inf),\n",
       "   'last_model_path': ''}},\n",
       " 'optimizer_states': [{'state': {0: {'step': tensor(8.),\n",
       "     'exp_avg': tensor([[[ -0.3122,   7.6363,   8.3902,   0.8268,   6.1079,   0.5877,   3.9479,\n",
       "                 2.7987],\n",
       "              [152.2988,  -3.1341,   2.7358, 117.9020,   1.8943,  37.0508,  51.1731,\n",
       "                90.0605]]], device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([[[3.3852e-02, 2.0484e+01, 2.4727e+01, 2.4102e-01, 1.3106e+01,\n",
       "               1.2197e-01, 5.4773e+00, 2.7535e+00],\n",
       "              [8.1350e+03, 3.3587e+00, 2.7047e+00, 4.8813e+03, 1.3136e+00,\n",
       "               4.8066e+02, 9.2037e+02, 2.8436e+03]]], device='cuda:0')},\n",
       "    1: {'step': tensor(8.),\n",
       "     'exp_avg': tensor([[[-4.5871e-06,  2.4927e-04,  2.8360e-04,  2.3762e-05,  2.0802e-04,\n",
       "                1.4780e-05,  1.3649e-04,  9.8433e-05],\n",
       "              [-9.7920e-05,  7.8184e-06,  3.8245e-06, -7.4535e-05,  4.3970e-06,\n",
       "               -1.9504e-05, -2.9132e-05, -5.5572e-05]]], device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([[[3.4159e-11, 2.2611e-08, 2.7284e-08, 2.7599e-10, 1.4482e-08,\n",
       "               1.2757e-10, 6.0702e-09, 3.0621e-09],\n",
       "              [3.7361e-09, 3.1462e-12, 1.3491e-12, 2.2353e-09, 9.1788e-13,\n",
       "               2.1437e-10, 4.1475e-10, 1.2971e-09]]], device='cuda:0')},\n",
       "    2: {'step': tensor(8.),\n",
       "     'exp_avg': tensor([-1.2658e-06, -4.6788e-05, -5.5152e-05, -3.3733e-05, -7.3801e-05,\n",
       "             -3.8041e-05, -5.3510e-05, -5.5955e-05, -5.1123e-05, -1.2658e-06,\n",
       "             -5.0988e-05, -4.7901e-05, -5.0988e-05, -4.9535e-05, -5.5998e-05,\n",
       "             -5.4370e-05], device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([6.9790e-13, 9.2922e-10, 1.2561e-09, 5.1936e-10, 2.1627e-09, 6.4227e-10,\n",
       "             1.1889e-09, 1.2905e-09, 1.0915e-09, 6.9790e-13, 1.0915e-09, 9.6804e-10,\n",
       "             1.0915e-09, 1.0288e-09, 1.2905e-09, 1.2223e-09], device='cuda:0')},\n",
       "    3: {'step': tensor(8.),\n",
       "     'exp_avg': tensor([[  3.6087],\n",
       "             [  9.2303],\n",
       "             [ 12.1503],\n",
       "             [ 45.2670],\n",
       "             [ 36.7949],\n",
       "             [ 30.7145],\n",
       "             [ 17.8976],\n",
       "             [  2.7102],\n",
       "             [-27.7923],\n",
       "             [113.1379],\n",
       "             [ 14.2445],\n",
       "             [  2.5072],\n",
       "             [ 69.9650],\n",
       "             [-16.8057],\n",
       "             [100.3404],\n",
       "             [-21.8177]], device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([[4.5679e+00],\n",
       "             [3.0097e+01],\n",
       "             [5.2142e+01],\n",
       "             [7.2112e+02],\n",
       "             [4.7423e+02],\n",
       "             [3.3192e+02],\n",
       "             [1.1251e+02],\n",
       "             [2.6539e+00],\n",
       "             [2.7086e+02],\n",
       "             [4.4885e+03],\n",
       "             [7.1403e+01],\n",
       "             [2.2587e+00],\n",
       "             [1.7183e+03],\n",
       "             [9.8820e+01],\n",
       "             [3.5345e+03],\n",
       "             [1.6680e+02]], device='cuda:0')},\n",
       "    4: {'step': tensor(8.),\n",
       "     'exp_avg': tensor([[[-0.0474, -0.0253, -0.0263, -0.0364, -0.0464, -0.0291, -0.0349,\n",
       "               -0.0317, -0.0552, -0.0353, -0.0136, -0.0155, -0.0403, -0.0198,\n",
       "               -0.0098, -0.0407],\n",
       "              [-0.0186, -0.0358, -0.0430, -0.0268, -0.0223, -0.0188, -0.0269,\n",
       "               -0.0256, -0.0322, -0.0180, -0.0302, -0.0368, -0.0512, -0.0330,\n",
       "               -0.0192, -0.0236],\n",
       "              [-0.0262, -0.0481, -0.0671, -0.0521, -0.0369, -0.0554, -0.0206,\n",
       "               -0.0609, -0.0586, -0.0479, -0.0241, -0.0721, -0.0616, -0.0498,\n",
       "               -0.0596, -0.0388]]], device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([[[7.9130e-04, 2.2624e-04, 2.4487e-04, 4.6862e-04, 7.6107e-04,\n",
       "               2.9880e-04, 4.3011e-04, 3.5550e-04, 1.0732e-03, 4.3956e-04,\n",
       "               6.5188e-05, 8.5100e-05, 5.7296e-04, 1.3858e-04, 3.3766e-05,\n",
       "               5.8392e-04],\n",
       "              [1.2249e-04, 4.5192e-04, 6.5398e-04, 2.5295e-04, 1.7530e-04,\n",
       "               1.2548e-04, 2.5465e-04, 2.3049e-04, 3.6554e-04, 1.1462e-04,\n",
       "               3.1966e-04, 4.7805e-04, 9.2489e-04, 3.8412e-04, 1.2901e-04,\n",
       "               1.9614e-04],\n",
       "              [2.4169e-04, 8.1703e-04, 1.5886e-03, 9.5787e-04, 4.8084e-04,\n",
       "               1.0842e-03, 1.4987e-04, 1.3077e-03, 1.2137e-03, 8.1144e-04,\n",
       "               2.0545e-04, 1.8340e-03, 1.3377e-03, 8.7462e-04, 1.2513e-03,\n",
       "               5.3093e-04]]], device='cuda:0')},\n",
       "    5: {'step': tensor(8.),\n",
       "     'exp_avg': tensor([[[-1.2674e-05, -6.7307e-06, -3.8124e-06, -5.7723e-06, -1.0504e-05,\n",
       "               -7.3902e-06, -1.1618e-05, -5.6943e-06, -1.2559e-05, -1.0178e-05,\n",
       "               -2.8373e-06, -2.4275e-06, -8.4134e-06, -6.4792e-06, -4.3043e-06,\n",
       "               -7.8194e-06],\n",
       "              [-3.8155e-05, -5.8121e-05, -5.5882e-05, -6.1941e-05, -4.5411e-05,\n",
       "               -2.8070e-05, -5.5288e-05, -5.2032e-05, -4.8421e-05, -4.6168e-05,\n",
       "               -5.1511e-05, -3.9782e-05, -7.0693e-05, -4.9866e-05, -5.8671e-05,\n",
       "               -3.6469e-05],\n",
       "              [-3.6305e-04, -4.2409e-04, -3.3677e-04, -3.3111e-04, -2.8634e-04,\n",
       "               -3.5877e-04, -2.7785e-04, -3.8005e-04, -2.5470e-04, -2.4383e-04,\n",
       "               -3.1600e-04, -3.5472e-04, -3.1394e-04, -2.5835e-04, -3.2576e-04,\n",
       "               -2.3016e-04]]], device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([[[1.1146e-10, 4.9914e-11, 2.8762e-11, 4.2371e-11, 8.6192e-11,\n",
       "               5.5543e-11, 9.8687e-11, 4.1746e-11, 1.1011e-10, 7.0625e-11,\n",
       "               2.2942e-11, 2.0737e-11, 6.4879e-11, 4.7827e-11, 3.1841e-11,\n",
       "               5.9402e-11],\n",
       "              [6.5714e-10, 1.4000e-09, 1.3021e-09, 1.5740e-09, 8.9445e-10,\n",
       "               3.8657e-10, 1.2783e-09, 1.1445e-09, 1.0040e-09, 9.2194e-10,\n",
       "               1.1234e-09, 7.0603e-10, 2.0106e-09, 1.0581e-09, 1.4248e-09,\n",
       "               6.0620e-10],\n",
       "              [4.7634e-08, 6.4729e-08, 4.1073e-08, 3.9727e-08, 2.9855e-08,\n",
       "               4.6524e-08, 2.8139e-08, 5.2131e-08, 2.3723e-08, 2.1779e-08,\n",
       "               3.6235e-08, 4.5494e-08, 3.5776e-08, 2.4394e-08, 3.8474e-08,\n",
       "               1.9453e-08]]], device='cuda:0')},\n",
       "    6: {'step': tensor(8.),\n",
       "     'exp_avg': tensor([-1.6727e-06, -4.4510e-07, -3.5966e-06,  1.2793e-06, -1.1994e-06,\n",
       "             -3.2925e-06, -3.2419e-06, -1.7235e-06, -3.5713e-06, -1.6727e-06,\n",
       "             -3.5207e-06, -1.6347e-06,  1.1153e-06, -3.3940e-06, -3.1658e-06,\n",
       "             -3.2420e-06,  2.2944e-06, -2.0139e-07, -2.1478e-07,  2.3698e-06,\n",
       "             -3.2672e-06, -1.7487e-06,  1.1405e-06, -1.8247e-06, -1.7740e-06,\n",
       "             -1.7867e-06, -2.2241e-06,  4.4649e-07,  8.5209e-08,  2.2874e-06,\n",
       "             -4.8311e-07, -1.6211e-06, -3.3940e-06, -3.1406e-06,  1.0898e-06,\n",
       "             -3.4954e-06, -1.7740e-06,  6.9727e-07, -3.3433e-06, -3.5714e-06,\n",
       "             -3.1913e-06, -1.1341e-07, -1.6979e-06, -3.5714e-06, -1.8628e-06,\n",
       "             -1.8248e-06,  6.9704e-07, -1.8247e-06], device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([9.5960e-13, 6.2097e-13, 1.0158e-12, 7.0300e-13, 6.7459e-13, 1.2815e-12,\n",
       "             1.3321e-12, 9.2440e-13, 1.0355e-12, 9.5961e-13, 1.0762e-12, 9.8722e-13,\n",
       "             6.4954e-13, 1.1857e-12, 1.4114e-12, 1.3321e-12, 6.0217e-13, 7.6320e-13,\n",
       "             7.5685e-13, 6.0958e-13, 1.3065e-12, 9.0743e-13, 6.5655e-13, 8.5934e-13,\n",
       "             8.9094e-13, 8.8288e-13, 5.9886e-13, 6.2124e-13, 5.9855e-13, 6.0168e-13,\n",
       "             6.2824e-13, 9.9714e-13, 1.1857e-12, 1.4387e-12, 6.4295e-13, 1.0972e-12,\n",
       "             8.9095e-13, 6.3131e-13, 1.2327e-12, 1.0355e-12, 1.3845e-12, 8.0832e-13,\n",
       "             9.4175e-13, 1.0355e-12, 8.3681e-13, 8.5934e-13, 6.3130e-13, 8.5934e-13],\n",
       "            device='cuda:0')},\n",
       "    7: {'step': tensor(8.),\n",
       "     'exp_avg': tensor([[ 5.6721e-06,  2.6574e-01,  2.9226e-01,  2.8617e-02,  2.1304e-01,\n",
       "               2.0519e-02,  1.3856e-01,  9.7691e-02, -4.5628e-01, -1.6369e-06,\n",
       "              -8.3144e-03, -3.5437e-01, -5.7871e-03, -1.1091e-01, -1.5347e-01,\n",
       "              -2.7056e-01],\n",
       "             [ 5.6887e-06,  1.2894e-01,  1.4180e-01,  1.3936e-02,  1.0340e-01,\n",
       "               9.9920e-03,  6.7259e-02,  4.7454e-02, -2.2059e-01,  5.7082e-06,\n",
       "              -4.0217e-03, -1.7139e-01, -2.7977e-03, -5.3592e-02, -7.4243e-02,\n",
       "              -1.3079e-01],\n",
       "             [-2.5185e-06,  2.8874e-01,  3.1755e-01,  3.1114e-02,  2.3155e-01,\n",
       "               2.2299e-02,  1.5041e-01,  1.0604e-01, -4.7885e-01,  1.9351e-06,\n",
       "              -8.7266e-03, -3.7189e-01, -6.0790e-03, -1.1642e-01, -1.6103e-01,\n",
       "              -2.8393e-01],\n",
       "             [ 5.6913e-06,  7.3413e-03,  8.0977e-03,  7.6059e-04,  5.7934e-03,\n",
       "               5.5567e-04,  3.9429e-03,  2.7672e-03, -2.6896e-02, -3.6670e-06,\n",
       "              -4.8409e-04, -2.0866e-02, -3.3253e-04, -6.5260e-03, -9.0524e-03,\n",
       "              -1.5973e-02],\n",
       "             [ 2.6989e-07,  3.2443e-02,  3.5685e-02,  3.4687e-03,  2.6001e-02,\n",
       "               2.4919e-03,  1.6875e-02,  1.1883e-02, -5.4602e-02,  2.8415e-07,\n",
       "              -9.8755e-04, -4.2367e-02, -6.8601e-04, -1.3286e-02, -1.8332e-02,\n",
       "              -3.2384e-02],\n",
       "             [ 5.6625e-06,  4.2242e-01,  4.6454e-01,  4.5591e-02,  3.3882e-01,\n",
       "               3.2668e-02,  2.2003e-01,  1.5518e-01, -6.9155e-01,  3.7495e-06,\n",
       "              -1.2611e-02, -5.3718e-01, -8.7853e-03, -1.6810e-01, -2.3261e-01,\n",
       "              -4.1002e-01],\n",
       "             [-3.8134e-07,  4.6273e-01,  5.0889e-01,  4.9931e-02,  3.7111e-01,\n",
       "               3.5787e-02,  2.4115e-01,  1.7007e-01, -7.7450e-01,  5.7448e-06,\n",
       "              -1.4121e-02, -6.0161e-01, -9.8335e-03, -1.8825e-01, -2.6054e-01,\n",
       "              -4.5920e-01],\n",
       "             [ 3.6712e-06,  2.9081e-01,  3.1981e-01,  3.1329e-02,  2.3324e-01,\n",
       "               2.2455e-02,  1.5139e-01,  1.0673e-01, -4.7397e-01,  5.7327e-06,\n",
       "              -8.6364e-03, -3.6809e-01, -6.0164e-03, -1.1525e-01, -1.5936e-01,\n",
       "              -2.8103e-01],\n",
       "             [ 5.6758e-06,  2.1808e-01,  2.3985e-01,  2.3479e-02,  1.7486e-01,\n",
       "               1.6840e-02,  1.1366e-01,  8.0135e-02, -3.7342e-01,  5.7274e-06,\n",
       "              -6.7995e-03, -2.9000e-01, -4.7321e-03, -9.0779e-02, -1.2558e-01,\n",
       "              -2.2142e-01],\n",
       "             [ 5.6741e-06,  2.5498e-01,  2.8042e-01,  2.7464e-02,  2.0439e-01,\n",
       "               1.9693e-02,  1.3298e-01,  9.3755e-02, -4.4004e-01,  1.9352e-06,\n",
       "              -8.0192e-03, -3.4176e-01, -5.5812e-03, -1.0696e-01, -1.4802e-01,\n",
       "              -2.6094e-01],\n",
       "             [-2.5134e-06,  2.8941e-01,  3.1827e-01,  3.1236e-02,  2.3214e-01,\n",
       "               2.2381e-02,  1.5077e-01,  1.0634e-01, -4.7932e-01,  5.7246e-06,\n",
       "              -8.7370e-03, -3.7233e-01, -6.0847e-03, -1.1650e-01, -1.6124e-01,\n",
       "              -2.8418e-01],\n",
       "             [ 5.6833e-06,  2.0217e-01,  2.2232e-01,  2.1834e-02,  1.6218e-01,\n",
       "               1.5649e-02,  1.0533e-01,  7.4294e-02, -3.3575e-01, -3.2933e-07,\n",
       "              -6.1176e-03, -2.6082e-01, -4.2596e-03, -8.1603e-02, -1.1295e-01,\n",
       "              -1.9905e-01],\n",
       "             [ 1.8614e-06,  4.2678e-01,  4.6936e-01,  4.5988e-02,  3.4225e-01,\n",
       "               3.2966e-02,  2.2232e-01,  1.5675e-01, -7.1117e-01,  1.9513e-06,\n",
       "              -1.2960e-02, -5.5233e-01, -9.0252e-03, -1.7289e-01, -2.3917e-01,\n",
       "              -4.2167e-01],\n",
       "             [ 9.0736e-08,  4.8236e-01,  5.3045e-01,  5.2051e-02,  3.8693e-01,\n",
       "               3.7298e-02,  2.5119e-01,  1.7715e-01, -7.8548e-01,  5.7433e-06,\n",
       "              -1.4322e-02, -6.1012e-01, -9.9787e-03, -1.9095e-01, -2.6419e-01,\n",
       "              -4.6570e-01],\n",
       "             [ 5.6679e-06,  4.0625e-01,  4.4677e-01,  4.3837e-02,  3.2576e-01,\n",
       "               3.1416e-02,  2.1179e-01,  1.4937e-01, -6.8528e-01,  5.7416e-06,\n",
       "              -1.2498e-02, -5.3233e-01, -8.7026e-03, -1.6654e-01, -2.3056e-01,\n",
       "              -4.0632e-01],\n",
       "             [ 1.8596e-06,  4.3340e-01,  4.7664e-01,  4.6707e-02,  3.4751e-01,\n",
       "               3.3470e-02,  2.2588e-01,  1.5927e-01, -7.2940e-01, -2.4373e-06,\n",
       "              -1.3298e-02, -5.6651e-01, -9.2593e-03, -1.7731e-01, -2.4533e-01,\n",
       "              -4.3250e-01],\n",
       "             [-1.9300e-07,  2.9645e-01,  3.2601e-01,  3.2004e-02,  2.3780e-01,\n",
       "               2.2927e-02,  1.5443e-01,  1.0891e-01, -4.9217e-01,  2.1784e-06,\n",
       "              -8.9683e-03, -3.8230e-01, -6.2454e-03, -1.1963e-01, -1.6555e-01,\n",
       "              -2.9179e-01],\n",
       "             [ 5.6707e-06,  2.8724e-01,  3.1591e-01,  3.0949e-02,  2.3033e-01,\n",
       "               2.2176e-02,  1.4970e-01,  1.0554e-01, -4.8954e-01,  3.7357e-06,\n",
       "              -8.9177e-03, -3.8018e-01, -6.2086e-03, -1.1901e-01, -1.6464e-01,\n",
       "              -2.9026e-01],\n",
       "             [ 3.6879e-06,  6.4485e-02,  7.0927e-02,  6.9282e-03,  5.1665e-02,\n",
       "               4.9705e-03,  3.3633e-02,  2.3689e-02, -1.1430e-01,  1.9099e-06,\n",
       "              -2.0792e-03, -8.8729e-02, -1.4442e-03, -2.7787e-02, -3.8429e-02,\n",
       "              -6.7775e-02],\n",
       "             [-1.1864e-06,  8.3619e-02,  9.1960e-02,  9.0392e-03,  6.7045e-02,\n",
       "               6.4913e-03,  4.3664e-02,  3.0817e-02, -1.4783e-01,  2.8269e-07,\n",
       "              -2.6940e-03, -1.1486e-01, -1.8737e-03, -3.5899e-02, -4.9775e-02,\n",
       "              -8.7635e-02],\n",
       "             [ 3.6678e-06,  3.3779e-01,  3.7148e-01,  3.6464e-02,  2.7096e-01,\n",
       "               2.6130e-02,  1.7596e-01,  1.2409e-01, -5.5662e-01, -1.1392e-06,\n",
       "              -1.0147e-02, -4.3237e-01, -7.0670e-03, -1.3530e-01, -1.8723e-01,\n",
       "              -3.3001e-01],\n",
       "             [-1.1998e-06,  1.9886e-01,  2.1869e-01,  2.1410e-02,  1.5944e-01,\n",
       "               1.5352e-02,  1.0362e-01,  7.3048e-02, -3.3411e-01, -1.6458e-06,\n",
       "              -6.0865e-03, -2.5946e-01, -4.2381e-03, -8.1226e-02, -1.1236e-01,\n",
       "              -1.9811e-01],\n",
       "             [ 5.6643e-06,  3.7677e-01,  4.1435e-01,  4.0663e-02,  3.0217e-01,\n",
       "               2.9146e-02,  1.9637e-01,  1.3849e-01, -6.3496e-01, -1.1323e-06,\n",
       "              -1.1576e-02, -4.9321e-01, -8.0609e-03, -1.5432e-01, -2.1361e-01,\n",
       "              -3.7645e-01],\n",
       "             [ 1.8247e-08,  1.2922e-01,  1.4211e-01,  1.3966e-02,  1.0361e-01,\n",
       "               1.0016e-02,  6.7448e-02,  4.7580e-02, -2.2655e-01,  5.7168e-06,\n",
       "              -4.1311e-03, -1.7600e-01, -2.8728e-03, -5.5032e-02, -7.6256e-02,\n",
       "              -1.3431e-01],\n",
       "             [ 5.6726e-06,  2.7986e-01,  3.0777e-01,  3.0160e-02,  2.2447e-01,\n",
       "               2.1601e-02,  1.4569e-01,  1.0272e-01, -4.5704e-01,  3.1211e-07,\n",
       "              -8.3251e-03, -3.5493e-01, -5.7990e-03, -1.1113e-01, -1.5366e-01,\n",
       "              -2.7099e-01],\n",
       "             [ 3.6830e-06,  2.0356e-01,  2.2387e-01,  2.1988e-02,  1.6328e-01,\n",
       "               1.5758e-02,  1.0609e-01,  7.4829e-02, -3.3747e-01,  5.7150e-06,\n",
       "              -6.1529e-03, -2.6215e-01, -4.2850e-03, -8.2012e-02, -1.1354e-01,\n",
       "              -2.0007e-01],\n",
       "             [ 5.6930e-06, -1.5974e-02, -1.7550e-02, -1.7512e-03, -1.2893e-02,\n",
       "              -1.2448e-03, -8.2058e-03, -5.8026e-03,  1.0946e-02,  1.3034e-07,\n",
       "               1.9551e-04,  8.5459e-03,  1.3697e-04,  2.6742e-03,  3.6725e-03,\n",
       "               6.4725e-03],\n",
       "             [ 5.6725e-06,  2.8309e-01,  3.1135e-01,  3.0495e-02,  2.2700e-01,\n",
       "               2.1866e-02,  1.4753e-01,  1.0401e-01, -4.7952e-01,  5.7368e-06,\n",
       "              -8.7367e-03, -3.7239e-01, -6.0832e-03, -1.1657e-01, -1.6127e-01,\n",
       "              -2.8432e-01],\n",
       "             [ 5.6717e-06,  2.8744e-01,  3.1612e-01,  3.0973e-02,  2.3050e-01,\n",
       "               2.2200e-02,  1.4975e-01,  1.0558e-01, -4.8269e-01,  3.7357e-06,\n",
       "              -8.7940e-03, -3.7485e-01, -6.1237e-03, -1.1735e-01, -1.6232e-01,\n",
       "              -2.8619e-01],\n",
       "             [ 5.6889e-06,  4.6063e-02,  5.0657e-02,  4.9450e-03,  3.6934e-02,\n",
       "               3.5438e-03,  2.3933e-02,  1.6866e-02, -7.3379e-02,  5.7047e-06,\n",
       "              -1.3295e-03, -5.6949e-02, -9.2486e-04, -1.7857e-02, -2.4637e-02,\n",
       "              -4.3514e-02],\n",
       "             [ 5.6897e-06,  1.0788e-01,  1.1864e-01,  1.1664e-02,  8.6485e-02,\n",
       "               8.3671e-03,  5.6345e-02,  3.9752e-02, -1.9231e-01, -1.1716e-06,\n",
       "              -3.5052e-03, -1.4941e-01, -2.4382e-03, -4.6706e-02, -6.4747e-02,\n",
       "              -1.1401e-01],\n",
       "             [-1.7087e-06,  4.2894e-01,  4.7173e-01,  4.6232e-02,  3.4394e-01,\n",
       "               3.3135e-02,  2.2350e-01,  1.5759e-01, -7.1778e-01,  1.9548e-06,\n",
       "              -1.3086e-02, -5.5745e-01, -9.1144e-03, -1.7449e-01, -2.4141e-01,\n",
       "              -4.2559e-01],\n",
       "             [ 9.6137e-08,  4.1692e-01,  4.5852e-01,  4.4981e-02,  3.3431e-01,\n",
       "               3.2241e-02,  2.1743e-01,  1.5333e-01, -7.1934e-01,  5.7452e-06,\n",
       "              -1.3113e-02, -5.5877e-01, -9.1273e-03, -1.7482e-01, -2.4202e-01,\n",
       "              -4.2651e-01],\n",
       "             [-1.7050e-06,  4.3185e-01,  4.7491e-01,  4.6588e-02,  3.4630e-01,\n",
       "               3.3400e-02,  2.2510e-01,  1.5875e-01, -7.2509e-01,  5.7440e-06,\n",
       "              -1.3224e-02, -5.6324e-01, -9.2096e-03, -1.7623e-01, -2.4394e-01,\n",
       "              -4.2992e-01],\n",
       "             [ 5.6650e-06,  3.6246e-01,  3.9863e-01,  3.9051e-02,  2.9058e-01,\n",
       "               2.8000e-02,  1.8900e-01,  1.3325e-01, -6.2441e-01, -1.1311e-06,\n",
       "              -1.1381e-02, -4.8495e-01, -7.9224e-03, -1.5177e-01, -2.1003e-01,\n",
       "              -3.7025e-01],\n",
       "             [-2.5240e-06,  3.5647e-01,  3.9204e-01,  3.8413e-02,  2.8584e-01,\n",
       "               2.7523e-02,  1.8574e-01,  1.3096e-01, -5.9948e-01,  7.2966e-07,\n",
       "              -1.0925e-02, -4.6558e-01, -7.6070e-03, -1.4574e-01, -2.0161e-01,\n",
       "              -3.5546e-01],\n",
       "             [ 2.1297e-06,  1.7414e-01,  1.9149e-01,  1.8815e-02,  1.3970e-01,\n",
       "               1.3482e-02,  9.0701e-02,  6.3978e-02, -2.8416e-01,  5.7111e-06,\n",
       "              -5.1788e-03, -2.2075e-01, -3.6068e-03, -6.9064e-02, -9.5591e-02,\n",
       "              -1.6847e-01],\n",
       "             [-2.5286e-06,  4.1589e-01,  4.5736e-01,  4.4828e-02,  3.3358e-01,\n",
       "               3.2121e-02,  2.1652e-01,  1.5266e-01, -6.8072e-01,  5.7460e-06,\n",
       "              -1.2403e-02, -5.2866e-01, -8.6395e-03, -1.6552e-01, -2.2888e-01,\n",
       "              -4.0361e-01],\n",
       "             [ 5.6604e-06,  4.9486e-01,  5.4422e-01,  5.3393e-02,  3.9685e-01,\n",
       "               3.8270e-02,  2.5792e-01,  1.8189e-01, -8.3236e-01, -1.1283e-06,\n",
       "              -1.5178e-02, -6.4655e-01, -1.0569e-02, -2.0231e-01, -2.8001e-01,\n",
       "              -4.9352e-01],\n",
       "             [ 5.6673e-06,  3.3859e-01,  3.7236e-01,  3.6483e-02,  2.7155e-01,\n",
       "               2.6150e-02,  1.7634e-01,  1.2432e-01, -5.6201e-01,  5.7391e-06,\n",
       "              -1.0238e-02, -4.3647e-01, -7.1301e-03, -1.3664e-01, -1.8898e-01,\n",
       "              -3.3323e-01],\n",
       "             [ 2.4351e-07,  3.8542e-01,  4.2388e-01,  4.1529e-02,  3.0906e-01,\n",
       "               2.9773e-02,  2.0085e-01,  1.4162e-01, -6.5588e-01,  1.9474e-06,\n",
       "              -1.1949e-02, -5.0938e-01, -8.3183e-03, -1.5944e-01, -2.2058e-01,\n",
       "              -3.8890e-01],\n",
       "             [ 5.6818e-06,  1.4499e-01,  1.5945e-01,  1.5615e-02,  1.1631e-01,\n",
       "               1.1178e-02,  7.5443e-02,  5.3181e-02, -2.3380e-01,  5.7158e-06,\n",
       "              -4.2543e-03, -1.8154e-01, -2.9630e-03, -5.6862e-02, -7.8582e-02,\n",
       "              -1.3863e-01],\n",
       "             [ 3.6796e-06,  2.5505e-01,  2.8048e-01,  2.7540e-02,  2.0459e-01,\n",
       "               1.9725e-02,  1.3285e-01,  9.3702e-02, -4.1887e-01,  3.7203e-06,\n",
       "              -7.6349e-03, -3.2538e-01, -5.3197e-03, -1.0181e-01, -1.4090e-01,\n",
       "              -2.4834e-01],\n",
       "             [ 2.5311e-07,  2.6821e-01,  2.9497e-01,  2.8889e-02,  2.1510e-01,\n",
       "               2.0711e-02,  1.3968e-01,  9.8482e-02, -4.4463e-01,  3.1198e-07,\n",
       "              -8.0995e-03, -3.4530e-01, -5.6406e-03, -1.0811e-01, -1.4951e-01,\n",
       "              -2.6364e-01],\n",
       "             [ 5.6841e-06,  1.0875e-01,  1.1961e-01,  1.1693e-02,  8.7100e-02,\n",
       "               8.3869e-03,  5.6820e-02,  4.0049e-02, -2.0191e-01,  5.3817e-08,\n",
       "              -3.6756e-03, -1.5679e-01, -2.5549e-03, -4.9063e-02, -6.7928e-02,\n",
       "              -1.1974e-01],\n",
       "             [ 2.6167e-07,  1.4011e-01,  1.5409e-01,  1.5070e-02,  1.1230e-01,\n",
       "               1.0815e-02,  7.3070e-02,  5.1507e-02, -2.4514e-01, -2.4712e-06,\n",
       "              -4.4625e-03, -1.9036e-01, -3.1045e-03, -5.9588e-02, -8.2442e-02,\n",
       "              -1.4536e-01],\n",
       "             [-1.2119e-06,  3.5059e-01,  3.8557e-01,  3.7772e-02,  2.8116e-01,\n",
       "               2.7078e-02,  1.8263e-01,  1.2877e-01, -5.8485e-01,  1.8503e-07,\n",
       "              -1.0657e-02, -4.5421e-01, -7.4215e-03, -1.4219e-01, -1.9668e-01,\n",
       "              -3.4678e-01],\n",
       "             [-2.5098e-06,  1.5407e-01,  1.6945e-01,  1.6569e-02,  1.2345e-01,\n",
       "               1.1887e-02,  8.0458e-02,  5.6706e-02, -2.8109e-01,  1.5206e-07,\n",
       "              -5.1188e-03, -2.1829e-01, -3.5594e-03, -6.8307e-02, -9.4564e-02,\n",
       "              -1.6668e-01]], device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([[7.8780e-13, 2.4653e-02, 2.9816e-02, 2.8830e-04, 1.5852e-02, 1.4818e-04,\n",
       "              6.7151e-03, 3.3430e-03, 7.3078e-02, 8.1406e-13, 2.4361e-05, 4.4124e-02,\n",
       "              1.1808e-05, 4.3123e-03, 8.2822e-03, 2.5689e-02],\n",
       "             [7.9449e-13, 5.8400e-03, 7.0628e-03, 6.8304e-05, 3.7559e-03, 3.5103e-05,\n",
       "              1.5900e-03, 7.9153e-04, 1.7118e-02, 8.0260e-13, 5.7070e-06, 1.0336e-02,\n",
       "              2.7650e-06, 1.0102e-03, 1.9399e-03, 6.0173e-03],\n",
       "             [7.8763e-13, 2.9112e-02, 3.5205e-02, 3.4063e-04, 1.8731e-02, 1.7492e-04,\n",
       "              7.9136e-03, 3.9396e-03, 8.0479e-02, 8.1439e-13, 2.6835e-05, 4.8589e-02,\n",
       "              1.3023e-05, 4.7509e-03, 9.1171e-03, 2.8287e-02],\n",
       "             [7.9553e-13, 1.7509e-05, 2.1247e-05, 2.0095e-07, 1.0965e-05, 1.0669e-07,\n",
       "              5.1493e-06, 2.5677e-06, 2.5179e-04, 8.0093e-13, 8.4252e-08, 1.5218e-04,\n",
       "              4.0139e-08, 1.4758e-05, 2.8750e-05, 8.8726e-05],\n",
       "             [7.9496e-13, 3.6206e-04, 4.3785e-04, 4.2359e-06, 2.3287e-04, 2.1766e-06,\n",
       "              9.8536e-05, 4.9055e-05, 1.0414e-03, 8.0090e-13, 3.4686e-07, 6.2877e-04,\n",
       "              1.6814e-07, 6.1458e-05, 1.1800e-04, 3.6605e-04],\n",
       "             [7.8403e-13, 6.2501e-02, 7.5579e-02, 7.3143e-04, 4.0223e-02, 3.7549e-04,\n",
       "              1.6976e-02, 8.4511e-03, 1.6804e-01, 8.2095e-13, 5.6018e-05, 1.0145e-01,\n",
       "              2.7196e-05, 9.9209e-03, 1.9033e-02, 5.9058e-02],\n",
       "             [7.8405e-13, 7.4990e-02, 9.0687e-02, 8.7733e-04, 4.8249e-02, 4.5063e-04,\n",
       "              2.0390e-02, 1.0150e-02, 2.1076e-01, 8.1879e-13, 7.0230e-05, 1.2725e-01,\n",
       "              3.4069e-05, 1.2441e-02, 2.3877e-02, 7.4079e-02],\n",
       "             [7.8744e-13, 2.9529e-02, 3.5707e-02, 3.4557e-04, 1.9005e-02, 1.7739e-04,\n",
       "              8.0184e-03, 3.9916e-03, 7.8843e-02, 8.1333e-13, 2.6283e-05, 4.7600e-02,\n",
       "              1.2762e-05, 4.6551e-03, 8.9296e-03, 2.7709e-02],\n",
       "             [7.8927e-13, 1.6595e-02, 2.0071e-02, 1.9410e-04, 1.0675e-02, 9.9756e-05,\n",
       "              4.5174e-03, 2.2487e-03, 4.8937e-02, 8.1096e-13, 1.6297e-05, 2.9546e-02,\n",
       "              7.8986e-06, 2.8883e-03, 5.5451e-03, 1.7201e-02],\n",
       "             [7.8857e-13, 2.2695e-02, 2.7448e-02, 2.6538e-04, 1.4591e-02, 1.3642e-04,\n",
       "              6.1845e-03, 3.0789e-03, 6.7968e-02, 8.1445e-13, 2.2663e-05, 4.1039e-02,\n",
       "              1.0984e-05, 4.0104e-03, 7.7039e-03, 2.3893e-02],\n",
       "             [7.8968e-13, 2.9353e-02, 3.5497e-02, 3.4348e-04, 1.8891e-02, 1.7637e-04,\n",
       "              7.9751e-03, 3.9700e-03, 8.0743e-02, 8.0975e-13, 2.6898e-05, 4.8747e-02,\n",
       "              1.3053e-05, 4.7670e-03, 9.1457e-03, 2.8378e-02],\n",
       "             [7.9226e-13, 1.4335e-02, 1.7335e-02, 1.6774e-04, 9.2265e-03, 8.6138e-05,\n",
       "              3.8943e-03, 1.9385e-03, 3.9630e-02, 8.0534e-13, 1.3194e-05, 2.3925e-02,\n",
       "              6.4014e-06, 2.3398e-03, 4.4886e-03, 1.3928e-02],\n",
       "             [7.8363e-13, 6.3636e-02, 7.6956e-02, 7.4454e-04, 4.0947e-02, 3.8239e-04,\n",
       "              1.7299e-02, 8.6116e-03, 1.7755e-01, 8.2183e-13, 5.9159e-05, 1.0719e-01,\n",
       "              2.8701e-05, 1.0481e-02, 2.0113e-02, 6.2403e-02],\n",
       "             [7.8382e-13, 8.1484e-02, 9.8533e-02, 9.5367e-04, 5.2448e-02, 4.8950e-04,\n",
       "              2.2123e-02, 1.1013e-02, 2.1676e-01, 8.1812e-13, 7.2249e-05, 1.3087e-01,\n",
       "              3.5082e-05, 1.2799e-02, 2.4549e-02, 7.6180e-02],\n",
       "             [7.8614e-13, 5.7809e-02, 6.9911e-02, 6.7622e-04, 3.7183e-02, 3.4740e-04,\n",
       "              1.5730e-02, 7.8309e-03, 1.6502e-01, 8.1736e-13, 5.5022e-05, 9.9635e-02,\n",
       "              2.6687e-05, 9.7395e-03, 1.8699e-02, 5.8006e-02],\n",
       "             [7.8292e-13, 6.5629e-02, 7.9367e-02, 7.6769e-04, 4.2213e-02, 3.9439e-04,\n",
       "              1.7857e-02, 8.8897e-03, 1.8678e-01, 8.2256e-13, 6.2289e-05, 1.1277e-01,\n",
       "              3.0209e-05, 1.1024e-02, 2.1164e-02, 6.5654e-02],\n",
       "             [7.8731e-13, 3.0798e-02, 3.7244e-02, 3.6039e-04, 1.9824e-02, 1.8506e-04,\n",
       "              8.3661e-03, 4.1645e-03, 8.5127e-02, 8.1410e-13, 2.8341e-05, 5.1392e-02,\n",
       "              1.3751e-05, 5.0263e-03, 9.6414e-03, 2.9918e-02],\n",
       "             [7.8726e-13, 2.8812e-02, 3.4844e-02, 3.3702e-04, 1.8535e-02, 1.7315e-04,\n",
       "              7.8397e-03, 3.9024e-03, 8.4126e-02, 8.1466e-13, 2.8022e-05, 5.0785e-02,\n",
       "              1.3589e-05, 4.9654e-03, 9.5317e-03, 2.9566e-02],\n",
       "             [7.9414e-13, 1.4430e-03, 1.7453e-03, 1.6870e-05, 9.2736e-04, 8.6777e-06,\n",
       "              3.9378e-04, 1.9600e-04, 4.5778e-03, 8.0336e-13, 1.5274e-06, 2.7633e-03,\n",
       "              7.3930e-07, 2.7004e-04, 5.1902e-04, 1.6090e-03],\n",
       "             [7.9565e-13, 2.4625e-03, 2.9783e-03, 2.8785e-05, 1.5829e-03, 1.4807e-05,\n",
       "              6.7154e-04, 3.3428e-04, 7.6955e-03, 8.0029e-13, 2.5641e-06, 4.6454e-03,\n",
       "              1.2425e-06, 4.5402e-04, 8.7235e-04, 2.7047e-03],\n",
       "             [7.8611e-13, 3.9980e-02, 4.8347e-02, 4.6787e-04, 2.5732e-02, 2.4021e-04,\n",
       "              1.0859e-02, 5.4057e-03, 1.0888e-01, 8.1607e-13, 3.6277e-05, 6.5730e-02,\n",
       "              1.7604e-05, 6.4283e-03, 1.2331e-02, 3.8264e-02],\n",
       "             [7.9023e-13, 1.3798e-02, 1.6686e-02, 1.6140e-04, 8.8756e-03, 8.2918e-05,\n",
       "              3.7535e-03, 1.8685e-03, 3.9174e-02, 8.1009e-13, 1.3061e-05, 2.3649e-02,\n",
       "              6.3370e-06, 2.3122e-03, 4.4387e-03, 1.3768e-02],\n",
       "             [7.8475e-13, 4.9733e-02, 6.0144e-02, 5.8182e-04, 3.1998e-02, 2.9887e-04,\n",
       "              1.3525e-02, 6.7324e-03, 1.4168e-01, 8.1921e-13, 4.7204e-05, 8.5533e-02,\n",
       "              2.2899e-05, 8.3633e-03, 1.6051e-02, 4.9795e-02],\n",
       "             [7.9179e-13, 5.8669e-03, 7.0957e-03, 6.8603e-05, 3.7724e-03, 3.5274e-05,\n",
       "              1.5989e-03, 7.9588e-04, 1.8058e-02, 8.0634e-13, 6.0181e-06, 1.0900e-02,\n",
       "              2.9151e-06, 1.0655e-03, 2.0467e-03, 6.3465e-03],\n",
       "             [7.8800e-13, 2.7346e-02, 3.3068e-02, 3.2005e-04, 1.7602e-02, 1.6429e-04,\n",
       "              7.4249e-03, 3.6961e-03, 7.3307e-02, 8.1307e-13, 2.4424e-05, 4.4258e-02,\n",
       "              1.1857e-05, 4.3285e-03, 8.3021e-03, 2.5764e-02],\n",
       "             [7.9214e-13, 1.4537e-02, 1.7579e-02, 1.7010e-04, 9.3534e-03, 8.7343e-05,\n",
       "              3.9508e-03, 1.9667e-03, 4.0038e-02, 8.0554e-13, 1.3347e-05, 2.4172e-02,\n",
       "              6.4779e-06, 2.3636e-03, 4.5357e-03, 1.4072e-02],\n",
       "             [7.9625e-13, 9.2087e-05, 1.1121e-04, 1.0856e-06, 5.9896e-05, 5.4984e-07,\n",
       "              2.4183e-05, 1.2041e-05, 4.2884e-05, 7.9979e-13, 1.4037e-08, 2.5966e-05,\n",
       "              7.0144e-09, 2.5741e-06, 4.7655e-06, 1.5057e-05],\n",
       "             [7.8795e-13, 2.7987e-02, 3.3847e-02, 3.2739e-04, 1.8004e-02, 1.6820e-04,\n",
       "              7.6145e-03, 3.7904e-03, 8.0713e-02, 8.1519e-13, 2.6896e-05, 4.8726e-02,\n",
       "              1.3046e-05, 4.7639e-03, 9.1451e-03, 2.8367e-02],\n",
       "             [7.8766e-13, 2.8851e-02, 3.4891e-02, 3.3754e-04, 1.8563e-02, 1.7338e-04,\n",
       "              7.8456e-03, 3.9054e-03, 8.1780e-02, 8.1469e-13, 2.7250e-05, 4.9370e-02,\n",
       "              1.3221e-05, 4.8274e-03, 9.2649e-03, 2.8742e-02],\n",
       "             [7.9457e-13, 7.3360e-04, 8.8705e-04, 8.5894e-06, 4.7236e-04, 4.4074e-06,\n",
       "              1.9896e-04, 9.9048e-05, 1.8830e-03, 8.0115e-13, 6.2695e-07, 1.1369e-03,\n",
       "              3.0443e-07, 1.1121e-04, 2.1319e-04, 6.6177e-04],\n",
       "             [7.9490e-13, 4.0925e-03, 4.9499e-03, 4.7843e-05, 2.6305e-03, 2.4610e-05,\n",
       "              1.1166e-03, 5.5579e-04, 1.3017e-02, 8.0187e-13, 4.3371e-06, 7.8574e-03,\n",
       "              2.1012e-06, 7.6791e-04, 1.4757e-03, 4.5750e-03],\n",
       "             [7.8402e-13, 6.4292e-02, 7.7748e-02, 7.5215e-04, 4.1357e-02, 3.8632e-04,\n",
       "              1.7485e-02, 8.7043e-03, 1.8088e-01, 8.2345e-13, 6.0318e-05, 1.0920e-01,\n",
       "              2.9271e-05, 1.0677e-02, 2.0494e-02, 6.3574e-02],\n",
       "             [7.8591e-13, 6.0881e-02, 7.3630e-02, 7.1199e-04, 3.9157e-02, 3.6595e-04,\n",
       "              1.6577e-02, 8.2518e-03, 1.8184e-01, 8.1900e-13, 6.0565e-05, 1.0978e-01,\n",
       "              2.9354e-05, 1.0731e-02, 2.0605e-02, 6.3915e-02],\n",
       "             [7.8546e-13, 6.5320e-02, 7.8991e-02, 7.6409e-04, 4.2016e-02, 3.9252e-04,\n",
       "              1.7767e-02, 8.8449e-03, 1.8474e-01, 8.1843e-13, 6.1601e-05, 1.1154e-01,\n",
       "              2.9885e-05, 1.0904e-02, 2.0931e-02, 6.4936e-02],\n",
       "             [7.8502e-13, 4.5889e-02, 5.5497e-02, 5.3663e-04, 2.9507e-02, 2.7584e-04,\n",
       "              1.2499e-02, 6.2218e-03, 1.3688e-01, 8.1976e-13, 4.5628e-05, 8.2641e-02,\n",
       "              2.2119e-05, 8.0775e-03, 1.5512e-02, 4.8115e-02],\n",
       "             [7.8548e-13, 4.4384e-02, 5.3674e-02, 5.1922e-04, 2.8553e-02, 2.6671e-04,\n",
       "              1.2072e-02, 6.0094e-03, 1.2615e-01, 8.1832e-13, 4.2044e-05, 7.6165e-02,\n",
       "              2.0394e-05, 7.4464e-03, 1.4292e-02, 4.4341e-02],\n",
       "             [7.9327e-13, 1.0640e-02, 1.2866e-02, 1.2453e-04, 6.8488e-03, 6.3922e-05,\n",
       "              2.8885e-03, 1.4379e-03, 2.8391e-02, 8.0388e-13, 9.4584e-06, 1.7141e-02,\n",
       "              4.5917e-06, 1.6764e-03, 3.2151e-03, 9.9782e-03],\n",
       "             [7.8370e-13, 6.0424e-02, 7.3066e-02, 7.0714e-04, 3.8893e-02, 3.6301e-04,\n",
       "              1.6407e-02, 8.1673e-03, 1.6265e-01, 8.1937e-13, 5.4186e-05, 9.8199e-02,\n",
       "              2.6302e-05, 9.6040e-03, 1.8421e-02, 5.7166e-02],\n",
       "             [7.8323e-13, 8.5758e-02, 1.0371e-01, 1.0032e-03, 5.5169e-02, 5.1535e-04,\n",
       "              2.3323e-02, 1.1610e-02, 2.4343e-01, 8.2106e-13, 8.1130e-05, 1.4697e-01,\n",
       "              3.9355e-05, 1.4369e-02, 2.7578e-02, 8.5562e-02],\n",
       "             [7.8591e-13, 4.0038e-02, 4.8417e-02, 4.6849e-04, 2.5766e-02, 2.4058e-04,\n",
       "              1.0879e-02, 5.4155e-03, 1.1086e-01, 8.1621e-13, 3.6930e-05, 6.6933e-02,\n",
       "              1.7919e-05, 6.5453e-03, 1.2557e-02, 3.8965e-02],\n",
       "             [7.8444e-13, 5.1890e-02, 6.2753e-02, 6.0695e-04, 3.3382e-02, 3.1188e-04,\n",
       "              1.4118e-02, 7.0275e-03, 1.5102e-01, 8.1999e-13, 5.0293e-05, 9.1175e-02,\n",
       "              2.4384e-05, 8.9140e-03, 1.7110e-02, 5.3081e-02],\n",
       "             [7.9168e-13, 7.3268e-03, 8.8594e-03, 8.5765e-05, 4.7170e-03, 4.4014e-05,\n",
       "              1.9879e-03, 9.8960e-04, 1.9170e-02, 8.0587e-13, 6.3855e-06, 1.1573e-02,\n",
       "              3.1007e-06, 1.1321e-03, 2.1707e-03, 6.7372e-03],\n",
       "             [7.9079e-13, 2.2803e-02, 2.7574e-02, 2.6686e-04, 1.4677e-02, 1.3700e-04,\n",
       "              6.1927e-03, 3.0828e-03, 6.1666e-02, 8.0785e-13, 2.0544e-05, 3.7230e-02,\n",
       "              9.9751e-06, 3.6410e-03, 6.9839e-03, 2.1673e-02],\n",
       "             [7.8820e-13, 2.5114e-02, 3.0370e-02, 2.9384e-04, 1.6161e-02, 1.5090e-04,\n",
       "              6.8245e-03, 3.3972e-03, 6.9382e-02, 8.1301e-13, 2.3119e-05, 4.1889e-02,\n",
       "              1.1218e-05, 4.0961e-03, 7.8589e-03, 2.4386e-02],\n",
       "             [7.9260e-13, 4.1163e-03, 4.9793e-03, 4.8082e-05, 2.6429e-03, 2.4767e-05,\n",
       "              1.1266e-03, 5.6081e-04, 1.4303e-02, 8.0670e-13, 4.7684e-06, 8.6351e-03,\n",
       "              2.3066e-06, 8.4330e-04, 1.6222e-03, 5.0283e-03],\n",
       "             [7.9161e-13, 6.8401e-03, 8.2727e-03, 7.9974e-05, 4.3973e-03, 4.1127e-05,\n",
       "              1.8647e-03, 9.2824e-04, 2.1083e-02, 8.0726e-13, 7.0251e-06, 1.2729e-02,\n",
       "              3.4035e-06, 1.2439e-03, 2.3896e-03, 7.4109e-03],\n",
       "             [7.8546e-13, 4.2932e-02, 5.1917e-02, 5.0230e-04, 2.7623e-02, 2.5798e-04,\n",
       "              1.1671e-02, 5.8097e-03, 1.2007e-01, 8.1712e-13, 4.0011e-05, 7.2489e-02,\n",
       "              1.9412e-05, 7.0879e-03, 1.3601e-02, 4.2201e-02],\n",
       "             [7.9112e-13, 8.2745e-03, 1.0009e-02, 9.6682e-05, 5.3153e-03, 4.9766e-05,\n",
       "              2.2616e-03, 1.1257e-03, 2.7728e-02, 8.0914e-13, 9.2407e-06, 1.6741e-02,\n",
       "              4.4720e-06, 1.6353e-03, 3.1442e-03, 9.7477e-03]], device='cuda:0')},\n",
       "    8: {'step': tensor(8.),\n",
       "     'exp_avg': tensor([[ 7.6217e-06,  4.0528e+01,  4.4532e+01,  4.3806e+00,  3.2411e+01,\n",
       "               3.1163e+00,  2.0941e+01,  1.4838e+01, -1.3242e+01,  3.9239e-06,\n",
       "              -2.4174e-01, -1.0262e+01, -1.6847e-01, -3.2170e+00, -4.4575e+00,\n",
       "              -7.8282e+00]], device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([[3.2080e-12, 5.7396e+02, 6.9286e+02, 6.7536e+00, 3.6723e+02, 3.4178e+00,\n",
       "              1.5348e+02, 7.7154e+01, 6.1867e+01, 1.4238e-12, 2.0568e-02, 3.7123e+01,\n",
       "              9.9892e-03, 3.6555e+00, 6.9995e+00, 2.1626e+01]], device='cuda:0')},\n",
       "    9: {'step': tensor(8.),\n",
       "     'exp_avg': tensor([-1.6887e-06], device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([3.6822e-12], device='cuda:0')},\n",
       "    10: {'step': tensor(8.),\n",
       "     'exp_avg': tensor([[-0.2537,  0.2759, -0.2634, -0.6151, -0.5208,  0.1322,  0.4028, -0.3015,\n",
       "              -0.7739, -0.2043,  0.4364,  0.2376, -0.4496,  0.6025,  0.9300, -0.5683,\n",
       "               0.2139, -0.2426, -0.7767,  0.4694,  0.2213, -0.1329,  0.2498,  0.1841,\n",
       "              -0.3247,  0.5127, -0.0769, -0.9018, -0.8254, -0.3299,  0.8420, -0.1529,\n",
       "               1.1461,  0.6034, -0.6970, -0.1195,  0.2183, -0.0880,  0.8548, -0.1842,\n",
       "              -0.8506, -0.4863,  0.9450, -0.7990, -0.6238, -0.4646, -0.4639, -0.1761]],\n",
       "            device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([[0.0227, 0.0267, 0.0243, 0.1327, 0.0954, 0.0061, 0.0567, 0.0319, 0.2106,\n",
       "              0.0146, 0.0669, 0.0199, 0.0710, 0.1272, 0.3032, 0.1133, 0.0161, 0.0207,\n",
       "              0.2118, 0.0772, 0.0172, 0.0061, 0.0218, 0.0119, 0.0370, 0.0923, 0.0022,\n",
       "              0.2851, 0.2392, 0.0382, 0.2486, 0.0082, 0.4602, 0.1273, 0.1706, 0.0050,\n",
       "              0.0167, 0.0028, 0.2562, 0.0120, 0.2538, 0.0829, 0.3129, 0.2243, 0.1366,\n",
       "              0.0757, 0.0756, 0.0109]], device='cuda:0')},\n",
       "    11: {'step': tensor(8.),\n",
       "     'exp_avg': tensor([-3.2039e-06], device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([1.3712e-12], device='cuda:0')},\n",
       "    12: {'step': tensor(8.),\n",
       "     'exp_avg': tensor([209.6822, 436.7199, 344.2280,  83.4900, 103.8852, 279.5186, 227.2372,\n",
       "              88.9310, 264.0051, 257.8671, 182.8367,  85.7994, 228.7001, 213.4726,\n",
       "             135.5870, 161.9762, 226.4550,  96.2078, 205.7529, 277.4391, 206.0604,\n",
       "             431.7364,  17.9314, 181.6440,  40.4010, 372.2743, 211.1828, 168.8148,\n",
       "             -17.2502, 219.3414], device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([15454.0859, 67068.4062, 41655.2734,  2451.5251,  3793.4915, 27482.8906,\n",
       "             18148.1602,  2781.9548, 24503.2852, 23373.3359, 11755.7119,  2585.8850,\n",
       "             18379.7188, 16019.0195,  6461.3477,  9228.1729, 18030.5605,  3256.3784,\n",
       "             14888.9795, 27071.7461, 14934.4180, 65525.5352,   113.3313, 11607.0479,\n",
       "               574.4426, 48723.2891, 15674.5645, 10031.5078,   104.7359, 16911.4043],\n",
       "            device='cuda:0')},\n",
       "    13: {'step': tensor(8.),\n",
       "     'exp_avg': tensor([ 212.6319, -269.5852,  257.3539,   88.3166, -170.1887,  222.5039,\n",
       "              253.1317,   87.5294, -237.9497,  253.6333, -213.7322,  157.4947,\n",
       "              214.6361,  229.9334, -198.9491, -260.7745,  233.9953,   17.7831,\n",
       "             -237.1248,  266.9129,  293.9963, -225.9960, -144.0574,  120.9627,\n",
       "             -122.0381, -241.8981, -163.0111,  236.4635, -209.1361, -214.1521],\n",
       "            device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([15895.2461, 25555.1543, 23286.6094,  2742.0352, 10177.6230, 17403.8809,\n",
       "             22528.0684,  2693.0615, 19905.6426, 22618.6074, 16060.7549,  8715.8545,\n",
       "             16190.9727, 18585.1211, 13912.9238, 23913.4395, 19251.9258,   111.2641,\n",
       "             19771.6582, 25050.6719, 30395.0586, 17953.9238,  7291.7520,  5144.7705,\n",
       "              5232.2822, 20570.9746,  9338.2988, 19668.2363, 15406.9297, 16121.8906],\n",
       "            device='cuda:0')},\n",
       "    14: {'step': tensor(8.),\n",
       "     'exp_avg': tensor([[ 6.6360e-04, -8.4414e-04,  9.9578e-04,  ...,  9.1082e-04,\n",
       "              -3.0539e-04, -6.0893e-04],\n",
       "             [ 3.1314e-04, -4.9182e-04,  4.9027e-04,  ...,  6.2552e-04,\n",
       "              -3.8567e-04, -4.8850e-04],\n",
       "             [-3.4851e+00,  6.5062e+00, -5.3984e+00,  ..., -3.4602e+00,\n",
       "              -5.6336e-01,  2.0765e+00],\n",
       "             ...,\n",
       "             [ 5.0978e+00, -1.0114e+01,  1.0683e+01,  ...,  6.1866e+00,\n",
       "               1.7338e-01, -6.2417e+00],\n",
       "             [ 3.2060e+01, -5.9124e+01,  5.0375e+01,  ...,  3.2155e+01,\n",
       "               9.4324e+00, -3.5786e+01],\n",
       "             [ 6.1161e+01, -1.1663e+02,  1.1209e+02,  ...,  6.7288e+01,\n",
       "               4.5748e+00, -6.3453e+01]], device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([[1.9417e-07, 3.1315e-07, 4.3494e-07,  ..., 3.6424e-07, 4.1879e-08,\n",
       "              1.6316e-07],\n",
       "             [4.3996e-08, 1.0723e-07, 1.0657e-07,  ..., 1.7269e-07, 6.6323e-08,\n",
       "              1.0581e-07],\n",
       "             [4.3593e+00, 1.5320e+01, 1.0586e+01,  ..., 4.2150e+00, 1.1767e-01,\n",
       "              1.5824e+00],\n",
       "             ...,\n",
       "             [9.1621e+00, 3.6068e+01, 4.0220e+01,  ..., 1.3495e+01, 1.0314e-02,\n",
       "              1.3732e+01],\n",
       "             [3.6176e+02, 1.2303e+03, 8.9312e+02,  ..., 3.6389e+02, 3.1313e+01,\n",
       "              4.5072e+02],\n",
       "             [1.3165e+03, 4.7874e+03, 4.4223e+03,  ..., 1.5935e+03, 7.3659e+00,\n",
       "              1.4170e+03]], device='cuda:0')},\n",
       "    15: {'step': tensor(8.),\n",
       "     'exp_avg': tensor([ 6.3390e-04,  4.1197e-04, -3.6043e+00,  4.4082e+01,  2.5400e+01,\n",
       "              2.1132e+01,  3.6524e+01,  5.5329e+01,  3.7228e+01,  1.1876e+01,\n",
       "              4.8278e-05,  5.8244e-04,  5.7869e+01,  7.8105e+01,  8.6628e-04,\n",
       "             -2.7006e-02, -1.4100e+01,  4.6146e-05, -8.0097e+00,  4.4413e-01,\n",
       "              4.7674e+01,  5.7151e-04,  7.8919e-04,  1.2967e-03,  7.1277e+01,\n",
       "              4.0077e+01,  4.3084e+01,  1.7621e+01,  2.3380e+01, -1.1461e+00,\n",
       "              3.7318e+01,  1.2524e-03,  4.5936e+01,  6.2279e+01,  5.3202e-04,\n",
       "              2.0338e-05,  3.7500e+01,  7.5837e+01,  5.9509e+01,  3.9020e-05,\n",
       "              5.0282e-04,  7.3018e-04,  1.2981e-03,  6.9080e-04,  4.9304e+01,\n",
       "              3.2745e+01,  7.3974e+01,  1.2971e-03,  1.1965e-03,  5.2182e+01,\n",
       "              3.7522e+01,  6.8848e+01,  7.5696e+01, -2.8911e+01,  4.7845e+01,\n",
       "              2.0981e+01,  2.1341e+01,  1.0556e-03,  4.8098e+01,  4.7339e-03,\n",
       "              2.1700e+01,  5.9528e+00,  3.3915e+01,  6.7813e+01], device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([1.7731e-07, 7.5549e-08, 4.7656e+00, 6.8391e+02, 2.2700e+02, 1.5717e+02,\n",
       "             4.6951e+02, 1.0775e+03, 4.8779e+02, 4.9534e+01, 1.1940e-09, 1.4936e-07,\n",
       "             1.1787e+03, 2.1479e+03, 3.2969e-07, 5.7491e-05, 7.0441e+01, 1.1459e-09,\n",
       "             2.2724e+01, 6.9425e-02, 7.9991e+02, 1.4438e-07, 2.7394e-07, 7.3575e-07,\n",
       "             1.7881e+03, 5.6528e+02, 6.5341e+02, 1.0928e+02, 1.9239e+02, 4.9187e-01,\n",
       "             4.9004e+02, 6.8657e-07, 7.4245e+02, 1.3651e+03, 1.2529e-07, 1.7180e-10,\n",
       "             4.9473e+02, 2.0241e+03, 1.2464e+03, 8.5014e-10, 1.1203e-07, 2.3475e-07,\n",
       "             7.3618e-07, 2.1028e-07, 8.5565e+02, 3.7738e+02, 1.9262e+03, 7.3620e-07,\n",
       "             6.2690e-07, 9.5837e+02, 4.9551e+02, 1.6685e+03, 2.0166e+03, 2.9527e+02,\n",
       "             8.0573e+02, 1.5493e+02, 1.6029e+02, 4.8844e-07, 8.1421e+02, 4.2066e-06,\n",
       "             1.6546e+02, 1.2496e+01, 4.0483e+02, 1.6185e+03], device='cuda:0')},\n",
       "    16: {'step': tensor(8.),\n",
       "     'exp_avg': tensor([[-2.9825e-01, -3.0091e-01, -1.1455e+00,  ..., -4.8489e+00,\n",
       "              -3.2467e-01, -1.1978e+00],\n",
       "             [-1.2179e+00, -1.2167e+00, -1.6657e+00,  ..., -3.8029e+01,\n",
       "              -1.3027e+00, -4.4502e+00],\n",
       "             [ 8.8458e-05,  3.7462e-04,  8.8458e-05,  ...,  4.0802e-04,\n",
       "               8.9415e-05,  8.8458e-05],\n",
       "             ...,\n",
       "             [ 2.5049e+00,  2.5045e+00,  5.4491e+00,  ...,  8.4211e+01,\n",
       "               2.7596e+00,  9.6439e+00],\n",
       "             [ 2.8462e-04,  8.0310e-04,  8.1161e-03,  ...,  5.4417e-04,\n",
       "               3.1663e-04,  3.1759e-04],\n",
       "             [ 1.3985e-05, -1.6378e-04,  1.3985e-05,  ...,  7.5089e-05,\n",
       "               1.3029e-05,  1.3029e-05]], device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([[3.0141e-02, 3.0146e-02, 6.2953e-01,  ..., 8.1528e+00, 3.6096e-02,\n",
       "              5.0321e-01],\n",
       "             [5.1500e-01, 5.1501e-01, 1.5164e+00,  ..., 5.0871e+02, 6.0274e-01,\n",
       "              6.9791e+00],\n",
       "             [3.8097e-09, 6.2628e-08, 3.8097e-09,  ..., 7.4125e-08, 3.8879e-09,\n",
       "              3.8097e-09],\n",
       "             ...,\n",
       "             [2.2111e+00, 2.2111e+00, 1.0352e+01,  ..., 2.4970e+03, 2.6833e+00,\n",
       "              3.2743e+01],\n",
       "             [1.1598e-08, 1.8955e-07, 9.6298e-06,  ..., 7.1509e-08, 1.5826e-08,\n",
       "              1.5966e-08],\n",
       "             [1.6076e-10, 1.2398e-08, 1.6076e-10,  ..., 2.8001e-09, 1.4521e-10,\n",
       "              1.4521e-10]], device='cuda:0')},\n",
       "    17: {'step': tensor(8.),\n",
       "     'exp_avg': tensor([-1.7941e+00, -7.4161e+00,  5.7560e-04,  2.4879e+01,  1.6021e-03,\n",
       "              2.6467e+01,  5.0874e-03,  2.7320e+01,  8.2575e-04, -9.0456e-04,\n",
       "              5.3224e-05,  1.0466e-03,  2.1776e+01,  9.1960e-04,  3.4009e-02,\n",
       "              1.5619e-03,  2.7242e-04,  4.4849e-04,  1.8432e+01,  2.2609e+01,\n",
       "              1.8718e+01,  5.5465e-04, -1.7419e+01,  1.3117e-04,  1.7454e+01,\n",
       "              1.1644e-03,  7.2010e-03,  2.3575e+01, -1.7251e-03, -1.0154e+01,\n",
       "              2.3405e+01, -2.0116e-02,  2.6963e+01,  1.8503e+01,  2.1790e+01,\n",
       "              1.9231e+01,  1.2966e-03, -1.3072e+01,  6.8205e-04,  1.2644e-03,\n",
       "             -3.2433e-02,  3.2461e-02,  1.7135e-03, -9.0784e-03,  3.0188e+01,\n",
       "              2.1911e-04,  1.9681e+01,  1.0396e-02,  2.3561e+01,  1.5777e-03,\n",
       "              3.9940e+00,  1.4390e-03,  2.2031e-04,  1.7105e+01,  1.2787e-03,\n",
       "              1.3318e-04,  1.1810e+01,  1.1451e-03,  2.0605e+01,  2.1789e-02,\n",
       "              3.5167e-04,  3.0111e-04,  1.9035e+01, -1.2367e-03,  2.9228e+01,\n",
       "             -1.0102e-02,  1.5831e+01,  2.6363e+01,  2.0470e+01,  2.6802e+01,\n",
       "              2.2560e+01,  1.4004e+01,  1.8767e-03, -8.9176e-03,  2.3265e+01,\n",
       "             -1.4789e+01,  2.4768e+01,  1.6332e-03,  1.1110e+01,  4.8302e-04,\n",
       "              6.3622e-04,  1.3309e-02,  1.6168e+00, -9.6464e-03, -1.1956e-02,\n",
       "              2.6711e+01,  2.0541e-03,  1.0784e-02, -2.4372e+00,  2.2127e-04,\n",
       "              1.3631e-03,  6.1518e-04, -3.7814e-03,  4.9850e-04, -1.2989e+01,\n",
       "              1.7390e+01,  8.5286e-04,  7.3514e-04,  1.6769e-03,  3.8762e-04,\n",
       "              1.4847e-03,  2.4445e+01,  3.2662e-03,  3.4282e-02,  7.0541e-04,\n",
       "              1.3845e+01,  5.9083e-04,  2.8832e+01,  1.9858e-03,  2.3676e+01,\n",
       "             -3.9684e-02,  2.8004e+01, -8.3277e+00,  2.5009e+01,  1.1905e-05,\n",
       "              5.1930e-04,  1.5285e+01,  4.5586e+00,  1.5873e-02,  8.3627e-05,\n",
       "              2.5890e-04,  3.4915e+01,  1.7283e-04, -1.9743e+01,  1.8029e+01,\n",
       "              1.5465e+01,  1.9853e-03,  1.1086e-04], device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([1.1489e+00, 1.9631e+01, 1.4644e-07, 2.1805e+02, 1.1214e-06, 2.4721e+02,\n",
       "             6.8759e-06, 2.6270e+02, 2.9973e-07, 3.9422e-06, 1.4832e-09, 4.8023e-07,\n",
       "             1.6691e+02, 3.7125e-07, 6.3058e-05, 2.5415e-07, 3.3461e-08, 8.9355e-08,\n",
       "             1.1982e+02, 1.8014e+02, 1.2330e+02, 1.3606e-07, 1.0731e+02, 8.0750e-09,\n",
       "             1.0723e+02, 5.9379e-07, 1.0339e-05, 1.9561e+02, 5.1380e-05, 3.6574e+01,\n",
       "             1.9310e+02, 7.0980e-05, 2.5600e+02, 1.2051e+02, 1.6716e+02, 1.3058e+02,\n",
       "             7.3562e-07, 6.0491e+01, 2.0503e-07, 6.9858e-07, 1.0895e-04, 6.3302e-05,\n",
       "             5.4768e-07, 6.4894e-06, 3.2077e+02, 2.1844e-08, 1.3634e+02, 1.7299e-05,\n",
       "             1.9538e+02, 1.0876e-06, 5.6167e+00, 1.5081e-05, 2.2079e-08, 1.0309e+02,\n",
       "             7.1560e-07, 8.3152e-09, 4.9284e+01, 5.7439e-07, 1.4946e+02, 6.7384e-05,\n",
       "             5.4959e-08, 4.0731e-08, 1.2753e+02, 1.1530e-05, 3.0062e+02, 3.3120e-05,\n",
       "             8.8224e+01, 2.4463e+02, 1.4747e+02, 2.5284e+02, 1.7914e+02, 6.9001e+01,\n",
       "             1.5373e-06, 1.9685e-05, 1.9050e+02, 7.7271e+01, 2.1592e+02, 1.1652e-06,\n",
       "             4.3466e+01, 1.0347e-07, 1.7860e-07, 5.6126e-05, 9.2021e-01, 6.6951e-05,\n",
       "             1.2449e-05, 2.5115e+02, 1.8390e-06, 2.3952e-05, 2.1034e+00, 2.2267e-08,\n",
       "             4.5112e-07, 1.6707e-07, 7.8724e-06, 1.1014e-07, 5.9807e+01, 1.0645e+02,\n",
       "             3.1961e-07, 2.3793e-07, 3.5352e-07, 6.6986e-08, 9.6356e-07, 2.1034e+02,\n",
       "             3.0520e-06, 6.8981e-05, 2.1920e-07, 6.7431e+01, 1.5421e-07, 2.9257e+02,\n",
       "             1.7207e-06, 1.9731e+02, 1.2035e-04, 2.7602e+02, 2.4456e+01, 2.2015e+02,\n",
       "             1.2795e-10, 1.1942e-07, 8.2231e+01, 7.3143e+00, 4.5429e-05, 3.4270e-09,\n",
       "             3.0280e-08, 4.2911e+02, 1.3761e-08, 1.3788e+02, 1.1442e+02, 8.4280e+01,\n",
       "             6.0755e-07, 5.8497e-09], device='cuda:0')},\n",
       "    18: {'step': tensor(8.),\n",
       "     'exp_avg': tensor([[ 2.4148e-04,  3.9830e-04,  2.4148e-04,  ...,  2.4243e-04,\n",
       "              -2.2198e-03,  1.2385e-03],\n",
       "             [ 5.7674e-03,  2.4633e-03, -5.3483e-03,  ..., -4.9650e-03,\n",
       "               4.2711e-03, -1.4694e-04],\n",
       "             [ 3.2217e-04,  5.7775e-04,  1.8222e-04,  ...,  1.8762e-04,\n",
       "               3.9327e-04, -5.5692e-05],\n",
       "             ...,\n",
       "             [ 4.5053e-05,  5.4309e-05,  6.5269e-05,  ..., -7.0036e-04,\n",
       "               5.6916e-05,  6.4313e-05],\n",
       "             [-1.1503e+01, -2.2046e+01, -1.1345e+00,  ..., -6.9787e+01,\n",
       "              -1.1275e+00,  8.6748e-01],\n",
       "             [ 3.6943e+00,  5.5476e+00,  2.5289e-01,  ..., -2.2163e+00,\n",
       "               2.3841e-01,  2.4899e-01]], device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([[2.6417e-08, 7.0679e-08, 2.6417e-08,  ..., 2.6623e-08, 2.1490e-06,\n",
       "              6.7140e-07],\n",
       "             [1.4812e-05, 2.6406e-06, 4.9571e-06,  ..., 1.1331e-05, 3.6783e-06,\n",
       "              3.5688e-08],\n",
       "             [4.6526e-08, 1.4752e-07, 1.5252e-08,  ..., 1.6142e-08, 6.8928e-08,\n",
       "              1.6111e-09],\n",
       "             ...,\n",
       "             [1.0976e-09, 1.5388e-09, 2.1573e-09,  ..., 2.1545e-07, 1.6764e-09,\n",
       "              2.0992e-09],\n",
       "             [4.7222e+01, 1.7176e+02, 4.4651e-01,  ..., 1.7138e+03, 4.4650e-01,\n",
       "              2.6390e-01],\n",
       "             [4.7852e+00, 1.0845e+01, 2.1312e-02,  ..., 1.7246e+00, 2.1316e-02,\n",
       "              2.1295e-02]], device='cuda:0')},\n",
       "    19: {'step': tensor(8.),\n",
       "     'exp_avg': tensor([ 1.5203e-03,  3.3475e-03,  5.8947e-04,  1.6208e-03,  1.3581e+01,\n",
       "              1.0342e-03,  2.3358e-02,  1.2503e+01, -4.8284e+00,  7.1123e-03,\n",
       "              3.7592e+00, -3.0721e-02,  1.1141e+01,  7.9155e+00, -8.1889e+00,\n",
       "              1.7628e-03,  4.6469e-03,  1.2091e+01,  1.9334e-02,  1.0759e-04,\n",
       "              9.2737e-04,  1.4646e+01,  1.1233e+01,  1.3639e-03,  3.4078e-03,\n",
       "             -1.1921e+00,  7.6125e+00,  1.4847e-02,  2.7808e-03,  2.8448e+00,\n",
       "             -1.0051e+01,  6.7842e-03,  2.3582e-02,  8.7923e+00,  1.0106e+01,\n",
       "              3.6952e+00, -4.6331e+00, -1.4795e+00,  4.9106e-03,  1.3603e+01,\n",
       "              9.2669e-03,  6.5314e+00,  7.6934e-04,  8.5004e+00,  6.2366e-03,\n",
       "              6.9083e+00,  1.3094e+01,  1.3087e+01,  1.0976e+01,  1.5382e+01,\n",
       "              2.4439e-02,  9.1078e+00,  4.5739e-02,  2.5225e-03,  1.8607e-03,\n",
       "              4.4930e-03,  2.2498e-02,  4.3854e-03,  4.1666e-03,  1.2661e+01,\n",
       "             -7.0960e+00,  1.5291e-03,  9.7863e+00,  2.7177e-03,  2.2152e+00,\n",
       "             -2.4741e+00,  1.0768e+01, -5.8438e-01,  1.6872e+00,  2.6153e+00,\n",
       "              1.9608e-03,  3.2162e-03,  1.0404e+01,  9.3760e+00,  2.3754e-03,\n",
       "              8.5177e+00,  5.2888e-03,  2.7796e-03,  1.2411e+01,  4.6340e+00,\n",
       "              9.1318e-04,  4.9432e+00,  6.7420e-03,  1.1246e-03,  7.7873e+00,\n",
       "              1.0348e-03,  1.2520e+01,  1.8050e-03,  9.9982e+00, -4.0233e+00,\n",
       "              1.5670e-02,  8.7939e+00,  2.3807e-03,  1.2141e+01,  1.2755e-02,\n",
       "              1.2749e+01,  1.3885e+01,  2.5689e+00,  1.0825e-02, -3.3592e+00,\n",
       "              4.5894e+00,  3.1432e-03,  1.1745e+01,  5.9915e+00,  1.0885e-02,\n",
       "              1.3131e-03,  2.8635e-03,  5.6059e+00,  1.2343e+01, -6.3729e+00,\n",
       "              3.1539e-03,  9.8043e+00,  1.1898e+01,  5.4756e-03,  1.2530e-03,\n",
       "              6.4864e-04,  1.0713e+01,  4.6974e-03, -2.1309e+00,  5.2056e+00,\n",
       "             -1.4816e+00,  1.2824e+01,  3.0586e-03,  6.6120e-04,  9.5773e+00,\n",
       "              4.2653e-04, -6.9385e+00,  1.5194e+00], device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([1.0102e-06, 3.1407e-06, 1.5351e-07, 1.1477e-06, 6.4916e+01, 4.6893e-07,\n",
       "             9.6705e-05, 5.5038e+01, 8.2368e+00, 9.1438e-06, 4.9720e+00, 1.6161e-04,\n",
       "             4.3685e+01, 2.2051e+01, 2.3589e+01, 1.3568e-06, 4.5020e-06, 5.1451e+01,\n",
       "             8.3904e-05, 5.4208e-09, 3.7752e-07, 7.5500e+01, 4.4436e+01, 8.1364e-07,\n",
       "             3.5823e-06, 5.0550e-01, 2.0400e+01, 3.2353e-05, 3.3692e-06, 2.8499e+00,\n",
       "             3.5512e+01, 5.6323e-06, 1.4798e-04, 2.7229e+01, 3.5982e+01, 4.8061e+00,\n",
       "             7.5538e+00, 7.8475e-01, 1.0490e-05, 6.5108e+01, 1.4014e-05, 1.5034e+01,\n",
       "             1.3353e-04, 2.5445e+01, 2.4552e-05, 1.6813e+01, 6.0341e+01, 6.0284e+01,\n",
       "             4.2216e+01, 8.3318e+01, 1.1412e-04, 2.9229e+01, 1.2966e-04, 2.1452e-06,\n",
       "             1.5113e-06, 8.7830e-06, 1.0772e-04, 3.8182e-06, 3.2738e-06, 5.6280e+01,\n",
       "             1.7801e+01, 1.0218e-06, 3.3713e+01, 3.2184e-06, 1.7271e+00, 2.1711e+00,\n",
       "             4.0830e+01, 1.0195e-01, 1.0013e+00, 2.4129e+00, 1.6777e-06, 4.5047e-06,\n",
       "             3.7937e+01, 3.0978e+01, 2.4601e-06, 2.5534e+01, 1.2166e-05, 3.3663e-06,\n",
       "             5.4241e+01, 7.5596e+00, 3.5432e-06, 8.6070e+00, 6.2960e-05, 5.5410e-07,\n",
       "             2.1361e+01, 4.6951e-07, 5.5235e+01, 1.4224e-06, 3.5230e+01, 5.7756e+00,\n",
       "             4.5999e-05, 2.7231e+01, 2.4709e-06, 5.1856e+01, 2.8265e-05, 5.7207e+01,\n",
       "             6.7880e+01, 2.3256e+00, 2.7811e-05, 3.9759e+00, 7.4467e+00, 1.4926e-06,\n",
       "             4.8592e+01, 1.2634e+01, 2.1432e-05, 7.5435e-07, 3.5723e-06, 1.1060e+01,\n",
       "             5.3613e+01, 1.4247e+01, 4.3322e-06, 3.3858e+01, 4.9866e+01, 7.0859e-06,\n",
       "             6.8715e-07, 1.8558e-07, 4.0439e+01, 9.5995e-06, 1.6296e+00, 9.5448e+00,\n",
       "             7.7252e-01, 5.7912e+01, 4.0718e-06, 1.9216e-07, 3.2318e+01, 8.0915e-08,\n",
       "             1.7020e+01, 8.1157e-01], device='cuda:0')},\n",
       "    20: {'step': tensor(8.),\n",
       "     'exp_avg': tensor([[ 7.0794e-05, -2.9306e-04, -1.7375e-03,  ..., -1.1135e-03,\n",
       "               1.7457e-04, -4.2864e-04],\n",
       "             [ 2.4504e+00,  1.2981e-01,  2.4582e+00,  ..., -3.4070e+00,\n",
       "               1.6315e+02, -1.3735e-01],\n",
       "             [ 1.5352e-03,  5.8706e-03, -1.3375e-02,  ...,  2.6095e-03,\n",
       "               2.6263e-03,  1.5440e-03],\n",
       "             ...,\n",
       "             [ 1.4320e-02,  1.6044e-02, -1.1743e-03,  ..., -1.0129e-02,\n",
       "               7.5620e-03,  1.0659e-02],\n",
       "             [ 1.1633e-02,  1.0088e-02,  1.0459e-02,  ..., -1.8214e-02,\n",
       "               4.8262e-03,  8.3820e-03],\n",
       "             [ 5.6596e-03,  2.1320e-03,  7.7095e-03,  ..., -8.1324e-03,\n",
       "               5.1314e-04,  3.3746e-03]], device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([[2.5086e-09, 3.8620e-08, 1.3184e-06,  ..., 5.4330e-07, 1.4031e-08,\n",
       "              8.1707e-08],\n",
       "             [2.1753e+00, 4.3343e-03, 2.1752e+00,  ..., 4.1091e+00, 9.3598e+03,\n",
       "              5.9550e-03],\n",
       "             [1.0300e-06, 1.4987e-05, 7.7707e-05,  ..., 2.9676e-06, 3.0058e-06,\n",
       "              1.0419e-06],\n",
       "             ...,\n",
       "             [8.9074e-05, 1.1181e-04, 6.0388e-07,  ..., 4.4576e-05, 2.4857e-05,\n",
       "              4.9363e-05],\n",
       "             [5.8798e-05, 4.4224e-05, 4.7527e-05,  ..., 1.4409e-04, 1.0132e-05,\n",
       "              3.0535e-05],\n",
       "             [1.3930e-05, 1.9826e-06, 2.5835e-05,  ..., 2.8745e-05, 1.1616e-07,\n",
       "              4.9586e-06]], device='cuda:0')},\n",
       "    21: {'step': tensor(8.),\n",
       "     'exp_avg': tensor([ 4.6123e-04,  1.5374e+01,  9.5062e-03,  8.1253e+00,  7.5620e-03,\n",
       "              1.6697e-02,  4.0853e+00,  3.6042e-04,  5.3216e+00,  5.9423e-04,\n",
       "              2.6815e-02,  1.3469e+01,  1.7489e+01, -4.3828e-01,  1.3577e-02,\n",
       "              2.6617e+00,  1.6600e+01,  1.7518e-03,  1.9037e+01,  2.3065e-02,\n",
       "              3.3642e-03,  3.4781e-02,  6.1699e+00,  1.2483e+01,  1.1596e+01,\n",
       "              1.0654e+01,  1.1180e+01,  1.1859e-02,  1.0121e+01,  3.0649e-02,\n",
       "              1.9740e-02,  5.5780e-03], device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([9.4443e-08, 8.2892e+01, 3.9269e-05, 2.3267e+01, 2.4856e-05, 1.2109e-04,\n",
       "             5.8767e+00, 5.8032e-08, 9.9669e+00, 1.5598e-07, 3.1224e-04, 6.3881e+01,\n",
       "             1.0776e+02, 1.3462e-01, 8.0079e-05, 2.4954e+00, 9.7344e+01, 1.3401e-06,\n",
       "             1.2747e+02, 2.3103e-04, 4.9281e-06, 5.2527e-04, 1.3406e+01, 5.4740e+01,\n",
       "             4.7168e+01, 4.0088e+01, 4.3998e+01, 6.1103e-05, 3.6047e+01, 4.0789e-04,\n",
       "             1.6923e-04, 1.3531e-05], device='cuda:0')},\n",
       "    22: {'step': tensor(8.),\n",
       "     'exp_avg': tensor([[-4.4643e+00,  1.4971e+03,  4.2662e+00,  9.3569e+02, -1.3862e+00,\n",
       "              -5.2828e+00,  4.0074e+02,  4.1050e+00,  5.9217e+01, -8.1186e+00,\n",
       "              -6.9532e+00,  6.9119e+02,  5.3854e+02,  5.5461e+01, -6.6644e-01,\n",
       "               4.2693e+02,  6.4591e+02, -9.4273e-01,  1.3101e+03, -1.3301e+00,\n",
       "              -1.0534e+00, -8.1608e-01,  7.4730e+02,  1.4674e+03,  5.6223e+01,\n",
       "               1.0171e+03,  3.5726e+02,  3.8330e+00,  1.1757e+03, -4.9639e-01,\n",
       "               4.5960e+00, -1.7199e+00]], device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([[7.7133e+00, 7.8827e+05, 6.2444e+00, 3.0817e+05, 6.4154e-01, 1.0167e+01,\n",
       "              5.6592e+04, 6.2496e+00, 1.2402e+03, 2.3901e+01, 1.8870e+01, 1.6816e+05,\n",
       "              1.0197e+05, 1.5224e+03, 1.3927e-01, 6.4141e+04, 1.4701e+05, 3.0274e-01,\n",
       "              6.0391e+05, 6.4068e-01, 3.7735e-01, 3.0497e-01, 1.9659e+05, 7.5771e+05,\n",
       "              1.1021e+03, 3.6380e+05, 4.4869e+04, 6.2581e+00, 4.8642e+05, 1.4051e-01,\n",
       "              6.2497e+00, 1.2011e+00]], device='cuda:0')},\n",
       "    23: {'step': tensor(8.),\n",
       "     'exp_avg': tensor([25.3694], device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([237.9591], device='cuda:0')}},\n",
       "   'param_groups': [{'lr': 0.050000000000000024,\n",
       "     'betas': (0.9, 0.999),\n",
       "     'eps': 1e-08,\n",
       "     'weight_decay': 0,\n",
       "     'amsgrad': False,\n",
       "     'maximize': False,\n",
       "     'foreach': None,\n",
       "     'capturable': False,\n",
       "     'differentiable': False,\n",
       "     'fused': None,\n",
       "     'initial_lr': 0.10000000000000005,\n",
       "     'params': [0,\n",
       "      1,\n",
       "      2,\n",
       "      3,\n",
       "      4,\n",
       "      5,\n",
       "      6,\n",
       "      7,\n",
       "      8,\n",
       "      9,\n",
       "      10,\n",
       "      11,\n",
       "      12,\n",
       "      13,\n",
       "      14,\n",
       "      15,\n",
       "      16,\n",
       "      17,\n",
       "      18,\n",
       "      19,\n",
       "      20,\n",
       "      21,\n",
       "      22,\n",
       "      23]}]}],\n",
       " 'lr_schedulers': [{'base_lrs': [0.10000000000000005],\n",
       "   'last_epoch': 2,\n",
       "   'verbose': False,\n",
       "   '_step_count': 3,\n",
       "   '_get_lr_called_within_step': False,\n",
       "   '_last_lr': [0.050000000000000024],\n",
       "   'lr_lambdas': [None]}],\n",
       " 'hparams_name': 'kwargs',\n",
       " 'hyper_parameters': {'config': Config(lr_max=0.1, l1_lambda=1e-05, num_nodes_choices=[30], sync_batchnorm=False, grace_period=5, gat_heads=[1, 2, 4, 8], lr_min=0.1, modality_choices=['plasma'], batch_size_choices=[8], num_nodes=30, precision='32-true', l1_lambda_max=1e-05, weight_decay=0, lr_scheduler_choices=['LambdaLR'], gat={'num_layers': 2, 'hidden_channels': 256, 'heads': 4, 'v2': True}, mutation_choices=[['GRN']], gpu_per_worker=1, accumulate_grad_batches=1, adj_thresh=0.1, sex=['M'], sex_choices=[['M']], reduction_factor=8, gcn_hidden_channels=[8, 32, 128], cpu_per_worker=16, gat_v4_heads=[[2, 3]], ray_results_dir='/scratch/lcornelis/outputs/ray_results', batch_size=8, gat_v4_fc_dim=[[64, 128, 128, 32]], dropout=0, nodes_count=1, pin_memory=True, gat_v4_fc_act=['relu'], gcn_num_layers=[2, 3, 4], dataset_name='ftd', ray_tmp_dir='/scratch/lcornelis/tmp', l1_lambda_min=1e-05, wgcna_minModuleSize=10, optimizer='Adam', wandb_api_key_path='wandb_api_key.txt', device=[0], lr=0.10000000000000005, gat_hidden_channels=[8, 32, 128, 256], checkpoint_every_n_epochs_train=1, model_grid_search=['gat-v4'], act_choices=['relu'], epochs=5, checkpoint_dir='/scratch/lcornelis/outputs/checkpoints', error_protein_file_name='bimodal_aptamers_for_removal.xlsx', num_workers=16, num_samples=1, num_to_keep=3, project='proteo', wandb_offline=False, gat_num_layers=[2, 4, 6, 12], gat_v4_fc_dropout=[0.1], wgcna_mergeCutHeight=0.25, modality='plasma', output_dir='/scratch/lcornelis/outputs', wandb_tmp_dir='/tmp', log_every_n_steps=10, act='relu', gcn={'num_layers': 3, 'hidden_channels': 32}, use_progress_bar=True, y_val='nfl', dropout_choices=[0], gat_v4_weight_initializer=['uniform'], gat_v4_hidden_channels=[[8, 16]], adj_thresh_choices=[0.1], gat-v4={'hidden_channels': [8, 16], 'heads': [2, 3], 'use_layer_norm': True, 'which_layer': ['layer1', 'layer2', 'layer3'], 'fc_dim': [64, 128, 128, 32], 'fc_dropout': 0.1, 'fc_act': 'relu', 'weight_initializer': 'uniform', 'num_layers': None}, lr_scheduler='LambdaLR', data_dir='/home/data/data_louisa', seed=19543, mutation=['GRN'], y_val_choices=['nfl'], raw_file_name='ALLFTD_dataset_for_nina_louisa_071124.csv', model='gat-v4', root_dir='/home/lcornelis/code/proteo', trainer_accelerator='gpu'),\n",
       "  'in_channels': 1,\n",
       "  'out_channels': 1,\n",
       "  'avg_node_degree': 0.9,\n",
       "  'pos_weight': 1.0,\n",
       "  'focal_loss_weight': [1.0]}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in train and test datasets using config\n",
    "# run model and get val_targets val_preds train_targets train_preds\n",
    "# find loss for each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proteo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
