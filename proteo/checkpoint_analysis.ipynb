{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import train as proteo_train\n",
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "from proteo.datasets.ftd import FTDDataset, reverse_log_transform\n",
    "import torch.nn.functional as F\n",
    "import pytorch_lightning as pl\n",
    "from scipy.stats import zscore\n",
    "from proteo.checkpoint_analysis import full_load_and_run_and_convert, process_checkpoints"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint from: /scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_10-30-17/model=gat-v4,seed=3784_347_act=elu,adj_thresh=0.0500,batch_size=8,dropout=0.1000,l1_lambda=0.0010,lr=0.0007,lr_scheduler=CosineAnn_2024-08-01_11-17-45/checkpoint_000101\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Proteo:\n\tMissing key(s) in state_dict: \"model.sex_encoder.weight\", \"model.mutation_encoder.weight\", \"model.age_encoder.weight\", \"model.age_encoder.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 28\u001b[0m\n\u001b[1;32m     18\u001b[0m c9_BEST_RUNS_F\u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_10-30-17/model=gat-v4,seed=15140_461_act=tanh,adj_thresh=0.5000,batch_size=8,dropout=0.1000,l1_lambda=0.0001,lr=0.0002,lr_scheduler=CosineA_2024-08-01_11-48-59/checkpoint_000016\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_10-30-17/model=gat-v4,seed=29159_100_act=sigmoid,adj_thresh=0.1000,batch_size=50,dropout=0.1000,l1_lambda=0.0004,lr=0.0005,lr_scheduler=Lam_2024-08-01_10-30-18/checkpoint_000249\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     21\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_10-30-17/model=gat-v4,seed=44912_137_act=leaky_relu,adj_thresh=0.9000,batch_size=8,dropout=0,l1_lambda=0.0037,lr=0.0229,lr_scheduler=StepLR_2024-08-01_10-30-18/checkpoint_000009\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     22\u001b[0m ]\n\u001b[1;32m     23\u001b[0m c9_BEST_RUNS_M_F\u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_10-30-17/model=gat-v4,seed=40910_881_act=tanh,adj_thresh=0.7000,batch_size=16,dropout=0.1000,l1_lambda=0.0000,lr=0.0037,lr_scheduler=Cosine_2024-08-01_13-32-59/checkpoint_000039\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_10-30-17/model=gat-v4,seed=42404_611_act=leaky_relu,adj_thresh=0.9000,batch_size=16,dropout=0.2000,l1_lambda=0.0000,lr=0.0061,lr_scheduler=_2024-08-01_12-24-45/checkpoint_000146\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_10-30-17/model=gat-v4,seed=40995_232_act=relu,adj_thresh=0.9000,batch_size=8,dropout=0,l1_lambda=0.0001,lr=0.0004,lr_scheduler=ReduceLROnPl_2024-08-01_10-40-25/checkpoint_000027\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     27\u001b[0m ]\n\u001b[0;32m---> 28\u001b[0m \u001b[43mprocess_checkpoints\u001b[49m\u001b[43m(\u001b[49m\u001b[43mc9_BEST_RUNS_M\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc9_mean_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc9_std_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     29\u001b[0m process_checkpoints(c9_BEST_RUNS_F, c9_mean_dict, c9_std_dict, device)\n\u001b[1;32m     30\u001b[0m process_checkpoints(c9_BEST_RUNS_M_F, c9_mean_dict, c9_std_dict, device)\n",
      "File \u001b[0;32m~/code/proteo/proteo/checkpoint_analysis.py:137\u001b[0m, in \u001b[0;36mprocess_checkpoints\u001b[0;34m(checkpoint_paths, mean_dict, std_dict, device)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m checkpoint_path \u001b[38;5;129;01min\u001b[39;00m checkpoint_paths:\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading checkpoint from: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcheckpoint_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 137\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[43mload_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m     config \u001b[38;5;241m=\u001b[39m load_config(module)\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;28mprint\u001b[39m(config)\n",
      "File \u001b[0;32m~/code/proteo/proteo/checkpoint_analysis.py:58\u001b[0m, in \u001b[0;36mload_checkpoint\u001b[0;34m(relative_checkpoint_path)\u001b[0m\n\u001b[1;32m     55\u001b[0m     checkpoint[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhyper_parameters\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmaster_nodes \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     57\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(checkpoint, relative_checkpoint_path)\n\u001b[0;32m---> 58\u001b[0m module \u001b[38;5;241m=\u001b[39m \u001b[43mproteo_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mProteo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_from_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrelative_checkpoint_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\n",
      "File \u001b[0;32m~/anaconda3/envs/proteo/lib/python3.11/site-packages/pytorch_lightning/utilities/model_helpers.py:125\u001b[0m, in \u001b[0;36m_restricted_classmethod_impl.__get__.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m instance \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_scripting:\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    122\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe classmethod `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmethod\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` cannot be called on an instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    123\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Please call it on the class type and make sure the return value is used.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    124\u001b[0m     )\n\u001b[0;32m--> 125\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/proteo/lib/python3.11/site-packages/pytorch_lightning/core/module.py:1582\u001b[0m, in \u001b[0;36mLightningModule.load_from_checkpoint\u001b[0;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;129m@_restricted_classmethod\u001b[39m\n\u001b[1;32m   1494\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_from_checkpoint\u001b[39m(\n\u001b[1;32m   1495\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m   1501\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Primary way of loading a model from a checkpoint. When Lightning saves a checkpoint it stores the arguments\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;124;03m    passed to ``__init__``  in the checkpoint under ``\"hyper_parameters\"``.\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1580\u001b[0m \n\u001b[1;32m   1581\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1582\u001b[0m     loaded \u001b[38;5;241m=\u001b[39m \u001b[43m_load_from_checkpoint\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1583\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1584\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1585\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhparams_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1587\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1588\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1589\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1590\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(Self, loaded)\n",
      "File \u001b[0;32m~/anaconda3/envs/proteo/lib/python3.11/site-packages/pytorch_lightning/core/saving.py:91\u001b[0m, in \u001b[0;36m_load_from_checkpoint\u001b[0;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _load_state(\u001b[38;5;28mcls\u001b[39m, checkpoint, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, pl\u001b[38;5;241m.\u001b[39mLightningModule):\n\u001b[0;32m---> 91\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43m_load_state\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m     state_dict \u001b[38;5;241m=\u001b[39m checkpoint[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstate_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m state_dict:\n",
      "File \u001b[0;32m~/anaconda3/envs/proteo/lib/python3.11/site-packages/pytorch_lightning/core/saving.py:187\u001b[0m, in \u001b[0;36m_load_state\u001b[0;34m(cls, checkpoint, strict, **cls_kwargs_new)\u001b[0m\n\u001b[1;32m    184\u001b[0m     obj\u001b[38;5;241m.\u001b[39mon_load_checkpoint(checkpoint)\n\u001b[1;32m    186\u001b[0m \u001b[38;5;66;03m# load the state_dict on the model automatically\u001b[39;00m\n\u001b[0;32m--> 187\u001b[0m keys \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstate_dict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m strict:\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m keys\u001b[38;5;241m.\u001b[39mmissing_keys:\n",
      "File \u001b[0;32m~/anaconda3/envs/proteo/lib/python3.11/site-packages/torch/nn/modules/module.py:2152\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2147\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2148\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2149\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2152\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2153\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2154\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Proteo:\n\tMissing key(s) in state_dict: \"model.sex_encoder.weight\", \"model.mutation_encoder.weight\", \"model.age_encoder.weight\", \"model.age_encoder.bias\". "
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "c9_mean_dict = {\"['M']_csf\":2.20139473218633, \n",
    "                \"['F']_plasma\":2.5069125020915246,\n",
    "                \"['F']_csf\":2.3905483112831987,\n",
    "                \"['M', 'F']_plasma\":2.4382370774886417,\n",
    "                \"['M', 'F']_csf\":2.323617044833538}\n",
    "c9_std_dict = {\"['M']_csf\":0.9414006476156331,\n",
    "                \"['F']_plasma\":0.9801098341235991,\n",
    "                \"['F']_csf\":0.95108017948172,\n",
    "                \"['M', 'F']_plasma\":0.9639665529956777,\n",
    "                \"['M', 'F']_csf\":0.951972757962228}\n",
    "\n",
    "c9_BEST_RUNS_M=[\n",
    "    '/scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_10-30-17/model=gat-v4,seed=3784_347_act=elu,adj_thresh=0.0500,batch_size=8,dropout=0.1000,l1_lambda=0.0010,lr=0.0007,lr_scheduler=CosineAnn_2024-08-01_11-17-45/checkpoint_000101',\n",
    "    '/scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_10-30-17/model=gat-v4,seed=36658_797_act=leaky_relu,adj_thresh=0.7000,batch_size=16,dropout=0.1000,l1_lambda=0.0002,lr=0.0010,lr_scheduler=_2024-08-01_13-15-10/checkpoint_000132',\n",
    "    '/scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_10-30-17/model=gat-v4,seed=43041_59_act=leaky_relu,adj_thresh=0.1000,batch_size=32,dropout=0.2000,l1_lambda=0.0033,lr=0.0122,lr_scheduler=C_2024-08-01_10-30-18/checkpoint_000006'\n",
    "]\n",
    "c9_BEST_RUNS_F= [\n",
    "    '/scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_10-30-17/model=gat-v4,seed=15140_461_act=tanh,adj_thresh=0.5000,batch_size=8,dropout=0.1000,l1_lambda=0.0001,lr=0.0002,lr_scheduler=CosineA_2024-08-01_11-48-59/checkpoint_000016',\n",
    "    '/scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_10-30-17/model=gat-v4,seed=29159_100_act=sigmoid,adj_thresh=0.1000,batch_size=50,dropout=0.1000,l1_lambda=0.0004,lr=0.0005,lr_scheduler=Lam_2024-08-01_10-30-18/checkpoint_000249',\n",
    "    '/scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_10-30-17/model=gat-v4,seed=44912_137_act=leaky_relu,adj_thresh=0.9000,batch_size=8,dropout=0,l1_lambda=0.0037,lr=0.0229,lr_scheduler=StepLR_2024-08-01_10-30-18/checkpoint_000009'\n",
    "]\n",
    "c9_BEST_RUNS_M_F= [\n",
    "    '/scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_10-30-17/model=gat-v4,seed=40910_881_act=tanh,adj_thresh=0.7000,batch_size=16,dropout=0.1000,l1_lambda=0.0000,lr=0.0037,lr_scheduler=Cosine_2024-08-01_13-32-59/checkpoint_000039',\n",
    "    '/scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_10-30-17/model=gat-v4,seed=42404_611_act=leaky_relu,adj_thresh=0.9000,batch_size=16,dropout=0.2000,l1_lambda=0.0000,lr=0.0061,lr_scheduler=_2024-08-01_12-24-45/checkpoint_000146',\n",
    "    '/scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_10-30-17/model=gat-v4,seed=40995_232_act=relu,adj_thresh=0.9000,batch_size=8,dropout=0,l1_lambda=0.0001,lr=0.0004,lr_scheduler=ReduceLROnPl_2024-08-01_10-40-25/checkpoint_000027'\n",
    "]\n",
    "process_checkpoints(c9_BEST_RUNS_M, c9_mean_dict, c9_std_dict, device)\n",
    "process_checkpoints(c9_BEST_RUNS_F, c9_mean_dict, c9_std_dict, device)\n",
    "process_checkpoints(c9_BEST_RUNS_M_F, c9_mean_dict, c9_std_dict, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint from: /scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_10-30-17/model=gat-v4,seed=62542_686_act=leaky_relu,adj_thresh=0.0500,batch_size=8,dropout=0.2000,l1_lambda=0.0000,lr=0.0053,lr_scheduler=R_2024-08-01_12-44-53/checkpoint_000024\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Error(s) in loading state_dict for Proteo:\n\tMissing key(s) in state_dict: \"model.sex_encoder.weight\", \"model.mutation_encoder.weight\", \"model.age_encoder.weight\", \"model.age_encoder.bias\". ",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 29\u001b[0m\n\u001b[1;32m     17\u001b[0m MAPT_BEST_RUNS_F\u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     18\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_10-30-17/model=gat-v4,seed=37235_729_act=leaky_relu,adj_thresh=0.9000,batch_size=32,dropout=0,l1_lambda=0.0001,lr=0.0007,lr_scheduler=Reduc_2024-08-01_12-56-46/checkpoint_000015\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_10-30-17/model=gat-v4,seed=46905_207_act=sigmoid,adj_thresh=0.1000,batch_size=32,dropout=0.3000,l1_lambda=0.0003,lr=0.0006,lr_scheduler=Ste_2024-08-01_10-31-43/checkpoint_000028\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     20\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_10-30-17/model=gat-v4,seed=14399_99_act=tanh,adj_thresh=0.7000,batch_size=50,dropout=0.1000,l1_lambda=0.0000,lr=0.0019,lr_scheduler=CosineA_2024-08-01_10-30-18/checkpoint_000027\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     21\u001b[0m ]\n\u001b[1;32m     23\u001b[0m MAPT_BEST_RUNS_M_F\u001b[38;5;241m=\u001b[39m [\n\u001b[1;32m     24\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_10-30-17/model=gat-v4,seed=23432_69_act=sigmoid,adj_thresh=0.9000,batch_size=50,dropout=0,l1_lambda=0.0003,lr=0.0057,lr_scheduler=ReduceLRO_2024-08-01_10-30-18/checkpoint_000009\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     25\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_10-30-17/model=gat-v4,seed=35171_951_act=elu,adj_thresh=0.9000,batch_size=16,dropout=0.0500,l1_lambda=0.0001,lr=0.0019,lr_scheduler=StepLR,_2024-08-01_13-46-49/checkpoint_000008\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     26\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_10-30-17/model=gat-v4,seed=25447_249_act=sigmoid,adj_thresh=0.7000,batch_size=32,dropout=0.2000,l1_lambda=0.0001,lr=0.0101,lr_scheduler=Ste_2024-08-01_10-47-31/checkpoint_000002\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     27\u001b[0m ]\n\u001b[0;32m---> 29\u001b[0m \u001b[43mprocess_checkpoints\u001b[49m\u001b[43m(\u001b[49m\u001b[43mMAPT_BEST_RUNS_M\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMAPT_mean_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mMAPT_std_dict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     30\u001b[0m process_checkpoints(MAPT_BEST_RUNS_F, MAPT_mean_dict, MAPT_std_dict, device)\n\u001b[1;32m     31\u001b[0m process_checkpoints(MAPT_BEST_RUNS_M_F, MAPT_mean_dict, MAPT_std_dict, device)\n",
      "File \u001b[0;32m~/code/proteo/proteo/checkpoint_analysis.py:137\u001b[0m, in \u001b[0;36mprocess_checkpoints\u001b[0;34m(checkpoint_paths, mean_dict, std_dict, device)\u001b[0m\n\u001b[1;32m    135\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m checkpoint_path \u001b[38;5;129;01min\u001b[39;00m checkpoint_paths:\n\u001b[1;32m    136\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoading checkpoint from: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mcheckpoint_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 137\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[43mload_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    138\u001b[0m     config \u001b[38;5;241m=\u001b[39m load_config(module)\n\u001b[1;32m    139\u001b[0m     \u001b[38;5;66;03m#print(\"Config being used:\", config)\u001b[39;00m\n",
      "File \u001b[0;32m~/code/proteo/proteo/checkpoint_analysis.py:58\u001b[0m, in \u001b[0;36mload_checkpoint\u001b[0;34m(relative_checkpoint_path)\u001b[0m\n\u001b[1;32m     55\u001b[0m     checkpoint[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mhyper_parameters\u001b[39m\u001b[38;5;124m'\u001b[39m][\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mconfig\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;241m.\u001b[39mmaster_nodes \u001b[38;5;241m=\u001b[39m []\n\u001b[1;32m     57\u001b[0m torch\u001b[38;5;241m.\u001b[39msave(checkpoint, relative_checkpoint_path)\n\u001b[0;32m---> 58\u001b[0m module \u001b[38;5;241m=\u001b[39m \u001b[43mproteo_train\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mProteo\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_from_checkpoint\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrelative_checkpoint_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m module\n",
      "File \u001b[0;32m~/anaconda3/envs/proteo/lib/python3.11/site-packages/pytorch_lightning/utilities/model_helpers.py:125\u001b[0m, in \u001b[0;36m_restricted_classmethod_impl.__get__.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m instance \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_scripting:\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    122\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe classmethod `\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mcls\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmethod\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m` cannot be called on an instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    123\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m Please call it on the class type and make sure the return value is used.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    124\u001b[0m     )\n\u001b[0;32m--> 125\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmethod\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/proteo/lib/python3.11/site-packages/pytorch_lightning/core/module.py:1582\u001b[0m, in \u001b[0;36mLightningModule.load_from_checkpoint\u001b[0;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[1;32m   1493\u001b[0m \u001b[38;5;129m@_restricted_classmethod\u001b[39m\n\u001b[1;32m   1494\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_from_checkpoint\u001b[39m(\n\u001b[1;32m   1495\u001b[0m     \u001b[38;5;28mcls\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1500\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m   1501\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Self:\n\u001b[1;32m   1502\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Primary way of loading a model from a checkpoint. When Lightning saves a checkpoint it stores the arguments\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m \u001b[38;5;124;03m    passed to ``__init__``  in the checkpoint under ``\"hyper_parameters\"``.\u001b[39;00m\n\u001b[1;32m   1504\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1580\u001b[0m \n\u001b[1;32m   1581\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1582\u001b[0m     loaded \u001b[38;5;241m=\u001b[39m \u001b[43m_load_from_checkpoint\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1583\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1584\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcheckpoint_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1585\u001b[0m \u001b[43m        \u001b[49m\u001b[43mmap_location\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1586\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhparams_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1587\u001b[0m \u001b[43m        \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1588\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1589\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1590\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(Self, loaded)\n",
      "File \u001b[0;32m~/anaconda3/envs/proteo/lib/python3.11/site-packages/pytorch_lightning/core/saving.py:91\u001b[0m, in \u001b[0;36m_load_from_checkpoint\u001b[0;34m(cls, checkpoint_path, map_location, hparams_file, strict, **kwargs)\u001b[0m\n\u001b[1;32m     89\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _load_state(\u001b[38;5;28mcls\u001b[39m, checkpoint, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m     90\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28missubclass\u001b[39m(\u001b[38;5;28mcls\u001b[39m, pl\u001b[38;5;241m.\u001b[39mLightningModule):\n\u001b[0;32m---> 91\u001b[0m     model \u001b[38;5;241m=\u001b[39m \u001b[43m_load_state\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mcls\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     92\u001b[0m     state_dict \u001b[38;5;241m=\u001b[39m checkpoint[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstate_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     93\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m state_dict:\n",
      "File \u001b[0;32m~/anaconda3/envs/proteo/lib/python3.11/site-packages/pytorch_lightning/core/saving.py:187\u001b[0m, in \u001b[0;36m_load_state\u001b[0;34m(cls, checkpoint, strict, **cls_kwargs_new)\u001b[0m\n\u001b[1;32m    184\u001b[0m     obj\u001b[38;5;241m.\u001b[39mon_load_checkpoint(checkpoint)\n\u001b[1;32m    186\u001b[0m \u001b[38;5;66;03m# load the state_dict on the model automatically\u001b[39;00m\n\u001b[0;32m--> 187\u001b[0m keys \u001b[38;5;241m=\u001b[39m \u001b[43mobj\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mload_state_dict\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcheckpoint\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstate_dict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstrict\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstrict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    189\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m strict:\n\u001b[1;32m    190\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m keys\u001b[38;5;241m.\u001b[39mmissing_keys:\n",
      "File \u001b[0;32m~/anaconda3/envs/proteo/lib/python3.11/site-packages/torch/nn/modules/module.py:2152\u001b[0m, in \u001b[0;36mModule.load_state_dict\u001b[0;34m(self, state_dict, strict, assign)\u001b[0m\n\u001b[1;32m   2147\u001b[0m         error_msgs\u001b[38;5;241m.\u001b[39minsert(\n\u001b[1;32m   2148\u001b[0m             \u001b[38;5;241m0\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMissing key(s) in state_dict: \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m. \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2149\u001b[0m                 \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m'\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m k \u001b[38;5;129;01min\u001b[39;00m missing_keys)))\n\u001b[1;32m   2151\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(error_msgs) \u001b[38;5;241m>\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m-> 2152\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mError(s) in loading state_dict for \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m:\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m   2153\u001b[0m                        \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__class__\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\t\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mjoin(error_msgs)))\n\u001b[1;32m   2154\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m _IncompatibleKeys(missing_keys, unexpected_keys)\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Error(s) in loading state_dict for Proteo:\n\tMissing key(s) in state_dict: \"model.sex_encoder.weight\", \"model.mutation_encoder.weight\", \"model.age_encoder.weight\", \"model.age_encoder.bias\". "
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "MAPT_mean_dict = {\"['M']_csf\":2.080694213697065, \n",
    "                \"['M']_plasma\":2.1657279439973016,\n",
    "                \"['F']_csf\":2.0152637385189265,\n",
    "                \"['M', 'F']_csf\": 2.0454624193703754}\n",
    "MAPT_std_dict = {\"['M']_csf\":0.6213240141321779,\n",
    "                \"['M']_plasma\":0.6840496344783593,\n",
    "                \"['F']_csf\":0.7999340389937927,\n",
    "                \"['M', 'F']_csf\":0.7237378322971036}\n",
    "\n",
    "MAPT_BEST_RUNS_M=[\n",
    "    '/scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_10-30-17/model=gat-v4,seed=62542_686_act=leaky_relu,adj_thresh=0.0500,batch_size=8,dropout=0.2000,l1_lambda=0.0000,lr=0.0053,lr_scheduler=R_2024-08-01_12-44-53/checkpoint_000024',\n",
    "    '/scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_10-30-17/model=gat-v4,seed=8990_704_act=leaky_relu,adj_thresh=0.7000,batch_size=32,dropout=0.2000,l1_lambda=0.0002,lr=0.0011,lr_scheduler=L_2024-08-01_12-49-21/checkpoint_000027',\n",
    "    '/scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_10-30-17/model=gat-v4,seed=16742_1047_act=sigmoid,adj_thresh=0.5000,batch_size=16,dropout=0.0500,l1_lambda=0.0000,lr=0.0000,lr_scheduler=La_2024-08-01_14-01-42/checkpoint_000000'\n",
    "]\n",
    "    \n",
    "MAPT_BEST_RUNS_F= [\n",
    "    '/scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_10-30-17/model=gat-v4,seed=37235_729_act=leaky_relu,adj_thresh=0.9000,batch_size=32,dropout=0,l1_lambda=0.0001,lr=0.0007,lr_scheduler=Reduc_2024-08-01_12-56-46/checkpoint_000015',\n",
    "    '/scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_10-30-17/model=gat-v4,seed=46905_207_act=sigmoid,adj_thresh=0.1000,batch_size=32,dropout=0.3000,l1_lambda=0.0003,lr=0.0006,lr_scheduler=Ste_2024-08-01_10-31-43/checkpoint_000028',\n",
    "    '/scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_10-30-17/model=gat-v4,seed=14399_99_act=tanh,adj_thresh=0.7000,batch_size=50,dropout=0.1000,l1_lambda=0.0000,lr=0.0019,lr_scheduler=CosineA_2024-08-01_10-30-18/checkpoint_000027'\n",
    "]\n",
    "\n",
    "MAPT_BEST_RUNS_M_F= [\n",
    "    '/scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_10-30-17/model=gat-v4,seed=23432_69_act=sigmoid,adj_thresh=0.9000,batch_size=50,dropout=0,l1_lambda=0.0003,lr=0.0057,lr_scheduler=ReduceLRO_2024-08-01_10-30-18/checkpoint_000009',\n",
    "    '/scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_10-30-17/model=gat-v4,seed=35171_951_act=elu,adj_thresh=0.9000,batch_size=16,dropout=0.0500,l1_lambda=0.0001,lr=0.0019,lr_scheduler=StepLR,_2024-08-01_13-46-49/checkpoint_000008',\n",
    "    '/scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_10-30-17/model=gat-v4,seed=25447_249_act=sigmoid,adj_thresh=0.7000,batch_size=32,dropout=0.2000,l1_lambda=0.0001,lr=0.0101,lr_scheduler=Ste_2024-08-01_10-47-31/checkpoint_000002'\n",
    "]\n",
    "\n",
    "process_checkpoints(MAPT_BEST_RUNS_M, MAPT_mean_dict, MAPT_std_dict, device)\n",
    "process_checkpoints(MAPT_BEST_RUNS_F, MAPT_mean_dict, MAPT_std_dict, device)\n",
    "process_checkpoints(MAPT_BEST_RUNS_M_F, MAPT_mean_dict, MAPT_std_dict, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint from: /scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_10-30-17/model=gat-v4,seed=52208_883_act=relu,adj_thresh=0.7000,batch_size=8,dropout=0,l1_lambda=0.0002,lr=0.0010,lr_scheduler=ReduceLROnPl_2024-08-01_13-33-15/checkpoint_000020\n",
      "1 best checkpoint for ['M'] and csf\n",
      "Loading data from: /home/data/data_louisa/processed/ftd_y_val_nfl_adj_thresh_0.7_num_nodes_10_mutation_GRN_csf_sex_M_train.pt\n",
      "Loading data from: /home/data/data_louisa/processed/ftd_y_val_nfl_adj_thresh_0.7_num_nodes_10_mutation_GRN_csf_sex_M_test.pt\n",
      "Normalized Val MSE: 0.0497010201215744\n",
      "Normalized train MSE: 0.7081002593040466\n",
      "Original Units Val MSE: tensor(0.2582, grad_fn=<MseLossBackward0>)\n",
      "Original Units Val RMSE: tensor(0.5081, grad_fn=<SqrtBackward0>)\n",
      "Loading checkpoint from: /scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_10-30-17/model=gat-v4,seed=10511_829_act=sigmoid,adj_thresh=0.9000,batch_size=8,dropout=0.3000,l1_lambda=0.0052,lr=0.0010,lr_scheduler=Redu_2024-08-01_13-24-19/checkpoint_000003\n",
      "2 best checkpoint for ['M'] and csf\n",
      "Loading data from: /home/data/data_louisa/processed/ftd_y_val_nfl_adj_thresh_0.9_num_nodes_30_mutation_GRN_csf_sex_M_train.pt\n",
      "Loading data from: /home/data/data_louisa/processed/ftd_y_val_nfl_adj_thresh_0.9_num_nodes_30_mutation_GRN_csf_sex_M_test.pt\n",
      "Normalized Val MSE: 0.17164771258831024\n",
      "Normalized train MSE: 0.6563622355461121\n",
      "Original Units Val MSE: tensor(1.8549, grad_fn=<MseLossBackward0>)\n",
      "Original Units Val RMSE: tensor(1.3619, grad_fn=<SqrtBackward0>)\n",
      "Loading checkpoint from: /scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_10-30-17/model=gat-v4,seed=7148_163_act=sigmoid,adj_thresh=0.1000,batch_size=32,dropout=0.0500,l1_lambda=0.0183,lr=0.0192,lr_scheduler=Step_2024-08-01_10-30-18/checkpoint_000005\n",
      "3 best checkpoint for ['M'] and csf\n",
      "Loading data from: /home/data/data_louisa/processed/ftd_y_val_nfl_adj_thresh_0.1_num_nodes_10_mutation_GRN_csf_sex_M_train.pt\n",
      "Loading data from: /home/data/data_louisa/processed/ftd_y_val_nfl_adj_thresh_0.1_num_nodes_10_mutation_GRN_csf_sex_M_test.pt\n",
      "Normalized Val MSE: 0.22492647171020508\n",
      "Normalized train MSE: 1.5601261854171753\n",
      "Original Units Val MSE: tensor(4.8309, grad_fn=<MseLossBackward0>)\n",
      "Original Units Val RMSE: tensor(2.1979, grad_fn=<SqrtBackward0>)\n",
      "Loading checkpoint from: /scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_17-06-03/model=gat-v4,seed=6059_182_act=relu,adj_thresh=0.1000,batch_size=16,dropout=0.3000,l1_lambda=0.0001,lr=0.0011,lr_scheduler=CosineA_2024-08-01_17-06-04/checkpoint_000065\n",
      "1 best checkpoint for ['F'] and plasma\n",
      "Loading data from: /home/data/data_louisa/processed/ftd_y_val_nfl_adj_thresh_0.1_num_nodes_30_mutation_GRN_plasma_sex_F_train.pt\n",
      "Loading data from: /home/data/data_louisa/processed/ftd_y_val_nfl_adj_thresh_0.1_num_nodes_30_mutation_GRN_plasma_sex_F_test.pt\n",
      "Normalized Val MSE: 0.07332743704319\n",
      "Normalized train MSE: 0.43438684940338135\n",
      "Original Units Val MSE: tensor(274.4327, grad_fn=<MseLossBackward0>)\n",
      "Original Units Val RMSE: tensor(16.5660, grad_fn=<SqrtBackward0>)\n",
      "Loading checkpoint from: /scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_17-06-03/model=gat-v4,seed=42177_32_act=leaky_relu,adj_thresh=0.0500,batch_size=8,dropout=0.1000,l1_lambda=0.0000,lr=0.0072,lr_scheduler=La_2024-08-01_17-06-04/checkpoint_000104\n",
      "2 best checkpoint for ['F'] and plasma\n",
      "Loading data from: /home/data/data_louisa/processed/ftd_y_val_nfl_adj_thresh_0.05_num_nodes_1000_mutation_GRN_plasma_sex_F_train.pt\n",
      "Loading data from: /home/data/data_louisa/processed/ftd_y_val_nfl_adj_thresh_0.05_num_nodes_1000_mutation_GRN_plasma_sex_F_test.pt\n",
      "Normalized Val MSE: 0.07383512705564499\n",
      "Normalized train MSE: 0.1407872438430786\n",
      "Original Units Val MSE: tensor(298.8770, grad_fn=<MseLossBackward0>)\n",
      "Original Units Val RMSE: tensor(17.2881, grad_fn=<SqrtBackward0>)\n",
      "Loading checkpoint from: /scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_17-06-03/model=gat-v4,seed=41068_56_act=tanh,adj_thresh=0.0500,batch_size=50,dropout=0,l1_lambda=0.0011,lr=0.0096,lr_scheduler=CosineAnneal_2024-08-01_17-06-04/checkpoint_000066\n",
      "3 best checkpoint for ['F'] and plasma\n",
      "Loading data from: /home/data/data_louisa/processed/ftd_y_val_nfl_adj_thresh_0.05_num_nodes_10_mutation_GRN_plasma_sex_F_train.pt\n",
      "Loading data from: /home/data/data_louisa/processed/ftd_y_val_nfl_adj_thresh_0.05_num_nodes_10_mutation_GRN_plasma_sex_F_test.pt\n",
      "Normalized Val MSE: 0.15480871498584747\n",
      "Normalized train MSE: 0.4351668357849121\n",
      "Original Units Val MSE: tensor(415.8345, grad_fn=<MseLossBackward0>)\n",
      "Original Units Val RMSE: tensor(20.3920, grad_fn=<SqrtBackward0>)\n",
      "Loading checkpoint from: /scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_10-30-17/model=gat-v4,seed=59173_241_act=tanh,adj_thresh=0.1000,batch_size=32,dropout=0.0500,l1_lambda=0.0000,lr=0.0064,lr_scheduler=Lambda_2024-08-01_10-44-20/checkpoint_000017\n",
      "4 best checkpoint for ['F'] and csf\n",
      "Loading data from: /home/data/data_louisa/processed/ftd_y_val_nfl_adj_thresh_0.1_num_nodes_30_mutation_GRN_csf_sex_F_train.pt\n",
      "Loading data from: /home/data/data_louisa/processed/ftd_y_val_nfl_adj_thresh_0.1_num_nodes_30_mutation_GRN_csf_sex_F_test.pt\n",
      "Normalized Val MSE: 0.49168848991394043\n",
      "Normalized train MSE: 0.5584195852279663\n",
      "Original Units Val MSE: tensor(4412.1221, grad_fn=<MseLossBackward0>)\n",
      "Original Units Val RMSE: tensor(66.4238, grad_fn=<SqrtBackward0>)\n",
      "Loading checkpoint from: /scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_10-30-17/model=gat-v4,seed=39163_985_act=leaky_relu,adj_thresh=0.9000,batch_size=8,dropout=0.0500,l1_lambda=0.0000,lr=0.0041,lr_scheduler=R_2024-08-01_13-53-51/checkpoint_000019\n",
      "1 best checkpoint for ['M', 'F'] and csf\n",
      "Loading data from: /home/data/data_louisa/processed/ftd_y_val_nfl_adj_thresh_0.9_num_nodes_10_mutation_GRN_csf_sex_M,F_train.pt\n",
      "Loading data from: /home/data/data_louisa/processed/ftd_y_val_nfl_adj_thresh_0.9_num_nodes_10_mutation_GRN_csf_sex_M,F_test.pt\n",
      "Normalized Val MSE: 0.1153869777917862\n",
      "Normalized train MSE: 0.6506036520004272\n",
      "Original Units Val MSE: tensor(157.5311, grad_fn=<MseLossBackward0>)\n",
      "Original Units Val RMSE: tensor(12.5511, grad_fn=<SqrtBackward0>)\n",
      "Loading checkpoint from: /scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_10-30-17/model=gat-v4,seed=63998_355_act=elu,adj_thresh=0.1000,batch_size=8,dropout=0,l1_lambda=0.0001,lr=0.0108,lr_scheduler=ReduceLROnPla_2024-08-01_11-20-27/checkpoint_000003\n",
      "2 best checkpoint for ['M', 'F'] and csf\n",
      "Loading data from: /home/data/data_louisa/processed/ftd_y_val_nfl_adj_thresh_0.1_num_nodes_10_mutation_GRN_csf_sex_M,F_train.pt\n",
      "Loading data from: /home/data/data_louisa/processed/ftd_y_val_nfl_adj_thresh_0.1_num_nodes_10_mutation_GRN_csf_sex_M,F_test.pt\n",
      "Normalized Val MSE: 0.11639781296253204\n",
      "Normalized train MSE: 0.2161395102739334\n",
      "Original Units Val MSE: tensor(74.0087, grad_fn=<MseLossBackward0>)\n",
      "Original Units Val RMSE: tensor(8.6028, grad_fn=<SqrtBackward0>)\n",
      "Loading checkpoint from: /scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_10-30-17/model=gat-v4,seed=14600_751_act=tanh,adj_thresh=0.7000,batch_size=32,dropout=0.0500,l1_lambda=0.0011,lr=0.0236,lr_scheduler=Cosine_2024-08-01_12-59-43/checkpoint_000042\n",
      "3 best checkpoint for ['M', 'F'] and csf\n",
      "Loading data from: /home/data/data_louisa/processed/ftd_y_val_nfl_adj_thresh_0.7_num_nodes_30_mutation_GRN_csf_sex_M,F_train.pt\n",
      "Loading data from: /home/data/data_louisa/processed/ftd_y_val_nfl_adj_thresh_0.7_num_nodes_30_mutation_GRN_csf_sex_M,F_test.pt\n",
      "Normalized Val MSE: 0.1435537338256836\n",
      "Normalized train MSE: 0.2351238876581192\n",
      "Original Units Val MSE: tensor(230.8784, grad_fn=<MseLossBackward0>)\n",
      "Original Units Val RMSE: tensor(15.1947, grad_fn=<SqrtBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(tensor([[38.1163],\n",
       "          [ 4.3769],\n",
       "          [ 9.2230],\n",
       "          [ 7.9793],\n",
       "          [33.8475],\n",
       "          [13.0684],\n",
       "          [43.1009],\n",
       "          [32.2196],\n",
       "          [ 0.3669],\n",
       "          [15.1122],\n",
       "          [20.5845],\n",
       "          [14.0804],\n",
       "          [ 4.1669],\n",
       "          [48.3165],\n",
       "          [ 0.6697],\n",
       "          [ 2.2397],\n",
       "          [ 0.7753],\n",
       "          [36.7248],\n",
       "          [ 2.0329],\n",
       "          [ 5.7276],\n",
       "          [ 0.9056],\n",
       "          [40.8088],\n",
       "          [ 3.1494],\n",
       "          [ 5.8064],\n",
       "          [39.7984]]),\n",
       "  tensor([[80.2171],\n",
       "          [ 7.9675],\n",
       "          [11.2010],\n",
       "          [10.8412],\n",
       "          [92.7933],\n",
       "          [ 6.9760],\n",
       "          [44.1702],\n",
       "          [35.0793],\n",
       "          [ 2.8600],\n",
       "          [ 6.0449],\n",
       "          [21.8106],\n",
       "          [11.1943],\n",
       "          [ 3.2937],\n",
       "          [84.4435],\n",
       "          [ 2.2781],\n",
       "          [ 9.1830],\n",
       "          [ 4.5831],\n",
       "          [73.4552],\n",
       "          [ 6.6160],\n",
       "          [13.1766],\n",
       "          [ 5.1185],\n",
       "          [95.4446],\n",
       "          [ 5.8523],\n",
       "          [ 4.8881],\n",
       "          [41.2233]]),\n",
       "  tensor(449.0646),\n",
       "  tensor(21.1911),\n",
       "  tensor([[39.4750],\n",
       "          [13.6242],\n",
       "          [52.9532],\n",
       "          [11.5989],\n",
       "          [14.7677],\n",
       "          [42.8506],\n",
       "          [40.9360]], grad_fn=<ExpBackward0>),\n",
       "  tensor([[41.9474],\n",
       "          [10.4173],\n",
       "          [82.9245],\n",
       "          [11.3758],\n",
       "          [ 6.2857],\n",
       "          [53.5672],\n",
       "          [39.8413]]),\n",
       "  tensor(157.5311, grad_fn=<MseLossBackward0>),\n",
       "  tensor(12.5511, grad_fn=<SqrtBackward0>)),\n",
       " (tensor([[ 6.0029],\n",
       "          [14.1770],\n",
       "          [ 7.6247],\n",
       "          [21.3782],\n",
       "          [62.4471],\n",
       "          [55.9568],\n",
       "          [46.1209],\n",
       "          [11.4199],\n",
       "          [50.2309],\n",
       "          [14.9679],\n",
       "          [ 7.1377],\n",
       "          [ 5.9914],\n",
       "          [ 5.4554],\n",
       "          [12.9554],\n",
       "          [42.8928],\n",
       "          [ 5.7789],\n",
       "          [10.9689],\n",
       "          [54.4983],\n",
       "          [10.4491],\n",
       "          [10.0588],\n",
       "          [57.6765],\n",
       "          [ 7.7451],\n",
       "          [16.5793],\n",
       "          [11.7234],\n",
       "          [49.7303]]),\n",
       "  tensor([[ 4.5831],\n",
       "          [ 6.9760],\n",
       "          [ 6.6160],\n",
       "          [21.8106],\n",
       "          [44.1702],\n",
       "          [95.4446],\n",
       "          [35.0793],\n",
       "          [10.8412],\n",
       "          [73.4552],\n",
       "          [11.1943],\n",
       "          [ 9.1830],\n",
       "          [ 2.2781],\n",
       "          [ 2.8600],\n",
       "          [11.2010],\n",
       "          [92.7933],\n",
       "          [ 5.1185],\n",
       "          [ 3.2937],\n",
       "          [41.2233],\n",
       "          [13.1766],\n",
       "          [ 4.8881],\n",
       "          [84.4435],\n",
       "          [ 5.8523],\n",
       "          [ 6.0449],\n",
       "          [ 7.9675],\n",
       "          [80.2171]]),\n",
       "  tensor(287.4573),\n",
       "  tensor(16.9546),\n",
       "  tensor([[48.5811],\n",
       "          [14.5617],\n",
       "          [64.6582],\n",
       "          [14.6092],\n",
       "          [15.3011],\n",
       "          [52.0367],\n",
       "          [45.2398]], grad_fn=<ExpBackward0>),\n",
       "  tensor([[41.9474],\n",
       "          [10.4173],\n",
       "          [82.9245],\n",
       "          [11.3758],\n",
       "          [ 6.2857],\n",
       "          [53.5672],\n",
       "          [39.8413]]),\n",
       "  tensor(74.0087, grad_fn=<MseLossBackward0>),\n",
       "  tensor(8.6028, grad_fn=<SqrtBackward0>)),\n",
       " (tensor([[14.4146],\n",
       "          [ 3.7328],\n",
       "          [60.7470],\n",
       "          [ 4.2358],\n",
       "          [66.0060],\n",
       "          [ 3.0484],\n",
       "          [39.3110],\n",
       "          [ 2.4002],\n",
       "          [ 3.4162],\n",
       "          [53.9031],\n",
       "          [ 5.2225],\n",
       "          [ 2.7087],\n",
       "          [63.9536],\n",
       "          [ 2.3333],\n",
       "          [84.5024],\n",
       "          [ 2.2054],\n",
       "          [ 2.8943],\n",
       "          [17.0415],\n",
       "          [54.5857],\n",
       "          [ 5.1335],\n",
       "          [59.5195],\n",
       "          [ 6.2747],\n",
       "          [ 3.5461],\n",
       "          [ 3.6632],\n",
       "          [ 3.2118]]),\n",
       "  tensor([[11.1943],\n",
       "          [13.1766],\n",
       "          [80.2171],\n",
       "          [ 6.0449],\n",
       "          [73.4552],\n",
       "          [ 5.1185],\n",
       "          [41.2233],\n",
       "          [ 2.2781],\n",
       "          [ 4.8881],\n",
       "          [44.1702],\n",
       "          [ 6.9760],\n",
       "          [ 6.6160],\n",
       "          [95.4446],\n",
       "          [ 4.5831],\n",
       "          [84.4435],\n",
       "          [ 2.8600],\n",
       "          [ 9.1830],\n",
       "          [21.8106],\n",
       "          [92.7933],\n",
       "          [10.8412],\n",
       "          [35.0793],\n",
       "          [11.2010],\n",
       "          [ 3.2937],\n",
       "          [ 7.9675],\n",
       "          [ 5.8523]]),\n",
       "  tensor(154.3848),\n",
       "  tensor(12.4252),\n",
       "  tensor([[62.5812],\n",
       "          [ 9.4163],\n",
       "          [86.0614],\n",
       "          [ 4.9689],\n",
       "          [ 4.7554],\n",
       "          [63.7642],\n",
       "          [71.9689]], grad_fn=<ExpBackward0>),\n",
       "  tensor([[41.9474],\n",
       "          [10.4173],\n",
       "          [82.9245],\n",
       "          [11.3758],\n",
       "          [ 6.2857],\n",
       "          [53.5672],\n",
       "          [39.8413]]),\n",
       "  tensor(230.8784, grad_fn=<MseLossBackward0>),\n",
       "  tensor(15.1947, grad_fn=<SqrtBackward0>))]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "59173\n",
    "GRN_mean_dict = {\"['M']_csf\": 2.178815827183045,\n",
    "                \"['F']_plasma\":3.120974866855634,\n",
    "                \"['F']_csf\": 3.2586357196385385,\n",
    "                \"['M', 'F']_csf\":2.752470145050026}\n",
    "GRN_std_dict = {\"['M']_csf\":0.7776541040264751,\n",
    "                \"['F']_plasma\":1.2401561087499366,\n",
    "                \"['F']_csf\":1.1764975422138229,\n",
    "                \"['M', 'F']_csf\":1.1441881493582908}\n",
    "\n",
    "GRN_BEST_RUNS_M=[\n",
    "    '/scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_10-30-17/model=gat-v4,seed=52208_883_act=relu,adj_thresh=0.7000,batch_size=8,dropout=0,l1_lambda=0.0002,lr=0.0010,lr_scheduler=ReduceLROnPl_2024-08-01_13-33-15/checkpoint_000020',\n",
    "    '/scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_10-30-17/model=gat-v4,seed=10511_829_act=sigmoid,adj_thresh=0.9000,batch_size=8,dropout=0.3000,l1_lambda=0.0052,lr=0.0010,lr_scheduler=Redu_2024-08-01_13-24-19/checkpoint_000003',\n",
    "    '/scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_10-30-17/model=gat-v4,seed=7148_163_act=sigmoid,adj_thresh=0.1000,batch_size=32,dropout=0.0500,l1_lambda=0.0183,lr=0.0192,lr_scheduler=Step_2024-08-01_10-30-18/checkpoint_000005',\n",
    "\n",
    "]\n",
    "GRN_BEST_RUNS_F= [\n",
    "    '/scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_17-06-03/model=gat-v4,seed=6059_182_act=relu,adj_thresh=0.1000,batch_size=16,dropout=0.3000,l1_lambda=0.0001,lr=0.0011,lr_scheduler=CosineA_2024-08-01_17-06-04/checkpoint_000065',\n",
    "    '/scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_17-06-03/model=gat-v4,seed=42177_32_act=leaky_relu,adj_thresh=0.0500,batch_size=8,dropout=0.1000,l1_lambda=0.0000,lr=0.0072,lr_scheduler=La_2024-08-01_17-06-04/checkpoint_000104',\n",
    "    '/scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_17-06-03/model=gat-v4,seed=41068_56_act=tanh,adj_thresh=0.0500,batch_size=50,dropout=0,l1_lambda=0.0011,lr=0.0096,lr_scheduler=CosineAnneal_2024-08-01_17-06-04/checkpoint_000066',\n",
    "    '/scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_10-30-17/model=gat-v4,seed=59173_241_act=tanh,adj_thresh=0.1000,batch_size=32,dropout=0.0500,l1_lambda=0.0000,lr=0.0064,lr_scheduler=Lambda_2024-08-01_10-44-20/checkpoint_000017'\n",
    "]\n",
    "\n",
    "GRN_BEST_RUNS_M_F= [\n",
    "    '/scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_10-30-17/model=gat-v4,seed=39163_985_act=leaky_relu,adj_thresh=0.9000,batch_size=8,dropout=0.0500,l1_lambda=0.0000,lr=0.0041,lr_scheduler=R_2024-08-01_13-53-51/checkpoint_000019',\n",
    "    '/scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_10-30-17/model=gat-v4,seed=63998_355_act=elu,adj_thresh=0.1000,batch_size=8,dropout=0,l1_lambda=0.0001,lr=0.0108,lr_scheduler=ReduceLROnPla_2024-08-01_11-20-27/checkpoint_000003',\n",
    "    '/scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-01_10-30-17/model=gat-v4,seed=14600_751_act=tanh,adj_thresh=0.7000,batch_size=32,dropout=0.0500,l1_lambda=0.0011,lr=0.0236,lr_scheduler=Cosine_2024-08-01_12-59-43/checkpoint_000042'\n",
    "]\n",
    "process_checkpoints(GRN_BEST_RUNS_M, GRN_mean_dict, GRN_std_dict, device)\n",
    "process_checkpoints(GRN_BEST_RUNS_F, GRN_mean_dict, GRN_std_dict, device)\n",
    "process_checkpoints(GRN_BEST_RUNS_M_F, GRN_mean_dict, GRN_std_dict, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gat_v4_hidden_channels=[[8, 16], [32, 64], [64, 128]] error_protein_file_name='bimodal_aptamers_for_removal.xlsx' model_grid_search=['gat-v4'] weight_decay=0 modality='csf' act_choices=['relu', 'tanh', 'sigmoid', 'leaky_relu', 'elu'] gat_heads=[1, 2, 4, 8] gcn={'num_layers': 3, 'hidden_channels': 32} device=[0, 1, 2, 3, 4, 5, 6, 7] gat_v4_fc_dim=[[64, 128, 128, 32], [128, 256, 256, 64], [256, 512, 512, 128]] modality_choices=['plasma', 'csf'] lr_scheduler_choices=['LambdaLR', 'ReduceLROnPlateau', 'ExponentialLR', 'StepLR', 'CosineAnnealingLR'] gat_v4_weight_initializer=['xavier', 'kaiming', 'orthogonal', 'truncated_normal', 'uniform'] raw_file_name='ALLFTD_dataset_for_nina_louisa_071124.csv' trainer_accelerator='gpu' output_dir='/scratch/lcornelis/outputs' gpu_per_worker=1 wandb_offline=False reduction_factor=8 epochs=300 lr_max=0.1 lr=3.383950010759831e-05 y_val_choices=['nfl', 'memory'] gat-v4={'hidden_channels': [8, 16], 'heads': [2, 3], 'use_layer_norm': True, 'which_layer': ['layer1', 'layer2', 'layer3', 'sex', 'mutation', 'age'], 'fc_dim': [128, 256, 256, 64], 'fc_dropout': 0.1, 'fc_act': 'elu', 'weight_initializer': 'uniform', 'num_layers': None} gat={'num_layers': 2, 'hidden_channels': 256, 'heads': 4, 'v2': True} sex=['M', 'F'] grace_period=30 num_nodes=7000 act='sigmoid' root_dir='/home/lcornelis/code/proteo' num_nodes_choices=[7000] sync_batchnorm=False seed=31061 data_dir='/home/data/data_louisa' wandb_api_key_path='wandb_api_key.txt' sex_choices=[['M', 'F']] checkpoint_dir='/scratch/lcornelis/outputs/checkpoints' lr_min=1e-06 mutation=['GRN', 'MAPT', 'C9orf72', 'CTL'] nodes_count=1 lr_scheduler='LambdaLR' batch_size_choices=[8, 16, 32, 50] wgcna_minModuleSize=10 ray_results_dir='/scratch/lcornelis/outputs/ray_results' use_progress_bar=True gcn_num_layers=[2, 3, 4] dataset_name='ftd' log_every_n_steps=10 model='gat-v4' num_samples=300 mutation_choices=[['GRN', 'MAPT', 'C9orf72', 'CTL']] gat_v4_fc_act=['relu', 'tanh', 'sigmoid', 'leaky_relu', 'elu'] l1_lambda=0.0007633793301436636 optimizer='Adam' ray_tmp_dir='/scratch/lcornelis/tmp' gat_num_layers=[2, 4, 6, 12] pin_memory=True num_to_keep=3 wandb_tmp_dir='/tmp' gat_hidden_channels=[8, 32, 128, 256] accumulate_grad_batches=1 dropout=0.1 adj_thresh_choices=[0.05, 0.07, 0.1, 0.2, 0.5, 0.7, 0.9] gat_v4_fc_dropout=[0.1, 0.2, 0.5] wgcna_mergeCutHeight=0.25 checkpoint_every_n_epochs_train=1 num_workers=16 l1_lambda_min=1e-05 l1_lambda_max=0.1 dropout_choices=[0, 0.05, 0.1, 0.2, 0.3] gat_v4_heads=[[2, 3], [2, 2], [4, 4]] project='proteo' batch_size=8 gcn_hidden_channels=[8, 32, 128] precision='32-true' cpu_per_worker=16 adj_thresh=0.1 y_val='nfl' use_master_nodes=False master_nodes=[]\n",
      "Loading data from: /home/data/data_louisa/processed/ftd_y_val_nfl_adj_thresh_0.1_num_nodes_7000_mutation_GRN,MAPT,C9orf72,CTL_csf_sex_M,F_train.pt\n",
      "Loading data from: /home/data/data_louisa/processed/ftd_y_val_nfl_adj_thresh_0.1_num_nodes_7000_mutation_GRN,MAPT,C9orf72,CTL_csf_sex_M,F_test.pt\n",
      "Normalized Val MSE: 0.2927089333534241\n",
      "Normalized train MSE: 0.6178205013275146\n",
      "[12.844107   7.547421  24.042084   8.603236   2.8657448  8.574533\n",
      "  8.206101   7.1123896  4.2857428  4.868487   7.256488  26.506147\n",
      "  3.3411803  4.6200047 12.720602  10.90655   11.4102125  6.9502163\n",
      " 22.184807   6.33207    5.9523396  3.8900576  3.6387572  8.249515\n",
      "  6.39467    6.4177437 13.0004425 15.254776   3.7150097  5.184729\n",
      " 12.785119   6.682045   3.287738  10.367624   3.3027124  8.719203\n",
      "  3.1877427 23.381355   3.6926892 16.87402   10.855902   6.439096\n",
      "  4.72403    5.3021183  9.03105  ]\n",
      "Original Units Val MSE: tensor(143.7400, grad_fn=<MseLossBackward0>)\n",
      "Original Units Val RMSE: tensor(11.9892, grad_fn=<SqrtBackward0>)\n",
      "Val Z scores: [ 0.08007427 -0.35723093 -5.6265106  -0.13323592  0.16462378 -0.8384576\n",
      "  0.27037892  0.23258622  0.35803932  0.31581706 -0.13154203 -0.4004911\n",
      "  0.4621954   0.31633872  0.2783712   0.5549174   0.6093879   0.5653731\n",
      " -0.9533682   0.3187764   0.30903617  0.39018387  0.30414397 -0.29444697\n",
      "  0.43691432 -0.8787028  -2.0129092  -0.26389274  0.22393844  0.06741636\n",
      "  0.468977    0.41799548  0.07926772  0.3240515   0.33311749  0.06185817\n",
      "  0.3116971   1.1062895   0.33067948  0.5276201   0.18146111  0.48026302\n",
      "  0.20408219  0.3690941   0.435822  ]\n",
      "output_dir='/scratch/lcornelis/outputs' modality_choices=['plasma', 'csf'] pin_memory=True num_samples=300 error_protein_file_name='bimodal_aptamers_for_removal.xlsx' project='proteo' lr_min=1e-06 gat_v4_weight_initializer=['xavier', 'kaiming', 'orthogonal', 'truncated_normal', 'uniform'] sync_batchnorm=False lr=2.051447344023592e-05 wandb_tmp_dir='/tmp' trainer_accelerator='gpu' grace_period=30 gpu_per_worker=1 model='gat-v4' cpu_per_worker=16 gat_v4_fc_act=['relu', 'tanh', 'sigmoid', 'leaky_relu', 'elu'] l1_lambda_min=1e-05 gat_heads=[1, 2, 4, 8] num_nodes_choices=[7000] dropout_choices=[0, 0.05, 0.1, 0.2, 0.3] use_progress_bar=True gat_v4_hidden_channels=[[8, 16], [32, 64], [64, 128]] gcn_num_layers=[2, 3, 4] modality='plasma' checkpoint_every_n_epochs_train=1 l1_lambda_max=0.1 gat_v4_heads=[[2, 3], [2, 2], [4, 4]] epochs=300 sex=['M', 'F'] adj_thresh=0.7 batch_size_choices=[8, 16, 32, 50] weight_decay=0 mutation=['GRN', 'MAPT', 'C9orf72', 'CTL'] l1_lambda=0.0005824652403837053 wgcna_minModuleSize=10 lr_max=0.1 num_nodes=7000 gcn_hidden_channels=[8, 32, 128] ray_results_dir='/scratch/lcornelis/outputs/ray_results' wandb_offline=False data_dir='/home/data/data_louisa' gat-v4={'hidden_channels': [32, 64], 'heads': [4, 4], 'use_layer_norm': True, 'which_layer': ['layer1', 'layer2', 'layer3'], 'fc_dim': [64, 128, 128, 32], 'fc_dropout': 0.1, 'fc_act': 'elu', 'weight_initializer': 'uniform', 'num_layers': None} dropout=0.2 precision='32-true' gat_num_layers=[2, 4, 6, 12] batch_size=8 act='sigmoid' wandb_api_key_path='wandb_api_key.txt' num_to_keep=3 ray_tmp_dir='/scratch/lcornelis/tmp' checkpoint_dir='/scratch/lcornelis/outputs/checkpoints' reduction_factor=8 gat={'num_layers': 2, 'hidden_channels': 256, 'heads': 4, 'v2': True} lr_scheduler_choices=['LambdaLR', 'ReduceLROnPlateau', 'ExponentialLR', 'StepLR', 'CosineAnnealingLR'] gcn={'num_layers': 3, 'hidden_channels': 32} gat_v4_fc_dim=[[64, 128, 128, 32], [128, 256, 256, 64], [256, 512, 512, 128]] seed=35068 gat_hidden_channels=[8, 32, 128, 256] y_val='nfl' wgcna_mergeCutHeight=0.25 mutation_choices=[['GRN', 'MAPT', 'C9orf72', 'CTL']] root_dir='/home/lcornelis/code/proteo' sex_choices=[['M', 'F']] accumulate_grad_batches=1 y_val_choices=['nfl'] adj_thresh_choices=[0.05, 0.07, 0.1, 0.2, 0.5, 0.7, 0.9] optimizer='Adam' num_workers=16 raw_file_name='ALLFTD_dataset_for_nina_louisa_071124.csv' dataset_name='ftd' gat_v4_fc_dropout=[0.1, 0.2, 0.5] device=[0, 1, 2, 3, 4, 5, 6, 7] nodes_count=1 act_choices=['relu', 'tanh', 'sigmoid', 'leaky_relu', 'elu'] lr_scheduler='LambdaLR' model_grid_search=['gat-v4'] log_every_n_steps=10 use_master_nodes=False master_nodes=[]\n",
      "Loading data from: /home/data/data_louisa/processed/ftd_y_val_nfl_adj_thresh_0.7_num_nodes_7000_mutation_GRN,MAPT,C9orf72,CTL_plasma_sex_M,F_train.pt\n",
      "Loading data from: /home/data/data_louisa/processed/ftd_y_val_nfl_adj_thresh_0.7_num_nodes_7000_mutation_GRN,MAPT,C9orf72,CTL_plasma_sex_M,F_test.pt\n",
      "Normalized Val MSE: 0.7553808093070984\n",
      "Normalized train MSE: 0.9566059708595276\n",
      "[8.128743  9.172058  7.4034986 7.9600005 7.9708366 7.4626875 7.801028\n",
      " 7.713559  8.170197  7.9901204 8.116993  7.63884   8.106142  8.45427\n",
      " 8.777234  8.001244  8.143648  8.64211   8.21559   7.7741947 8.26719\n",
      " 7.7076488 8.58198   8.369882  7.781343  8.221921  7.765564  8.110147\n",
      " 7.7799573 7.989627  7.8378663 7.4415817 7.7408495 8.068891  9.716749\n",
      " 8.605286  6.901504  8.150393  8.062355  7.4642906 7.8877463 7.9420085\n",
      " 7.5020213 8.222201  7.799049  7.77616   8.671283  7.7449603 8.505443\n",
      " 7.4723673 8.687355  7.960936  8.920307  7.5877423 7.590717  8.060832\n",
      " 8.051317  7.6328983 8.864269  8.546698  8.201194  7.8964057 7.9013906\n",
      " 7.8054276 8.353574  8.6033125 7.9985847 7.819196  7.7083564 7.9849005\n",
      " 7.5725126 8.927098  7.906375  7.6005034 7.9200077 7.490183  8.508171\n",
      " 8.271392  7.7478323 7.467103  7.692314  7.6466155 7.7664676 7.835521\n",
      " 8.316891  8.48174   8.478798  7.8659225 8.121149 ]\n",
      "Original Units Val MSE: tensor(484.0799, grad_fn=<MseLossBackward0>)\n",
      "Original Units Val RMSE: tensor(22.0018, grad_fn=<SqrtBackward0>)\n",
      "Val Z scores: [ 2.28890330e-01  3.11936699e-02  3.82640272e-01  3.37022662e-01\n",
      "  2.15043277e-01  3.52325588e-01  2.56554455e-01  3.15153241e-01\n",
      "  2.17144325e-01  3.68919611e-01  2.26330996e-01 -2.76854515e-01\n",
      "  1.57033831e-01  3.89579952e-01 -2.84700930e-01  4.41108555e-01\n",
      "  1.13096245e-01  8.48695934e-02  1.94728270e-01  3.88601601e-01\n",
      " -2.79833704e-01  3.62047940e-01  2.74378449e-01  2.91119218e-01\n",
      "  3.43575120e-01  2.85665810e-01  3.10335279e-01  3.09851140e-01\n",
      "  3.92063498e-01  3.56822550e-01  4.01602834e-01  1.76806673e-01\n",
      "  6.07719785e-03 -7.26928040e-02 -2.03399944e+00  1.29676983e-01\n",
      "  2.89084852e-01 -7.93799210e+00  8.22287574e-02  2.53305078e-01\n",
      "  8.14919770e-02  2.99891680e-01  3.96314383e-01  2.56164998e-01\n",
      "  2.75049061e-01  2.54051834e-01 -1.51404774e+00  4.16307092e-01\n",
      " -3.60737383e-01  4.35052335e-01  2.26450861e-01  3.52931499e-01\n",
      " -1.03345975e-01  3.38299513e-01  3.83719563e-01 -3.71650755e-02\n",
      "  3.35928261e-01  3.70156676e-01  1.43330500e-01 -1.20683420e+00\n",
      "  5.86508028e-03  3.04896593e-01  2.52465099e-01  2.16849074e-01\n",
      " -4.07253094e-02 -1.10839283e+00  3.35997403e-01  4.03183162e-01\n",
      "  4.29264814e-01  3.62133056e-01  3.06709558e-01 -3.87274593e-01\n",
      "  3.69241327e-01  4.30349410e-01  3.23403835e-01 -5.92460819e-02\n",
      "  1.84641019e-01 -3.39413464e-01  3.26896250e-01  2.87949532e-01\n",
      "  2.31466576e-01  4.37699378e-01  3.51161063e-01  3.25891405e-01\n",
      "  3.95938903e-01 -1.23171377e+00  3.16321384e-03 -2.68168187e+00\n",
      "  1.41468927e-01]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[tensor([[6.7605],\n",
       "         [7.5976],\n",
       "         [8.9255],\n",
       "         [7.9153],\n",
       "         [8.6370],\n",
       "         [8.4952],\n",
       "         [7.8124],\n",
       "         [7.5010],\n",
       "         [8.0240],\n",
       "         [7.7899],\n",
       "         [8.0164],\n",
       "         [8.0451],\n",
       "         [7.8951],\n",
       "         [8.0144],\n",
       "         [7.9530],\n",
       "         [7.7884],\n",
       "         [8.8329],\n",
       "         [8.7235],\n",
       "         [8.0949],\n",
       "         [7.6290],\n",
       "         [7.9864],\n",
       "         [7.8258],\n",
       "         [8.5184],\n",
       "         [7.5285],\n",
       "         [7.8070],\n",
       "         [8.6711],\n",
       "         [8.1106],\n",
       "         [8.2972],\n",
       "         [8.4704],\n",
       "         [7.8292],\n",
       "         [8.5415],\n",
       "         [8.5747],\n",
       "         [8.0433],\n",
       "         [8.6962],\n",
       "         [7.6386],\n",
       "         [7.3432],\n",
       "         [6.3409],\n",
       "         [7.4029],\n",
       "         [8.2924],\n",
       "         [8.8029],\n",
       "         [7.8724],\n",
       "         [7.9866],\n",
       "         [8.1770],\n",
       "         [7.4482],\n",
       "         [7.9503],\n",
       "         [7.9893],\n",
       "         [7.4055],\n",
       "         [8.0823],\n",
       "         [7.6467],\n",
       "         [7.1267],\n",
       "         [7.8022],\n",
       "         [7.5426],\n",
       "         [8.3347],\n",
       "         [7.7611],\n",
       "         [7.6747],\n",
       "         [7.6458],\n",
       "         [8.3796],\n",
       "         [7.9513],\n",
       "         [8.7866],\n",
       "         [5.3170],\n",
       "         [8.5587],\n",
       "         [6.9649],\n",
       "         [7.7931],\n",
       "         [7.7018],\n",
       "         [8.0675],\n",
       "         [7.9935],\n",
       "         [7.9429],\n",
       "         [7.9675],\n",
       "         [8.3217],\n",
       "         [8.1431],\n",
       "         [8.1567],\n",
       "         [7.8120],\n",
       "         [8.6850],\n",
       "         [8.9170],\n",
       "         [8.0319],\n",
       "         [8.1859],\n",
       "         [8.5968],\n",
       "         [8.0943],\n",
       "         [8.2236],\n",
       "         [7.8692],\n",
       "         [8.1868],\n",
       "         [8.1155],\n",
       "         [7.7019],\n",
       "         [9.1065],\n",
       "         [8.0573],\n",
       "         [7.6989],\n",
       "         [8.1458],\n",
       "         [7.8013],\n",
       "         [7.8743],\n",
       "         [7.9888],\n",
       "         [8.2918],\n",
       "         [8.2204],\n",
       "         [8.6655],\n",
       "         [7.4147],\n",
       "         [7.6871],\n",
       "         [8.2127],\n",
       "         [7.9466],\n",
       "         [9.1725],\n",
       "         [7.6205],\n",
       "         [7.4861],\n",
       "         [8.5846],\n",
       "         [7.7908],\n",
       "         [7.8785],\n",
       "         [7.9352],\n",
       "         [8.0004],\n",
       "         [8.1292],\n",
       "         [6.9891],\n",
       "         [8.2184],\n",
       "         [7.2068],\n",
       "         [8.1270],\n",
       "         [7.9998],\n",
       "         [7.6060],\n",
       "         [7.2901],\n",
       "         [8.2575],\n",
       "         [9.0289],\n",
       "         [7.8556],\n",
       "         [7.1476],\n",
       "         [8.2278],\n",
       "         [7.7644],\n",
       "         [7.6014],\n",
       "         [7.9502],\n",
       "         [8.3537],\n",
       "         [7.5197],\n",
       "         [8.3595],\n",
       "         [7.9769],\n",
       "         [7.7581],\n",
       "         [7.6100],\n",
       "         [7.6165],\n",
       "         [7.9802],\n",
       "         [7.7672],\n",
       "         [8.1074],\n",
       "         [6.9010],\n",
       "         [8.1247],\n",
       "         [7.9550],\n",
       "         [7.6450],\n",
       "         [8.0856],\n",
       "         [7.3162],\n",
       "         [8.0917],\n",
       "         [8.0329],\n",
       "         [8.4586],\n",
       "         [7.5763],\n",
       "         [7.7445],\n",
       "         [7.6025],\n",
       "         [7.7168],\n",
       "         [8.3911],\n",
       "         [7.8413],\n",
       "         [6.9001],\n",
       "         [8.4667],\n",
       "         [8.1149],\n",
       "         [8.7427],\n",
       "         [7.5726],\n",
       "         [7.8829],\n",
       "         [7.5253],\n",
       "         [7.3993],\n",
       "         [8.6073],\n",
       "         [7.7986],\n",
       "         [7.6277],\n",
       "         [7.5132],\n",
       "         [8.5019],\n",
       "         [7.7170],\n",
       "         [8.2529],\n",
       "         [9.0717],\n",
       "         [7.7981],\n",
       "         [7.9799],\n",
       "         [7.6986],\n",
       "         [4.8559],\n",
       "         [8.2466],\n",
       "         [8.5150],\n",
       "         [8.3815],\n",
       "         [8.2654],\n",
       "         [7.6358],\n",
       "         [8.5961],\n",
       "         [8.3749],\n",
       "         [7.6038],\n",
       "         [7.7981],\n",
       "         [8.6121],\n",
       "         [8.4031],\n",
       "         [7.3602],\n",
       "         [7.7295],\n",
       "         [7.7784],\n",
       "         [8.2272],\n",
       "         [7.7982],\n",
       "         [7.7135],\n",
       "         [7.5813],\n",
       "         [8.8332],\n",
       "         [8.0646],\n",
       "         [8.3426],\n",
       "         [7.8519],\n",
       "         [8.2370],\n",
       "         [8.6753],\n",
       "         [8.4521],\n",
       "         [8.0344],\n",
       "         [7.5839],\n",
       "         [8.0078],\n",
       "         [7.9792],\n",
       "         [7.7055],\n",
       "         [8.9397],\n",
       "         [7.5519],\n",
       "         [7.6518],\n",
       "         [9.4202],\n",
       "         [7.2047],\n",
       "         [7.6141],\n",
       "         [7.5076],\n",
       "         [7.8496],\n",
       "         [8.7022],\n",
       "         [7.5000],\n",
       "         [8.5761],\n",
       "         [8.8953],\n",
       "         [7.6296],\n",
       "         [8.9095],\n",
       "         [8.1138],\n",
       "         [7.4948],\n",
       "         [8.2303],\n",
       "         [7.8670],\n",
       "         [8.8575],\n",
       "         [8.4712],\n",
       "         [8.1367],\n",
       "         [8.1510],\n",
       "         [8.4442],\n",
       "         [7.7437],\n",
       "         [7.0755],\n",
       "         [8.4249],\n",
       "         [7.4784],\n",
       "         [8.4643],\n",
       "         [8.2435],\n",
       "         [8.1109],\n",
       "         [7.3757],\n",
       "         [8.4370],\n",
       "         [7.7908],\n",
       "         [8.0359],\n",
       "         [8.7875],\n",
       "         [8.6550],\n",
       "         [7.7607],\n",
       "         [8.2452],\n",
       "         [7.6561],\n",
       "         [7.9812],\n",
       "         [8.2460],\n",
       "         [7.7802],\n",
       "         [8.6653],\n",
       "         [7.3163],\n",
       "         [7.4515],\n",
       "         [8.3237],\n",
       "         [8.6829],\n",
       "         [7.6286],\n",
       "         [8.1446],\n",
       "         [7.2885],\n",
       "         [7.2298],\n",
       "         [8.4393],\n",
       "         [7.1497],\n",
       "         [8.9876],\n",
       "         [8.6344],\n",
       "         [8.5817],\n",
       "         [7.7112],\n",
       "         [7.1909],\n",
       "         [7.7765],\n",
       "         [7.7681],\n",
       "         [8.0842],\n",
       "         [7.7146],\n",
       "         [8.3289],\n",
       "         [7.4046],\n",
       "         [8.2663],\n",
       "         [8.0823],\n",
       "         [7.5566],\n",
       "         [8.0075],\n",
       "         [8.1359],\n",
       "         [7.9633],\n",
       "         [7.6299],\n",
       "         [7.5860],\n",
       "         [8.2576],\n",
       "         [7.9576],\n",
       "         [8.3613],\n",
       "         [7.6755],\n",
       "         [7.5517],\n",
       "         [7.4463],\n",
       "         [9.4718],\n",
       "         [7.5355],\n",
       "         [7.4312],\n",
       "         [8.1230],\n",
       "         [7.3997],\n",
       "         [7.8589],\n",
       "         [7.7281],\n",
       "         [8.4488],\n",
       "         [7.9072],\n",
       "         [8.3491],\n",
       "         [8.0273],\n",
       "         [8.3490],\n",
       "         [7.8433],\n",
       "         [7.7533],\n",
       "         [8.0085],\n",
       "         [7.1399],\n",
       "         [8.4035],\n",
       "         [8.1217],\n",
       "         [7.8236],\n",
       "         [9.0059],\n",
       "         [8.3007],\n",
       "         [7.8972],\n",
       "         [8.1880],\n",
       "         [8.4674],\n",
       "         [8.3893],\n",
       "         [8.0840],\n",
       "         [8.6236],\n",
       "         [7.7937],\n",
       "         [7.3529],\n",
       "         [7.9144],\n",
       "         [7.4665],\n",
       "         [8.4351],\n",
       "         [8.6693],\n",
       "         [8.6719],\n",
       "         [8.0889],\n",
       "         [8.3360],\n",
       "         [8.3950],\n",
       "         [7.4636],\n",
       "         [8.3193],\n",
       "         [8.3827],\n",
       "         [7.5219],\n",
       "         [8.8669],\n",
       "         [8.2929],\n",
       "         [8.0500],\n",
       "         [6.9009],\n",
       "         [8.5461],\n",
       "         [7.9802],\n",
       "         [8.0556],\n",
       "         [7.7614],\n",
       "         [7.9540],\n",
       "         [7.4557],\n",
       "         [8.4331],\n",
       "         [7.8111],\n",
       "         [8.0954],\n",
       "         [7.9106],\n",
       "         [8.9041],\n",
       "         [8.3546],\n",
       "         [8.3154],\n",
       "         [7.9553],\n",
       "         [7.5368],\n",
       "         [8.1988],\n",
       "         [8.0404],\n",
       "         [7.6055],\n",
       "         [7.9141],\n",
       "         [8.3047],\n",
       "         [8.0489],\n",
       "         [8.5600],\n",
       "         [7.6706],\n",
       "         [6.9303],\n",
       "         [8.0825],\n",
       "         [8.1637],\n",
       "         [7.7070],\n",
       "         [7.6113],\n",
       "         [8.1990],\n",
       "         [8.4342],\n",
       "         [8.1712],\n",
       "         [7.5657],\n",
       "         [7.5742]]),\n",
       " tensor([[  4.1501],\n",
       "         [  4.7249],\n",
       "         [ 13.9076],\n",
       "         [  6.8529],\n",
       "         [ 69.3277],\n",
       "         [ 31.3306],\n",
       "         [  5.4111],\n",
       "         [  3.6899],\n",
       "         [  8.5671],\n",
       "         [  3.9092],\n",
       "         [  9.2346],\n",
       "         [  4.4535],\n",
       "         [  6.3445],\n",
       "         [  7.9129],\n",
       "         [ 12.3885],\n",
       "         [  4.5664],\n",
       "         [ 40.4705],\n",
       "         [ 13.1148],\n",
       "         [140.3906],\n",
       "         [  5.5629],\n",
       "         [ 12.0386],\n",
       "         [  4.7178],\n",
       "         [ 12.0789],\n",
       "         [  7.3751],\n",
       "         [  4.4531],\n",
       "         [ 13.4350],\n",
       "         [  4.7379],\n",
       "         [  7.2258],\n",
       "         [  7.4712],\n",
       "         [  3.2672],\n",
       "         [  7.5376],\n",
       "         [ 66.8119],\n",
       "         [  5.2978],\n",
       "         [ 69.5244],\n",
       "         [  4.7377],\n",
       "         [  2.3499],\n",
       "         [  6.0771],\n",
       "         [  5.8038],\n",
       "         [ 75.0533],\n",
       "         [ 14.1166],\n",
       "         [  2.7791],\n",
       "         [  8.3819],\n",
       "         [  8.9060],\n",
       "         [  3.3876],\n",
       "         [  4.9066],\n",
       "         [ 11.6376],\n",
       "         [  3.9229],\n",
       "         [  8.2664],\n",
       "         [  4.7019],\n",
       "         [  5.1941],\n",
       "         [  3.7150],\n",
       "         [  2.8963],\n",
       "         [ 22.1793],\n",
       "         [  2.9999],\n",
       "         [  2.9043],\n",
       "         [  6.0806],\n",
       "         [ 10.6087],\n",
       "         [  5.8945],\n",
       "         [ 14.1112],\n",
       "         [  2.7084],\n",
       "         [  8.8853],\n",
       "         [  3.0575],\n",
       "         [  2.8013],\n",
       "         [  4.9881],\n",
       "         [ 11.5183],\n",
       "         [  2.9986],\n",
       "         [ 29.5254],\n",
       "         [  7.5904],\n",
       "         [  7.8075],\n",
       "         [ 12.9573],\n",
       "         [  9.4072],\n",
       "         [  7.1050],\n",
       "         [ 20.0350],\n",
       "         [ 45.3326],\n",
       "         [ 11.5109],\n",
       "         [  8.7044],\n",
       "         [ 13.5079],\n",
       "         [  7.1864],\n",
       "         [ 14.0524],\n",
       "         [  4.0489],\n",
       "         [  9.2139],\n",
       "         [  7.4815],\n",
       "         [  4.6912],\n",
       "         [  9.6280],\n",
       "         [  8.7635],\n",
       "         [ 10.0630],\n",
       "         [ 75.8435],\n",
       "         [  3.3462],\n",
       "         [  8.7265],\n",
       "         [  8.4592],\n",
       "         [ 45.4780],\n",
       "         [  8.1392],\n",
       "         [ 23.2538],\n",
       "         [  3.4998],\n",
       "         [  5.1666],\n",
       "         [ 20.3414],\n",
       "         [ 73.9881],\n",
       "         [105.2334],\n",
       "         [  4.6571],\n",
       "         [  3.5302],\n",
       "         [ 38.9413],\n",
       "         [  4.0722],\n",
       "         [  4.0956],\n",
       "         [ 14.1400],\n",
       "         [  6.6772],\n",
       "         [ 11.7478],\n",
       "         [  5.7221],\n",
       "         [ 12.3673],\n",
       "         [ 17.3989],\n",
       "         [ 11.9712],\n",
       "         [  4.3903],\n",
       "         [  4.0229],\n",
       "         [  2.6888],\n",
       "         [ 11.7767],\n",
       "         [ 24.9968],\n",
       "         [  8.5123],\n",
       "         [ 11.8818],\n",
       "         [  8.5688],\n",
       "         [  4.3646],\n",
       "         [  5.5507],\n",
       "         [ 15.8809],\n",
       "         [  5.6469],\n",
       "         [  3.5338],\n",
       "         [ 43.1643],\n",
       "         [  8.0497],\n",
       "         [  8.1447],\n",
       "         [  5.1978],\n",
       "         [  6.8081],\n",
       "         [  6.8718],\n",
       "         [  9.3310],\n",
       "         [  6.4317],\n",
       "         [  3.1291],\n",
       "         [  7.0443],\n",
       "         [  9.1229],\n",
       "         [  6.7330],\n",
       "         [ 30.0601],\n",
       "         [  4.3294],\n",
       "         [  5.8782],\n",
       "         [ 10.1505],\n",
       "         [ 33.1524],\n",
       "         [  4.6448],\n",
       "         [  4.0196],\n",
       "         [  4.2119],\n",
       "         [  3.2376],\n",
       "         [ 12.7524],\n",
       "         [  5.6367],\n",
       "         [  3.5765],\n",
       "         [ 26.8455],\n",
       "         [  7.7274],\n",
       "         [ 33.8598],\n",
       "         [  6.8675],\n",
       "         [  5.7555],\n",
       "         [  4.1813],\n",
       "         [  4.2158],\n",
       "         [ 37.6767],\n",
       "         [  6.5270],\n",
       "         [  6.8967],\n",
       "         [  3.8131],\n",
       "         [ 42.6522],\n",
       "         [  7.0673],\n",
       "         [ 10.5367],\n",
       "         [ 26.6768],\n",
       "         [  4.1640],\n",
       "         [ 25.2310],\n",
       "         [  4.4526],\n",
       "         [  2.8268],\n",
       "         [ 12.3827],\n",
       "         [ 13.3975],\n",
       "         [  6.7294],\n",
       "         [  5.9583],\n",
       "         [  3.7997],\n",
       "         [ 74.8811],\n",
       "         [  7.6264],\n",
       "         [  4.8916],\n",
       "         [  3.3093],\n",
       "         [ 10.6130],\n",
       "         [ 14.6990],\n",
       "         [ 22.6638],\n",
       "         [  4.5358],\n",
       "         [  4.8128],\n",
       "         [  6.7643],\n",
       "         [  4.4688],\n",
       "         [  4.4039],\n",
       "         [  4.5499],\n",
       "         [ 28.2716],\n",
       "         [  6.9050],\n",
       "         [  9.5073],\n",
       "         [  4.1063],\n",
       "         [ 13.2985],\n",
       "         [ 47.3681],\n",
       "         [ 24.2909],\n",
       "         [ 14.9570],\n",
       "         [  9.5301],\n",
       "         [  6.0270],\n",
       "         [  5.4352],\n",
       "         [  1.4927],\n",
       "         [ 60.8117],\n",
       "         [  3.2271],\n",
       "         [  9.2982],\n",
       "         [ 30.2965],\n",
       "         [  3.8459],\n",
       "         [  4.6812],\n",
       "         [  3.6869],\n",
       "         [  4.0690],\n",
       "         [ 75.4599],\n",
       "         [  2.5107],\n",
       "         [  9.3984],\n",
       "         [163.2311],\n",
       "         [  3.5448],\n",
       "         [ 18.5725],\n",
       "         [ 12.3311],\n",
       "         [  2.8710],\n",
       "         [  8.8696],\n",
       "         [  3.2766],\n",
       "         [ 76.1444],\n",
       "         [ 12.4730],\n",
       "         [  8.2036],\n",
       "         [  4.3815],\n",
       "         [  9.8303],\n",
       "         [  8.5080],\n",
       "         [  2.7738],\n",
       "         [  9.2410],\n",
       "         [  4.4857],\n",
       "         [ 49.8931],\n",
       "         [ 22.5188],\n",
       "         [ 26.2793],\n",
       "         [  3.3683],\n",
       "         [  9.2965],\n",
       "         [  3.5742],\n",
       "         [ 14.3419],\n",
       "         [ 13.5029],\n",
       "         [  9.5455],\n",
       "         [  3.8867],\n",
       "         [ 20.3977],\n",
       "         [  2.5479],\n",
       "         [  8.0700],\n",
       "         [ 17.3208],\n",
       "         [  2.5717],\n",
       "         [  9.3149],\n",
       "         [  6.3701],\n",
       "         [  2.9949],\n",
       "         [ 12.0938],\n",
       "         [ 49.3098],\n",
       "         [  5.8398],\n",
       "         [  7.7164],\n",
       "         [  5.0384],\n",
       "         [  2.9469],\n",
       "         [ 16.8722],\n",
       "         [  2.4276],\n",
       "         [ 34.0097],\n",
       "         [ 12.2208],\n",
       "         [  5.9807],\n",
       "         [  5.1500],\n",
       "         [  3.2936],\n",
       "         [  4.4464],\n",
       "         [  5.9780],\n",
       "         [  9.2907],\n",
       "         [  4.5630],\n",
       "         [  8.9525],\n",
       "         [  5.1446],\n",
       "         [  6.6120],\n",
       "         [  4.6697],\n",
       "         [  3.4906],\n",
       "         [  6.0260],\n",
       "         [  8.2817],\n",
       "         [  3.8628],\n",
       "         [  2.3592],\n",
       "         [  2.2688],\n",
       "         [ 17.6384],\n",
       "         [ 46.2187],\n",
       "         [ 73.7664],\n",
       "         [  2.5237],\n",
       "         [  4.7381],\n",
       "         [  3.4401],\n",
       "         [ 83.2648],\n",
       "         [  4.0696],\n",
       "         [  3.0233],\n",
       "         [  5.8430],\n",
       "         [  4.8501],\n",
       "         [  1.8924],\n",
       "         [  6.5489],\n",
       "         [ 18.5343],\n",
       "         [  7.8604],\n",
       "         [ 11.5825],\n",
       "         [  9.9786],\n",
       "         [ 54.9651],\n",
       "         [  2.5581],\n",
       "         [  2.7352],\n",
       "         [  5.6611],\n",
       "         [  7.8429],\n",
       "         [ 34.1198],\n",
       "         [  9.8857],\n",
       "         [ 10.3294],\n",
       "         [ 18.9995],\n",
       "         [ 14.1999],\n",
       "         [  6.9780],\n",
       "         [ 37.3530],\n",
       "         [  8.4631],\n",
       "         [  6.2394],\n",
       "         [ 35.8504],\n",
       "         [ 38.2352],\n",
       "         [ 12.1601],\n",
       "         [  3.2178],\n",
       "         [  4.7311],\n",
       "         [  4.7342],\n",
       "         [ 10.9393],\n",
       "         [ 34.2835],\n",
       "         [ 17.9323],\n",
       "         [  5.5593],\n",
       "         [ 11.4966],\n",
       "         [ 21.9265],\n",
       "         [  2.9781],\n",
       "         [ 12.1573],\n",
       "         [  7.1342],\n",
       "         [  3.5898],\n",
       "         [ 81.0327],\n",
       "         [  7.9486],\n",
       "         [ 32.3685],\n",
       "         [  2.1802],\n",
       "         [ 15.4244],\n",
       "         [  6.3746],\n",
       "         [ 26.5433],\n",
       "         [  4.7038],\n",
       "         [  2.9517],\n",
       "         [  4.9273],\n",
       "         [ 72.7039],\n",
       "         [  4.9533],\n",
       "         [  3.9267],\n",
       "         [  4.4807],\n",
       "         [ 11.1149],\n",
       "         [ 20.8344],\n",
       "         [  9.5566],\n",
       "         [  5.3798],\n",
       "         [  4.1691],\n",
       "         [  7.9039],\n",
       "         [ 10.8114],\n",
       "         [  1.4808],\n",
       "         [  4.1406],\n",
       "         [ 16.1122],\n",
       "         [  4.6960],\n",
       "         [ 11.4905],\n",
       "         [ 43.6101],\n",
       "         [  2.2014],\n",
       "         [  3.9746],\n",
       "         [  8.6836],\n",
       "         [  4.4944],\n",
       "         [  8.1202],\n",
       "         [  4.9356],\n",
       "         [  4.6625],\n",
       "         [  5.5389],\n",
       "         [  5.6475],\n",
       "         [  6.7008]]),\n",
       " tensor(408.0510),\n",
       " tensor(20.2003),\n",
       " tensor([[8.1287],\n",
       "         [9.1721],\n",
       "         [7.4035],\n",
       "         [7.9600],\n",
       "         [7.9708],\n",
       "         [7.4627],\n",
       "         [7.8010],\n",
       "         [7.7136],\n",
       "         [8.1702],\n",
       "         [7.9901],\n",
       "         [8.1170],\n",
       "         [7.6388],\n",
       "         [8.1061],\n",
       "         [8.4543],\n",
       "         [8.7772],\n",
       "         [8.0012],\n",
       "         [8.1436],\n",
       "         [8.6421],\n",
       "         [8.2156],\n",
       "         [7.7742],\n",
       "         [8.2672],\n",
       "         [7.7076],\n",
       "         [8.5820],\n",
       "         [8.3699],\n",
       "         [7.7813],\n",
       "         [8.2219],\n",
       "         [7.7656],\n",
       "         [8.1101],\n",
       "         [7.7800],\n",
       "         [7.9896],\n",
       "         [7.8379],\n",
       "         [7.4416],\n",
       "         [7.7408],\n",
       "         [8.0689],\n",
       "         [9.7167],\n",
       "         [8.6053],\n",
       "         [6.9015],\n",
       "         [8.1504],\n",
       "         [8.0624],\n",
       "         [7.4643],\n",
       "         [7.8877],\n",
       "         [7.9420],\n",
       "         [7.5020],\n",
       "         [8.2222],\n",
       "         [7.7990],\n",
       "         [7.7762],\n",
       "         [8.6713],\n",
       "         [7.7450],\n",
       "         [8.5054],\n",
       "         [7.4724],\n",
       "         [8.6874],\n",
       "         [7.9609],\n",
       "         [8.9203],\n",
       "         [7.5877],\n",
       "         [7.5907],\n",
       "         [8.0608],\n",
       "         [8.0513],\n",
       "         [7.6329],\n",
       "         [8.8643],\n",
       "         [8.5467],\n",
       "         [8.2012],\n",
       "         [7.8964],\n",
       "         [7.9014],\n",
       "         [7.8054],\n",
       "         [8.3536],\n",
       "         [8.6033],\n",
       "         [7.9986],\n",
       "         [7.8192],\n",
       "         [7.7084],\n",
       "         [7.9849],\n",
       "         [7.5725],\n",
       "         [8.9271],\n",
       "         [7.9064],\n",
       "         [7.6005],\n",
       "         [7.9200],\n",
       "         [7.4902],\n",
       "         [8.5082],\n",
       "         [8.2714],\n",
       "         [7.7478],\n",
       "         [7.4671],\n",
       "         [7.6923],\n",
       "         [7.6466],\n",
       "         [7.7665],\n",
       "         [7.8355],\n",
       "         [8.3169],\n",
       "         [8.4817],\n",
       "         [8.4788],\n",
       "         [7.8659],\n",
       "         [8.1211]], grad_fn=<ExpBackward0>),\n",
       " tensor([[  7.5889],\n",
       "         [ 12.9173],\n",
       "         [  3.5311],\n",
       "         [  5.0764],\n",
       "         [  7.7311],\n",
       "         [  4.2474],\n",
       "         [  6.6616],\n",
       "         [  5.3040],\n",
       "         [  7.8850],\n",
       "         [  4.4151],\n",
       "         [  7.6326],\n",
       "         [ 18.0611],\n",
       "         [  9.1238],\n",
       "         [  4.4315],\n",
       "         [ 19.3695],\n",
       "         [  2.8616],\n",
       "         [ 10.1137],\n",
       "         [ 11.2239],\n",
       "         [  8.4162],\n",
       "         [  3.7726],\n",
       "         [ 18.7540],\n",
       "         [  4.2816],\n",
       "         [  7.0562],\n",
       "         [  6.4812],\n",
       "         [  4.7557],\n",
       "         [  6.4515],\n",
       "         [  5.4604],\n",
       "         [  5.8155],\n",
       "         [  3.7033],\n",
       "         [  4.6768],\n",
       "         [  3.5545],\n",
       "         [  8.0307],\n",
       "         [ 12.0305],\n",
       "         [ 14.0659],\n",
       "         [ 58.2253],\n",
       "         [ 10.2159],\n",
       "         [  5.0569],\n",
       "         [184.6286],\n",
       "         [ 10.7014],\n",
       "         [  6.3953],\n",
       "         [ 10.5428],\n",
       "         [  5.8632],\n",
       "         [  3.3332],\n",
       "         [  7.0912],\n",
       "         [  6.2587],\n",
       "         [  6.6909],\n",
       "         [ 45.9098],\n",
       "         [  3.1428],\n",
       "         [ 20.7458],\n",
       "         [  2.4639],\n",
       "         [  8.2004],\n",
       "         [  4.7325],\n",
       "         [ 15.5817],\n",
       "         [  4.6764],\n",
       "         [  3.6949],\n",
       "         [ 13.2878],\n",
       "         [  5.1914],\n",
       "         [  4.0311],\n",
       "         [ 10.1789],\n",
       "         [ 39.1263],\n",
       "         [ 12.4955],\n",
       "         [  5.7091],\n",
       "         [  6.8506],\n",
       "         [  7.5266],\n",
       "         [ 13.6577],\n",
       "         [ 37.0492],\n",
       "         [  5.1372],\n",
       "         [  3.5015],\n",
       "         [  2.8254],\n",
       "         [  4.5570],\n",
       "         [  5.3459],\n",
       "         [ 21.7427],\n",
       "         [  4.3244],\n",
       "         [  2.6940],\n",
       "         [  5.3316],\n",
       "         [ 13.1957],\n",
       "         [  8.9274],\n",
       "         [ 20.0496],\n",
       "         [  5.0837],\n",
       "         [  5.6472],\n",
       "         [  7.0966],\n",
       "         [  2.5808],\n",
       "         [  4.5764],\n",
       "         [  5.1932],\n",
       "         [  4.1563],\n",
       "         [ 39.6006],\n",
       "         [ 12.8316],\n",
       "         [ 70.4130],\n",
       "         [  9.4762]]),\n",
       " tensor(484.0799, grad_fn=<MseLossBackward0>),\n",
       " tensor(22.0018, grad_fn=<SqrtBackward0>),\n",
       " array([ 2.28890330e-01,  3.11936699e-02,  3.82640272e-01,  3.37022662e-01,\n",
       "         2.15043277e-01,  3.52325588e-01,  2.56554455e-01,  3.15153241e-01,\n",
       "         2.17144325e-01,  3.68919611e-01,  2.26330996e-01, -2.76854515e-01,\n",
       "         1.57033831e-01,  3.89579952e-01, -2.84700930e-01,  4.41108555e-01,\n",
       "         1.13096245e-01,  8.48695934e-02,  1.94728270e-01,  3.88601601e-01,\n",
       "        -2.79833704e-01,  3.62047940e-01,  2.74378449e-01,  2.91119218e-01,\n",
       "         3.43575120e-01,  2.85665810e-01,  3.10335279e-01,  3.09851140e-01,\n",
       "         3.92063498e-01,  3.56822550e-01,  4.01602834e-01,  1.76806673e-01,\n",
       "         6.07719785e-03, -7.26928040e-02, -2.03399944e+00,  1.29676983e-01,\n",
       "         2.89084852e-01, -7.93799210e+00,  8.22287574e-02,  2.53305078e-01,\n",
       "         8.14919770e-02,  2.99891680e-01,  3.96314383e-01,  2.56164998e-01,\n",
       "         2.75049061e-01,  2.54051834e-01, -1.51404774e+00,  4.16307092e-01,\n",
       "        -3.60737383e-01,  4.35052335e-01,  2.26450861e-01,  3.52931499e-01,\n",
       "        -1.03345975e-01,  3.38299513e-01,  3.83719563e-01, -3.71650755e-02,\n",
       "         3.35928261e-01,  3.70156676e-01,  1.43330500e-01, -1.20683420e+00,\n",
       "         5.86508028e-03,  3.04896593e-01,  2.52465099e-01,  2.16849074e-01,\n",
       "        -4.07253094e-02, -1.10839283e+00,  3.35997403e-01,  4.03183162e-01,\n",
       "         4.29264814e-01,  3.62133056e-01,  3.06709558e-01, -3.87274593e-01,\n",
       "         3.69241327e-01,  4.30349410e-01,  3.23403835e-01, -5.92460819e-02,\n",
       "         1.84641019e-01, -3.39413464e-01,  3.26896250e-01,  2.87949532e-01,\n",
       "         2.31466576e-01,  4.37699378e-01,  3.51161063e-01,  3.25891405e-01,\n",
       "         3.95938903e-01, -1.23171377e+00,  3.16321384e-03, -2.68168187e+00,\n",
       "         1.41468927e-01], dtype=float32)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "#Best run passing in sex, mutation and age before encoder\n",
    "full_load_and_run_and_convert('/scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-13_15-49-20/model=gat-v4,seed=31061_269_act=sigmoid,adj_thresh=0.1000,batch_size=8,dropout=0.1000,l1_lambda=0.0008,lr=0.0000,lr_scheduler=Lamb_2024-08-13_16-58-56/checkpoint_000005', device, 2.124088581365514, 0.8733420033790319)\n",
    "#full_load_and_run_and_convert('/scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-13_15-49-20/model=gat-v4,seed=55118_1133_act=relu,adj_thresh=0.9000,batch_size=32,dropout=0.2000,l1_lambda=0.0001,lr=0.0000,lr_scheduler=Lambd_2024-08-14_01-14-01/checkpoint_000001',device, 2.124088581365514, 0.8733420033790319)\n",
    "\n",
    "\n",
    "full_load_and_run_and_convert('/scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-15_10-15-54/model=gat-v4,seed=35068_564_act=sigmoid,adj_thresh=0.7000,batch_size=8,dropout=0.2000,l1_lambda=0.0006,lr=0.0000,lr_scheduler=Lamb_2024-08-15_13-19-27/checkpoint_000065', device, 2.124088581365514, 0.8733420033790319)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from: /home/data/data_louisa/processed/ftd_y_val_nfl_adj_thresh_0.9_num_nodes_7247_mutation_GRN,MAPT,C9orf72,CTL_csf_sex_M,F_masternodes_True_train.pt\n",
      "Loading data from: /home/data/data_louisa/processed/ftd_y_val_nfl_adj_thresh_0.9_num_nodes_7247_mutation_GRN,MAPT,C9orf72,CTL_csf_sex_M,F_masternodes_True_test.pt\n",
      "Normalized Val MSE: 0.3589880168437958\n",
      "Normalized train MSE: 0.6138961911201477\n",
      "[15.2708235 10.195642  18.776457   9.160423   3.0481133  9.250263\n",
      " 11.133699  11.667741   4.350158   5.136927   8.905613  18.445415\n",
      "  3.127379   4.4976735 13.419723  13.967364  14.09947    7.299478\n",
      " 17.701893  11.746225  11.734119   4.4216065  3.7322218  8.885336\n",
      "  6.459698   6.8190637 17.22844   18.026674   6.6333866  6.278182\n",
      " 15.459351   8.390783   3.2082236 11.944394   4.344727  12.127326\n",
      "  3.2634714 18.682575   6.1436768 17.546104  12.951021   7.9535956\n",
      "  5.470645   4.4759927 13.552354 ]\n",
      "Original Units Val MSE: tensor(164.0844, grad_fn=<MseLossBackward0>)\n",
      "Original Units Val RMSE: tensor(12.8095, grad_fn=<SqrtBackward0>)\n",
      "Val Z scores: [ 0.18460555 -0.19706956 -5.628807   -0.15718545  0.08516078 -0.79147595\n",
      "  0.3977011   0.49129826  0.25239915  0.22991994 -0.06971449 -1.0792427\n",
      "  0.3255639   0.19964607  0.22963549  0.6678673   0.6883416   0.46403646\n",
      " -1.3022846   0.6375392   0.65757823  0.3184947   0.20549761 -0.29812652\n",
      "  0.32443246 -0.84979916 -1.5838066  -0.10215255  0.35459173  0.06813828\n",
      "  0.5590136   0.4365104  -0.01334689  0.34038803  0.30658197  0.24520792\n",
      "  0.2109953   0.5604699   0.41522962  0.45498434  0.25104246  0.478054\n",
      "  0.16557316  0.19241129  0.6741017 ]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[tensor([[ 5.6601],\n",
       "         [ 7.3133],\n",
       "         [19.0930],\n",
       "         [ 3.6284],\n",
       "         [ 9.7957],\n",
       "         [12.2536],\n",
       "         [ 3.2121],\n",
       "         [16.1121],\n",
       "         [12.6195],\n",
       "         [ 3.2712],\n",
       "         [ 4.2896],\n",
       "         [ 6.0337],\n",
       "         [ 3.5932],\n",
       "         [18.2804],\n",
       "         [16.0355],\n",
       "         [12.7171],\n",
       "         [18.5303],\n",
       "         [ 5.6577],\n",
       "         [ 8.6207],\n",
       "         [ 3.6887],\n",
       "         [ 3.7167],\n",
       "         [ 8.2238],\n",
       "         [12.4337],\n",
       "         [ 3.0844],\n",
       "         [ 3.8381],\n",
       "         [ 3.2121],\n",
       "         [10.0568],\n",
       "         [15.2929],\n",
       "         [ 3.2598],\n",
       "         [16.5107],\n",
       "         [ 4.2044],\n",
       "         [ 7.1950],\n",
       "         [13.6706],\n",
       "         [ 6.8542],\n",
       "         [ 4.7521],\n",
       "         [15.2225],\n",
       "         [ 7.7305],\n",
       "         [18.1262],\n",
       "         [18.8649],\n",
       "         [11.3500],\n",
       "         [11.7557],\n",
       "         [16.3371],\n",
       "         [ 3.1791],\n",
       "         [ 7.7107],\n",
       "         [13.3683],\n",
       "         [ 8.1163],\n",
       "         [ 3.6262],\n",
       "         [ 6.0099],\n",
       "         [10.8881],\n",
       "         [16.0550],\n",
       "         [ 9.8350],\n",
       "         [ 3.7392],\n",
       "         [ 5.0880],\n",
       "         [18.9743],\n",
       "         [ 3.1718],\n",
       "         [18.0433],\n",
       "         [ 9.4936],\n",
       "         [ 8.5808],\n",
       "         [ 3.8126],\n",
       "         [ 3.7257],\n",
       "         [ 3.9125],\n",
       "         [ 3.1013],\n",
       "         [18.7103],\n",
       "         [13.4985],\n",
       "         [ 7.9887],\n",
       "         [10.1111],\n",
       "         [11.6871],\n",
       "         [ 3.6476],\n",
       "         [ 6.6625],\n",
       "         [13.2547],\n",
       "         [ 6.5240],\n",
       "         [11.7877],\n",
       "         [11.2476],\n",
       "         [16.4747],\n",
       "         [10.0342],\n",
       "         [11.5408],\n",
       "         [18.3477],\n",
       "         [12.3859],\n",
       "         [15.9333],\n",
       "         [18.3013],\n",
       "         [ 3.1517],\n",
       "         [ 8.5061],\n",
       "         [16.8171],\n",
       "         [10.7506],\n",
       "         [12.5022],\n",
       "         [14.4889],\n",
       "         [11.1808],\n",
       "         [18.5670],\n",
       "         [ 3.5084],\n",
       "         [18.1695],\n",
       "         [ 8.8116],\n",
       "         [17.3424],\n",
       "         [ 3.3861],\n",
       "         [13.5336],\n",
       "         [ 9.6291],\n",
       "         [ 4.3890],\n",
       "         [ 3.5740],\n",
       "         [ 3.0422],\n",
       "         [10.0302],\n",
       "         [18.1054],\n",
       "         [ 4.5078],\n",
       "         [ 4.1819],\n",
       "         [ 3.4159],\n",
       "         [ 4.3780],\n",
       "         [ 5.9954],\n",
       "         [ 3.1050],\n",
       "         [16.2365],\n",
       "         [11.8239],\n",
       "         [14.4628],\n",
       "         [ 5.0462],\n",
       "         [ 5.1148],\n",
       "         [ 4.4364],\n",
       "         [17.1742],\n",
       "         [10.5823],\n",
       "         [15.9051],\n",
       "         [10.3563],\n",
       "         [ 3.9105],\n",
       "         [ 6.0230],\n",
       "         [15.2491],\n",
       "         [11.7464],\n",
       "         [ 3.1193],\n",
       "         [10.9710],\n",
       "         [ 3.6594],\n",
       "         [ 7.1313],\n",
       "         [11.3281],\n",
       "         [ 3.0790],\n",
       "         [13.8562],\n",
       "         [18.5699],\n",
       "         [ 7.5404],\n",
       "         [12.8900],\n",
       "         [10.5822],\n",
       "         [18.7073],\n",
       "         [12.3215],\n",
       "         [ 9.6992],\n",
       "         [18.0051],\n",
       "         [12.3181],\n",
       "         [ 3.6854],\n",
       "         [17.8837],\n",
       "         [ 7.7574],\n",
       "         [ 3.9547],\n",
       "         [10.4304],\n",
       "         [ 3.4093],\n",
       "         [ 5.9474],\n",
       "         [ 5.4054],\n",
       "         [ 3.1093],\n",
       "         [ 5.8167],\n",
       "         [ 7.4597],\n",
       "         [ 4.0099],\n",
       "         [ 5.2499],\n",
       "         [ 7.8582],\n",
       "         [12.0637],\n",
       "         [13.2417],\n",
       "         [12.2322],\n",
       "         [ 6.5316],\n",
       "         [10.2523],\n",
       "         [ 9.5587],\n",
       "         [ 4.4678],\n",
       "         [ 3.9428],\n",
       "         [ 3.3059],\n",
       "         [10.0198],\n",
       "         [11.7936],\n",
       "         [10.8066],\n",
       "         [ 7.2192],\n",
       "         [ 3.4396],\n",
       "         [12.3046],\n",
       "         [ 3.1012],\n",
       "         [ 4.2698],\n",
       "         [18.3331],\n",
       "         [15.0742],\n",
       "         [ 8.6314],\n",
       "         [10.5259],\n",
       "         [ 5.8331],\n",
       "         [13.1650],\n",
       "         [ 3.5516],\n",
       "         [17.0915],\n",
       "         [ 6.7893],\n",
       "         [13.3260],\n",
       "         [14.8737],\n",
       "         [18.0877]]),\n",
       " tensor([[ 10.1167],\n",
       "         [  4.8273],\n",
       "         [ 11.3758],\n",
       "         [  6.3309],\n",
       "         [  5.5243],\n",
       "         [ 19.0975],\n",
       "         [  2.2080],\n",
       "         [  8.7043],\n",
       "         [  5.4880],\n",
       "         [  2.1860],\n",
       "         [  9.7635],\n",
       "         [ 86.6399],\n",
       "         [  4.3265],\n",
       "         [ 11.1943],\n",
       "         [ 15.0883],\n",
       "         [ 62.0507],\n",
       "         [ 14.2380],\n",
       "         [  5.3757],\n",
       "         [  6.9591],\n",
       "         [  5.7730],\n",
       "         [  3.1793],\n",
       "         [  6.0964],\n",
       "         [ 10.6098],\n",
       "         [  2.4436],\n",
       "         [  2.5440],\n",
       "         [  4.5311],\n",
       "         [ 48.2977],\n",
       "         [ 13.3339],\n",
       "         [  4.1750],\n",
       "         [121.6692],\n",
       "         [  4.5896],\n",
       "         [  7.3740],\n",
       "         [  6.0449],\n",
       "         [  5.1557],\n",
       "         [  3.1938],\n",
       "         [ 13.0544],\n",
       "         [  8.4900],\n",
       "         [  6.2857],\n",
       "         [ 95.4445],\n",
       "         [  7.0365],\n",
       "         [  7.3990],\n",
       "         [ 11.2784],\n",
       "         [  7.1822],\n",
       "         [  2.8114],\n",
       "         [ 12.3482],\n",
       "         [  6.6437],\n",
       "         [  2.9927],\n",
       "         [  4.1744],\n",
       "         [  8.8680],\n",
       "         [  8.9682],\n",
       "         [ 13.1766],\n",
       "         [  3.3693],\n",
       "         [  2.5693],\n",
       "         [ 82.9245],\n",
       "         [  3.9373],\n",
       "         [ 37.7225],\n",
       "         [ 17.1284],\n",
       "         [ 23.9309],\n",
       "         [  2.6037],\n",
       "         [  3.6518],\n",
       "         [  4.2141],\n",
       "         [  2.7373],\n",
       "         [ 35.0793],\n",
       "         [  9.7706],\n",
       "         [  3.5725],\n",
       "         [  9.9528],\n",
       "         [  7.0325],\n",
       "         [  6.6709],\n",
       "         [  4.1341],\n",
       "         [  9.1830],\n",
       "         [  4.2755],\n",
       "         [ 24.6015],\n",
       "         [  4.2506],\n",
       "         [ 16.6183],\n",
       "         [  7.5283],\n",
       "         [ 56.1249],\n",
       "         [ 20.6275],\n",
       "         [ 12.7782],\n",
       "         [ 80.2171],\n",
       "         [  7.9675],\n",
       "         [  4.0191],\n",
       "         [  5.6098],\n",
       "         [  9.2476],\n",
       "         [ 13.3588],\n",
       "         [  6.0746],\n",
       "         [ 14.4016],\n",
       "         [  4.9069],\n",
       "         [ 14.4771],\n",
       "         [  2.7168],\n",
       "         [ 26.6115],\n",
       "         [  4.8881],\n",
       "         [ 41.2233],\n",
       "         [  3.0380],\n",
       "         [  8.1047],\n",
       "         [  6.9760],\n",
       "         [  4.5831],\n",
       "         [  4.8222],\n",
       "         [  1.8875],\n",
       "         [  4.5072],\n",
       "         [  8.0067],\n",
       "         [  4.6870],\n",
       "         [  4.3306],\n",
       "         [  2.3723],\n",
       "         [  6.1126],\n",
       "         [  5.2504],\n",
       "         [  4.4892],\n",
       "         [ 19.4275],\n",
       "         [  5.8640],\n",
       "         [ 10.4173],\n",
       "         [  6.6160],\n",
       "         [  3.0204],\n",
       "         [  4.8879],\n",
       "         [ 14.3599],\n",
       "         [ 12.6793],\n",
       "         [  9.8314],\n",
       "         [  5.6627],\n",
       "         [  4.9680],\n",
       "         [ 15.1033],\n",
       "         [  7.8152],\n",
       "         [  8.3577],\n",
       "         [  8.5448],\n",
       "         [ 53.5672],\n",
       "         [  4.2809],\n",
       "         [  3.6037],\n",
       "         [ 84.4434],\n",
       "         [  5.7691],\n",
       "         [  8.6358],\n",
       "         [ 41.9473],\n",
       "         [  2.9428],\n",
       "         [ 10.0625],\n",
       "         [ 85.7042],\n",
       "         [ 10.8005],\n",
       "         [ 24.8486],\n",
       "         [  4.2027],\n",
       "         [ 73.4551],\n",
       "         [  9.3809],\n",
       "         [  2.7222],\n",
       "         [ 43.6218],\n",
       "         [  3.3249],\n",
       "         [  4.8740],\n",
       "         [  5.9444],\n",
       "         [  3.0419],\n",
       "         [  9.8332],\n",
       "         [ 10.6730],\n",
       "         [  5.0684],\n",
       "         [  6.9884],\n",
       "         [  5.1185],\n",
       "         [  3.2937],\n",
       "         [  6.6486],\n",
       "         [  6.8371],\n",
       "         [  9.4036],\n",
       "         [ 78.9355],\n",
       "         [ 22.1398],\n",
       "         [  8.7210],\n",
       "         [  9.7408],\n",
       "         [  8.5715],\n",
       "         [  4.1530],\n",
       "         [  9.6421],\n",
       "         [  4.8015],\n",
       "         [  4.0045],\n",
       "         [ 12.8974],\n",
       "         [  4.8514],\n",
       "         [  7.0016],\n",
       "         [  5.2097],\n",
       "         [  4.0740],\n",
       "         [  2.2781],\n",
       "         [  4.5765],\n",
       "         [ 44.1702],\n",
       "         [ 12.2691],\n",
       "         [ 10.7287],\n",
       "         [  5.9804],\n",
       "         [  7.1664],\n",
       "         [  5.6356],\n",
       "         [  5.3738],\n",
       "         [ 11.2010],\n",
       "         [  4.6946],\n",
       "         [  9.2071],\n",
       "         [ 15.8086],\n",
       "         [  9.4545]]),\n",
       " tensor(357.7104),\n",
       " tensor(18.9132),\n",
       " tensor([[15.2708],\n",
       "         [10.1956],\n",
       "         [18.7765],\n",
       "         [ 9.1604],\n",
       "         [ 3.0481],\n",
       "         [ 9.2503],\n",
       "         [11.1337],\n",
       "         [11.6677],\n",
       "         [ 4.3502],\n",
       "         [ 5.1369],\n",
       "         [ 8.9056],\n",
       "         [18.4454],\n",
       "         [ 3.1274],\n",
       "         [ 4.4977],\n",
       "         [13.4197],\n",
       "         [13.9674],\n",
       "         [14.0995],\n",
       "         [ 7.2995],\n",
       "         [17.7019],\n",
       "         [11.7462],\n",
       "         [11.7341],\n",
       "         [ 4.4216],\n",
       "         [ 3.7322],\n",
       "         [ 8.8853],\n",
       "         [ 6.4597],\n",
       "         [ 6.8191],\n",
       "         [17.2284],\n",
       "         [18.0267],\n",
       "         [ 6.6334],\n",
       "         [ 6.2782],\n",
       "         [15.4594],\n",
       "         [ 8.3908],\n",
       "         [ 3.2082],\n",
       "         [11.9444],\n",
       "         [ 4.3447],\n",
       "         [12.1273],\n",
       "         [ 3.2635],\n",
       "         [18.6826],\n",
       "         [ 6.1437],\n",
       "         [17.5461],\n",
       "         [12.9510],\n",
       "         [ 7.9536],\n",
       "         [ 5.4706],\n",
       "         [ 4.4760],\n",
       "         [13.5524]], grad_fn=<ExpBackward0>),\n",
       " tensor([[15.4106],\n",
       "         [15.1858],\n",
       "         [92.7933],\n",
       "         [13.6437],\n",
       "         [ 4.4517],\n",
       "         [21.7942],\n",
       "         [ 8.5655],\n",
       "         [ 7.9101],\n",
       "         [ 3.6285],\n",
       "         [ 4.7009],\n",
       "         [12.2773],\n",
       "         [34.6463],\n",
       "         [ 1.4759],\n",
       "         [ 4.4464],\n",
       "         [12.9873],\n",
       "         [ 7.9659],\n",
       "         [ 7.8378],\n",
       "         [ 3.8883],\n",
       "         [36.7372],\n",
       "         [ 6.1302],\n",
       "         [ 5.8634],\n",
       "         [ 2.8600],\n",
       "         [ 3.6066],\n",
       "         [15.1597],\n",
       "         [ 4.8226],\n",
       "         [20.1041],\n",
       "         [39.8413],\n",
       "         [21.8106],\n",
       "         [ 4.6130],\n",
       "         [ 7.8981],\n",
       "         [10.8412],\n",
       "         [ 5.3294],\n",
       "         [ 5.8636],\n",
       "         [10.1045],\n",
       "         [ 2.9345],\n",
       "         [11.4970],\n",
       "         [ 3.0679],\n",
       "         [14.0459],\n",
       "         [ 3.3527],\n",
       "         [14.2499],\n",
       "         [12.2466],\n",
       "         [ 4.3643],\n",
       "         [ 5.8523],\n",
       "         [ 4.5166],\n",
       "         [ 7.4716]]),\n",
       " tensor(164.0844, grad_fn=<MseLossBackward0>),\n",
       " tensor(12.8095, grad_fn=<SqrtBackward0>),\n",
       " array([ 0.18460555, -0.19706956, -5.628807  , -0.15718545,  0.08516078,\n",
       "        -0.79147595,  0.3977011 ,  0.49129826,  0.25239915,  0.22991994,\n",
       "        -0.06971449, -1.0792427 ,  0.3255639 ,  0.19964607,  0.22963549,\n",
       "         0.6678673 ,  0.6883416 ,  0.46403646, -1.3022846 ,  0.6375392 ,\n",
       "         0.65757823,  0.3184947 ,  0.20549761, -0.29812652,  0.32443246,\n",
       "        -0.84979916, -1.5838066 , -0.10215255,  0.35459173,  0.06813828,\n",
       "         0.5590136 ,  0.4365104 , -0.01334689,  0.34038803,  0.30658197,\n",
       "         0.24520792,  0.2109953 ,  0.5604699 ,  0.41522962,  0.45498434,\n",
       "         0.25104246,  0.478054  ,  0.16557316,  0.19241129,  0.6741017 ],\n",
       "       dtype=float32)]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Best run using sex, mutation, age, masternodes\n",
    "full_load_and_run_and_convert('/scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-08-23_13-20-08/model=gat-v4,seed=44609_31_act=relu,adj_thresh=0.9000,batch_size=50,dropout=0,l1_lambda=0.0104,lr=0.0034,lr_scheduler=ReduceLROnPl_2024-08-23_13-20-08/checkpoint_000006', device, 2.124088581365514, 0.8733420033790319)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "716.7650146484375\n"
     ]
    }
   ],
   "source": [
    "#Sanity check\n",
    "def compute_manual_mse(val_preds, val_targets):\n",
    "    \"\"\"\n",
    "    Manually computes the Mean Squared Error (MSE) for the given predictions and targets.\n",
    "\n",
    "    Parameters:\n",
    "    val_preds (list of list of torch.Tensor): The predicted values.\n",
    "    val_targets (list of list of torch.Tensor): The true target values.\n",
    "\n",
    "    Returns:\n",
    "    float: The computed Mean Squared Error.\n",
    "    \"\"\"\n",
    "   # Compute the squared differences\n",
    "    squared_diffs = (val_preds - val_targets) ** 2\n",
    "\n",
    "    # Compute the mean of the squared differences\n",
    "    mse = squared_diffs.mean().item()\n",
    "\n",
    "    return mse\n",
    "\n",
    "print(compute_manual_mse(val_preds, val_targets))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading checkpoint from: /scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-07-31_15-31-35/model=gat-v4,seed=19543_0_act=relu,adj_thresh=0.1000,batch_size=8,dropout=0,l1_lambda=0.0000,lr=0.1000,lr_scheduler=LambdaLR,modal_2024-07-31_15-31-36/checkpoint_000001/checkpoint.ckpt\n",
      "Checkpoint keys: dict_keys(['epoch', 'global_step', 'pytorch-lightning_version', 'state_dict', 'loops', 'callbacks', 'optimizer_states', 'lr_schedulers', 'hparams_name', 'hyper_parameters'])\n",
      "checkpoint state_dict keys: odict_keys(['model.convs.0.att_src', 'model.convs.0.att_dst', 'model.convs.0.bias', 'model.convs.0.lin.weight', 'model.convs.1.att_src', 'model.convs.1.att_dst', 'model.convs.1.bias', 'model.convs.1.lin.weight', 'model.pools.0.weight', 'model.pools.0.bias', 'model.pools.1.weight', 'model.pools.1.bias', 'model.layer_norm.weight', 'model.layer_norm.bias', 'model.encoder.0.0.weight', 'model.encoder.0.0.bias', 'model.encoder.1.0.weight', 'model.encoder.1.0.bias', 'model.encoder.2.0.weight', 'model.encoder.2.0.bias', 'model.encoder.3.0.weight', 'model.encoder.3.0.bias', 'model.encoder.4.weight', 'model.encoder.4.bias'])\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import train as proteo_train\n",
    "\n",
    "# Define a function to load the checkpoint and calculate MSE\n",
    "def load_checkpoint_and_calculate_mse(relative_checkpoint_path, levels_up=5):\n",
    "    # Get the current script directory\n",
    "    current_directory = os.getcwd()\n",
    "    \n",
    "    # Navigate up the specified number of levels\n",
    "    for _ in range(levels_up):\n",
    "        current_directory = os.path.dirname(current_directory)\n",
    "    \n",
    "    # Construct the full path to the checkpoint\n",
    "    checkpoint_path = os.path.join(current_directory, relative_checkpoint_path)\n",
    "    print(f\"Loading checkpoint from: {checkpoint_path}\")\n",
    "\n",
    "    # Check if the file exists to avoid errors\n",
    "    if not os.path.isfile(checkpoint_path):\n",
    "        raise FileNotFoundError(f\"Checkpoint file not found: {checkpoint_path}\")\n",
    "\n",
    "    # Load the checkpoint\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    print(\"Checkpoint keys:\", checkpoint.keys())\n",
    "    print(\"checkpoint state_dict keys:\", checkpoint['state_dict'].keys())\n",
    "\n",
    "    module = proteo_train.Proteo.load_from_checkpoint(checkpoint_path)\n",
    "\n",
    "    # Access the attributes\n",
    "    # best_val_pred = module.best_val_pred\n",
    "    # print(\"best_val_pred:\", best_val_pred)\n",
    "    # # print(\"min_val loss:\", module.val_loss)\n",
    "    # best_val_target = module.best_val_target\n",
    "    # best_train_pred = module.best_train_pred\n",
    "    # best_train_target = module.best_train_target\n",
    "\n",
    "    # # Calculate MSE for validation and training\n",
    "    # mse_val = F.mse_loss(best_val_pred, best_val_target).item()\n",
    "    # mse_train = F.mse_loss(best_train_pred, best_train_target).item()\n",
    "\n",
    "    return module, checkpoint\n",
    "\n",
    "# Example usage\n",
    "relative_checkpoint_path = '/scratch/lcornelis/outputs/ray_results/TorchTrainer_2024-07-31_16-47-02/model=gat-v4,seed=19543_0_act=relu,adj_thresh=0.1000,batch_size=8,dropout=0,l1_lambda=0.0000,lr=0.1000,lr_scheduler=LambdaLR,modal_2024-07-31_16-47-02/checkpoint_000001/checkpoint.cpkt'\n",
    "module, checkpoint = load_checkpoint_and_calculate_mse(relative_checkpoint_path)\n",
    "# print(f\"MSE Loss for validation set: {mse_val}\")\n",
    "# print(f\"MSE Loss for training set: {mse_train}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'training': True,\n",
       " '_parameters': OrderedDict(),\n",
       " '_buffers': OrderedDict(),\n",
       " '_non_persistent_buffers_set': set(),\n",
       " '_backward_pre_hooks': OrderedDict(),\n",
       " '_backward_hooks': OrderedDict(),\n",
       " '_is_full_backward_hook': None,\n",
       " '_forward_hooks': OrderedDict(),\n",
       " '_forward_hooks_with_kwargs': OrderedDict(),\n",
       " '_forward_hooks_always_called': OrderedDict(),\n",
       " '_forward_pre_hooks': OrderedDict(),\n",
       " '_forward_pre_hooks_with_kwargs': OrderedDict(),\n",
       " '_state_dict_hooks': OrderedDict(),\n",
       " '_state_dict_pre_hooks': OrderedDict(),\n",
       " '_load_state_dict_pre_hooks': OrderedDict(),\n",
       " '_load_state_dict_post_hooks': OrderedDict(),\n",
       " '_modules': OrderedDict([('model',\n",
       "               GATv4(\n",
       "                 (convs): ModuleList(\n",
       "                   (0): CustomGATConv(1, 8, heads=2)\n",
       "                   (1): CustomGATConv(16, 16, heads=3)\n",
       "                 )\n",
       "                 (pools): ModuleList(\n",
       "                   (0): Linear(in_features=16, out_features=1, bias=True)\n",
       "                   (1): Linear(in_features=48, out_features=1, bias=True)\n",
       "                 )\n",
       "                 (layer_norm): LayerNorm((30,), eps=1e-05, elementwise_affine=True)\n",
       "                 (encoder): Sequential(\n",
       "                   (0): Sequential(\n",
       "                     (0): Linear(in_features=90, out_features=64, bias=True)\n",
       "                     (1): ReLU()\n",
       "                     (2): AlphaDropout(p=0.1, inplace=True)\n",
       "                   )\n",
       "                   (1): Sequential(\n",
       "                     (0): Linear(in_features=64, out_features=128, bias=True)\n",
       "                     (1): ReLU()\n",
       "                     (2): AlphaDropout(p=0.1, inplace=True)\n",
       "                   )\n",
       "                   (2): Sequential(\n",
       "                     (0): Linear(in_features=128, out_features=128, bias=True)\n",
       "                     (1): ReLU()\n",
       "                     (2): AlphaDropout(p=0.1, inplace=True)\n",
       "                   )\n",
       "                   (3): Sequential(\n",
       "                     (0): Linear(in_features=128, out_features=32, bias=True)\n",
       "                     (1): ReLU()\n",
       "                     (2): AlphaDropout(p=0.1, inplace=True)\n",
       "                   )\n",
       "                   (4): Linear(in_features=32, out_features=1, bias=True)\n",
       "                 )\n",
       "               ))]),\n",
       " 'prepare_data_per_node': True,\n",
       " 'allow_zero_length_dataloader_with_multiple_devices': False,\n",
       " '_log_hyperparams': True,\n",
       " '_dtype': torch.float32,\n",
       " '_device': device(type='cuda', index=0),\n",
       " '_trainer': None,\n",
       " '_example_input_array': None,\n",
       " '_automatic_optimization': True,\n",
       " '_strict_loading': None,\n",
       " '_current_fx_name': None,\n",
       " '_param_requires_grad_state': {},\n",
       " '_metric_attributes': None,\n",
       " '_compiler_ctx': None,\n",
       " '_fabric': None,\n",
       " '_fabric_optimizers': [],\n",
       " '_device_mesh': None,\n",
       " '_hparams_name': 'kwargs',\n",
       " '_hparams': \"avg_node_degree\":   0.9\n",
       " \"config\":            gat_v4_weight_initializer=['uniform'] gat_hidden_channels=[8, 32, 128, 256] device=[0] root_dir='/home/lcornelis/code/proteo' checkpoint_every_n_epochs_train=1 l1_lambda=1e-05 pin_memory=True sex=['M'] wgcna_mergeCutHeight=0.25 y_val='nfl' log_every_n_steps=10 num_samples=1 gat_v4_heads=[[2, 3]] cpu_per_worker=16 nodes_count=1 adj_thresh=0.1 gat_heads=[1, 2, 4, 8] optimizer='Adam' checkpoint_dir='/scratch/lcornelis/outputs/checkpoints' num_to_keep=3 seed=19543 modality_choices=['plasma'] l1_lambda_min=1e-05 gat-v4={'hidden_channels': [8, 16], 'heads': [2, 3], 'use_layer_norm': True, 'which_layer': ['layer1', 'layer2', 'layer3'], 'fc_dim': [64, 128, 128, 32], 'fc_dropout': 0.1, 'fc_act': 'relu', 'weight_initializer': 'uniform', 'num_layers': None} lr=0.10000000000000005 wgcna_minModuleSize=10 gat_num_layers=[2, 4, 6, 12] model='gat-v4' dataset_name='ftd' y_val_choices=['nfl'] gat_v4_hidden_channels=[[8, 16]] accumulate_grad_batches=1 gat={'num_layers': 2, 'hidden_channels': 256, 'heads': 4, 'v2': True} trainer_accelerator='gpu' precision='32-true' gat_v4_fc_act=['relu'] batch_size_choices=[8] lr_scheduler='LambdaLR' num_workers=16 epochs=30 data_dir='/home/data/data_louisa' wandb_api_key_path='wandb_api_key.txt' dropout_choices=[0] dropout=0 gat_v4_fc_dim=[[64, 128, 128, 32]] ray_tmp_dir='/scratch/lcornelis/tmp' error_protein_file_name='bimodal_aptamers_for_removal.xlsx' act='relu' gcn_hidden_channels=[8, 32, 128] lr_max=0.1 gpu_per_worker=1 wandb_tmp_dir='/tmp' weight_decay=0 reduction_factor=8 lr_scheduler_choices=['LambdaLR'] model_grid_search=['gat-v4'] gcn_num_layers=[2, 3, 4] wandb_offline=False act_choices=['relu'] project='proteo' num_nodes=30 grace_period=30 adj_thresh_choices=[0.1] gcn={'num_layers': 3, 'hidden_channels': 32} lr_min=0.1 mutation_choices=[['GRN']] raw_file_name='ALLFTD_dataset_for_nina_louisa_071124.csv' sex_choices=[['M']] num_nodes_choices=[30] mutation=['GRN'] ray_results_dir='/scratch/lcornelis/outputs/ray_results' l1_lambda_max=1e-05 batch_size=8 gat_v4_fc_dropout=[0.1] use_progress_bar=True modality='plasma' sync_batchnorm=False output_dir='/scratch/lcornelis/outputs'\n",
       " \"focal_loss_weight\": [1.0]\n",
       " \"in_channels\":       1\n",
       " \"out_channels\":      1\n",
       " \"pos_weight\":        1.0,\n",
       " '_hparams_initial': \"avg_node_degree\":   0.9\n",
       " \"config\":            gat_v4_weight_initializer=['uniform'] gat_hidden_channels=[8, 32, 128, 256] device=[0] root_dir='/home/lcornelis/code/proteo' checkpoint_every_n_epochs_train=1 l1_lambda=1e-05 pin_memory=True sex=['M'] wgcna_mergeCutHeight=0.25 y_val='nfl' log_every_n_steps=10 num_samples=1 gat_v4_heads=[[2, 3]] cpu_per_worker=16 nodes_count=1 adj_thresh=0.1 gat_heads=[1, 2, 4, 8] optimizer='Adam' checkpoint_dir='/scratch/lcornelis/outputs/checkpoints' num_to_keep=3 seed=19543 modality_choices=['plasma'] l1_lambda_min=1e-05 gat-v4={'hidden_channels': [8, 16], 'heads': [2, 3], 'use_layer_norm': True, 'which_layer': ['layer1', 'layer2', 'layer3'], 'fc_dim': [64, 128, 128, 32], 'fc_dropout': 0.1, 'fc_act': 'relu', 'weight_initializer': 'uniform', 'num_layers': None} lr=0.10000000000000005 wgcna_minModuleSize=10 gat_num_layers=[2, 4, 6, 12] model='gat-v4' dataset_name='ftd' y_val_choices=['nfl'] gat_v4_hidden_channels=[[8, 16]] accumulate_grad_batches=1 gat={'num_layers': 2, 'hidden_channels': 256, 'heads': 4, 'v2': True} trainer_accelerator='gpu' precision='32-true' gat_v4_fc_act=['relu'] batch_size_choices=[8] lr_scheduler='LambdaLR' num_workers=16 epochs=30 data_dir='/home/data/data_louisa' wandb_api_key_path='wandb_api_key.txt' dropout_choices=[0] dropout=0 gat_v4_fc_dim=[[64, 128, 128, 32]] ray_tmp_dir='/scratch/lcornelis/tmp' error_protein_file_name='bimodal_aptamers_for_removal.xlsx' act='relu' gcn_hidden_channels=[8, 32, 128] lr_max=0.1 gpu_per_worker=1 wandb_tmp_dir='/tmp' weight_decay=0 reduction_factor=8 lr_scheduler_choices=['LambdaLR'] model_grid_search=['gat-v4'] gcn_num_layers=[2, 3, 4] wandb_offline=False act_choices=['relu'] project='proteo' num_nodes=30 grace_period=30 adj_thresh_choices=[0.1] gcn={'num_layers': 3, 'hidden_channels': 32} lr_min=0.1 mutation_choices=[['GRN']] raw_file_name='ALLFTD_dataset_for_nina_louisa_071124.csv' sex_choices=[['M']] num_nodes_choices=[30] mutation=['GRN'] ray_results_dir='/scratch/lcornelis/outputs/ray_results' l1_lambda_max=1e-05 batch_size=8 gat_v4_fc_dropout=[0.1] use_progress_bar=True modality='plasma' sync_batchnorm=False output_dir='/scratch/lcornelis/outputs'\n",
       " \"focal_loss_weight\": [1.0]\n",
       " \"in_channels\":       1\n",
       " \"out_channels\":      1\n",
       " \"pos_weight\":        1.0,\n",
       " 'config': Config(gat_v4_weight_initializer=['uniform'], gat_hidden_channels=[8, 32, 128, 256], device=[0], root_dir='/home/lcornelis/code/proteo', checkpoint_every_n_epochs_train=1, l1_lambda=1e-05, pin_memory=True, sex=['M'], wgcna_mergeCutHeight=0.25, y_val='nfl', log_every_n_steps=10, num_samples=1, gat_v4_heads=[[2, 3]], cpu_per_worker=16, nodes_count=1, adj_thresh=0.1, gat_heads=[1, 2, 4, 8], optimizer='Adam', checkpoint_dir='/scratch/lcornelis/outputs/checkpoints', num_to_keep=3, seed=19543, modality_choices=['plasma'], l1_lambda_min=1e-05, gat-v4={'hidden_channels': [8, 16], 'heads': [2, 3], 'use_layer_norm': True, 'which_layer': ['layer1', 'layer2', 'layer3'], 'fc_dim': [64, 128, 128, 32], 'fc_dropout': 0.1, 'fc_act': 'relu', 'weight_initializer': 'uniform', 'num_layers': None}, lr=0.10000000000000005, wgcna_minModuleSize=10, gat_num_layers=[2, 4, 6, 12], model='gat-v4', dataset_name='ftd', y_val_choices=['nfl'], gat_v4_hidden_channels=[[8, 16]], accumulate_grad_batches=1, gat={'num_layers': 2, 'hidden_channels': 256, 'heads': 4, 'v2': True}, trainer_accelerator='gpu', precision='32-true', gat_v4_fc_act=['relu'], batch_size_choices=[8], lr_scheduler='LambdaLR', num_workers=16, epochs=30, data_dir='/home/data/data_louisa', wandb_api_key_path='wandb_api_key.txt', dropout_choices=[0], dropout=0, gat_v4_fc_dim=[[64, 128, 128, 32]], ray_tmp_dir='/scratch/lcornelis/tmp', error_protein_file_name='bimodal_aptamers_for_removal.xlsx', act='relu', gcn_hidden_channels=[8, 32, 128], lr_max=0.1, gpu_per_worker=1, wandb_tmp_dir='/tmp', weight_decay=0, reduction_factor=8, lr_scheduler_choices=['LambdaLR'], model_grid_search=['gat-v4'], gcn_num_layers=[2, 3, 4], wandb_offline=False, act_choices=['relu'], project='proteo', num_nodes=30, grace_period=30, adj_thresh_choices=[0.1], gcn={'num_layers': 3, 'hidden_channels': 32}, lr_min=0.1, mutation_choices=[['GRN']], raw_file_name='ALLFTD_dataset_for_nina_louisa_071124.csv', sex_choices=[['M']], num_nodes_choices=[30], mutation=['GRN'], ray_results_dir='/scratch/lcornelis/outputs/ray_results', l1_lambda_max=1e-05, batch_size=8, gat_v4_fc_dropout=[0.1], use_progress_bar=True, modality='plasma', sync_batchnorm=False, output_dir='/scratch/lcornelis/outputs'),\n",
       " 'config_model': Config(fc_dropout=0.1, fc_dim=[64, 128, 128, 32], weight_initializer='uniform', which_layer=['layer1', 'layer2', 'layer3'], fc_act='relu', hidden_channels=[8, 16], num_layers=None, use_layer_norm=True, heads=[2, 3]),\n",
       " 'avg_node_degree': 0.9,\n",
       " 'train_preds': [],\n",
       " 'val_preds': [],\n",
       " 'train_targets': [],\n",
       " 'val_targets': [],\n",
       " 'x0': [],\n",
       " 'x1': [],\n",
       " 'x2': [],\n",
       " 'multiscale': [],\n",
       " 'pos_weight': 1.0,\n",
       " 'focal_loss_weight': [1.0],\n",
       " 'min_val_loss': 1000,\n",
       " 'min_train_loss': 1000,\n",
       " 'best_val_pred': [],\n",
       " 'best_val_target': [],\n",
       " 'best_train_pred': [],\n",
       " 'best_train_target': [],\n",
       " 'best_val_epoch': 0,\n",
       " 'best_train_epoch': 0}"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "module.__dict__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'epoch': 1,\n",
       " 'global_step': 8,\n",
       " 'pytorch-lightning_version': '2.3.3',\n",
       " 'state_dict': OrderedDict([('model.convs.0.att_src',\n",
       "               tensor([[[ 0.6818,  0.0561,  0.6685,  0.3070,  0.7125,  0.4150,  0.2690,\n",
       "                         -0.2861],\n",
       "                        [-0.2914,  0.9814, -0.0518, -0.1408,  0.3510, -0.2540,  0.5184,\n",
       "                         -0.2630]]], device='cuda:0')),\n",
       "              ('model.convs.0.att_dst',\n",
       "               tensor([[[ 0.8912, -0.2167,  0.5399, -0.1660,  0.3122, -0.2951,  0.1650,\n",
       "                          0.5460],\n",
       "                        [ 1.0074,  0.5066,  0.3665,  1.0729,  0.2071,  1.0349,  0.2690,\n",
       "                          1.0922]]], device='cuda:0')),\n",
       "              ('model.convs.0.bias',\n",
       "               tensor([-0.0016,  0.2387,  0.2148,  0.2318,  0.1968,  0.2223,  0.2042,  0.2067,\n",
       "                        0.2075, -0.0101,  0.2075,  0.2105,  0.2058,  0.2272,  0.2135,  0.2171],\n",
       "                      device='cuda:0')),\n",
       "              ('model.convs.0.lin.weight',\n",
       "               tensor([[-0.2747],\n",
       "                       [ 0.7066],\n",
       "                       [ 0.7997],\n",
       "                       [-0.1340],\n",
       "                       [ 0.5177],\n",
       "                       [-0.1635],\n",
       "                       [ 0.2512],\n",
       "                       [ 0.1101],\n",
       "                       [ 1.2385],\n",
       "                       [-0.2567],\n",
       "                       [-0.2180],\n",
       "                       [ 0.5406],\n",
       "                       [-0.2236],\n",
       "                       [ 0.4800],\n",
       "                       [ 0.1008],\n",
       "                       [ 0.8289]], device='cuda:0')),\n",
       "              ('model.convs.1.att_src',\n",
       "               tensor([[[1.0275, 0.5577, 0.5425, 0.7948, 0.3066, 0.3760, 0.8046, 0.2538,\n",
       "                         0.7116, 1.1075, 0.3752, 0.2974, 0.6756, 0.1849, 1.0669, 1.1004],\n",
       "                        [0.3614, 0.8969, 0.5968, 0.6395, 0.3789, 0.6781, 0.8925, 0.7558,\n",
       "                         0.2489, 0.4834, 0.8252, 0.8750, 0.7255, 0.1840, 0.8078, 1.0982],\n",
       "                        [1.0532, 0.8308, 1.0668, 0.6789, 0.2108, 0.2277, 0.8233, 0.3911,\n",
       "                         0.7611, 0.1549, 0.2636, 0.3881, 0.8713, 0.6433, 0.5321, 0.9736]]],\n",
       "                      device='cuda:0')),\n",
       "              ('model.convs.1.att_dst',\n",
       "               tensor([[[0.8691, 0.6961, 1.0142, 1.0584, 0.6388, 0.6385, 0.7971, 0.9807,\n",
       "                         0.3522, 0.1389, 0.4226, 1.0692, 0.9349, 0.4062, 0.7369, 0.9201],\n",
       "                        [0.4954, 0.7028, 0.3788, 0.6439, 1.0613, 0.7012, 0.7688, 0.1747,\n",
       "                         1.1378, 0.5853, 0.8032, 0.5995, 0.9331, 0.8822, 0.7703, 0.5779],\n",
       "                        [0.2614, 0.9890, 0.4682, 0.7781, 0.2033, 0.6818, 0.6701, 0.5199,\n",
       "                         0.8749, 0.4317, 0.4214, 1.0276, 0.8983, 0.7483, 0.8996, 0.6155]]],\n",
       "                      device='cuda:0')),\n",
       "              ('model.convs.1.bias',\n",
       "               tensor([ 0.0259,  0.0188,  0.0345, -0.0023, -0.0155, -0.0085, -0.0145,  0.0348,\n",
       "                        0.0304,  0.0262,  0.0225,  0.0197,  0.0355,  0.0046, -0.0231, -0.0146,\n",
       "                       -0.0085,  0.0423,  0.0451, -0.0270, -0.0114,  0.0390,  0.0294,  0.0533,\n",
       "                        0.0439,  0.0459, -0.0094, -0.0195,  0.0108, -0.0066,  0.0281,  0.0175,\n",
       "                        0.0045, -0.0258,  0.0419,  0.0190,  0.0435, -0.0049, -0.0022,  0.0310,\n",
       "                       -0.0203,  0.0246,  0.0303,  0.0305,  0.0606,  0.0531, -0.0049,  0.0532],\n",
       "                      device='cuda:0')),\n",
       "              ('model.convs.1.lin.weight',\n",
       "               tensor([[-6.1789e-02,  3.2537e-01,  3.1245e-01, -1.4879e-01,  6.2613e-01,\n",
       "                        -7.6595e-02,  3.7200e-01,  2.8607e-01,  1.0946e+00,  5.1263e-02,\n",
       "                         3.8707e-01,  7.5295e-01,  8.1540e-01,  1.0228e+00,  3.1976e-01,\n",
       "                         7.2641e-01],\n",
       "                       [ 8.0462e-02,  7.4923e-02,  3.9717e-01,  5.7739e-01,  6.6411e-01,\n",
       "                         1.8960e-01, -1.6194e-01,  3.4741e-01,  3.5658e-01,  3.2658e-01,\n",
       "                         1.7487e-01,  6.5015e-01,  4.8669e-01,  8.8121e-01,  2.2233e-01,\n",
       "                         7.9592e-01],\n",
       "                       [-5.4787e-02, -1.7452e-01, -4.0066e-03,  3.6991e-01, -1.3842e-01,\n",
       "                         6.6489e-01,  5.1400e-01,  2.2546e-01,  6.6229e-01, -1.2439e-01,\n",
       "                         1.9736e-01,  8.0312e-01,  1.5757e-01,  2.1747e-01,  7.7982e-01,\n",
       "                         1.6635e-01],\n",
       "                       [ 3.3565e-01, -7.6811e-02,  1.8208e-01,  9.0041e-02, -2.8528e-01,\n",
       "                         3.6721e-01, -3.0266e-02,  3.4870e-01,  1.8523e-01,  3.9882e-02,\n",
       "                         1.1283e+00,  9.7768e-01,  8.1971e-01,  9.8342e-01,  1.0393e+00,\n",
       "                         8.9602e-01],\n",
       "                       [-8.3597e-02, -5.6796e-03,  5.1126e-01, -6.8543e-02,  4.9811e-01,\n",
       "                         2.4712e-02, -1.6763e-01, -6.6246e-02,  1.1119e+00, -7.7936e-02,\n",
       "                         8.4879e-01,  8.3962e-01,  5.3172e-01,  8.0456e-01,  8.2557e-01,\n",
       "                         3.3084e-01],\n",
       "                       [ 3.2889e-01,  2.4728e-01,  2.3987e-01,  4.8654e-01,  6.0219e-01,\n",
       "                         4.9324e-01, -5.0379e-02,  1.2001e-01,  2.2488e-01, -9.1733e-02,\n",
       "                         5.1895e-01,  8.6833e-01,  3.9100e-01,  6.1802e-01,  2.5641e-01,\n",
       "                         1.0594e+00],\n",
       "                       [-2.8237e-02,  8.2666e-01,  6.6929e-01,  4.8833e-01,  3.2791e-01,\n",
       "                         9.4391e-02,  5.1456e-02,  2.6413e-01,  6.3778e-01,  7.5601e-02,\n",
       "                         4.3326e-01,  9.9159e-01,  1.1278e+00,  9.0982e-01,  4.6125e-01,\n",
       "                         3.0125e-01],\n",
       "                       [-7.9173e-02,  4.4135e-02,  1.6634e-01, -3.0145e-01,  4.3109e-01,\n",
       "                         3.5091e-01, -2.0437e-01, -2.1063e-01,  5.7857e-01,  3.5037e-01,\n",
       "                         7.3467e-01,  5.6129e-01,  5.4390e-01,  9.0472e-01,  1.0916e+00,\n",
       "                         4.6168e-01],\n",
       "                       [ 1.8318e-01,  5.8674e-01, -4.3542e-03, -1.8643e-01,  3.9555e-01,\n",
       "                         1.9433e-01, -9.3008e-02,  4.6639e-02,  1.0120e+00,  2.7417e-01,\n",
       "                         9.4436e-01,  1.0217e+00,  8.3782e-01,  1.1464e+00,  1.1411e+00,\n",
       "                         5.0122e-01],\n",
       "                       [ 2.6993e-01,  2.3349e-01, -1.3734e-01,  6.1490e-01,  2.5105e-01,\n",
       "                         1.8006e-01,  6.1518e-01,  3.6357e-01,  1.1062e+00, -1.1610e-01,\n",
       "                         1.0098e+00,  5.4218e-01,  9.2764e-01,  3.5500e-01,  3.9014e-01,\n",
       "                         4.3998e-01],\n",
       "                       [-5.7937e-02,  6.2023e-02,  5.5346e-01, -1.4472e-01,  1.5873e-01,\n",
       "                        -2.1920e-01, -2.8521e-01,  4.3509e-01,  1.6317e-01, -5.0245e-02,\n",
       "                         8.4219e-01,  4.6536e-01,  1.0751e+00,  7.2416e-01,  1.5604e-01,\n",
       "                         6.8802e-01],\n",
       "                       [-5.3703e-02,  2.0671e-01, -9.8078e-02, -2.3637e-02,  1.3031e-01,\n",
       "                         1.8595e-01,  4.9995e-01,  6.7261e-02,  2.7332e-01, -2.6724e-02,\n",
       "                         5.4704e-01,  6.8578e-01,  3.8651e-01,  2.3658e-01,  2.2531e-01,\n",
       "                         5.4300e-01],\n",
       "                       [-1.2625e-01,  8.3075e-01,  4.2194e-02, -1.8660e-01, -1.5091e-01,\n",
       "                         8.3820e-03, -1.9707e-01, -5.3533e-02,  8.7044e-01, -1.2201e-01,\n",
       "                         9.8095e-01,  6.6980e-01,  5.5789e-01,  5.0437e-01,  1.6476e-01,\n",
       "                         1.0666e+00],\n",
       "                       [ 3.9707e-02,  6.3395e-01,  2.7295e-02, -9.3213e-02,  7.9628e-01,\n",
       "                         2.8047e-01, -5.1423e-02,  5.4591e-01,  2.9945e-01,  1.4810e-01,\n",
       "                         3.5107e-01,  4.5017e-01,  6.6818e-01,  2.7357e-01,  4.5058e-01,\n",
       "                         8.9165e-01],\n",
       "                       [ 4.7607e-02,  7.3774e-01,  4.4192e-01,  5.7419e-01,  4.8977e-01,\n",
       "                        -9.4977e-02, -2.9531e-01,  2.7908e-02,  2.4138e-01,  2.5806e-01,\n",
       "                         1.1048e+00,  2.6158e-01,  4.7928e-01,  3.5841e-01,  1.0207e+00,\n",
       "                         1.9289e-01],\n",
       "                       [-1.2323e-01,  2.3414e-01,  1.1138e-02,  5.1637e-01,  7.7759e-02,\n",
       "                        -2.2337e-01,  2.8335e-03,  1.3823e-01,  1.0611e+00, -4.2548e-02,\n",
       "                         1.9616e-01,  3.1252e-01,  6.8873e-01,  2.0445e-01,  5.9222e-01,\n",
       "                         1.1504e+00],\n",
       "                       [-8.2269e-03,  1.0148e-01,  1.6072e-01,  5.8242e-01, -1.2309e-01,\n",
       "                        -1.6382e-01,  5.6530e-01,  2.0329e-01,  2.7407e-01, -5.0663e-03,\n",
       "                         1.1073e+00,  6.0172e-01,  6.4172e-01,  2.3175e-01,  1.0551e+00,\n",
       "                         3.1647e-01],\n",
       "                       [ 9.2765e-02,  2.4335e-01,  9.9624e-02,  2.0190e-01,  2.9261e-01,\n",
       "                        -2.9909e-01,  3.0571e-01,  3.0523e-01,  2.7487e-01, -9.0866e-02,\n",
       "                         2.7141e-01,  1.0718e+00,  5.0720e-01,  8.7260e-01,  4.8652e-01,\n",
       "                         1.0429e+00],\n",
       "                       [-1.0747e-01,  3.3175e-01,  1.6985e-01,  1.0153e-01, -1.0712e-01,\n",
       "                         2.3820e-01,  3.7530e-03, -2.7521e-01,  7.0924e-01, -1.1747e-01,\n",
       "                         1.5831e-01,  9.0371e-01,  1.1342e+00,  1.1464e+00,  8.3291e-01,\n",
       "                         8.5850e-01],\n",
       "                       [-8.3544e-02,  4.1696e-01,  5.5923e-01, -2.8244e-01,  5.7896e-01,\n",
       "                         4.5857e-01, -2.0962e-01,  3.9820e-01,  8.4677e-01, -9.7585e-02,\n",
       "                         1.0654e+00,  1.6275e-01,  8.0893e-01,  9.1433e-01,  6.2007e-01,\n",
       "                         3.0630e-01],\n",
       "                       [-7.0392e-02,  4.9858e-01,  7.1534e-02,  5.7008e-01,  2.3622e-01,\n",
       "                         2.2913e-01,  6.9814e-02, -1.5193e-01,  2.9367e-01, -4.2914e-02,\n",
       "                         1.8581e-01,  3.2357e-01,  6.9095e-01,  1.0165e+00,  8.9382e-01,\n",
       "                         6.6348e-01],\n",
       "                       [-9.1428e-02, -3.0039e-03, -1.9863e-01, -2.8992e-01, -1.9991e-01,\n",
       "                        -2.8740e-02,  5.3236e-01,  4.0624e-01,  5.6427e-01,  4.6337e-02,\n",
       "                         1.0052e+00,  2.7561e-01,  1.0864e+00,  9.9614e-01,  7.8114e-01,\n",
       "                         2.3480e-01],\n",
       "                       [ 1.5823e-02,  1.4643e-01,  7.7213e-01,  5.2885e-01,  1.5802e-01,\n",
       "                         4.2133e-01, -2.8676e-02, -1.0677e-01,  1.9836e-01, -6.3353e-02,\n",
       "                         1.0802e+00,  8.1558e-01,  6.4320e-01,  6.6718e-01,  1.0471e+00,\n",
       "                         4.9031e-01],\n",
       "                       [ 1.0024e-02,  1.8798e-01,  6.4722e-01,  4.6741e-01, -1.4054e-01,\n",
       "                         7.0739e-02,  2.4527e-01,  3.1747e-03,  2.1365e-01,  1.0402e-01,\n",
       "                         1.7304e-01,  9.9013e-01,  9.3846e-01,  5.3760e-01,  5.8874e-01,\n",
       "                         5.1971e-01],\n",
       "                       [ 2.2454e-01,  5.0284e-01, -1.4982e-01,  1.7405e-01, -7.6939e-02,\n",
       "                        -2.0570e-01,  4.2681e-01, -3.1569e-02,  4.6229e-01, -1.0122e-01,\n",
       "                         5.9872e-01,  7.5500e-01,  4.1563e-01,  7.2763e-01,  9.2856e-01,\n",
       "                         7.4097e-01],\n",
       "                       [-8.7878e-02, -1.2619e-01,  2.7934e-01,  8.2400e-02,  5.7327e-01,\n",
       "                         1.6471e-01,  3.7383e-01,  6.2203e-01,  3.6847e-01,  2.6509e-01,\n",
       "                         1.0014e+00,  6.6684e-01,  8.6832e-01,  6.5191e-01,  2.1117e-01,\n",
       "                         2.3197e-01],\n",
       "                       [ 2.0167e-01,  8.9660e-01,  3.5287e-01,  3.5829e-01,  1.0833e+00,\n",
       "                         9.7756e-01,  4.1247e-01,  4.7035e-01,  2.0534e-01,  3.0840e-02,\n",
       "                        -2.9043e-01,  2.4465e-01, -3.0218e-01,  2.4498e-01,  3.7365e-01,\n",
       "                        -2.0722e-01],\n",
       "                       [ 3.8382e-01, -3.1117e-01,  1.0137e-01, -1.4501e-01, -2.0265e-01,\n",
       "                         6.0093e-01,  2.5217e-01, -9.0923e-02,  8.1218e-01,  2.8764e-01,\n",
       "                         5.7233e-01,  7.9353e-01,  9.7602e-01,  9.4282e-01,  5.4244e-01,\n",
       "                         7.2327e-01],\n",
       "                       [ 1.0640e-01,  6.4738e-01,  5.9631e-02,  6.4713e-01, -6.6647e-02,\n",
       "                         4.4682e-01, -9.1903e-02,  1.8783e-01,  1.0726e+00, -5.3999e-02,\n",
       "                         7.8765e-01,  1.1102e+00,  3.7974e-01,  8.7364e-01,  3.2741e-01,\n",
       "                         9.1035e-01],\n",
       "                       [ 3.0623e-01,  6.3933e-01, -5.3601e-02,  3.9040e-01, -1.5687e-01,\n",
       "                        -7.0999e-03, -2.2357e-01,  4.0273e-01,  7.3623e-01,  2.9932e-01,\n",
       "                         6.8632e-01,  4.2192e-01,  6.3763e-01,  7.4047e-01,  2.4466e-01,\n",
       "                         1.1424e+00],\n",
       "                       [ 3.1066e-01,  4.9755e-01,  6.0222e-01,  3.4521e-01,  1.6600e-01,\n",
       "                         2.8173e-01,  3.9538e-01,  4.7118e-01,  5.3607e-01, -9.0838e-02,\n",
       "                         2.6352e-01,  2.1935e-01,  9.3491e-01,  7.3639e-01,  2.5958e-01,\n",
       "                         4.4757e-01],\n",
       "                       [ 5.5597e-02,  1.3717e-01,  3.1788e-01,  8.5282e-02, -1.4423e-01,\n",
       "                         9.2605e-02, -2.7042e-01,  1.5581e-02,  9.3803e-01, -7.2307e-02,\n",
       "                         1.0651e+00,  5.2684e-01,  3.2238e-01,  2.3622e-01,  2.6320e-01,\n",
       "                         1.8704e-01],\n",
       "                       [ 2.0437e-02,  8.2966e-01,  5.2065e-01,  6.4797e-01,  7.5894e-01,\n",
       "                        -2.9197e-01,  6.2863e-01, -7.8341e-02,  2.6526e-01,  9.4292e-02,\n",
       "                         9.7485e-01,  1.5727e-01,  5.4041e-01,  5.5766e-01,  9.9932e-01,\n",
       "                         6.1418e-01],\n",
       "                       [ 4.2404e-02,  4.6133e-01,  7.7823e-01, -2.4805e-01,  7.5333e-01,\n",
       "                         3.6918e-02,  3.4113e-01,  6.6660e-01,  6.4147e-01,  2.9623e-01,\n",
       "                         5.2513e-01,  3.4410e-01,  6.7323e-01,  9.2891e-01,  8.7367e-01,\n",
       "                         7.9857e-01],\n",
       "                       [-6.4963e-02, -5.1305e-02,  8.7132e-02,  1.4932e-01,  7.4525e-01,\n",
       "                         1.6174e-01, -7.5785e-03,  1.5364e-01,  9.1941e-01, -5.0252e-02,\n",
       "                         8.5261e-01,  9.7274e-01,  1.0399e+00,  4.8435e-01,  5.0499e-01,\n",
       "                         1.0426e+00],\n",
       "                       [-2.3129e-02, -2.6016e-02,  3.4675e-01,  4.5557e-01,  5.5676e-01,\n",
       "                        -2.5736e-01,  4.9284e-01,  1.5886e-01,  5.5016e-01,  5.7016e-02,\n",
       "                         8.0660e-01,  7.4709e-01,  7.7972e-01,  7.7132e-01,  9.0483e-01,\n",
       "                         8.1184e-01],\n",
       "                       [-1.5376e-02,  4.1715e-01, -6.0401e-02,  5.7464e-01,  1.7197e-01,\n",
       "                         1.9836e-01,  6.3797e-01,  5.9748e-01,  8.1034e-01,  3.9749e-01,\n",
       "                         9.8818e-01,  6.5461e-01,  4.6975e-01,  6.2472e-01,  2.4805e-01,\n",
       "                         1.6921e-01],\n",
       "                       [ 7.1472e-03,  2.5287e-02,  7.3029e-01,  5.2384e-02,  5.7289e-01,\n",
       "                         1.6944e-01, -1.0625e-01,  2.5976e-01,  8.7490e-01,  1.3609e-01,\n",
       "                         4.0510e-01,  6.9725e-01,  4.9180e-01,  7.2291e-01,  1.7993e-01,\n",
       "                         9.1813e-01],\n",
       "                       [ 4.7645e-02,  2.6112e-02,  8.0982e-01,  3.7111e-01,  4.0908e-01,\n",
       "                         4.6897e-01,  3.7436e-01,  1.5881e-01,  3.4708e-01, -9.3791e-02,\n",
       "                         2.9486e-01,  2.3979e-01,  2.6902e-01,  8.4037e-01,  5.1409e-01,\n",
       "                         3.7723e-01],\n",
       "                       [ 3.1859e-01,  4.4834e-03,  4.1992e-01, -7.5275e-02,  8.1353e-01,\n",
       "                         1.0510e-01,  5.1014e-01,  7.2824e-02,  7.2208e-01,  1.9530e-01,\n",
       "                         4.8768e-01,  1.0886e+00,  1.0630e+00,  1.0944e+00,  1.0871e+00,\n",
       "                         2.5494e-01],\n",
       "                       [-6.4572e-02, -1.1057e-01,  8.5611e-02, -3.3536e-02,  1.7557e-02,\n",
       "                         4.9556e-01, -9.4643e-02,  2.3534e-01,  6.0250e-01, -1.0670e-01,\n",
       "                         5.4327e-01,  9.9727e-01,  1.0021e+00,  7.4503e-01,  7.9601e-01,\n",
       "                         9.4132e-01],\n",
       "                       [ 9.7156e-02, -1.5339e-01, -8.2892e-02,  1.8969e-01,  1.1208e-01,\n",
       "                        -2.3451e-01,  4.6688e-01,  5.4376e-01,  9.3226e-01,  1.3946e-01,\n",
       "                         1.0759e+00,  7.5403e-01,  1.0783e+00,  1.1336e+00,  2.1366e-01,\n",
       "                         2.9932e-01],\n",
       "                       [-5.4709e-02,  5.7997e-01,  6.5488e-01,  7.4711e-02,  5.8435e-01,\n",
       "                        -2.3037e-01, -6.9903e-02,  4.5906e-01,  1.8399e-01, -1.0932e-01,\n",
       "                         5.5551e-01,  2.5707e-01,  1.6536e-01,  6.3421e-01,  4.3730e-01,\n",
       "                         8.8396e-01],\n",
       "                       [-6.4474e-02, -2.5300e-01,  6.2420e-01, -2.3939e-01,  4.3356e-01,\n",
       "                         7.8004e-02, -1.7776e-01,  2.3874e-01,  1.0221e+00, -1.2595e-01,\n",
       "                         6.6821e-01,  1.0325e+00,  9.8608e-01,  6.8065e-01,  2.4554e-01,\n",
       "                         1.1189e+00],\n",
       "                       [ 9.9066e-02,  4.9792e-01, -3.0293e-01,  6.5331e-01, -1.1997e-01,\n",
       "                        -1.0157e-01,  6.3349e-01,  4.6744e-01,  8.5826e-01,  1.0325e-03,\n",
       "                         9.6870e-01,  8.9656e-01,  9.1134e-01,  4.3616e-01,  9.3381e-01,\n",
       "                         7.6981e-01],\n",
       "                       [-1.1852e-01, -1.6734e-02, -1.1419e-01, -1.6003e-01,  3.4947e-01,\n",
       "                         4.2883e-01,  1.9866e-01,  3.9098e-01,  5.0491e-01,  5.7703e-03,\n",
       "                         8.4698e-01,  8.4353e-01,  3.6388e-01,  5.9902e-01,  5.8381e-01,\n",
       "                         1.0004e+00],\n",
       "                       [-5.3341e-02, -1.2626e-01, -9.2537e-02, -2.1584e-01,  6.0601e-01,\n",
       "                         6.0209e-01,  6.3205e-01,  6.2344e-01,  9.1527e-01, -6.5925e-03,\n",
       "                         1.0396e+00,  7.7323e-01,  5.7603e-01,  6.1150e-01,  9.7067e-01,\n",
       "                         6.1477e-01],\n",
       "                       [ 2.2653e-02,  4.7389e-01, -2.1200e-01, -2.2163e-01,  3.0626e-01,\n",
       "                        -3.0814e-01,  2.1165e-01, -2.7951e-01,  7.4982e-01,  2.8117e-02,\n",
       "                         1.0650e+00,  5.1720e-01,  6.4846e-01,  3.7866e-01,  5.1017e-01,\n",
       "                         5.5838e-01]], device='cuda:0')),\n",
       "              ('model.pools.0.weight',\n",
       "               tensor([[ 0.4060, -0.2327, -0.2839,  0.5846,  0.2651,  0.2414, -0.0378, -0.3005,\n",
       "                         1.1013,  0.4775,  0.5591,  0.4634,  0.9739,  0.6093,  0.7148,  0.8974]],\n",
       "                      device='cuda:0')),\n",
       "              ('model.pools.0.bias', tensor([-0.1132], device='cuda:0')),\n",
       "              ('model.pools.1.weight',\n",
       "               tensor([[ 0.7945,  0.0357,  0.8407,  0.2521,  0.3038,  0.6476,  0.7370,  0.8442,\n",
       "                         0.6971,  0.7716,  0.3729,  0.1908,  1.1325,  0.7739,  0.6159,  1.1438,\n",
       "                         0.3900,  0.8443,  0.3728, -0.0579,  0.4740,  0.6538,  0.5594,  0.0392,\n",
       "                         0.8226,  0.1911,  0.2036,  0.8334,  0.8417,  0.3319, -0.0058,  1.1360,\n",
       "                         0.6471,  0.6689,  1.0000,  0.9846,  0.1288,  1.1072,  0.8045,  0.9476,\n",
       "                         1.0507,  0.5390,  0.2988,  0.7987,  0.4674,  0.5322,  0.9721,  0.5639]],\n",
       "                      device='cuda:0')),\n",
       "              ('model.pools.1.bias', tensor([-0.0190], device='cuda:0')),\n",
       "              ('model.layer_norm.weight',\n",
       "               tensor([0.6804, 0.8471, 0.8471, 0.6804, 0.6804, 0.6804, 0.8470, 0.6804, 0.6804,\n",
       "                       0.8470, 0.6804, 0.6804, 0.8470, 0.8471, 0.8470, 0.8471, 0.8471, 0.8471,\n",
       "                       0.6804, 0.8471, 0.8471, 0.8471, 0.8471, 0.8471, 0.6804, 0.6804, 0.6804,\n",
       "                       0.8471, 1.1529, 0.6804], device='cuda:0')),\n",
       "              ('model.layer_norm.bias',\n",
       "               tensor([-0.3196,  0.1529, -0.1529, -0.1529,  0.3196, -0.3196, -0.1529, -0.1530,\n",
       "                        0.3196, -0.1529,  0.3196, -0.3196, -0.3196, -0.1530,  0.1530,  0.1529,\n",
       "                       -0.1529, -0.3196,  0.3196, -0.1529, -0.1529,  0.1529,  0.1530, -0.1529,\n",
       "                        0.3196,  0.3196,  0.3196, -0.3196,  0.3196,  0.3196], device='cuda:0')),\n",
       "              ('model.encoder.0.0.weight',\n",
       "               tensor([[-0.3118,  0.3542, -0.2663,  ..., -0.2376,  0.2587,  0.1907],\n",
       "                       [-0.2175,  0.2472, -0.2465,  ..., -0.3083,  0.2546,  0.3754],\n",
       "                       [ 0.1608, -0.2232,  0.3099,  ...,  0.2172,  0.2532, -0.2464],\n",
       "                       ...,\n",
       "                       [-0.2368,  0.2226, -0.0948,  ..., -0.0727, -0.2776,  0.1130],\n",
       "                       [-0.2327,  0.2996, -0.3134,  ..., -0.2944, -0.2654,  0.2487],\n",
       "                       [-0.2172,  0.1583, -0.1531,  ..., -0.1671, -0.2554,  0.2874]],\n",
       "                      device='cuda:0')),\n",
       "              ('model.encoder.0.0.bias',\n",
       "               tensor([-0.2957, -0.2709,  0.2742, -0.1572, -0.1954, -0.2215, -0.2228, -0.1793,\n",
       "                       -0.0641, -0.1270, -0.2000, -0.1968, -0.1195, -0.1185, -0.2798,  0.2635,\n",
       "                        0.2195, -0.3121,  0.3077, -0.1992, -0.1925, -0.3384, -0.2267, -0.3597,\n",
       "                       -0.0504, -0.2476, -0.0797, -0.3130, -0.2429,  0.1831, -0.1325, -0.3823,\n",
       "                       -0.1030, -0.2908, -0.3881, -0.1783, -0.2287, -0.2214, -0.1695, -0.3014,\n",
       "                       -0.3189, -0.2475, -0.2124, -0.3518, -0.0837, -0.2509, -0.0816, -0.3761,\n",
       "                       -0.2981, -0.2748, -0.1725, -0.1354, -0.1611,  0.2245, -0.2550, -0.2516,\n",
       "                       -0.2409, -0.3739, -0.2675, -0.1594, -0.1273, -0.1531, -0.2091, -0.2365],\n",
       "                      device='cuda:0')),\n",
       "              ('model.encoder.1.0.weight',\n",
       "               tensor([[ 0.2577,  0.2492,  0.4155,  ...,  0.1981,  0.4044,  0.3009],\n",
       "                       [ 0.3951,  0.2850,  0.0971,  ...,  0.2040,  0.2455,  0.0687],\n",
       "                       [-0.2935, -0.2409, -0.3020,  ..., -0.2595, -0.2648, -0.3192],\n",
       "                       ...,\n",
       "                       [-0.1167, -0.1897, -0.1761,  ..., -0.1484, -0.1892, -0.0281],\n",
       "                       [-0.3764, -0.3598, -0.3269,  ..., -0.3420, -0.3591, -0.3198],\n",
       "                       [-0.2017,  0.2218, -0.2256,  ..., -0.3046, -0.3574, -0.2834]],\n",
       "                      device='cuda:0')),\n",
       "              ('model.encoder.1.0.bias',\n",
       "               tensor([ 0.3938,  0.1650, -0.3123, -0.0722, -0.2145, -0.2042, -0.2071, -0.1625,\n",
       "                       -0.2829, -0.2033, -0.4128, -0.4048, -0.1547, -0.3013, -0.3767, -0.4771,\n",
       "                       -0.2385, -0.2516, -0.1779, -0.1476, -0.2646, -0.2894,  0.3728, -0.2386,\n",
       "                       -0.2567, -0.2159, -0.2915, -0.0927, -0.1542,  0.3129, -0.0422, -0.1254,\n",
       "                       -0.0415, -0.1371, -0.1531, -0.0296, -0.3227,  0.3420, -0.3328, -0.1731,\n",
       "                       -0.0955, -0.4057, -0.3520, -0.1978, -0.1944, -0.2638, -0.0306, -0.2479,\n",
       "                       -0.1543, -0.3192, -0.0979, -0.0951, -0.3227, -0.0564, -0.2703, -0.2215,\n",
       "                       -0.0448, -0.3693, -0.2316, -0.4097, -0.1977, -0.3372, -0.0503, -0.1899,\n",
       "                       -0.1414, -0.0067, -0.0934, -0.1276, -0.0349, -0.0610, -0.0284, -0.2135,\n",
       "                       -0.3505,  0.1834, -0.1594,  0.2747, -0.2607, -0.2349, -0.1548, -0.2714,\n",
       "                       -0.2231, -0.2509, -0.0325, -0.1085, -0.1011, -0.2389, -0.1835, -0.1404,\n",
       "                        0.3281, -0.3466, -0.2604, -0.3284, -0.1496, -0.3124,  0.2674, -0.0955,\n",
       "                       -0.4006, -0.3296, -0.4133, -0.2690, -0.3721, -0.1082, -0.2442, -0.2913,\n",
       "                       -0.2403, -0.0788, -0.3788, -0.1573, -0.2519, -0.1042, -0.1047, -0.1829,\n",
       "                        0.3332, -0.2265, -0.2152, -0.3991, -0.2421, -0.0846, -0.2778, -0.3573,\n",
       "                       -0.3322, -0.1333, -0.3346,  0.4299, -0.2094, -0.2295, -0.2969, -0.2333],\n",
       "                      device='cuda:0')),\n",
       "              ('model.encoder.2.0.weight',\n",
       "               tensor([[-0.3116, -0.3653, -0.3116,  ..., -0.2130,  0.2212, -0.2475],\n",
       "                       [-0.0764, -0.3087,  0.4356,  ...,  0.0026, -0.4267,  0.1908],\n",
       "                       [-0.3691, -0.2424, -0.2739,  ..., -0.2848, -0.2524,  0.2174],\n",
       "                       ...,\n",
       "                       [-0.3140, -0.2122, -0.2197,  ...,  0.2124, -0.3673, -0.3064],\n",
       "                       [ 0.3004,  0.0700,  0.3924,  ...,  0.2081,  0.3296, -0.0855],\n",
       "                       [-0.3687, -0.1848, -0.3410,  ...,  0.3786, -0.1126, -0.2819]],\n",
       "                      device='cuda:0')),\n",
       "              ('model.encoder.2.0.bias',\n",
       "               tensor([-0.3076, -0.3718, -0.2235, -0.3803, -0.1010, -0.2482, -0.3071, -0.0781,\n",
       "                        0.2805, -0.4538, -0.2342, -0.1713, -0.1424, -0.1854,  0.3183, -0.3131,\n",
       "                       -0.1867, -0.0788, -0.2941, -0.2077, -0.3425, -0.2267, -0.1298, -0.2329,\n",
       "                       -0.2736,  0.2990, -0.1673, -0.3340, -0.3162, -0.1914,  0.3621, -0.3184,\n",
       "                       -0.3758, -0.1419, -0.1010, -0.2321,  0.2803,  0.2464, -0.3417, -0.1637,\n",
       "                       -0.3345, -0.1791,  0.2308, -0.0974, -0.3263, -0.1345, -0.3481, -0.1393,\n",
       "                       -0.1299, -0.2279, -0.3281, -0.0682, -0.2735, -0.2988, -0.2898, -0.2174,\n",
       "                       -0.4516, -0.2858, -0.3201, -0.2251,  0.2701, -0.2423, -0.2399, -0.2706,\n",
       "                       -0.2038,  0.3360, -0.1028,  0.0968, -0.2329, -0.1456, -0.2648, -0.2624,\n",
       "                       -0.1316, -0.1994, -0.2826, -0.1975, -0.2139, -0.3355, -0.0861, -0.1604,\n",
       "                       -0.0281, -0.2295, -0.0512, -0.2352, -0.0715, -0.2377, -0.2336, -0.3645,\n",
       "                       -0.0823,  0.3823, -0.3547, -0.1508, -0.2854, -0.1861, -0.3443, -0.2254,\n",
       "                       -0.1151, -0.1300, -0.2844,  0.3240, -0.1096, -0.2836, -0.2194, -0.2144,\n",
       "                       -0.3581, -0.3084, -0.3092, -0.2126, -0.2406,  0.1997, -0.3134, -0.0986,\n",
       "                       -0.1698, -0.3857, -0.2452, -0.3619, -0.0654, -0.2373,  0.3084, -0.1799,\n",
       "                        0.3053, -0.2381, -0.2083, -0.2079, -0.1493, -0.3710,  0.3861, -0.3226],\n",
       "                      device='cuda:0')),\n",
       "              ('model.encoder.3.0.weight',\n",
       "               tensor([[-0.2617,  0.3182,  0.2676,  ...,  0.3259, -0.3590,  0.2886],\n",
       "                       [-0.1314, -0.1124, -0.2434,  ...,  0.2329, -0.1053,  0.3767],\n",
       "                       [-0.3132, -0.2186,  0.2647,  ..., -0.3257, -0.2496, -0.2634],\n",
       "                       ...,\n",
       "                       [-0.2138, -0.3098,  0.3007,  ...,  0.2810, -0.3257, -0.2222],\n",
       "                       [-0.3398, -0.3357, -0.2823,  ...,  0.3420, -0.3068, -0.3396],\n",
       "                       [-0.3232, -0.3615, -0.3480,  ...,  0.3345, -0.2119, -0.3834]],\n",
       "                      device='cuda:0')),\n",
       "              ('model.encoder.3.0.bias',\n",
       "               tensor([-0.2946, -0.1966, -0.3245, -0.1110, -0.3663, -0.3230, -0.1561, -0.3534,\n",
       "                       -0.1908, -0.2633, -0.2353, -0.1242, -0.1402,  0.1564, -0.2956, -0.1551,\n",
       "                       -0.1462, -0.3483, -0.2318, -0.2892, -0.3606, -0.3117, -0.1552, -0.1704,\n",
       "                       -0.2938, -0.0670, -0.0977, -0.3078, -0.1314, -0.3465, -0.3704, -0.3665],\n",
       "                      device='cuda:0')),\n",
       "              ('model.encoder.4.weight',\n",
       "               tensor([[ 0.3901,  0.4044,  0.1967,  0.2329,  0.9586,  1.1057, -0.0656,  0.5906,\n",
       "                         0.0553,  0.3685,  0.7775,  0.4062,  0.7243, -0.2794,  0.5203, -0.1106,\n",
       "                         0.6743,  0.2463,  0.6612,  0.6275,  0.5381,  0.8999,  0.0214,  0.2844,\n",
       "                         0.7713,  0.2675,  0.3015, -0.1120,  0.1863,  0.8431,  0.3391,  0.6872]],\n",
       "                      device='cuda:0')),\n",
       "              ('model.encoder.4.bias', tensor([-0.1516], device='cuda:0'))]),\n",
       " 'loops': {'fit_loop': {'state_dict': {},\n",
       "   'epoch_loop.state_dict': {'_batches_that_stepped': 7},\n",
       "   'epoch_loop.batch_progress': {'total': {'ready': 8,\n",
       "     'completed': 8,\n",
       "     'started': 8,\n",
       "     'processed': 8},\n",
       "    'current': {'ready': 4, 'completed': 4, 'started': 4, 'processed': 4},\n",
       "    'is_last_batch': True},\n",
       "   'epoch_loop.scheduler_progress': {'total': {'ready': 2, 'completed': 2},\n",
       "    'current': {'ready': 1, 'completed': 1}},\n",
       "   'epoch_loop.automatic_optimization.state_dict': {},\n",
       "   'epoch_loop.automatic_optimization.optim_progress': {'optimizer': {'step': {'total': {'ready': 8,\n",
       "       'completed': 8},\n",
       "      'current': {'ready': 4, 'completed': 4}},\n",
       "     'zero_grad': {'total': {'ready': 8, 'completed': 8, 'started': 8},\n",
       "      'current': {'ready': 4, 'completed': 4, 'started': 4}}}},\n",
       "   'epoch_loop.manual_optimization.state_dict': {},\n",
       "   'epoch_loop.manual_optimization.optim_step_progress': {'total': {'ready': 0,\n",
       "     'completed': 0},\n",
       "    'current': {'ready': 0, 'completed': 0}},\n",
       "   'epoch_loop.val_loop.state_dict': {},\n",
       "   'epoch_loop.val_loop.batch_progress': {'total': {'ready': 1,\n",
       "     'completed': 1,\n",
       "     'started': 1,\n",
       "     'processed': 1},\n",
       "    'current': {'ready': 1, 'completed': 1, 'started': 1, 'processed': 1},\n",
       "    'is_last_batch': True},\n",
       "   'epoch_progress': {'total': {'ready': 2,\n",
       "     'completed': 1,\n",
       "     'started': 2,\n",
       "     'processed': 1},\n",
       "    'current': {'ready': 2, 'completed': 1, 'started': 2, 'processed': 1}}},\n",
       "  'validate_loop': {'state_dict': {},\n",
       "   'batch_progress': {'total': {'ready': 0,\n",
       "     'completed': 0,\n",
       "     'started': 0,\n",
       "     'processed': 0},\n",
       "    'current': {'ready': 0, 'completed': 0, 'started': 0, 'processed': 0},\n",
       "    'is_last_batch': False}},\n",
       "  'test_loop': {'state_dict': {},\n",
       "   'batch_progress': {'total': {'ready': 0,\n",
       "     'completed': 0,\n",
       "     'started': 0,\n",
       "     'processed': 0},\n",
       "    'current': {'ready': 0, 'completed': 0, 'started': 0, 'processed': 0},\n",
       "    'is_last_batch': False}},\n",
       "  'predict_loop': {'state_dict': {},\n",
       "   'batch_progress': {'total': {'ready': 0,\n",
       "     'completed': 0,\n",
       "     'started': 0,\n",
       "     'processed': 0},\n",
       "    'current': {'ready': 0, 'completed': 0, 'started': 0, 'processed': 0}}}},\n",
       " 'callbacks': {\"ModelCheckpoint{'monitor': None, 'mode': 'min', 'every_n_train_steps': 0, 'every_n_epochs': 1, 'train_time_interval': None}\": {'monitor': None,\n",
       "   'best_model_score': None,\n",
       "   'best_model_path': '/scratch/lcornelis/tmp/session_2024-07-31_15-31-32_784450_1871092/artifacts/2024-07-31_15-31-35/TorchTrainer_2024-07-31_15-31-35/working_dirs/model=gat-v4,seed=19543_0_act=relu,adj_thresh=0.1000,batch_size=8,dropout=0,l1_lambda=0.0000,lr=0.1000,lr_scheduler=LambdaLR,modal_2024-07-31_15-31-36/lightning_logs/version_0/checkpoints/epoch=0-step=4.ckpt',\n",
       "   'current_score': None,\n",
       "   'dirpath': '/scratch/lcornelis/tmp/session_2024-07-31_15-31-32_784450_1871092/artifacts/2024-07-31_15-31-35/TorchTrainer_2024-07-31_15-31-35/working_dirs/model=gat-v4,seed=19543_0_act=relu,adj_thresh=0.1000,batch_size=8,dropout=0,l1_lambda=0.0000,lr=0.1000,lr_scheduler=LambdaLR,modal_2024-07-31_15-31-36/lightning_logs/version_0/checkpoints',\n",
       "   'best_k_models': {},\n",
       "   'kth_best_model_path': '',\n",
       "   'kth_value': tensor(inf),\n",
       "   'last_model_path': ''}},\n",
       " 'optimizer_states': [{'state': {0: {'step': tensor(8.),\n",
       "     'exp_avg': tensor([[[ -0.3122,   7.6363,   8.3902,   0.8268,   6.1079,   0.5877,   3.9479,\n",
       "                 2.7987],\n",
       "              [152.2988,  -3.1341,   2.7358, 117.9020,   1.8943,  37.0508,  51.1731,\n",
       "                90.0605]]], device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([[[3.3852e-02, 2.0484e+01, 2.4727e+01, 2.4102e-01, 1.3106e+01,\n",
       "               1.2197e-01, 5.4773e+00, 2.7535e+00],\n",
       "              [8.1350e+03, 3.3587e+00, 2.7047e+00, 4.8813e+03, 1.3136e+00,\n",
       "               4.8066e+02, 9.2037e+02, 2.8436e+03]]], device='cuda:0')},\n",
       "    1: {'step': tensor(8.),\n",
       "     'exp_avg': tensor([[[-4.5871e-06,  2.4927e-04,  2.8360e-04,  2.3762e-05,  2.0802e-04,\n",
       "                1.4780e-05,  1.3649e-04,  9.8433e-05],\n",
       "              [-9.7920e-05,  7.8184e-06,  3.8245e-06, -7.4535e-05,  4.3970e-06,\n",
       "               -1.9504e-05, -2.9132e-05, -5.5572e-05]]], device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([[[3.4159e-11, 2.2611e-08, 2.7284e-08, 2.7599e-10, 1.4482e-08,\n",
       "               1.2757e-10, 6.0702e-09, 3.0621e-09],\n",
       "              [3.7361e-09, 3.1462e-12, 1.3491e-12, 2.2353e-09, 9.1788e-13,\n",
       "               2.1437e-10, 4.1475e-10, 1.2971e-09]]], device='cuda:0')},\n",
       "    2: {'step': tensor(8.),\n",
       "     'exp_avg': tensor([-1.2658e-06, -4.6788e-05, -5.5152e-05, -3.3733e-05, -7.3801e-05,\n",
       "             -3.8041e-05, -5.3510e-05, -5.5955e-05, -5.1123e-05, -1.2658e-06,\n",
       "             -5.0988e-05, -4.7901e-05, -5.0988e-05, -4.9535e-05, -5.5998e-05,\n",
       "             -5.4370e-05], device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([6.9790e-13, 9.2922e-10, 1.2561e-09, 5.1936e-10, 2.1627e-09, 6.4227e-10,\n",
       "             1.1889e-09, 1.2905e-09, 1.0915e-09, 6.9790e-13, 1.0915e-09, 9.6804e-10,\n",
       "             1.0915e-09, 1.0288e-09, 1.2905e-09, 1.2223e-09], device='cuda:0')},\n",
       "    3: {'step': tensor(8.),\n",
       "     'exp_avg': tensor([[  3.6087],\n",
       "             [  9.2303],\n",
       "             [ 12.1503],\n",
       "             [ 45.2670],\n",
       "             [ 36.7949],\n",
       "             [ 30.7145],\n",
       "             [ 17.8976],\n",
       "             [  2.7102],\n",
       "             [-27.7923],\n",
       "             [113.1379],\n",
       "             [ 14.2445],\n",
       "             [  2.5072],\n",
       "             [ 69.9650],\n",
       "             [-16.8057],\n",
       "             [100.3404],\n",
       "             [-21.8177]], device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([[4.5679e+00],\n",
       "             [3.0097e+01],\n",
       "             [5.2142e+01],\n",
       "             [7.2112e+02],\n",
       "             [4.7423e+02],\n",
       "             [3.3192e+02],\n",
       "             [1.1251e+02],\n",
       "             [2.6539e+00],\n",
       "             [2.7086e+02],\n",
       "             [4.4885e+03],\n",
       "             [7.1403e+01],\n",
       "             [2.2587e+00],\n",
       "             [1.7183e+03],\n",
       "             [9.8820e+01],\n",
       "             [3.5345e+03],\n",
       "             [1.6680e+02]], device='cuda:0')},\n",
       "    4: {'step': tensor(8.),\n",
       "     'exp_avg': tensor([[[-0.0474, -0.0253, -0.0263, -0.0364, -0.0464, -0.0291, -0.0349,\n",
       "               -0.0317, -0.0552, -0.0353, -0.0136, -0.0155, -0.0403, -0.0198,\n",
       "               -0.0098, -0.0407],\n",
       "              [-0.0186, -0.0358, -0.0430, -0.0268, -0.0223, -0.0188, -0.0269,\n",
       "               -0.0256, -0.0322, -0.0180, -0.0302, -0.0368, -0.0512, -0.0330,\n",
       "               -0.0192, -0.0236],\n",
       "              [-0.0262, -0.0481, -0.0671, -0.0521, -0.0369, -0.0554, -0.0206,\n",
       "               -0.0609, -0.0586, -0.0479, -0.0241, -0.0721, -0.0616, -0.0498,\n",
       "               -0.0596, -0.0388]]], device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([[[7.9130e-04, 2.2624e-04, 2.4487e-04, 4.6862e-04, 7.6107e-04,\n",
       "               2.9880e-04, 4.3011e-04, 3.5550e-04, 1.0732e-03, 4.3956e-04,\n",
       "               6.5188e-05, 8.5100e-05, 5.7296e-04, 1.3858e-04, 3.3766e-05,\n",
       "               5.8392e-04],\n",
       "              [1.2249e-04, 4.5192e-04, 6.5398e-04, 2.5295e-04, 1.7530e-04,\n",
       "               1.2548e-04, 2.5465e-04, 2.3049e-04, 3.6554e-04, 1.1462e-04,\n",
       "               3.1966e-04, 4.7805e-04, 9.2489e-04, 3.8412e-04, 1.2901e-04,\n",
       "               1.9614e-04],\n",
       "              [2.4169e-04, 8.1703e-04, 1.5886e-03, 9.5787e-04, 4.8084e-04,\n",
       "               1.0842e-03, 1.4987e-04, 1.3077e-03, 1.2137e-03, 8.1144e-04,\n",
       "               2.0545e-04, 1.8340e-03, 1.3377e-03, 8.7462e-04, 1.2513e-03,\n",
       "               5.3093e-04]]], device='cuda:0')},\n",
       "    5: {'step': tensor(8.),\n",
       "     'exp_avg': tensor([[[-1.2674e-05, -6.7307e-06, -3.8124e-06, -5.7723e-06, -1.0504e-05,\n",
       "               -7.3902e-06, -1.1618e-05, -5.6943e-06, -1.2559e-05, -1.0178e-05,\n",
       "               -2.8373e-06, -2.4275e-06, -8.4134e-06, -6.4792e-06, -4.3043e-06,\n",
       "               -7.8194e-06],\n",
       "              [-3.8155e-05, -5.8121e-05, -5.5882e-05, -6.1941e-05, -4.5411e-05,\n",
       "               -2.8070e-05, -5.5288e-05, -5.2032e-05, -4.8421e-05, -4.6168e-05,\n",
       "               -5.1511e-05, -3.9782e-05, -7.0693e-05, -4.9866e-05, -5.8671e-05,\n",
       "               -3.6469e-05],\n",
       "              [-3.6305e-04, -4.2409e-04, -3.3677e-04, -3.3111e-04, -2.8634e-04,\n",
       "               -3.5877e-04, -2.7785e-04, -3.8005e-04, -2.5470e-04, -2.4383e-04,\n",
       "               -3.1600e-04, -3.5472e-04, -3.1394e-04, -2.5835e-04, -3.2576e-04,\n",
       "               -2.3016e-04]]], device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([[[1.1146e-10, 4.9914e-11, 2.8762e-11, 4.2371e-11, 8.6192e-11,\n",
       "               5.5543e-11, 9.8687e-11, 4.1746e-11, 1.1011e-10, 7.0625e-11,\n",
       "               2.2942e-11, 2.0737e-11, 6.4879e-11, 4.7827e-11, 3.1841e-11,\n",
       "               5.9402e-11],\n",
       "              [6.5714e-10, 1.4000e-09, 1.3021e-09, 1.5740e-09, 8.9445e-10,\n",
       "               3.8657e-10, 1.2783e-09, 1.1445e-09, 1.0040e-09, 9.2194e-10,\n",
       "               1.1234e-09, 7.0603e-10, 2.0106e-09, 1.0581e-09, 1.4248e-09,\n",
       "               6.0620e-10],\n",
       "              [4.7634e-08, 6.4729e-08, 4.1073e-08, 3.9727e-08, 2.9855e-08,\n",
       "               4.6524e-08, 2.8139e-08, 5.2131e-08, 2.3723e-08, 2.1779e-08,\n",
       "               3.6235e-08, 4.5494e-08, 3.5776e-08, 2.4394e-08, 3.8474e-08,\n",
       "               1.9453e-08]]], device='cuda:0')},\n",
       "    6: {'step': tensor(8.),\n",
       "     'exp_avg': tensor([-1.6727e-06, -4.4510e-07, -3.5966e-06,  1.2793e-06, -1.1994e-06,\n",
       "             -3.2925e-06, -3.2419e-06, -1.7235e-06, -3.5713e-06, -1.6727e-06,\n",
       "             -3.5207e-06, -1.6347e-06,  1.1153e-06, -3.3940e-06, -3.1658e-06,\n",
       "             -3.2420e-06,  2.2944e-06, -2.0139e-07, -2.1478e-07,  2.3698e-06,\n",
       "             -3.2672e-06, -1.7487e-06,  1.1405e-06, -1.8247e-06, -1.7740e-06,\n",
       "             -1.7867e-06, -2.2241e-06,  4.4649e-07,  8.5209e-08,  2.2874e-06,\n",
       "             -4.8311e-07, -1.6211e-06, -3.3940e-06, -3.1406e-06,  1.0898e-06,\n",
       "             -3.4954e-06, -1.7740e-06,  6.9727e-07, -3.3433e-06, -3.5714e-06,\n",
       "             -3.1913e-06, -1.1341e-07, -1.6979e-06, -3.5714e-06, -1.8628e-06,\n",
       "             -1.8248e-06,  6.9704e-07, -1.8247e-06], device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([9.5960e-13, 6.2097e-13, 1.0158e-12, 7.0300e-13, 6.7459e-13, 1.2815e-12,\n",
       "             1.3321e-12, 9.2440e-13, 1.0355e-12, 9.5961e-13, 1.0762e-12, 9.8722e-13,\n",
       "             6.4954e-13, 1.1857e-12, 1.4114e-12, 1.3321e-12, 6.0217e-13, 7.6320e-13,\n",
       "             7.5685e-13, 6.0958e-13, 1.3065e-12, 9.0743e-13, 6.5655e-13, 8.5934e-13,\n",
       "             8.9094e-13, 8.8288e-13, 5.9886e-13, 6.2124e-13, 5.9855e-13, 6.0168e-13,\n",
       "             6.2824e-13, 9.9714e-13, 1.1857e-12, 1.4387e-12, 6.4295e-13, 1.0972e-12,\n",
       "             8.9095e-13, 6.3131e-13, 1.2327e-12, 1.0355e-12, 1.3845e-12, 8.0832e-13,\n",
       "             9.4175e-13, 1.0355e-12, 8.3681e-13, 8.5934e-13, 6.3130e-13, 8.5934e-13],\n",
       "            device='cuda:0')},\n",
       "    7: {'step': tensor(8.),\n",
       "     'exp_avg': tensor([[ 5.6721e-06,  2.6574e-01,  2.9226e-01,  2.8617e-02,  2.1304e-01,\n",
       "               2.0519e-02,  1.3856e-01,  9.7691e-02, -4.5628e-01, -1.6369e-06,\n",
       "              -8.3144e-03, -3.5437e-01, -5.7871e-03, -1.1091e-01, -1.5347e-01,\n",
       "              -2.7056e-01],\n",
       "             [ 5.6887e-06,  1.2894e-01,  1.4180e-01,  1.3936e-02,  1.0340e-01,\n",
       "               9.9920e-03,  6.7259e-02,  4.7454e-02, -2.2059e-01,  5.7082e-06,\n",
       "              -4.0217e-03, -1.7139e-01, -2.7977e-03, -5.3592e-02, -7.4243e-02,\n",
       "              -1.3079e-01],\n",
       "             [-2.5185e-06,  2.8874e-01,  3.1755e-01,  3.1114e-02,  2.3155e-01,\n",
       "               2.2299e-02,  1.5041e-01,  1.0604e-01, -4.7885e-01,  1.9351e-06,\n",
       "              -8.7266e-03, -3.7189e-01, -6.0790e-03, -1.1642e-01, -1.6103e-01,\n",
       "              -2.8393e-01],\n",
       "             [ 5.6913e-06,  7.3413e-03,  8.0977e-03,  7.6059e-04,  5.7934e-03,\n",
       "               5.5567e-04,  3.9429e-03,  2.7672e-03, -2.6896e-02, -3.6670e-06,\n",
       "              -4.8409e-04, -2.0866e-02, -3.3253e-04, -6.5260e-03, -9.0524e-03,\n",
       "              -1.5973e-02],\n",
       "             [ 2.6989e-07,  3.2443e-02,  3.5685e-02,  3.4687e-03,  2.6001e-02,\n",
       "               2.4919e-03,  1.6875e-02,  1.1883e-02, -5.4602e-02,  2.8415e-07,\n",
       "              -9.8755e-04, -4.2367e-02, -6.8601e-04, -1.3286e-02, -1.8332e-02,\n",
       "              -3.2384e-02],\n",
       "             [ 5.6625e-06,  4.2242e-01,  4.6454e-01,  4.5591e-02,  3.3882e-01,\n",
       "               3.2668e-02,  2.2003e-01,  1.5518e-01, -6.9155e-01,  3.7495e-06,\n",
       "              -1.2611e-02, -5.3718e-01, -8.7853e-03, -1.6810e-01, -2.3261e-01,\n",
       "              -4.1002e-01],\n",
       "             [-3.8134e-07,  4.6273e-01,  5.0889e-01,  4.9931e-02,  3.7111e-01,\n",
       "               3.5787e-02,  2.4115e-01,  1.7007e-01, -7.7450e-01,  5.7448e-06,\n",
       "              -1.4121e-02, -6.0161e-01, -9.8335e-03, -1.8825e-01, -2.6054e-01,\n",
       "              -4.5920e-01],\n",
       "             [ 3.6712e-06,  2.9081e-01,  3.1981e-01,  3.1329e-02,  2.3324e-01,\n",
       "               2.2455e-02,  1.5139e-01,  1.0673e-01, -4.7397e-01,  5.7327e-06,\n",
       "              -8.6364e-03, -3.6809e-01, -6.0164e-03, -1.1525e-01, -1.5936e-01,\n",
       "              -2.8103e-01],\n",
       "             [ 5.6758e-06,  2.1808e-01,  2.3985e-01,  2.3479e-02,  1.7486e-01,\n",
       "               1.6840e-02,  1.1366e-01,  8.0135e-02, -3.7342e-01,  5.7274e-06,\n",
       "              -6.7995e-03, -2.9000e-01, -4.7321e-03, -9.0779e-02, -1.2558e-01,\n",
       "              -2.2142e-01],\n",
       "             [ 5.6741e-06,  2.5498e-01,  2.8042e-01,  2.7464e-02,  2.0439e-01,\n",
       "               1.9693e-02,  1.3298e-01,  9.3755e-02, -4.4004e-01,  1.9352e-06,\n",
       "              -8.0192e-03, -3.4176e-01, -5.5812e-03, -1.0696e-01, -1.4802e-01,\n",
       "              -2.6094e-01],\n",
       "             [-2.5134e-06,  2.8941e-01,  3.1827e-01,  3.1236e-02,  2.3214e-01,\n",
       "               2.2381e-02,  1.5077e-01,  1.0634e-01, -4.7932e-01,  5.7246e-06,\n",
       "              -8.7370e-03, -3.7233e-01, -6.0847e-03, -1.1650e-01, -1.6124e-01,\n",
       "              -2.8418e-01],\n",
       "             [ 5.6833e-06,  2.0217e-01,  2.2232e-01,  2.1834e-02,  1.6218e-01,\n",
       "               1.5649e-02,  1.0533e-01,  7.4294e-02, -3.3575e-01, -3.2933e-07,\n",
       "              -6.1176e-03, -2.6082e-01, -4.2596e-03, -8.1603e-02, -1.1295e-01,\n",
       "              -1.9905e-01],\n",
       "             [ 1.8614e-06,  4.2678e-01,  4.6936e-01,  4.5988e-02,  3.4225e-01,\n",
       "               3.2966e-02,  2.2232e-01,  1.5675e-01, -7.1117e-01,  1.9513e-06,\n",
       "              -1.2960e-02, -5.5233e-01, -9.0252e-03, -1.7289e-01, -2.3917e-01,\n",
       "              -4.2167e-01],\n",
       "             [ 9.0736e-08,  4.8236e-01,  5.3045e-01,  5.2051e-02,  3.8693e-01,\n",
       "               3.7298e-02,  2.5119e-01,  1.7715e-01, -7.8548e-01,  5.7433e-06,\n",
       "              -1.4322e-02, -6.1012e-01, -9.9787e-03, -1.9095e-01, -2.6419e-01,\n",
       "              -4.6570e-01],\n",
       "             [ 5.6679e-06,  4.0625e-01,  4.4677e-01,  4.3837e-02,  3.2576e-01,\n",
       "               3.1416e-02,  2.1179e-01,  1.4937e-01, -6.8528e-01,  5.7416e-06,\n",
       "              -1.2498e-02, -5.3233e-01, -8.7026e-03, -1.6654e-01, -2.3056e-01,\n",
       "              -4.0632e-01],\n",
       "             [ 1.8596e-06,  4.3340e-01,  4.7664e-01,  4.6707e-02,  3.4751e-01,\n",
       "               3.3470e-02,  2.2588e-01,  1.5927e-01, -7.2940e-01, -2.4373e-06,\n",
       "              -1.3298e-02, -5.6651e-01, -9.2593e-03, -1.7731e-01, -2.4533e-01,\n",
       "              -4.3250e-01],\n",
       "             [-1.9300e-07,  2.9645e-01,  3.2601e-01,  3.2004e-02,  2.3780e-01,\n",
       "               2.2927e-02,  1.5443e-01,  1.0891e-01, -4.9217e-01,  2.1784e-06,\n",
       "              -8.9683e-03, -3.8230e-01, -6.2454e-03, -1.1963e-01, -1.6555e-01,\n",
       "              -2.9179e-01],\n",
       "             [ 5.6707e-06,  2.8724e-01,  3.1591e-01,  3.0949e-02,  2.3033e-01,\n",
       "               2.2176e-02,  1.4970e-01,  1.0554e-01, -4.8954e-01,  3.7357e-06,\n",
       "              -8.9177e-03, -3.8018e-01, -6.2086e-03, -1.1901e-01, -1.6464e-01,\n",
       "              -2.9026e-01],\n",
       "             [ 3.6879e-06,  6.4485e-02,  7.0927e-02,  6.9282e-03,  5.1665e-02,\n",
       "               4.9705e-03,  3.3633e-02,  2.3689e-02, -1.1430e-01,  1.9099e-06,\n",
       "              -2.0792e-03, -8.8729e-02, -1.4442e-03, -2.7787e-02, -3.8429e-02,\n",
       "              -6.7775e-02],\n",
       "             [-1.1864e-06,  8.3619e-02,  9.1960e-02,  9.0392e-03,  6.7045e-02,\n",
       "               6.4913e-03,  4.3664e-02,  3.0817e-02, -1.4783e-01,  2.8269e-07,\n",
       "              -2.6940e-03, -1.1486e-01, -1.8737e-03, -3.5899e-02, -4.9775e-02,\n",
       "              -8.7635e-02],\n",
       "             [ 3.6678e-06,  3.3779e-01,  3.7148e-01,  3.6464e-02,  2.7096e-01,\n",
       "               2.6130e-02,  1.7596e-01,  1.2409e-01, -5.5662e-01, -1.1392e-06,\n",
       "              -1.0147e-02, -4.3237e-01, -7.0670e-03, -1.3530e-01, -1.8723e-01,\n",
       "              -3.3001e-01],\n",
       "             [-1.1998e-06,  1.9886e-01,  2.1869e-01,  2.1410e-02,  1.5944e-01,\n",
       "               1.5352e-02,  1.0362e-01,  7.3048e-02, -3.3411e-01, -1.6458e-06,\n",
       "              -6.0865e-03, -2.5946e-01, -4.2381e-03, -8.1226e-02, -1.1236e-01,\n",
       "              -1.9811e-01],\n",
       "             [ 5.6643e-06,  3.7677e-01,  4.1435e-01,  4.0663e-02,  3.0217e-01,\n",
       "               2.9146e-02,  1.9637e-01,  1.3849e-01, -6.3496e-01, -1.1323e-06,\n",
       "              -1.1576e-02, -4.9321e-01, -8.0609e-03, -1.5432e-01, -2.1361e-01,\n",
       "              -3.7645e-01],\n",
       "             [ 1.8247e-08,  1.2922e-01,  1.4211e-01,  1.3966e-02,  1.0361e-01,\n",
       "               1.0016e-02,  6.7448e-02,  4.7580e-02, -2.2655e-01,  5.7168e-06,\n",
       "              -4.1311e-03, -1.7600e-01, -2.8728e-03, -5.5032e-02, -7.6256e-02,\n",
       "              -1.3431e-01],\n",
       "             [ 5.6726e-06,  2.7986e-01,  3.0777e-01,  3.0160e-02,  2.2447e-01,\n",
       "               2.1601e-02,  1.4569e-01,  1.0272e-01, -4.5704e-01,  3.1211e-07,\n",
       "              -8.3251e-03, -3.5493e-01, -5.7990e-03, -1.1113e-01, -1.5366e-01,\n",
       "              -2.7099e-01],\n",
       "             [ 3.6830e-06,  2.0356e-01,  2.2387e-01,  2.1988e-02,  1.6328e-01,\n",
       "               1.5758e-02,  1.0609e-01,  7.4829e-02, -3.3747e-01,  5.7150e-06,\n",
       "              -6.1529e-03, -2.6215e-01, -4.2850e-03, -8.2012e-02, -1.1354e-01,\n",
       "              -2.0007e-01],\n",
       "             [ 5.6930e-06, -1.5974e-02, -1.7550e-02, -1.7512e-03, -1.2893e-02,\n",
       "              -1.2448e-03, -8.2058e-03, -5.8026e-03,  1.0946e-02,  1.3034e-07,\n",
       "               1.9551e-04,  8.5459e-03,  1.3697e-04,  2.6742e-03,  3.6725e-03,\n",
       "               6.4725e-03],\n",
       "             [ 5.6725e-06,  2.8309e-01,  3.1135e-01,  3.0495e-02,  2.2700e-01,\n",
       "               2.1866e-02,  1.4753e-01,  1.0401e-01, -4.7952e-01,  5.7368e-06,\n",
       "              -8.7367e-03, -3.7239e-01, -6.0832e-03, -1.1657e-01, -1.6127e-01,\n",
       "              -2.8432e-01],\n",
       "             [ 5.6717e-06,  2.8744e-01,  3.1612e-01,  3.0973e-02,  2.3050e-01,\n",
       "               2.2200e-02,  1.4975e-01,  1.0558e-01, -4.8269e-01,  3.7357e-06,\n",
       "              -8.7940e-03, -3.7485e-01, -6.1237e-03, -1.1735e-01, -1.6232e-01,\n",
       "              -2.8619e-01],\n",
       "             [ 5.6889e-06,  4.6063e-02,  5.0657e-02,  4.9450e-03,  3.6934e-02,\n",
       "               3.5438e-03,  2.3933e-02,  1.6866e-02, -7.3379e-02,  5.7047e-06,\n",
       "              -1.3295e-03, -5.6949e-02, -9.2486e-04, -1.7857e-02, -2.4637e-02,\n",
       "              -4.3514e-02],\n",
       "             [ 5.6897e-06,  1.0788e-01,  1.1864e-01,  1.1664e-02,  8.6485e-02,\n",
       "               8.3671e-03,  5.6345e-02,  3.9752e-02, -1.9231e-01, -1.1716e-06,\n",
       "              -3.5052e-03, -1.4941e-01, -2.4382e-03, -4.6706e-02, -6.4747e-02,\n",
       "              -1.1401e-01],\n",
       "             [-1.7087e-06,  4.2894e-01,  4.7173e-01,  4.6232e-02,  3.4394e-01,\n",
       "               3.3135e-02,  2.2350e-01,  1.5759e-01, -7.1778e-01,  1.9548e-06,\n",
       "              -1.3086e-02, -5.5745e-01, -9.1144e-03, -1.7449e-01, -2.4141e-01,\n",
       "              -4.2559e-01],\n",
       "             [ 9.6137e-08,  4.1692e-01,  4.5852e-01,  4.4981e-02,  3.3431e-01,\n",
       "               3.2241e-02,  2.1743e-01,  1.5333e-01, -7.1934e-01,  5.7452e-06,\n",
       "              -1.3113e-02, -5.5877e-01, -9.1273e-03, -1.7482e-01, -2.4202e-01,\n",
       "              -4.2651e-01],\n",
       "             [-1.7050e-06,  4.3185e-01,  4.7491e-01,  4.6588e-02,  3.4630e-01,\n",
       "               3.3400e-02,  2.2510e-01,  1.5875e-01, -7.2509e-01,  5.7440e-06,\n",
       "              -1.3224e-02, -5.6324e-01, -9.2096e-03, -1.7623e-01, -2.4394e-01,\n",
       "              -4.2992e-01],\n",
       "             [ 5.6650e-06,  3.6246e-01,  3.9863e-01,  3.9051e-02,  2.9058e-01,\n",
       "               2.8000e-02,  1.8900e-01,  1.3325e-01, -6.2441e-01, -1.1311e-06,\n",
       "              -1.1381e-02, -4.8495e-01, -7.9224e-03, -1.5177e-01, -2.1003e-01,\n",
       "              -3.7025e-01],\n",
       "             [-2.5240e-06,  3.5647e-01,  3.9204e-01,  3.8413e-02,  2.8584e-01,\n",
       "               2.7523e-02,  1.8574e-01,  1.3096e-01, -5.9948e-01,  7.2966e-07,\n",
       "              -1.0925e-02, -4.6558e-01, -7.6070e-03, -1.4574e-01, -2.0161e-01,\n",
       "              -3.5546e-01],\n",
       "             [ 2.1297e-06,  1.7414e-01,  1.9149e-01,  1.8815e-02,  1.3970e-01,\n",
       "               1.3482e-02,  9.0701e-02,  6.3978e-02, -2.8416e-01,  5.7111e-06,\n",
       "              -5.1788e-03, -2.2075e-01, -3.6068e-03, -6.9064e-02, -9.5591e-02,\n",
       "              -1.6847e-01],\n",
       "             [-2.5286e-06,  4.1589e-01,  4.5736e-01,  4.4828e-02,  3.3358e-01,\n",
       "               3.2121e-02,  2.1652e-01,  1.5266e-01, -6.8072e-01,  5.7460e-06,\n",
       "              -1.2403e-02, -5.2866e-01, -8.6395e-03, -1.6552e-01, -2.2888e-01,\n",
       "              -4.0361e-01],\n",
       "             [ 5.6604e-06,  4.9486e-01,  5.4422e-01,  5.3393e-02,  3.9685e-01,\n",
       "               3.8270e-02,  2.5792e-01,  1.8189e-01, -8.3236e-01, -1.1283e-06,\n",
       "              -1.5178e-02, -6.4655e-01, -1.0569e-02, -2.0231e-01, -2.8001e-01,\n",
       "              -4.9352e-01],\n",
       "             [ 5.6673e-06,  3.3859e-01,  3.7236e-01,  3.6483e-02,  2.7155e-01,\n",
       "               2.6150e-02,  1.7634e-01,  1.2432e-01, -5.6201e-01,  5.7391e-06,\n",
       "              -1.0238e-02, -4.3647e-01, -7.1301e-03, -1.3664e-01, -1.8898e-01,\n",
       "              -3.3323e-01],\n",
       "             [ 2.4351e-07,  3.8542e-01,  4.2388e-01,  4.1529e-02,  3.0906e-01,\n",
       "               2.9773e-02,  2.0085e-01,  1.4162e-01, -6.5588e-01,  1.9474e-06,\n",
       "              -1.1949e-02, -5.0938e-01, -8.3183e-03, -1.5944e-01, -2.2058e-01,\n",
       "              -3.8890e-01],\n",
       "             [ 5.6818e-06,  1.4499e-01,  1.5945e-01,  1.5615e-02,  1.1631e-01,\n",
       "               1.1178e-02,  7.5443e-02,  5.3181e-02, -2.3380e-01,  5.7158e-06,\n",
       "              -4.2543e-03, -1.8154e-01, -2.9630e-03, -5.6862e-02, -7.8582e-02,\n",
       "              -1.3863e-01],\n",
       "             [ 3.6796e-06,  2.5505e-01,  2.8048e-01,  2.7540e-02,  2.0459e-01,\n",
       "               1.9725e-02,  1.3285e-01,  9.3702e-02, -4.1887e-01,  3.7203e-06,\n",
       "              -7.6349e-03, -3.2538e-01, -5.3197e-03, -1.0181e-01, -1.4090e-01,\n",
       "              -2.4834e-01],\n",
       "             [ 2.5311e-07,  2.6821e-01,  2.9497e-01,  2.8889e-02,  2.1510e-01,\n",
       "               2.0711e-02,  1.3968e-01,  9.8482e-02, -4.4463e-01,  3.1198e-07,\n",
       "              -8.0995e-03, -3.4530e-01, -5.6406e-03, -1.0811e-01, -1.4951e-01,\n",
       "              -2.6364e-01],\n",
       "             [ 5.6841e-06,  1.0875e-01,  1.1961e-01,  1.1693e-02,  8.7100e-02,\n",
       "               8.3869e-03,  5.6820e-02,  4.0049e-02, -2.0191e-01,  5.3817e-08,\n",
       "              -3.6756e-03, -1.5679e-01, -2.5549e-03, -4.9063e-02, -6.7928e-02,\n",
       "              -1.1974e-01],\n",
       "             [ 2.6167e-07,  1.4011e-01,  1.5409e-01,  1.5070e-02,  1.1230e-01,\n",
       "               1.0815e-02,  7.3070e-02,  5.1507e-02, -2.4514e-01, -2.4712e-06,\n",
       "              -4.4625e-03, -1.9036e-01, -3.1045e-03, -5.9588e-02, -8.2442e-02,\n",
       "              -1.4536e-01],\n",
       "             [-1.2119e-06,  3.5059e-01,  3.8557e-01,  3.7772e-02,  2.8116e-01,\n",
       "               2.7078e-02,  1.8263e-01,  1.2877e-01, -5.8485e-01,  1.8503e-07,\n",
       "              -1.0657e-02, -4.5421e-01, -7.4215e-03, -1.4219e-01, -1.9668e-01,\n",
       "              -3.4678e-01],\n",
       "             [-2.5098e-06,  1.5407e-01,  1.6945e-01,  1.6569e-02,  1.2345e-01,\n",
       "               1.1887e-02,  8.0458e-02,  5.6706e-02, -2.8109e-01,  1.5206e-07,\n",
       "              -5.1188e-03, -2.1829e-01, -3.5594e-03, -6.8307e-02, -9.4564e-02,\n",
       "              -1.6668e-01]], device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([[7.8780e-13, 2.4653e-02, 2.9816e-02, 2.8830e-04, 1.5852e-02, 1.4818e-04,\n",
       "              6.7151e-03, 3.3430e-03, 7.3078e-02, 8.1406e-13, 2.4361e-05, 4.4124e-02,\n",
       "              1.1808e-05, 4.3123e-03, 8.2822e-03, 2.5689e-02],\n",
       "             [7.9449e-13, 5.8400e-03, 7.0628e-03, 6.8304e-05, 3.7559e-03, 3.5103e-05,\n",
       "              1.5900e-03, 7.9153e-04, 1.7118e-02, 8.0260e-13, 5.7070e-06, 1.0336e-02,\n",
       "              2.7650e-06, 1.0102e-03, 1.9399e-03, 6.0173e-03],\n",
       "             [7.8763e-13, 2.9112e-02, 3.5205e-02, 3.4063e-04, 1.8731e-02, 1.7492e-04,\n",
       "              7.9136e-03, 3.9396e-03, 8.0479e-02, 8.1439e-13, 2.6835e-05, 4.8589e-02,\n",
       "              1.3023e-05, 4.7509e-03, 9.1171e-03, 2.8287e-02],\n",
       "             [7.9553e-13, 1.7509e-05, 2.1247e-05, 2.0095e-07, 1.0965e-05, 1.0669e-07,\n",
       "              5.1493e-06, 2.5677e-06, 2.5179e-04, 8.0093e-13, 8.4252e-08, 1.5218e-04,\n",
       "              4.0139e-08, 1.4758e-05, 2.8750e-05, 8.8726e-05],\n",
       "             [7.9496e-13, 3.6206e-04, 4.3785e-04, 4.2359e-06, 2.3287e-04, 2.1766e-06,\n",
       "              9.8536e-05, 4.9055e-05, 1.0414e-03, 8.0090e-13, 3.4686e-07, 6.2877e-04,\n",
       "              1.6814e-07, 6.1458e-05, 1.1800e-04, 3.6605e-04],\n",
       "             [7.8403e-13, 6.2501e-02, 7.5579e-02, 7.3143e-04, 4.0223e-02, 3.7549e-04,\n",
       "              1.6976e-02, 8.4511e-03, 1.6804e-01, 8.2095e-13, 5.6018e-05, 1.0145e-01,\n",
       "              2.7196e-05, 9.9209e-03, 1.9033e-02, 5.9058e-02],\n",
       "             [7.8405e-13, 7.4990e-02, 9.0687e-02, 8.7733e-04, 4.8249e-02, 4.5063e-04,\n",
       "              2.0390e-02, 1.0150e-02, 2.1076e-01, 8.1879e-13, 7.0230e-05, 1.2725e-01,\n",
       "              3.4069e-05, 1.2441e-02, 2.3877e-02, 7.4079e-02],\n",
       "             [7.8744e-13, 2.9529e-02, 3.5707e-02, 3.4557e-04, 1.9005e-02, 1.7739e-04,\n",
       "              8.0184e-03, 3.9916e-03, 7.8843e-02, 8.1333e-13, 2.6283e-05, 4.7600e-02,\n",
       "              1.2762e-05, 4.6551e-03, 8.9296e-03, 2.7709e-02],\n",
       "             [7.8927e-13, 1.6595e-02, 2.0071e-02, 1.9410e-04, 1.0675e-02, 9.9756e-05,\n",
       "              4.5174e-03, 2.2487e-03, 4.8937e-02, 8.1096e-13, 1.6297e-05, 2.9546e-02,\n",
       "              7.8986e-06, 2.8883e-03, 5.5451e-03, 1.7201e-02],\n",
       "             [7.8857e-13, 2.2695e-02, 2.7448e-02, 2.6538e-04, 1.4591e-02, 1.3642e-04,\n",
       "              6.1845e-03, 3.0789e-03, 6.7968e-02, 8.1445e-13, 2.2663e-05, 4.1039e-02,\n",
       "              1.0984e-05, 4.0104e-03, 7.7039e-03, 2.3893e-02],\n",
       "             [7.8968e-13, 2.9353e-02, 3.5497e-02, 3.4348e-04, 1.8891e-02, 1.7637e-04,\n",
       "              7.9751e-03, 3.9700e-03, 8.0743e-02, 8.0975e-13, 2.6898e-05, 4.8747e-02,\n",
       "              1.3053e-05, 4.7670e-03, 9.1457e-03, 2.8378e-02],\n",
       "             [7.9226e-13, 1.4335e-02, 1.7335e-02, 1.6774e-04, 9.2265e-03, 8.6138e-05,\n",
       "              3.8943e-03, 1.9385e-03, 3.9630e-02, 8.0534e-13, 1.3194e-05, 2.3925e-02,\n",
       "              6.4014e-06, 2.3398e-03, 4.4886e-03, 1.3928e-02],\n",
       "             [7.8363e-13, 6.3636e-02, 7.6956e-02, 7.4454e-04, 4.0947e-02, 3.8239e-04,\n",
       "              1.7299e-02, 8.6116e-03, 1.7755e-01, 8.2183e-13, 5.9159e-05, 1.0719e-01,\n",
       "              2.8701e-05, 1.0481e-02, 2.0113e-02, 6.2403e-02],\n",
       "             [7.8382e-13, 8.1484e-02, 9.8533e-02, 9.5367e-04, 5.2448e-02, 4.8950e-04,\n",
       "              2.2123e-02, 1.1013e-02, 2.1676e-01, 8.1812e-13, 7.2249e-05, 1.3087e-01,\n",
       "              3.5082e-05, 1.2799e-02, 2.4549e-02, 7.6180e-02],\n",
       "             [7.8614e-13, 5.7809e-02, 6.9911e-02, 6.7622e-04, 3.7183e-02, 3.4740e-04,\n",
       "              1.5730e-02, 7.8309e-03, 1.6502e-01, 8.1736e-13, 5.5022e-05, 9.9635e-02,\n",
       "              2.6687e-05, 9.7395e-03, 1.8699e-02, 5.8006e-02],\n",
       "             [7.8292e-13, 6.5629e-02, 7.9367e-02, 7.6769e-04, 4.2213e-02, 3.9439e-04,\n",
       "              1.7857e-02, 8.8897e-03, 1.8678e-01, 8.2256e-13, 6.2289e-05, 1.1277e-01,\n",
       "              3.0209e-05, 1.1024e-02, 2.1164e-02, 6.5654e-02],\n",
       "             [7.8731e-13, 3.0798e-02, 3.7244e-02, 3.6039e-04, 1.9824e-02, 1.8506e-04,\n",
       "              8.3661e-03, 4.1645e-03, 8.5127e-02, 8.1410e-13, 2.8341e-05, 5.1392e-02,\n",
       "              1.3751e-05, 5.0263e-03, 9.6414e-03, 2.9918e-02],\n",
       "             [7.8726e-13, 2.8812e-02, 3.4844e-02, 3.3702e-04, 1.8535e-02, 1.7315e-04,\n",
       "              7.8397e-03, 3.9024e-03, 8.4126e-02, 8.1466e-13, 2.8022e-05, 5.0785e-02,\n",
       "              1.3589e-05, 4.9654e-03, 9.5317e-03, 2.9566e-02],\n",
       "             [7.9414e-13, 1.4430e-03, 1.7453e-03, 1.6870e-05, 9.2736e-04, 8.6777e-06,\n",
       "              3.9378e-04, 1.9600e-04, 4.5778e-03, 8.0336e-13, 1.5274e-06, 2.7633e-03,\n",
       "              7.3930e-07, 2.7004e-04, 5.1902e-04, 1.6090e-03],\n",
       "             [7.9565e-13, 2.4625e-03, 2.9783e-03, 2.8785e-05, 1.5829e-03, 1.4807e-05,\n",
       "              6.7154e-04, 3.3428e-04, 7.6955e-03, 8.0029e-13, 2.5641e-06, 4.6454e-03,\n",
       "              1.2425e-06, 4.5402e-04, 8.7235e-04, 2.7047e-03],\n",
       "             [7.8611e-13, 3.9980e-02, 4.8347e-02, 4.6787e-04, 2.5732e-02, 2.4021e-04,\n",
       "              1.0859e-02, 5.4057e-03, 1.0888e-01, 8.1607e-13, 3.6277e-05, 6.5730e-02,\n",
       "              1.7604e-05, 6.4283e-03, 1.2331e-02, 3.8264e-02],\n",
       "             [7.9023e-13, 1.3798e-02, 1.6686e-02, 1.6140e-04, 8.8756e-03, 8.2918e-05,\n",
       "              3.7535e-03, 1.8685e-03, 3.9174e-02, 8.1009e-13, 1.3061e-05, 2.3649e-02,\n",
       "              6.3370e-06, 2.3122e-03, 4.4387e-03, 1.3768e-02],\n",
       "             [7.8475e-13, 4.9733e-02, 6.0144e-02, 5.8182e-04, 3.1998e-02, 2.9887e-04,\n",
       "              1.3525e-02, 6.7324e-03, 1.4168e-01, 8.1921e-13, 4.7204e-05, 8.5533e-02,\n",
       "              2.2899e-05, 8.3633e-03, 1.6051e-02, 4.9795e-02],\n",
       "             [7.9179e-13, 5.8669e-03, 7.0957e-03, 6.8603e-05, 3.7724e-03, 3.5274e-05,\n",
       "              1.5989e-03, 7.9588e-04, 1.8058e-02, 8.0634e-13, 6.0181e-06, 1.0900e-02,\n",
       "              2.9151e-06, 1.0655e-03, 2.0467e-03, 6.3465e-03],\n",
       "             [7.8800e-13, 2.7346e-02, 3.3068e-02, 3.2005e-04, 1.7602e-02, 1.6429e-04,\n",
       "              7.4249e-03, 3.6961e-03, 7.3307e-02, 8.1307e-13, 2.4424e-05, 4.4258e-02,\n",
       "              1.1857e-05, 4.3285e-03, 8.3021e-03, 2.5764e-02],\n",
       "             [7.9214e-13, 1.4537e-02, 1.7579e-02, 1.7010e-04, 9.3534e-03, 8.7343e-05,\n",
       "              3.9508e-03, 1.9667e-03, 4.0038e-02, 8.0554e-13, 1.3347e-05, 2.4172e-02,\n",
       "              6.4779e-06, 2.3636e-03, 4.5357e-03, 1.4072e-02],\n",
       "             [7.9625e-13, 9.2087e-05, 1.1121e-04, 1.0856e-06, 5.9896e-05, 5.4984e-07,\n",
       "              2.4183e-05, 1.2041e-05, 4.2884e-05, 7.9979e-13, 1.4037e-08, 2.5966e-05,\n",
       "              7.0144e-09, 2.5741e-06, 4.7655e-06, 1.5057e-05],\n",
       "             [7.8795e-13, 2.7987e-02, 3.3847e-02, 3.2739e-04, 1.8004e-02, 1.6820e-04,\n",
       "              7.6145e-03, 3.7904e-03, 8.0713e-02, 8.1519e-13, 2.6896e-05, 4.8726e-02,\n",
       "              1.3046e-05, 4.7639e-03, 9.1451e-03, 2.8367e-02],\n",
       "             [7.8766e-13, 2.8851e-02, 3.4891e-02, 3.3754e-04, 1.8563e-02, 1.7338e-04,\n",
       "              7.8456e-03, 3.9054e-03, 8.1780e-02, 8.1469e-13, 2.7250e-05, 4.9370e-02,\n",
       "              1.3221e-05, 4.8274e-03, 9.2649e-03, 2.8742e-02],\n",
       "             [7.9457e-13, 7.3360e-04, 8.8705e-04, 8.5894e-06, 4.7236e-04, 4.4074e-06,\n",
       "              1.9896e-04, 9.9048e-05, 1.8830e-03, 8.0115e-13, 6.2695e-07, 1.1369e-03,\n",
       "              3.0443e-07, 1.1121e-04, 2.1319e-04, 6.6177e-04],\n",
       "             [7.9490e-13, 4.0925e-03, 4.9499e-03, 4.7843e-05, 2.6305e-03, 2.4610e-05,\n",
       "              1.1166e-03, 5.5579e-04, 1.3017e-02, 8.0187e-13, 4.3371e-06, 7.8574e-03,\n",
       "              2.1012e-06, 7.6791e-04, 1.4757e-03, 4.5750e-03],\n",
       "             [7.8402e-13, 6.4292e-02, 7.7748e-02, 7.5215e-04, 4.1357e-02, 3.8632e-04,\n",
       "              1.7485e-02, 8.7043e-03, 1.8088e-01, 8.2345e-13, 6.0318e-05, 1.0920e-01,\n",
       "              2.9271e-05, 1.0677e-02, 2.0494e-02, 6.3574e-02],\n",
       "             [7.8591e-13, 6.0881e-02, 7.3630e-02, 7.1199e-04, 3.9157e-02, 3.6595e-04,\n",
       "              1.6577e-02, 8.2518e-03, 1.8184e-01, 8.1900e-13, 6.0565e-05, 1.0978e-01,\n",
       "              2.9354e-05, 1.0731e-02, 2.0605e-02, 6.3915e-02],\n",
       "             [7.8546e-13, 6.5320e-02, 7.8991e-02, 7.6409e-04, 4.2016e-02, 3.9252e-04,\n",
       "              1.7767e-02, 8.8449e-03, 1.8474e-01, 8.1843e-13, 6.1601e-05, 1.1154e-01,\n",
       "              2.9885e-05, 1.0904e-02, 2.0931e-02, 6.4936e-02],\n",
       "             [7.8502e-13, 4.5889e-02, 5.5497e-02, 5.3663e-04, 2.9507e-02, 2.7584e-04,\n",
       "              1.2499e-02, 6.2218e-03, 1.3688e-01, 8.1976e-13, 4.5628e-05, 8.2641e-02,\n",
       "              2.2119e-05, 8.0775e-03, 1.5512e-02, 4.8115e-02],\n",
       "             [7.8548e-13, 4.4384e-02, 5.3674e-02, 5.1922e-04, 2.8553e-02, 2.6671e-04,\n",
       "              1.2072e-02, 6.0094e-03, 1.2615e-01, 8.1832e-13, 4.2044e-05, 7.6165e-02,\n",
       "              2.0394e-05, 7.4464e-03, 1.4292e-02, 4.4341e-02],\n",
       "             [7.9327e-13, 1.0640e-02, 1.2866e-02, 1.2453e-04, 6.8488e-03, 6.3922e-05,\n",
       "              2.8885e-03, 1.4379e-03, 2.8391e-02, 8.0388e-13, 9.4584e-06, 1.7141e-02,\n",
       "              4.5917e-06, 1.6764e-03, 3.2151e-03, 9.9782e-03],\n",
       "             [7.8370e-13, 6.0424e-02, 7.3066e-02, 7.0714e-04, 3.8893e-02, 3.6301e-04,\n",
       "              1.6407e-02, 8.1673e-03, 1.6265e-01, 8.1937e-13, 5.4186e-05, 9.8199e-02,\n",
       "              2.6302e-05, 9.6040e-03, 1.8421e-02, 5.7166e-02],\n",
       "             [7.8323e-13, 8.5758e-02, 1.0371e-01, 1.0032e-03, 5.5169e-02, 5.1535e-04,\n",
       "              2.3323e-02, 1.1610e-02, 2.4343e-01, 8.2106e-13, 8.1130e-05, 1.4697e-01,\n",
       "              3.9355e-05, 1.4369e-02, 2.7578e-02, 8.5562e-02],\n",
       "             [7.8591e-13, 4.0038e-02, 4.8417e-02, 4.6849e-04, 2.5766e-02, 2.4058e-04,\n",
       "              1.0879e-02, 5.4155e-03, 1.1086e-01, 8.1621e-13, 3.6930e-05, 6.6933e-02,\n",
       "              1.7919e-05, 6.5453e-03, 1.2557e-02, 3.8965e-02],\n",
       "             [7.8444e-13, 5.1890e-02, 6.2753e-02, 6.0695e-04, 3.3382e-02, 3.1188e-04,\n",
       "              1.4118e-02, 7.0275e-03, 1.5102e-01, 8.1999e-13, 5.0293e-05, 9.1175e-02,\n",
       "              2.4384e-05, 8.9140e-03, 1.7110e-02, 5.3081e-02],\n",
       "             [7.9168e-13, 7.3268e-03, 8.8594e-03, 8.5765e-05, 4.7170e-03, 4.4014e-05,\n",
       "              1.9879e-03, 9.8960e-04, 1.9170e-02, 8.0587e-13, 6.3855e-06, 1.1573e-02,\n",
       "              3.1007e-06, 1.1321e-03, 2.1707e-03, 6.7372e-03],\n",
       "             [7.9079e-13, 2.2803e-02, 2.7574e-02, 2.6686e-04, 1.4677e-02, 1.3700e-04,\n",
       "              6.1927e-03, 3.0828e-03, 6.1666e-02, 8.0785e-13, 2.0544e-05, 3.7230e-02,\n",
       "              9.9751e-06, 3.6410e-03, 6.9839e-03, 2.1673e-02],\n",
       "             [7.8820e-13, 2.5114e-02, 3.0370e-02, 2.9384e-04, 1.6161e-02, 1.5090e-04,\n",
       "              6.8245e-03, 3.3972e-03, 6.9382e-02, 8.1301e-13, 2.3119e-05, 4.1889e-02,\n",
       "              1.1218e-05, 4.0961e-03, 7.8589e-03, 2.4386e-02],\n",
       "             [7.9260e-13, 4.1163e-03, 4.9793e-03, 4.8082e-05, 2.6429e-03, 2.4767e-05,\n",
       "              1.1266e-03, 5.6081e-04, 1.4303e-02, 8.0670e-13, 4.7684e-06, 8.6351e-03,\n",
       "              2.3066e-06, 8.4330e-04, 1.6222e-03, 5.0283e-03],\n",
       "             [7.9161e-13, 6.8401e-03, 8.2727e-03, 7.9974e-05, 4.3973e-03, 4.1127e-05,\n",
       "              1.8647e-03, 9.2824e-04, 2.1083e-02, 8.0726e-13, 7.0251e-06, 1.2729e-02,\n",
       "              3.4035e-06, 1.2439e-03, 2.3896e-03, 7.4109e-03],\n",
       "             [7.8546e-13, 4.2932e-02, 5.1917e-02, 5.0230e-04, 2.7623e-02, 2.5798e-04,\n",
       "              1.1671e-02, 5.8097e-03, 1.2007e-01, 8.1712e-13, 4.0011e-05, 7.2489e-02,\n",
       "              1.9412e-05, 7.0879e-03, 1.3601e-02, 4.2201e-02],\n",
       "             [7.9112e-13, 8.2745e-03, 1.0009e-02, 9.6682e-05, 5.3153e-03, 4.9766e-05,\n",
       "              2.2616e-03, 1.1257e-03, 2.7728e-02, 8.0914e-13, 9.2407e-06, 1.6741e-02,\n",
       "              4.4720e-06, 1.6353e-03, 3.1442e-03, 9.7477e-03]], device='cuda:0')},\n",
       "    8: {'step': tensor(8.),\n",
       "     'exp_avg': tensor([[ 7.6217e-06,  4.0528e+01,  4.4532e+01,  4.3806e+00,  3.2411e+01,\n",
       "               3.1163e+00,  2.0941e+01,  1.4838e+01, -1.3242e+01,  3.9239e-06,\n",
       "              -2.4174e-01, -1.0262e+01, -1.6847e-01, -3.2170e+00, -4.4575e+00,\n",
       "              -7.8282e+00]], device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([[3.2080e-12, 5.7396e+02, 6.9286e+02, 6.7536e+00, 3.6723e+02, 3.4178e+00,\n",
       "              1.5348e+02, 7.7154e+01, 6.1867e+01, 1.4238e-12, 2.0568e-02, 3.7123e+01,\n",
       "              9.9892e-03, 3.6555e+00, 6.9995e+00, 2.1626e+01]], device='cuda:0')},\n",
       "    9: {'step': tensor(8.),\n",
       "     'exp_avg': tensor([-1.6887e-06], device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([3.6822e-12], device='cuda:0')},\n",
       "    10: {'step': tensor(8.),\n",
       "     'exp_avg': tensor([[-0.2537,  0.2759, -0.2634, -0.6151, -0.5208,  0.1322,  0.4028, -0.3015,\n",
       "              -0.7739, -0.2043,  0.4364,  0.2376, -0.4496,  0.6025,  0.9300, -0.5683,\n",
       "               0.2139, -0.2426, -0.7767,  0.4694,  0.2213, -0.1329,  0.2498,  0.1841,\n",
       "              -0.3247,  0.5127, -0.0769, -0.9018, -0.8254, -0.3299,  0.8420, -0.1529,\n",
       "               1.1461,  0.6034, -0.6970, -0.1195,  0.2183, -0.0880,  0.8548, -0.1842,\n",
       "              -0.8506, -0.4863,  0.9450, -0.7990, -0.6238, -0.4646, -0.4639, -0.1761]],\n",
       "            device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([[0.0227, 0.0267, 0.0243, 0.1327, 0.0954, 0.0061, 0.0567, 0.0319, 0.2106,\n",
       "              0.0146, 0.0669, 0.0199, 0.0710, 0.1272, 0.3032, 0.1133, 0.0161, 0.0207,\n",
       "              0.2118, 0.0772, 0.0172, 0.0061, 0.0218, 0.0119, 0.0370, 0.0923, 0.0022,\n",
       "              0.2851, 0.2392, 0.0382, 0.2486, 0.0082, 0.4602, 0.1273, 0.1706, 0.0050,\n",
       "              0.0167, 0.0028, 0.2562, 0.0120, 0.2538, 0.0829, 0.3129, 0.2243, 0.1366,\n",
       "              0.0757, 0.0756, 0.0109]], device='cuda:0')},\n",
       "    11: {'step': tensor(8.),\n",
       "     'exp_avg': tensor([-3.2039e-06], device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([1.3712e-12], device='cuda:0')},\n",
       "    12: {'step': tensor(8.),\n",
       "     'exp_avg': tensor([209.6822, 436.7199, 344.2280,  83.4900, 103.8852, 279.5186, 227.2372,\n",
       "              88.9310, 264.0051, 257.8671, 182.8367,  85.7994, 228.7001, 213.4726,\n",
       "             135.5870, 161.9762, 226.4550,  96.2078, 205.7529, 277.4391, 206.0604,\n",
       "             431.7364,  17.9314, 181.6440,  40.4010, 372.2743, 211.1828, 168.8148,\n",
       "             -17.2502, 219.3414], device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([15454.0859, 67068.4062, 41655.2734,  2451.5251,  3793.4915, 27482.8906,\n",
       "             18148.1602,  2781.9548, 24503.2852, 23373.3359, 11755.7119,  2585.8850,\n",
       "             18379.7188, 16019.0195,  6461.3477,  9228.1729, 18030.5605,  3256.3784,\n",
       "             14888.9795, 27071.7461, 14934.4180, 65525.5352,   113.3313, 11607.0479,\n",
       "               574.4426, 48723.2891, 15674.5645, 10031.5078,   104.7359, 16911.4043],\n",
       "            device='cuda:0')},\n",
       "    13: {'step': tensor(8.),\n",
       "     'exp_avg': tensor([ 212.6319, -269.5852,  257.3539,   88.3166, -170.1887,  222.5039,\n",
       "              253.1317,   87.5294, -237.9497,  253.6333, -213.7322,  157.4947,\n",
       "              214.6361,  229.9334, -198.9491, -260.7745,  233.9953,   17.7831,\n",
       "             -237.1248,  266.9129,  293.9963, -225.9960, -144.0574,  120.9627,\n",
       "             -122.0381, -241.8981, -163.0111,  236.4635, -209.1361, -214.1521],\n",
       "            device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([15895.2461, 25555.1543, 23286.6094,  2742.0352, 10177.6230, 17403.8809,\n",
       "             22528.0684,  2693.0615, 19905.6426, 22618.6074, 16060.7549,  8715.8545,\n",
       "             16190.9727, 18585.1211, 13912.9238, 23913.4395, 19251.9258,   111.2641,\n",
       "             19771.6582, 25050.6719, 30395.0586, 17953.9238,  7291.7520,  5144.7705,\n",
       "              5232.2822, 20570.9746,  9338.2988, 19668.2363, 15406.9297, 16121.8906],\n",
       "            device='cuda:0')},\n",
       "    14: {'step': tensor(8.),\n",
       "     'exp_avg': tensor([[ 6.6360e-04, -8.4414e-04,  9.9578e-04,  ...,  9.1082e-04,\n",
       "              -3.0539e-04, -6.0893e-04],\n",
       "             [ 3.1314e-04, -4.9182e-04,  4.9027e-04,  ...,  6.2552e-04,\n",
       "              -3.8567e-04, -4.8850e-04],\n",
       "             [-3.4851e+00,  6.5062e+00, -5.3984e+00,  ..., -3.4602e+00,\n",
       "              -5.6336e-01,  2.0765e+00],\n",
       "             ...,\n",
       "             [ 5.0978e+00, -1.0114e+01,  1.0683e+01,  ...,  6.1866e+00,\n",
       "               1.7338e-01, -6.2417e+00],\n",
       "             [ 3.2060e+01, -5.9124e+01,  5.0375e+01,  ...,  3.2155e+01,\n",
       "               9.4324e+00, -3.5786e+01],\n",
       "             [ 6.1161e+01, -1.1663e+02,  1.1209e+02,  ...,  6.7288e+01,\n",
       "               4.5748e+00, -6.3453e+01]], device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([[1.9417e-07, 3.1315e-07, 4.3494e-07,  ..., 3.6424e-07, 4.1879e-08,\n",
       "              1.6316e-07],\n",
       "             [4.3996e-08, 1.0723e-07, 1.0657e-07,  ..., 1.7269e-07, 6.6323e-08,\n",
       "              1.0581e-07],\n",
       "             [4.3593e+00, 1.5320e+01, 1.0586e+01,  ..., 4.2150e+00, 1.1767e-01,\n",
       "              1.5824e+00],\n",
       "             ...,\n",
       "             [9.1621e+00, 3.6068e+01, 4.0220e+01,  ..., 1.3495e+01, 1.0314e-02,\n",
       "              1.3732e+01],\n",
       "             [3.6176e+02, 1.2303e+03, 8.9312e+02,  ..., 3.6389e+02, 3.1313e+01,\n",
       "              4.5072e+02],\n",
       "             [1.3165e+03, 4.7874e+03, 4.4223e+03,  ..., 1.5935e+03, 7.3659e+00,\n",
       "              1.4170e+03]], device='cuda:0')},\n",
       "    15: {'step': tensor(8.),\n",
       "     'exp_avg': tensor([ 6.3390e-04,  4.1197e-04, -3.6043e+00,  4.4082e+01,  2.5400e+01,\n",
       "              2.1132e+01,  3.6524e+01,  5.5329e+01,  3.7228e+01,  1.1876e+01,\n",
       "              4.8278e-05,  5.8244e-04,  5.7869e+01,  7.8105e+01,  8.6628e-04,\n",
       "             -2.7006e-02, -1.4100e+01,  4.6146e-05, -8.0097e+00,  4.4413e-01,\n",
       "              4.7674e+01,  5.7151e-04,  7.8919e-04,  1.2967e-03,  7.1277e+01,\n",
       "              4.0077e+01,  4.3084e+01,  1.7621e+01,  2.3380e+01, -1.1461e+00,\n",
       "              3.7318e+01,  1.2524e-03,  4.5936e+01,  6.2279e+01,  5.3202e-04,\n",
       "              2.0338e-05,  3.7500e+01,  7.5837e+01,  5.9509e+01,  3.9020e-05,\n",
       "              5.0282e-04,  7.3018e-04,  1.2981e-03,  6.9080e-04,  4.9304e+01,\n",
       "              3.2745e+01,  7.3974e+01,  1.2971e-03,  1.1965e-03,  5.2182e+01,\n",
       "              3.7522e+01,  6.8848e+01,  7.5696e+01, -2.8911e+01,  4.7845e+01,\n",
       "              2.0981e+01,  2.1341e+01,  1.0556e-03,  4.8098e+01,  4.7339e-03,\n",
       "              2.1700e+01,  5.9528e+00,  3.3915e+01,  6.7813e+01], device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([1.7731e-07, 7.5549e-08, 4.7656e+00, 6.8391e+02, 2.2700e+02, 1.5717e+02,\n",
       "             4.6951e+02, 1.0775e+03, 4.8779e+02, 4.9534e+01, 1.1940e-09, 1.4936e-07,\n",
       "             1.1787e+03, 2.1479e+03, 3.2969e-07, 5.7491e-05, 7.0441e+01, 1.1459e-09,\n",
       "             2.2724e+01, 6.9425e-02, 7.9991e+02, 1.4438e-07, 2.7394e-07, 7.3575e-07,\n",
       "             1.7881e+03, 5.6528e+02, 6.5341e+02, 1.0928e+02, 1.9239e+02, 4.9187e-01,\n",
       "             4.9004e+02, 6.8657e-07, 7.4245e+02, 1.3651e+03, 1.2529e-07, 1.7180e-10,\n",
       "             4.9473e+02, 2.0241e+03, 1.2464e+03, 8.5014e-10, 1.1203e-07, 2.3475e-07,\n",
       "             7.3618e-07, 2.1028e-07, 8.5565e+02, 3.7738e+02, 1.9262e+03, 7.3620e-07,\n",
       "             6.2690e-07, 9.5837e+02, 4.9551e+02, 1.6685e+03, 2.0166e+03, 2.9527e+02,\n",
       "             8.0573e+02, 1.5493e+02, 1.6029e+02, 4.8844e-07, 8.1421e+02, 4.2066e-06,\n",
       "             1.6546e+02, 1.2496e+01, 4.0483e+02, 1.6185e+03], device='cuda:0')},\n",
       "    16: {'step': tensor(8.),\n",
       "     'exp_avg': tensor([[-2.9825e-01, -3.0091e-01, -1.1455e+00,  ..., -4.8489e+00,\n",
       "              -3.2467e-01, -1.1978e+00],\n",
       "             [-1.2179e+00, -1.2167e+00, -1.6657e+00,  ..., -3.8029e+01,\n",
       "              -1.3027e+00, -4.4502e+00],\n",
       "             [ 8.8458e-05,  3.7462e-04,  8.8458e-05,  ...,  4.0802e-04,\n",
       "               8.9415e-05,  8.8458e-05],\n",
       "             ...,\n",
       "             [ 2.5049e+00,  2.5045e+00,  5.4491e+00,  ...,  8.4211e+01,\n",
       "               2.7596e+00,  9.6439e+00],\n",
       "             [ 2.8462e-04,  8.0310e-04,  8.1161e-03,  ...,  5.4417e-04,\n",
       "               3.1663e-04,  3.1759e-04],\n",
       "             [ 1.3985e-05, -1.6378e-04,  1.3985e-05,  ...,  7.5089e-05,\n",
       "               1.3029e-05,  1.3029e-05]], device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([[3.0141e-02, 3.0146e-02, 6.2953e-01,  ..., 8.1528e+00, 3.6096e-02,\n",
       "              5.0321e-01],\n",
       "             [5.1500e-01, 5.1501e-01, 1.5164e+00,  ..., 5.0871e+02, 6.0274e-01,\n",
       "              6.9791e+00],\n",
       "             [3.8097e-09, 6.2628e-08, 3.8097e-09,  ..., 7.4125e-08, 3.8879e-09,\n",
       "              3.8097e-09],\n",
       "             ...,\n",
       "             [2.2111e+00, 2.2111e+00, 1.0352e+01,  ..., 2.4970e+03, 2.6833e+00,\n",
       "              3.2743e+01],\n",
       "             [1.1598e-08, 1.8955e-07, 9.6298e-06,  ..., 7.1509e-08, 1.5826e-08,\n",
       "              1.5966e-08],\n",
       "             [1.6076e-10, 1.2398e-08, 1.6076e-10,  ..., 2.8001e-09, 1.4521e-10,\n",
       "              1.4521e-10]], device='cuda:0')},\n",
       "    17: {'step': tensor(8.),\n",
       "     'exp_avg': tensor([-1.7941e+00, -7.4161e+00,  5.7560e-04,  2.4879e+01,  1.6021e-03,\n",
       "              2.6467e+01,  5.0874e-03,  2.7320e+01,  8.2575e-04, -9.0456e-04,\n",
       "              5.3224e-05,  1.0466e-03,  2.1776e+01,  9.1960e-04,  3.4009e-02,\n",
       "              1.5619e-03,  2.7242e-04,  4.4849e-04,  1.8432e+01,  2.2609e+01,\n",
       "              1.8718e+01,  5.5465e-04, -1.7419e+01,  1.3117e-04,  1.7454e+01,\n",
       "              1.1644e-03,  7.2010e-03,  2.3575e+01, -1.7251e-03, -1.0154e+01,\n",
       "              2.3405e+01, -2.0116e-02,  2.6963e+01,  1.8503e+01,  2.1790e+01,\n",
       "              1.9231e+01,  1.2966e-03, -1.3072e+01,  6.8205e-04,  1.2644e-03,\n",
       "             -3.2433e-02,  3.2461e-02,  1.7135e-03, -9.0784e-03,  3.0188e+01,\n",
       "              2.1911e-04,  1.9681e+01,  1.0396e-02,  2.3561e+01,  1.5777e-03,\n",
       "              3.9940e+00,  1.4390e-03,  2.2031e-04,  1.7105e+01,  1.2787e-03,\n",
       "              1.3318e-04,  1.1810e+01,  1.1451e-03,  2.0605e+01,  2.1789e-02,\n",
       "              3.5167e-04,  3.0111e-04,  1.9035e+01, -1.2367e-03,  2.9228e+01,\n",
       "             -1.0102e-02,  1.5831e+01,  2.6363e+01,  2.0470e+01,  2.6802e+01,\n",
       "              2.2560e+01,  1.4004e+01,  1.8767e-03, -8.9176e-03,  2.3265e+01,\n",
       "             -1.4789e+01,  2.4768e+01,  1.6332e-03,  1.1110e+01,  4.8302e-04,\n",
       "              6.3622e-04,  1.3309e-02,  1.6168e+00, -9.6464e-03, -1.1956e-02,\n",
       "              2.6711e+01,  2.0541e-03,  1.0784e-02, -2.4372e+00,  2.2127e-04,\n",
       "              1.3631e-03,  6.1518e-04, -3.7814e-03,  4.9850e-04, -1.2989e+01,\n",
       "              1.7390e+01,  8.5286e-04,  7.3514e-04,  1.6769e-03,  3.8762e-04,\n",
       "              1.4847e-03,  2.4445e+01,  3.2662e-03,  3.4282e-02,  7.0541e-04,\n",
       "              1.3845e+01,  5.9083e-04,  2.8832e+01,  1.9858e-03,  2.3676e+01,\n",
       "             -3.9684e-02,  2.8004e+01, -8.3277e+00,  2.5009e+01,  1.1905e-05,\n",
       "              5.1930e-04,  1.5285e+01,  4.5586e+00,  1.5873e-02,  8.3627e-05,\n",
       "              2.5890e-04,  3.4915e+01,  1.7283e-04, -1.9743e+01,  1.8029e+01,\n",
       "              1.5465e+01,  1.9853e-03,  1.1086e-04], device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([1.1489e+00, 1.9631e+01, 1.4644e-07, 2.1805e+02, 1.1214e-06, 2.4721e+02,\n",
       "             6.8759e-06, 2.6270e+02, 2.9973e-07, 3.9422e-06, 1.4832e-09, 4.8023e-07,\n",
       "             1.6691e+02, 3.7125e-07, 6.3058e-05, 2.5415e-07, 3.3461e-08, 8.9355e-08,\n",
       "             1.1982e+02, 1.8014e+02, 1.2330e+02, 1.3606e-07, 1.0731e+02, 8.0750e-09,\n",
       "             1.0723e+02, 5.9379e-07, 1.0339e-05, 1.9561e+02, 5.1380e-05, 3.6574e+01,\n",
       "             1.9310e+02, 7.0980e-05, 2.5600e+02, 1.2051e+02, 1.6716e+02, 1.3058e+02,\n",
       "             7.3562e-07, 6.0491e+01, 2.0503e-07, 6.9858e-07, 1.0895e-04, 6.3302e-05,\n",
       "             5.4768e-07, 6.4894e-06, 3.2077e+02, 2.1844e-08, 1.3634e+02, 1.7299e-05,\n",
       "             1.9538e+02, 1.0876e-06, 5.6167e+00, 1.5081e-05, 2.2079e-08, 1.0309e+02,\n",
       "             7.1560e-07, 8.3152e-09, 4.9284e+01, 5.7439e-07, 1.4946e+02, 6.7384e-05,\n",
       "             5.4959e-08, 4.0731e-08, 1.2753e+02, 1.1530e-05, 3.0062e+02, 3.3120e-05,\n",
       "             8.8224e+01, 2.4463e+02, 1.4747e+02, 2.5284e+02, 1.7914e+02, 6.9001e+01,\n",
       "             1.5373e-06, 1.9685e-05, 1.9050e+02, 7.7271e+01, 2.1592e+02, 1.1652e-06,\n",
       "             4.3466e+01, 1.0347e-07, 1.7860e-07, 5.6126e-05, 9.2021e-01, 6.6951e-05,\n",
       "             1.2449e-05, 2.5115e+02, 1.8390e-06, 2.3952e-05, 2.1034e+00, 2.2267e-08,\n",
       "             4.5112e-07, 1.6707e-07, 7.8724e-06, 1.1014e-07, 5.9807e+01, 1.0645e+02,\n",
       "             3.1961e-07, 2.3793e-07, 3.5352e-07, 6.6986e-08, 9.6356e-07, 2.1034e+02,\n",
       "             3.0520e-06, 6.8981e-05, 2.1920e-07, 6.7431e+01, 1.5421e-07, 2.9257e+02,\n",
       "             1.7207e-06, 1.9731e+02, 1.2035e-04, 2.7602e+02, 2.4456e+01, 2.2015e+02,\n",
       "             1.2795e-10, 1.1942e-07, 8.2231e+01, 7.3143e+00, 4.5429e-05, 3.4270e-09,\n",
       "             3.0280e-08, 4.2911e+02, 1.3761e-08, 1.3788e+02, 1.1442e+02, 8.4280e+01,\n",
       "             6.0755e-07, 5.8497e-09], device='cuda:0')},\n",
       "    18: {'step': tensor(8.),\n",
       "     'exp_avg': tensor([[ 2.4148e-04,  3.9830e-04,  2.4148e-04,  ...,  2.4243e-04,\n",
       "              -2.2198e-03,  1.2385e-03],\n",
       "             [ 5.7674e-03,  2.4633e-03, -5.3483e-03,  ..., -4.9650e-03,\n",
       "               4.2711e-03, -1.4694e-04],\n",
       "             [ 3.2217e-04,  5.7775e-04,  1.8222e-04,  ...,  1.8762e-04,\n",
       "               3.9327e-04, -5.5692e-05],\n",
       "             ...,\n",
       "             [ 4.5053e-05,  5.4309e-05,  6.5269e-05,  ..., -7.0036e-04,\n",
       "               5.6916e-05,  6.4313e-05],\n",
       "             [-1.1503e+01, -2.2046e+01, -1.1345e+00,  ..., -6.9787e+01,\n",
       "              -1.1275e+00,  8.6748e-01],\n",
       "             [ 3.6943e+00,  5.5476e+00,  2.5289e-01,  ..., -2.2163e+00,\n",
       "               2.3841e-01,  2.4899e-01]], device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([[2.6417e-08, 7.0679e-08, 2.6417e-08,  ..., 2.6623e-08, 2.1490e-06,\n",
       "              6.7140e-07],\n",
       "             [1.4812e-05, 2.6406e-06, 4.9571e-06,  ..., 1.1331e-05, 3.6783e-06,\n",
       "              3.5688e-08],\n",
       "             [4.6526e-08, 1.4752e-07, 1.5252e-08,  ..., 1.6142e-08, 6.8928e-08,\n",
       "              1.6111e-09],\n",
       "             ...,\n",
       "             [1.0976e-09, 1.5388e-09, 2.1573e-09,  ..., 2.1545e-07, 1.6764e-09,\n",
       "              2.0992e-09],\n",
       "             [4.7222e+01, 1.7176e+02, 4.4651e-01,  ..., 1.7138e+03, 4.4650e-01,\n",
       "              2.6390e-01],\n",
       "             [4.7852e+00, 1.0845e+01, 2.1312e-02,  ..., 1.7246e+00, 2.1316e-02,\n",
       "              2.1295e-02]], device='cuda:0')},\n",
       "    19: {'step': tensor(8.),\n",
       "     'exp_avg': tensor([ 1.5203e-03,  3.3475e-03,  5.8947e-04,  1.6208e-03,  1.3581e+01,\n",
       "              1.0342e-03,  2.3358e-02,  1.2503e+01, -4.8284e+00,  7.1123e-03,\n",
       "              3.7592e+00, -3.0721e-02,  1.1141e+01,  7.9155e+00, -8.1889e+00,\n",
       "              1.7628e-03,  4.6469e-03,  1.2091e+01,  1.9334e-02,  1.0759e-04,\n",
       "              9.2737e-04,  1.4646e+01,  1.1233e+01,  1.3639e-03,  3.4078e-03,\n",
       "             -1.1921e+00,  7.6125e+00,  1.4847e-02,  2.7808e-03,  2.8448e+00,\n",
       "             -1.0051e+01,  6.7842e-03,  2.3582e-02,  8.7923e+00,  1.0106e+01,\n",
       "              3.6952e+00, -4.6331e+00, -1.4795e+00,  4.9106e-03,  1.3603e+01,\n",
       "              9.2669e-03,  6.5314e+00,  7.6934e-04,  8.5004e+00,  6.2366e-03,\n",
       "              6.9083e+00,  1.3094e+01,  1.3087e+01,  1.0976e+01,  1.5382e+01,\n",
       "              2.4439e-02,  9.1078e+00,  4.5739e-02,  2.5225e-03,  1.8607e-03,\n",
       "              4.4930e-03,  2.2498e-02,  4.3854e-03,  4.1666e-03,  1.2661e+01,\n",
       "             -7.0960e+00,  1.5291e-03,  9.7863e+00,  2.7177e-03,  2.2152e+00,\n",
       "             -2.4741e+00,  1.0768e+01, -5.8438e-01,  1.6872e+00,  2.6153e+00,\n",
       "              1.9608e-03,  3.2162e-03,  1.0404e+01,  9.3760e+00,  2.3754e-03,\n",
       "              8.5177e+00,  5.2888e-03,  2.7796e-03,  1.2411e+01,  4.6340e+00,\n",
       "              9.1318e-04,  4.9432e+00,  6.7420e-03,  1.1246e-03,  7.7873e+00,\n",
       "              1.0348e-03,  1.2520e+01,  1.8050e-03,  9.9982e+00, -4.0233e+00,\n",
       "              1.5670e-02,  8.7939e+00,  2.3807e-03,  1.2141e+01,  1.2755e-02,\n",
       "              1.2749e+01,  1.3885e+01,  2.5689e+00,  1.0825e-02, -3.3592e+00,\n",
       "              4.5894e+00,  3.1432e-03,  1.1745e+01,  5.9915e+00,  1.0885e-02,\n",
       "              1.3131e-03,  2.8635e-03,  5.6059e+00,  1.2343e+01, -6.3729e+00,\n",
       "              3.1539e-03,  9.8043e+00,  1.1898e+01,  5.4756e-03,  1.2530e-03,\n",
       "              6.4864e-04,  1.0713e+01,  4.6974e-03, -2.1309e+00,  5.2056e+00,\n",
       "             -1.4816e+00,  1.2824e+01,  3.0586e-03,  6.6120e-04,  9.5773e+00,\n",
       "              4.2653e-04, -6.9385e+00,  1.5194e+00], device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([1.0102e-06, 3.1407e-06, 1.5351e-07, 1.1477e-06, 6.4916e+01, 4.6893e-07,\n",
       "             9.6705e-05, 5.5038e+01, 8.2368e+00, 9.1438e-06, 4.9720e+00, 1.6161e-04,\n",
       "             4.3685e+01, 2.2051e+01, 2.3589e+01, 1.3568e-06, 4.5020e-06, 5.1451e+01,\n",
       "             8.3904e-05, 5.4208e-09, 3.7752e-07, 7.5500e+01, 4.4436e+01, 8.1364e-07,\n",
       "             3.5823e-06, 5.0550e-01, 2.0400e+01, 3.2353e-05, 3.3692e-06, 2.8499e+00,\n",
       "             3.5512e+01, 5.6323e-06, 1.4798e-04, 2.7229e+01, 3.5982e+01, 4.8061e+00,\n",
       "             7.5538e+00, 7.8475e-01, 1.0490e-05, 6.5108e+01, 1.4014e-05, 1.5034e+01,\n",
       "             1.3353e-04, 2.5445e+01, 2.4552e-05, 1.6813e+01, 6.0341e+01, 6.0284e+01,\n",
       "             4.2216e+01, 8.3318e+01, 1.1412e-04, 2.9229e+01, 1.2966e-04, 2.1452e-06,\n",
       "             1.5113e-06, 8.7830e-06, 1.0772e-04, 3.8182e-06, 3.2738e-06, 5.6280e+01,\n",
       "             1.7801e+01, 1.0218e-06, 3.3713e+01, 3.2184e-06, 1.7271e+00, 2.1711e+00,\n",
       "             4.0830e+01, 1.0195e-01, 1.0013e+00, 2.4129e+00, 1.6777e-06, 4.5047e-06,\n",
       "             3.7937e+01, 3.0978e+01, 2.4601e-06, 2.5534e+01, 1.2166e-05, 3.3663e-06,\n",
       "             5.4241e+01, 7.5596e+00, 3.5432e-06, 8.6070e+00, 6.2960e-05, 5.5410e-07,\n",
       "             2.1361e+01, 4.6951e-07, 5.5235e+01, 1.4224e-06, 3.5230e+01, 5.7756e+00,\n",
       "             4.5999e-05, 2.7231e+01, 2.4709e-06, 5.1856e+01, 2.8265e-05, 5.7207e+01,\n",
       "             6.7880e+01, 2.3256e+00, 2.7811e-05, 3.9759e+00, 7.4467e+00, 1.4926e-06,\n",
       "             4.8592e+01, 1.2634e+01, 2.1432e-05, 7.5435e-07, 3.5723e-06, 1.1060e+01,\n",
       "             5.3613e+01, 1.4247e+01, 4.3322e-06, 3.3858e+01, 4.9866e+01, 7.0859e-06,\n",
       "             6.8715e-07, 1.8558e-07, 4.0439e+01, 9.5995e-06, 1.6296e+00, 9.5448e+00,\n",
       "             7.7252e-01, 5.7912e+01, 4.0718e-06, 1.9216e-07, 3.2318e+01, 8.0915e-08,\n",
       "             1.7020e+01, 8.1157e-01], device='cuda:0')},\n",
       "    20: {'step': tensor(8.),\n",
       "     'exp_avg': tensor([[ 7.0794e-05, -2.9306e-04, -1.7375e-03,  ..., -1.1135e-03,\n",
       "               1.7457e-04, -4.2864e-04],\n",
       "             [ 2.4504e+00,  1.2981e-01,  2.4582e+00,  ..., -3.4070e+00,\n",
       "               1.6315e+02, -1.3735e-01],\n",
       "             [ 1.5352e-03,  5.8706e-03, -1.3375e-02,  ...,  2.6095e-03,\n",
       "               2.6263e-03,  1.5440e-03],\n",
       "             ...,\n",
       "             [ 1.4320e-02,  1.6044e-02, -1.1743e-03,  ..., -1.0129e-02,\n",
       "               7.5620e-03,  1.0659e-02],\n",
       "             [ 1.1633e-02,  1.0088e-02,  1.0459e-02,  ..., -1.8214e-02,\n",
       "               4.8262e-03,  8.3820e-03],\n",
       "             [ 5.6596e-03,  2.1320e-03,  7.7095e-03,  ..., -8.1324e-03,\n",
       "               5.1314e-04,  3.3746e-03]], device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([[2.5086e-09, 3.8620e-08, 1.3184e-06,  ..., 5.4330e-07, 1.4031e-08,\n",
       "              8.1707e-08],\n",
       "             [2.1753e+00, 4.3343e-03, 2.1752e+00,  ..., 4.1091e+00, 9.3598e+03,\n",
       "              5.9550e-03],\n",
       "             [1.0300e-06, 1.4987e-05, 7.7707e-05,  ..., 2.9676e-06, 3.0058e-06,\n",
       "              1.0419e-06],\n",
       "             ...,\n",
       "             [8.9074e-05, 1.1181e-04, 6.0388e-07,  ..., 4.4576e-05, 2.4857e-05,\n",
       "              4.9363e-05],\n",
       "             [5.8798e-05, 4.4224e-05, 4.7527e-05,  ..., 1.4409e-04, 1.0132e-05,\n",
       "              3.0535e-05],\n",
       "             [1.3930e-05, 1.9826e-06, 2.5835e-05,  ..., 2.8745e-05, 1.1616e-07,\n",
       "              4.9586e-06]], device='cuda:0')},\n",
       "    21: {'step': tensor(8.),\n",
       "     'exp_avg': tensor([ 4.6123e-04,  1.5374e+01,  9.5062e-03,  8.1253e+00,  7.5620e-03,\n",
       "              1.6697e-02,  4.0853e+00,  3.6042e-04,  5.3216e+00,  5.9423e-04,\n",
       "              2.6815e-02,  1.3469e+01,  1.7489e+01, -4.3828e-01,  1.3577e-02,\n",
       "              2.6617e+00,  1.6600e+01,  1.7518e-03,  1.9037e+01,  2.3065e-02,\n",
       "              3.3642e-03,  3.4781e-02,  6.1699e+00,  1.2483e+01,  1.1596e+01,\n",
       "              1.0654e+01,  1.1180e+01,  1.1859e-02,  1.0121e+01,  3.0649e-02,\n",
       "              1.9740e-02,  5.5780e-03], device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([9.4443e-08, 8.2892e+01, 3.9269e-05, 2.3267e+01, 2.4856e-05, 1.2109e-04,\n",
       "             5.8767e+00, 5.8032e-08, 9.9669e+00, 1.5598e-07, 3.1224e-04, 6.3881e+01,\n",
       "             1.0776e+02, 1.3462e-01, 8.0079e-05, 2.4954e+00, 9.7344e+01, 1.3401e-06,\n",
       "             1.2747e+02, 2.3103e-04, 4.9281e-06, 5.2527e-04, 1.3406e+01, 5.4740e+01,\n",
       "             4.7168e+01, 4.0088e+01, 4.3998e+01, 6.1103e-05, 3.6047e+01, 4.0789e-04,\n",
       "             1.6923e-04, 1.3531e-05], device='cuda:0')},\n",
       "    22: {'step': tensor(8.),\n",
       "     'exp_avg': tensor([[-4.4643e+00,  1.4971e+03,  4.2662e+00,  9.3569e+02, -1.3862e+00,\n",
       "              -5.2828e+00,  4.0074e+02,  4.1050e+00,  5.9217e+01, -8.1186e+00,\n",
       "              -6.9532e+00,  6.9119e+02,  5.3854e+02,  5.5461e+01, -6.6644e-01,\n",
       "               4.2693e+02,  6.4591e+02, -9.4273e-01,  1.3101e+03, -1.3301e+00,\n",
       "              -1.0534e+00, -8.1608e-01,  7.4730e+02,  1.4674e+03,  5.6223e+01,\n",
       "               1.0171e+03,  3.5726e+02,  3.8330e+00,  1.1757e+03, -4.9639e-01,\n",
       "               4.5960e+00, -1.7199e+00]], device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([[7.7133e+00, 7.8827e+05, 6.2444e+00, 3.0817e+05, 6.4154e-01, 1.0167e+01,\n",
       "              5.6592e+04, 6.2496e+00, 1.2402e+03, 2.3901e+01, 1.8870e+01, 1.6816e+05,\n",
       "              1.0197e+05, 1.5224e+03, 1.3927e-01, 6.4141e+04, 1.4701e+05, 3.0274e-01,\n",
       "              6.0391e+05, 6.4068e-01, 3.7735e-01, 3.0497e-01, 1.9659e+05, 7.5771e+05,\n",
       "              1.1021e+03, 3.6380e+05, 4.4869e+04, 6.2581e+00, 4.8642e+05, 1.4051e-01,\n",
       "              6.2497e+00, 1.2011e+00]], device='cuda:0')},\n",
       "    23: {'step': tensor(8.),\n",
       "     'exp_avg': tensor([25.3694], device='cuda:0'),\n",
       "     'exp_avg_sq': tensor([237.9591], device='cuda:0')}},\n",
       "   'param_groups': [{'lr': 0.050000000000000024,\n",
       "     'betas': (0.9, 0.999),\n",
       "     'eps': 1e-08,\n",
       "     'weight_decay': 0,\n",
       "     'amsgrad': False,\n",
       "     'maximize': False,\n",
       "     'foreach': None,\n",
       "     'capturable': False,\n",
       "     'differentiable': False,\n",
       "     'fused': None,\n",
       "     'initial_lr': 0.10000000000000005,\n",
       "     'params': [0,\n",
       "      1,\n",
       "      2,\n",
       "      3,\n",
       "      4,\n",
       "      5,\n",
       "      6,\n",
       "      7,\n",
       "      8,\n",
       "      9,\n",
       "      10,\n",
       "      11,\n",
       "      12,\n",
       "      13,\n",
       "      14,\n",
       "      15,\n",
       "      16,\n",
       "      17,\n",
       "      18,\n",
       "      19,\n",
       "      20,\n",
       "      21,\n",
       "      22,\n",
       "      23]}]}],\n",
       " 'lr_schedulers': [{'base_lrs': [0.10000000000000005],\n",
       "   'last_epoch': 2,\n",
       "   'verbose': False,\n",
       "   '_step_count': 3,\n",
       "   '_get_lr_called_within_step': False,\n",
       "   '_last_lr': [0.050000000000000024],\n",
       "   'lr_lambdas': [None]}],\n",
       " 'hparams_name': 'kwargs',\n",
       " 'hyper_parameters': {'config': Config(lr_max=0.1, l1_lambda=1e-05, num_nodes_choices=[30], sync_batchnorm=False, grace_period=5, gat_heads=[1, 2, 4, 8], lr_min=0.1, modality_choices=['plasma'], batch_size_choices=[8], num_nodes=30, precision='32-true', l1_lambda_max=1e-05, weight_decay=0, lr_scheduler_choices=['LambdaLR'], gat={'num_layers': 2, 'hidden_channels': 256, 'heads': 4, 'v2': True}, mutation_choices=[['GRN']], gpu_per_worker=1, accumulate_grad_batches=1, adj_thresh=0.1, sex=['M'], sex_choices=[['M']], reduction_factor=8, gcn_hidden_channels=[8, 32, 128], cpu_per_worker=16, gat_v4_heads=[[2, 3]], ray_results_dir='/scratch/lcornelis/outputs/ray_results', batch_size=8, gat_v4_fc_dim=[[64, 128, 128, 32]], dropout=0, nodes_count=1, pin_memory=True, gat_v4_fc_act=['relu'], gcn_num_layers=[2, 3, 4], dataset_name='ftd', ray_tmp_dir='/scratch/lcornelis/tmp', l1_lambda_min=1e-05, wgcna_minModuleSize=10, optimizer='Adam', wandb_api_key_path='wandb_api_key.txt', device=[0], lr=0.10000000000000005, gat_hidden_channels=[8, 32, 128, 256], checkpoint_every_n_epochs_train=1, model_grid_search=['gat-v4'], act_choices=['relu'], epochs=5, checkpoint_dir='/scratch/lcornelis/outputs/checkpoints', error_protein_file_name='bimodal_aptamers_for_removal.xlsx', num_workers=16, num_samples=1, num_to_keep=3, project='proteo', wandb_offline=False, gat_num_layers=[2, 4, 6, 12], gat_v4_fc_dropout=[0.1], wgcna_mergeCutHeight=0.25, modality='plasma', output_dir='/scratch/lcornelis/outputs', wandb_tmp_dir='/tmp', log_every_n_steps=10, act='relu', gcn={'num_layers': 3, 'hidden_channels': 32}, use_progress_bar=True, y_val='nfl', dropout_choices=[0], gat_v4_weight_initializer=['uniform'], gat_v4_hidden_channels=[[8, 16]], adj_thresh_choices=[0.1], gat-v4={'hidden_channels': [8, 16], 'heads': [2, 3], 'use_layer_norm': True, 'which_layer': ['layer1', 'layer2', 'layer3'], 'fc_dim': [64, 128, 128, 32], 'fc_dropout': 0.1, 'fc_act': 'relu', 'weight_initializer': 'uniform', 'num_layers': None}, lr_scheduler='LambdaLR', data_dir='/home/data/data_louisa', seed=19543, mutation=['GRN'], y_val_choices=['nfl'], raw_file_name='ALLFTD_dataset_for_nina_louisa_071124.csv', model='gat-v4', root_dir='/home/lcornelis/code/proteo', trainer_accelerator='gpu'),\n",
       "  'in_channels': 1,\n",
       "  'out_channels': 1,\n",
       "  'avg_node_degree': 0.9,\n",
       "  'pos_weight': 1.0,\n",
       "  'focal_loss_weight': [1.0]}}"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "checkpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load in train and test datasets using config\n",
    "# run model and get val_targets val_preds train_targets train_preds\n",
    "# find loss for each"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "proteo",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
